# Legal Landscape of LLM Training Data: Comprehensive Research Report

**Research Date:** January 16, 2026
**Status:** Active litigation and regulatory developments ongoing

---

## Executive Summary

The legal landscape surrounding AI training data is in active flux, with over 50 copyright lawsuits filed in the U.S. alone as of late 2025, creating what experts describe as "AI's war in the courtroom." Key findings include:

- **No consensus on fair use:** Courts have issued conflicting rulings on whether AI training constitutes fair use, with some finding it "spectacularly transformative" and others rejecting the defense entirely
- **Major settlements emerging:** Anthropic's $1.5 billion settlement with authors in 2025 represents the largest known copyright settlement in history
- **Regulatory divergence:** The EU mandates training data transparency (effective August 2025), Japan permits broad commercial use under Article 30-4, while the U.S. remains judicially fragmented with no federal legislation
- **Platform wars:** Reddit, Stack Overflow, and X have monetized their data through API restrictions and licensing deals worth hundreds of millions
- **Critical timeline:** No appellate court decisions on AI training fair use are expected before summer 2026, leaving fundamental legal questions unresolved

---

## 1. Active Lawsuits and Legal Cases

As of September 14, 2025, **50 copyright lawsuits** have been filed against AI companies in the U.S., with 47 currently pending after 3 voluntary dismissals. Three cases are on appeal. Most litigation is concentrated in the Northern District of California and Southern District of New York.

### 1.1 The New York Times vs. OpenAI & Microsoft

**Case Number:** 1:2023cv11195 (S.D.N.Y.)
**Filed:** December 27, 2023
**Status:** Active litigation, ongoing discovery disputes

**Claims:** The New York Times alleges OpenAI and Microsoft used millions of Times articles without permission to train GPT models and that ChatGPT reproduces Times content, creating a market substitute.

**Recent Developments:**
- **April 2025:** Judge Wang denied OpenAI's motions to dismiss direct infringement claims, contributory copyright infringement claims, and trademark dilution claims, allowing core claims to proceed
- **May 13, 2025:** Court issued sweeping preservation order directing OpenAI to "preserve and segregate all output log data that would otherwise be deleted on a going forward basis," regardless of user deletion requests or privacy regulations
- **June 26, 2025:** Judge Sidney Stein denied OpenAI's objections and affirmed the preservation order, raising significant privacy concerns
- **Late 2025:** Discovery disputes continue, with Times requesting 20 million ChatGPT chat log records from December 2022 to November 2024

**Expected Timeline:** No summary judgment on fair use expected until summer 2026 at earliest.

**Sources:**
- [OpenAI Response to NYT Lawsuit](https://openai.com/new-york-times/)
- [Harvard Law Review Analysis](https://harvardlawreview.org/blog/2024/04/nyt-v-openai-the-timess-about-face/)
- [Court Opinion April 2025](https://www.nysd.uscourts.gov/sites/default/files/2025-04/yf%2023cv11195%20OpenAI%20MTD%20opinion%20april%204%202025.pdf)

### 1.2 Getty Images vs. Stability AI

**UK Case Number:** HP-2023-000001
**US Case Number:** 1:23-cv-00135 (D. Del.)
**Filed:** UK: January 16, 2023; US: February 2, 2023
**Status:** UK case largely dismissed November 2025; US case stalled

**Claims:** Getty alleged Stability AI infringed more than 12 million photographs, their captions and metadata by training Stable Diffusion without authorization.

**UK Outcome (November 4, 2025):**
- Getty accepted that training and development of Stable Diffusion did not occur in the UK
- Getty abandoned primary copyright infringement and database right infringement claims shortly before closing submissions
- Court found limited trademark infringements for small number of examples in certain Stable Diffusion iterations
- Unable to determine infringements were widespread or continued beyond v2.x release
- **Overall:** Major victory for Stability AI, with only narrow trademark findings

**US Status:** Case remained stalled as of November 2024 with no major updates; Getty requested court order Stability to proceed with discovery after months of no response.

**Sources:**
- [BakerHostetler Case Summary](https://www.bakerlaw.com/getty-images-v-stability-ai/)
- [Taylor Wessing UK Analysis](https://www.taylorwessing.com/en/insights-and-events/insights/2025/07/getty-v-stability)
- [High Court Decision Analysis](https://www.lw.com/en/insights/getty-images-v-stability-ai-english-high-court-rejects-secondary-copyright-claim)

### 1.3 Sarah Silverman et al. vs. Meta & OpenAI

**Case Numbers:**
- Meta: 3:23-cv-03417 (N.D. Cal.)
- OpenAI: 3:23-cv-03416 (N.D. Cal.)

**Filed:** July 2023
**Status:** Partially dismissed; some claims proceeding

**Plaintiffs:** Comedian Sarah Silverman, authors Christopher Golden and Richard Kadrey

**Claims:** AI companies trained LLaMA (Meta) and ChatGPT (OpenAI) on copyrighted books without authorization, allegedly sourced from "shadow libraries" (pirate sites).

**Court Rulings:**

**Meta Lawsuit:**
- **November 2023:** Judge dismissed most claims, rejecting theory that Meta's AI system is itself an infringing derivative work
- **June 2025:** U.S. District Judge Vince Chhabria sided with Meta on fair use question, finding AI training on copyrighted works can be protected under fair use
- **Caveat:** Judge cautioned against interpreting ruling as blanket endorsement of the practice, noting authors' lawyers failed to advance certain favorable arguments

**OpenAI Lawsuit:**
- Court allowed Claim 1 (direct copyright infringement) and Claim 4 (unfair business practice) to proceed
- Dismissed all other claims with leave to file amended claims by March 13, 2024
- Case remains ongoing as of late 2024/early 2025

**Sources:**
- [CNN Coverage](https://www.cnn.com/2023/07/10/tech/sarah-silverman-openai-meta-lawsuit/index.html)
- [Hollywood Reporter Analysis](https://www.hollywoodreporter.com/business/business-news/sarah-silverman-loses-key-issue-ai-lawsuit-against-meta-1236299919/)
- [Music Business Worldwide Update](https://www.musicbusinessworldwide.com/sarah-silvermans-meta-copyright-lawsuit-advances-as-judge-allows-authors-dmca-claims/)

### 1.4 Authors Guild vs. OpenAI & Microsoft

**Case Number:** 1:23-cv-08292 (S.D.N.Y.)
**Filed:** September 19, 2023 (Microsoft added December 4, 2023)
**Status:** Active; discovery and motion practice continuing

**Plaintiffs:** Authors Guild and 17 prominent authors including George R.R. Martin, John Grisham, David Baldacci, Jodi Picoult, Jonathan Franzen, and others

**Claims:** OpenAI used authors' copyrighted books without permission to train GPT models. Microsoft added as defendant due to collaboration with OpenAI and integration into Bing, Microsoft Copilot, and related products.

**Recent Ruling (October 28, 2024):**
- U.S. District Judge Sidney Stein ruled authors may be able to prove ChatGPT's outputs are similar enough to their works to violate book copyrights
- Significant procedural victory allowing case to proceed

**Current Status:** Remains active before Judge Stein with ongoing discovery as of late 2025.

**Sources:**
- [Authors Guild Case Overview](https://authorsguild.org/news/ai-class-action-lawsuits/)
- [Publishers Weekly Coverage](https://www.publishersweekly.com/pw/by-topic/digital/copyright/article/98961-authors-class-action-lawsuit-against-openai-moves-forward.html)
- [Forensis Group Legal Analysis](https://www.forensisgroup.com/resources/expert-legal-witness-blog/authors-guild-et-al-v-open-ai-inc-2023-present-artificial-intelligence-ai-copyright-lawsuit-and-legal-implications-for-creative-works)

### 1.5 Bartz et al. vs. Anthropic (SETTLED)

**Case Number:** 3:23-cv-04654 (N.D. Cal.)
**Filed:** 2023
**Status:** **SETTLED** - September 2025

**Plaintiffs:** Nonfiction authors Charles Graeber and Kirk Wallace Johnson, thriller author Andrea Bartz

**Claims:** Anthropic used books without permission to train Claude AI models.

**Key Ruling Before Settlement (June 2025):**
- Senior U.S. District Judge William Alsup ruled training use was fair use, stating "The training use was a fair use"
- **However:** Denied Anthropic's summary judgment on piracy issue, finding piracy was not fair use
- Court described use as "spectacularly transformative"

**Settlement Terms (September 25, 2025):**
- **Settlement Amount:** Approximately **$1.15 billion** paid in four installments
- Preliminarily approved by Judge Alsup on September 25, 2025
- Authors compensated approximately **$3,000 per book** for estimated 500,000 books covered
- **Described as:** Largest known copyright settlement in history

**Significance:** First major AI copyright case to settle; establishes precedent that pirated sources prevent fair use defense even if training itself is transformative.

**Sources:**
- [NPR Settlement Coverage](https://www.npr.org/2025/09/05/nx-s1-5529404/anthropic-settlement-authors-copyright-ai)
- [NPR Pre-Settlement Ruling](https://www.npr.org/2025/06/25/nx-s1-5445242/federal-rules-in-ai-companys-favor-in-landmark-copyright-infringement-lawsuit-authors-bartz-graeber-wallace-johnson-anthropic)
- [Authors Guild Settlement Explanation](https://authorsguild.org/advocacy/artificial-intelligence/what-authors-need-to-know-about-the-anthropic-settlement/)

### 1.6 RIAA (Music Labels) vs. Suno & Udio

**Case Numbers:**
- Suno: 1:24-cv-11586 (D. Mass.)
- Udio: 1:24-cv-05009 (S.D.N.Y.)

**Filed:** June 2024
**Plaintiffs:** Sony Music Entertainment, UMG Recordings, Warner Records (via RIAA)
**Status:** Udio settled; Suno ongoing

**Claims:** Mass copyright infringement based on unauthorized training of AI music models on copyrighted recordings. RIAA amended complaints to allege both companies sourced music via "stream-ripping" from YouTube.

**Company Responses (August 2024):**
- Both Suno and Udio acknowledged training on copyrighted recordings
- Argued use falls under fair use protections

**Settlements:**

**Udio (October-November 2025):**
- Settled with Universal Music Group and Warner Music
- Terms remain confidential
- UMG and Udio announced plans to collaborate on new AI-music service together

**Suno:**
- **November 2025:** Warner Music Group announced settlement with Suno
- Suno will launch entirely new model in 2026 with "more advanced and licensed models"
- Current models to be phased out
- Sony has not settled; case ongoing against Suno

**Significance:** First music industry copyright cases against AI companies; demonstrates willingness to settle when proper licensing mechanisms established.

**Sources:**
- [RIAA Lawsuit Announcement](https://www.riaa.com/record-companies-bring-landmark-cases-for-responsible-ai-againstsuno-and-udio-in-boston-and-new-york-federal-courts-respectively/)
- [UMG-Udio Settlement](https://musically.com/2025/10/30/umg-settles-udio-lawsuit-companies-plan-new-ai-music-service-together/)
- [Music Business Worldwide Analysis](https://www.musicbusinessworldwide.com/suno-argues-none-of-the-millions-of-tracks-made-on-its-platform-contain-anything-like-a-sample/)

### 1.7 Music Publishers vs. Anthropic

**Case Number:** 3:23-cv-01092 (M.D. Tenn.)
**Filed:** 2023
**Plaintiffs:** Universal Music Group, Concord Music Group, ABKCO, and other publishers
**Status:** Ongoing with limited procedural agreement

**Claims:** Copyright infringement for training Claude on lyrics from at least 500 songs from artists including Katy Perry, the Rolling Stones, and Beyoncé. First lawsuit by music publisher against AI firm over lyrics in LLM.

**Developments:**

**January 2025:**
- U.S. District Judge Eumi Lee approved agreement mandating Anthropic maintain guardrails preventing Claude from:
  - Providing lyrics to songs owned by publishers
  - Creating new song lyrics based on copyrighted material
- **Important:** Agreement addresses only guardrails, not underlying copyright infringement claims
- Lawsuit continues

**March 2025:**
- Judge denied publishers' motion for injunction to stop Anthropic from using song lyrics for training

**May 2025:**
- Publishers filed amended complaint alleging Anthropic's guardrails remain ineffective
- November 2024 testing showed latest Claude versions continued generating unauthorized lyrics copies when accessing via Anthropic's partners
- Over one year after initial lawsuit filing, violations continued

**Current Status:** Lawsuit remains active; core infringement claims unresolved.

**Sources:**
- [Hollywood Reporter Coverage](https://www.hollywoodreporter.com/business/business-news/anthropic-enforce-copyright-guardrails-ai-tools-1236098152/)
- [Music Business Worldwide Amended Complaint](https://www.musicbusinessworldwide.com/music-publishers-file-amended-lawsuit-against-ai-firm-anthropic-which-they-say-bolsters-the-case-over-companys-unauthorized-use-of-song-lyrics/)
- [TechPolicy.Press Analysis](https://www.techpolicy.press/analysis-what-anthropics-deal-with-music-publishers-does-and-doesnt-do/)

### 1.8 Andersen et al. vs. Stability AI, Midjourney, DeviantArt

**Case Number:** 3:23-cv-00201 (N.D. Cal.)
**Filed:** January 13, 2023
**Plaintiffs:** Illustrators Sarah Andersen, Kelly McKernan, Karla Ortiz; additional plaintiffs include Gerald Brom, Greg Rutkowski, Gregory Manchess, Julia Kaye, Hawke Southworth, Adam Ellis, photographer Jingna Zhang
**Status:** Active; significant motion to dismiss denied

**Claims:** Companies infringe copyrights by unlawfully storing and using artists' works to train AI image generation systems. Alleges training dataset LAION built by scraping billions of images from internet including stock photo sites (Shutterstock, Getty Images), platforms (Pinterest, Flickr, Tumblr).

**Key Rulings:**

**May 2024:**
- Judge William Orrick made tentative ruling allowing direct and induced infringement claims to proceed
- Found artists plausibly claimed copies of their work stored in various tool versions

**August 12, 2024:**
- Judge Orrick denied Stability AI and Midjourney's motion to dismiss copyright infringement claims
- Found artists reasonably argued companies violate rights by illegally storing work
- Ruled Stable Diffusion may have been built "to a significant extent on copyrighted works" and "created to facilitate that infringement by design"
- **Dismissed:** Unjust enrichment and breach of contract claims
- **Allowed to proceed:** Copyright infringement claims moving toward discovery

**Significance:** Major procedural win for visual artists; case now in discovery phase with potential to establish standards for image generation AI.

**Sources:**
- [Artnet Coverage](https://news.artnet.com/art-world/artists-vs-stability-ai-lawsuit-moves-ahead-2524849)
- [Hollywood Reporter Analysis](https://www.hollywoodreporter.com/business/business-news/artist-lawsuit-ai-midjourney-art-1235821096/)
- [Class Action Details](https://zhangjingna.com/blog/class-action-lawsuit-artists-v-stability-deviantart-midjourney-runway-ai)

### 1.9 Thomson Reuters vs. ROSS Intelligence (FIRST MAJOR FAIR USE RULING)

**Case Number:** 1:20-cv-00613 (D. Del.)
**Filed:** 2020
**Status:** On appeal to Third Circuit; district court granted partial summary judgment to Thomson Reuters

**Claims:** ROSS Intelligence unlawfully used Westlaw's proprietary headnotes (summaries of key legal points) to train AI-powered legal search engine designed to compete directly with Westlaw.

**Background:**
- ROSS sought to license Westlaw content but Thomson Reuters refused due to direct competition
- ROSS obtained training data via LegalEase company's "Bulk Memos"
- Used data to train AI search tool

**District Court Ruling (February 11, 2025):**
- Judge Stephanos Bibas (Third Circuit, sitting by designation) granted partial summary judgment to Thomson Reuters
- **Historic significance:** First U.S. court to reach conclusion on fair use doctrine application to AI training data
- Found ROSS infringed 2,243 Westlaw headnotes
- **Rejected fair use defense**

**Fair Use Analysis:**
- Fourth factor (market effect) deemed "single most important element" weighed decisively for Thomson Reuters
- ROSS's product intended as "market substitute" for Westlaw
- Could adversely impact potential derivative market for Thomson Reuters to license headnotes as AI training data

**Important Context:**
- Ruling addresses **non-generative AI** use
- ROSS's AI did not create new content; used existing content to provide relevant judicial opinions

**Appeal Status (June 17, 2025):**
- Third Circuit accepted interlocutory appeal
- Will be **first appellate court** to weigh in on fair use principles applied to AI-generated commercial products
- Question: Whether ROSS made "transformative use" by incorporating headnotes into AI training module

**Significance:** Critical because it's the only fair use ruling to reject AI training defense; all others have found training transformative. Appeal outcome will provide first circuit-level guidance.

**Sources:**
- [Reed Smith Analysis](https://www.reedsmith.com/en/perspectives/2025/03/court-ai-fair-use-thomson-reuters-enterprise-gmbh-ross-intelligence)
- [Jenner & Block Alert](https://www.jenner.com/en/news-insights/publications/client-alert-court-decides-that-use-of-copyrighted-works-in-ai-training-is-not-fair-use-thomson-reuters-enterprise-centre-gmbh-v-ross-intelligence-inc)
- [District Court Opinion](https://www.ded.uscourts.gov/sites/ded/files/opinions/20-613_5.pdf)

### 1.10 Doe et al. vs. GitHub, Microsoft, OpenAI (GitHub Copilot)

**Case Number:** 3:22-cv-06823 (N.D. Cal.)
**Filed:** November 3, 2022
**Plaintiffs:** Open-source programmers (class action)
**Status:** Partially dismissed; appeal accepted by Ninth Circuit December 2024; district proceedings stayed

**Claims:** GitHub, Microsoft, and OpenAI violated rights of creators who posted code under open-source licenses (MIT, GPL, Apache, etc.) by training Copilot AI on public GitHub repositories without proper attribution or compliance with license terms.

**District Court Ruling (2024):**
- Court dismissed most claims
- **Allowed to proceed:** Breach-of-license and contract claims
- **Dismissed:** Pure intellectual property claims

**Ninth Circuit Appeal (December 2024):**
- Ninth Circuit accepted appeal (case № 24-6136)
- **Key question:** Whether DMCA § 1202(b) applies to AI-generated outputs that are not exact copies but may be derivative works
- District court proceedings stayed pending appeal outcome

**Significance:** Critical test case for open-source licensing in AI context; Ninth Circuit ruling will provide first appellate guidance on whether license violations during training constitute actionable harms.

**Sources:**
- [Joseph Saveri Law Firm Case Page](https://www.saverilawfirm.com/our-cases/github-copilot-intellectual-property-litigation)
- [BakerHostetler Analysis](https://www.bakerlaw.com/the-copilot-litigation/)
- [InfoWorld Coverage](https://www.infoworld.com/article/2515112/judge-dismisses-lawsuit-over-github-copilot-ai-coding-assistant.html)

### 1.11 Newspaper Publishers vs. AI Companies (Multiple Cases)

**Various Cases Filed 2024-2025:**

#### Eight Publishers vs. Microsoft & OpenAI
- **Filed:** April 30, 2024 (S.D.N.Y.)
- **Plaintiffs:** Eight U.S. newspaper publishers
- **Claims:** Companies "purloining millions of publishers' copyrighted articles without permission and without payment"

#### Advance Local Media et al. vs. Cohere Inc.
- **Filed:** February 2025
- **Plaintiffs:** Fourteen major publishers including Forbes, Condé Nast, Los Angeles Times, The Atlantic
- **Claims:** Cohere reproduces substantial portions of works, sometimes near-verbatim, while bypassing paywalls

#### New York Times vs. Perplexity AI
- **Case Number:** S.D.N.Y. (2025)
- **Filed:** December 5, 2025
- **Claims:**
  - "Large-scale, unlawful copying and distribution" of millions of NYT articles
  - Perplexity intentionally ignored Robots Exclusion Protocol (robots.txt)
  - Circumvented "hard-block" implemented by newspaper
  - Made over 175,000 site access attempts in August 2025 alone
  - Generated responses "identical or substantially similar" to Times content (verbatim/near-verbatim reproductions, summaries, abridgements)

#### Chicago Tribune vs. Perplexity AI
- **Filed:** December 2025
- **Claims:** Similar to NYT; also accuses Perplexity of distributing fabricated content ("hallucinations") next to Tribune trademark

#### Japanese Publishers vs. Perplexity AI
- **Filed:** August 2025
- **Plaintiffs:** Nikkei, Asahi Shimbun (two of Japan's largest media groups)
- **Claims:** Copying and storing article content; ignoring technical measures preventing scraping

#### Other Plaintiffs vs. Perplexity
- News Corp (Wall Street Journal, Barron's, New York Post)
- Encyclopedia Britannica
- Merriam-Webster
- Reddit

**Perplexity's Response:** "Publishers have been suing new tech companies for a hundred years, starting with radio, TV, the internet, social media and now AI. Fortunately it's never worked, or we'd all be talking about this by telegraph." —Jesse Dwyer, Perplexity Head of Communication

**Industry Context:** Approximately 20 lawsuits from media companies vs. AI firms as of late 2025, contrasted with over 100 licensing deals where media companies receive payment through licensing or revenue sharing.

**Sources:**
- [NPR Analysis](https://www.npr.org/2025/12/10/nx-s1-5637429/why-news-organizations-are-suing-ai-companies-and-what-they-hope-to-win)
- [CNBC Coverage](https://www.cnbc.com/2024/04/30/eight-newspaper-publishers-sue-openai-over-copyright-infringement.html)
- [NYT Lawsuit Details](https://www.cnbc.com/2025/12/05/the-new-york-times-perplexity-copyright.html)
- [Chicago Tribune Lawsuit](https://www.axios.com/local/chicago/2025/12/15/chicago-tribune-perplexity-ai-copyright-lawsuit-newspapers)

### 1.12 Additional Notable Cases

**Disney & Universal vs. Midjourney**
- **Filed:** June 2025
- **Claims:** Image generator copyright infringement

**Hendrix vs. Apple**
- **Filed:** October 2025
- **Claims:** Apple Intelligence technology copyright infringement

**Encyclopaedia Britannica vs. Perplexity AI**
- **Filed:** 2025
- **Claims:** Copyright infringement of encyclopedia content

**Warner Brothers vs. Midjourney**
- **Filed:** 2025
- **Claims:** Copyright infringement via image generation

**Author vs. Adobe**
- **Filed:** December 2024 (Oregon author)
- **Claims:** Adobe used pirated books to train AI models

**GEMA vs. OpenAI (Germany)**
- **Filed:** 2024
- **Ruling:** November 2024 - Munich Regional Court ruled OpenAI violated German copyright laws
- **Plaintiff:** GEMA (German music rights organization representing 100,000+ composers, songwriters, publishers)
- **Significance:** First major adverse ruling against OpenAI in Europe

**Kneschke vs. LAION (Germany)**
- **Status:** German courts confirmed TDM exception in Article 4 DSM Directive applies to AI training
- **Significance:** European legal precedent supporting AI training under TDM exceptions

**Sources:**
- [Copyright Alliance 2025 Review](https://copyrightalliance.org/ai-copyright-lawsuit-developments-2025/)
- [Sustainable Tech Partner Timeline](https://sustainabletechpartner.com/topics/ai/generative-ai-lawsuit-timeline/)
- [McKool Smith Tracker](https://www.mckoolsmith.com/newsroom-ailitigation)

### 1.13 Settled Cases Summary

**Confirmed Settlements:**
1. **Bartz v. Anthropic** - $1.5 billion (September 2025)
2. **Warner Music Group v. Udio** - Terms confidential (October-November 2025)
3. **Warner Music Group v. Suno** - Terms confidential; new licensed model in 2026 (November 2025)
4. **Vacker v. ElevenLabs** - Terms confidential (2025)
5. **Planner 5D v. Facebook** - Terms confidential (2025)

**Settlement Negotiations:**
- Over a dozen centralized cases in **In re OpenAI** litigation have ongoing settlement discussions

**Sources:**
- [AI Lawsuit Tracker](https://chatgptiseatingtheworld.com/2025/10/08/status-of-all-51-copyright-lawsuits-v-ai-oct-8-2025-no-more-decisions-on-fair-use-in-2025/)
- [Copyright Alliance Settlements](https://copyrightalliance.org/ai-copyright-lawsuit-developments-2025/)

---

## 2. Legal Grey Areas

### 2.1 Fair Use Doctrine Application to AI Training

**The Central Tension:**

Courts and the Copyright Office recognize AI training presents unprecedented fair use challenges: training is **highly transformative** (favoring fair use) yet potentially **highly dilutive of markets** for original works (favoring infringement). No technology has previously exhibited both characteristics simultaneously.

**Four-Factor Fair Use Analysis:**

**Factor 1: Purpose and Character of Use (Transformative Nature)**

*Pro-AI Position:*
- Courts have found AI training "spectacularly transformative" [Bartz v. Anthropic, June 2025]
- Training extracts statistical patterns and relationships, not expressive content for consumption
- Purpose fundamentally different from original works' purpose (books exist to be read; AI training extracts patterns to power text generator)

*Anti-AI Position:*
- Copyright Office Report (May 2025): Use of copyrighted works to train AI is NOT "inherently transformative"
- Where models trained to produce content "sharing the purpose of appealing to a particular audience," use is "at best, modestly transformative"
- Models absorb "the essence of linguistic expression," not mere facts

**Factor 2: Nature of Copyrighted Work**

- Generally weighs neutrally in AI cases
- Creative works (novels, music, art) receive stronger protection than factual compilations
- Most AI lawsuits involve highly creative works, favoring plaintiffs

**Factor 3: Amount and Substantiality of Portion Used**

*AI Company Position:*
- Entire works necessary for effective training
- Bartz court found copying entire books "reasonably necessary" to train Claude

*Copyright Owner Position:*
- Wholesale copying of millions of works goes beyond what's necessary
- Could use smaller, licensed datasets

**Factor 4: Effect on Market for Original Work**

*Most contested and potentially dispositive factor*

**Pro-Copyright Position (Thomson Reuters v. ROSS):**
- Fourth factor is "single most important element of fair use"
- AI products serve as "market substitute" for original works
- Harms potential derivative licensing market for AI training
- **Result:** Fair use rejected

**Pro-Copyright Position (Kadrey v. Meta):**
- "Market dilution" concern: AI-generated works could "flood the market" and "crowd out many authors"
- Even if individual outputs differ, aggregate effect could significantly harm market
- Judge Chhabria endorsed "indirect market substitution" theory

**Pro-AI Position (Bartz v. Anthropic):**
- Claude does not create outputs that "displace demand" for original books
- Training use doesn't harm market for books themselves
- Outputs sufficiently different from inputs

**Copyright Office Position (May 2025):**
- Availability of licensing is relevant consideration
- Copying from pirated sources to generate unrestricted content competing in marketplace, when licensing reasonably available, unlikely to be fair use

### 2.2 The Piracy Distinction

**Emerging Legal Principle:** Courts distinguish between training on **lawfully obtained** vs. **pirated** copyrighted works.

**Bartz v. Anthropic (June 2025):**
- Court found training itself "spectacularly transformative" = fair use
- **But:** Using or retaining "pirated" (unauthorized) copies for ANY purpose, including training, **prevents fair use defense**
- This holding became basis for $1.5 billion settlement

**Kadrey v. Meta (June 2025):**
- More lenient standard
- Rejected argument that downloading from unauthorized sources alone precludes fair use
- Found no evidence Meta's actions supported shadow libraries' unlawful activities
- Training still "highly transformative" despite pirated sources

**Practical Impact:**
- AI companies now emphasize lawful data acquisition
- Settlement in Bartz suggests industry acknowledges piracy risk
- Unclear whether "knowledge of piracy" vs. "direct support of piracy" matters

### 2.3 Text and Data Mining (TDM) Exceptions by Jurisdiction

**European Union:**

*Legal Framework:*
- Digital Single Market Directive (2019/790) Articles 3 and 4
- **Article 3:** Allows research organizations and cultural heritage institutions to perform TDM for scientific research
- **Article 4:** Broader exception permits TDM by anyone (including commercial entities) PROVIDED rightsholders have not expressly reserved rights via opt-out mechanism

*Recent Developments:*
- German courts (GEMA v. OpenAI, Kneschke v. LAION) confirmed Article 4 applies to AI training
- AI Act Article 53(1)(c) obliges providers to respect copyright and opt-out declarations

*Challenges:*
- Opt-out mechanism renders Article 4 potentially "unworkable" for AI training requiring large, diverse datasets
- Courts requiring clear, specific, technically proper opt-out mechanisms
- General or ambiguous declarations likely insufficient
- Exact technical standards still in dispute

**United Kingdom:**

*Current Law:*
- TDM exception only for non-commercial scientific research
- Does NOT permit commercial AI training

*Proposed Reform (2024-2025):*
- December 17, 2024: UK Government announced consultation on EU-style broad TDM exception for AI training
- Consultation closed February 25, 2025
- Proposed opt-out model similar to EU Article 4
- Over 11,500 responses received
- Government must publish report and economic impact assessment by March 18, 2026

*Government Objectives:*
1. **Control:** Rightsholders should control and license content
2. **Access:** AI developers should access large content volumes lawfully
3. **Transparency:** Greater clarity about works used in training

**Japan:**

*Legal Framework:*
- Copyright Act Article 30-4(ii) permits uses of works "in data analysis"
- **No limitation** to non-commercial or scientific research
- One of world's most permissive regimes for AI training

*Key Provisions:*
- Allows exploitation "in any way and to the extent necessary"
- When "it is not a person's purpose to personally enjoy or cause another person to enjoy the thoughts or sentiments expressed in that work"

*Limitations:*
- **Non-enjoyment requirement:** Distinction between "information analysis" (allowed) vs. "purpose of enjoyment of thoughts/sentiments" (not allowed)
- Exploitation must not "unreasonably prejudice interests of copyright owner"
- **Output restrictions:** Prohibited if intention is to output products perceived as creative expressions of copyrighted works, including mimicking specific creator styles

*Government Position:*
- Copyright Office guidance: Article 30-4 exception for "non-enjoyment use" generally does not harm economic interests of copyright owners
- Permissive stance attracts AI development to Japan

### 2.4 The "Transformative Use" Debate

**Core Question:** Is creating an AI model from copyrighted works "transformative" when the model can generate similar content?

**Pro-Transformative Arguments:**

1. **Purpose Shift:** Training extracts patterns/statistics, not expressive content for human enjoyment [Bartz, Kadrey]
2. **Intermediate Copying:** Works copied as intermediate step to create entirely new technology
3. **Analogy to Human Learning:** AI learns patterns similarly to human reading/learning (though Copyright Office rejects this analogy)

**Anti-Transformative Arguments:**

1. **Output Similarity:** Models sometimes generate substantially similar outputs to training data
2. **Market Competition:** AI-generated content competes with original works in same markets
3. **Absorption of Expression:** Copyright Office: Models absorb "essence of linguistic expression," not just facts
4. **Purpose Overlap:** Where model produces content "appealing to particular audience" like original, only "modestly transformative"

**Copyright Office Spectrum (May 2025):**

*Likely Fair Use:*
- Noncommercial research
- Does not enable reproducing portions of works in outputs
- Analytical purposes

*Unlikely Fair Use:*
- Copying expressive works from pirate sources
- Generating unrestricted content competing in marketplace
- When licensing reasonably available

*"Matter of Degree":*
- Transformativeness depends on model functionality and deployment
- No bright-line rule; case-by-case analysis required

### 2.5 Mass Reproduction vs. Learning Distinction

**AI Company Framing:** AI training is "learning," analogous to human reading/education

**Copyright Owner Framing:** AI training is "mass reproduction" of copyrighted works for commercial exploitation

**Copyright Office Rejection of Learning Analogy (May 2025):**
- "The analogy to human learning rests on the faulty premise that fair use is a defense for all acts if those acts are performed for the purpose of learning"
- Humans don't create permanent copies during learning; AI systems do
- Scale vastly different (millions of works vs. individual human consumption)

**Technical Reality:**
- Training requires creating copies (reproductions) of works
- Copies stored temporarily or permanently during training
- Model weights arguably contain compressed representations of training data

**Legal Question:** Does the **purpose** (learning patterns) excuse the **method** (mass reproduction)?

**Current Status:**
- Courts split on whether reproduction for learning purposes is transformative enough
- Thomson Reuters v. ROSS: Rejected fair use
- Bartz v. Anthropic: Accepted fair use for training (but not for pirated copies)
- Kadrey v. Meta: Accepted fair use, but concerned about market harm

### 2.6 Output Similarity to Training Data Issues

**The Memorization Problem:**

**Technical Evidence:**
- Evaluations show LLMs memorize 1-7% of training data depending on model and definition of "memorization"
- GPT-2 series models: Over 1% exact duplicates, up to ~7% including near-matches

**Legal Standard:**
- Copyright infringement requires:
  1. **Access** to copyrighted work (presumed if in training data)
  2. **Substantial similarity** between output and original

**Recent Court Rulings:**

**Authors Guild v. OpenAI (October 2024):**
- Judge Sidney Stein ruled authors may be able to prove ChatGPT outputs are similar enough to violate book copyrights
- Allows case to proceed to discovery on similarity question

**GEMA v. OpenAI (Germany, November 2025):**
- Munich Regional Court held memorization and reproduction of copyrighted song lyrics by LLMs violated copyright law
- Prohibited memorization in AI models

**Copyright Office Position (May 2025):**
- Where generated outputs substantially similar to inputs, "strong argument" that model weights implicate reproduction and derivative work rights of original works
- **Contested:** Model developers argue models are "strings of numbers" that cannot be infringing copies
- **Counter-argument:** Ability to generate substantially similar outputs is evidence weights constitute copies

**Practical Implications:**
- AI companies implementing "guardrails" to prevent verbatim reproduction
- Music publishers' amended complaint against Anthropic (May 2025): Guardrails continue failing to prevent lyric reproduction
- Question remains whether technical measures sufficient to avoid liability

**Unresolved Questions:**
1. What degree of similarity constitutes infringement?
2. Are model weights themselves infringing derivative works?
3. Do effective guardrails prevent liability even if model capable of infringing outputs?
4. Is probabilistic generation of occasional similar outputs different from deterministic reproduction?

**Sources for Section 2:**
- [Copyright Office Report May 2025](https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-3-Generative-AI-Training-Report-Pre-Publication-Version.pdf)
- [Reed Smith Fair Use Analysis](https://www.reedsmith.com/en/perspectives/2025/07/a-new-look-fair-use-anthropic-meta-copyright-ai-training)
- [IPWatchdog Three Key Decisions](https://ipwatchdog.com/2025/12/23/copyright-ai-collide-three-key-decisions-ai-training-copyrighted-content-2025/)
- [Jones Day Analysis](https://www.jonesday.com/en/insights/2025/06/two-us-courts-address-fair-use-in-genai-training-cases)
- [TechnoLlama EU TDM](https://www.technollama.co.uk/we-need-to-talk-about-the-eu-tdm-exception-and-ai-training)

---

## 3. Regulatory Landscape

### 3.1 European Union: AI Act Training Data Requirements

**Legal Framework:**

**EU AI Act (Regulation 2024/1689)**
- Entered into force: August 1, 2024
- Training data transparency requirements: Effective August 2, 2025
- Full enforcement begins: August 2, 2026

**Key Requirements for General-Purpose AI (GPAI) Models:**

**1. Mandatory Training Data Summary (Article 53(1)(d))**

*What Must Be Disclosed:*
- Provider and model identification
- Training data modalities and sizes
- Lists of data sources:
  - Public datasets
  - Licensed private data
  - Web-scraped content
  - User data
  - Synthetic data generation details
- Data processing measures:
  - Respect for copyright reservations
  - Steps to remove illegal content
  - Copyright opt-out compliance

*Mandatory Template:*
- European Commission published mandatory template July 24, 2025
- All GPAI providers must use standardized template
- Public disclosure required

**2. Implementation Timeline:**

- **August 2, 2025:** Requirement effective for new models
- **August 2, 2027:** Deadline for models placed on market before August 2, 2025
- **August 2, 2026:** AI Office may verify compliance and issue corrective measures

**3. Penalties:**

- Up to **€15 million** OR
- **3% of global annual revenue**
- Whichever is greater

**4. Copyright Integration (Article 53(1)(c)):**

- Providers must respect copyright and related rights
- Must comply with opt-out declarations under DSM Directive Article 4
- Transparency requirements support copyright enforcement

**Purpose:**

- Help providers fulfill disclosure obligations
- Support enforcement of copyright and data protection law
- Provide transparency for rightsholders and public
- Enable verification of lawful data sourcing

**Significance:**

- Most comprehensive AI training data transparency requirement globally
- Creates audit trail for copyright compliance
- Potential model for other jurisdictions

**Sources:**
- [WilmerHale EU Template Analysis](https://www.wilmerhale.com/en/insights/blogs/wilmerhale-privacy-and-cybersecurity-law/european-commission-releases-mandatory-template-for-public-disclosure-of-ai-training-data)
- [Securiti EU Template Coverage](https://securiti.ai/eu-publishes-template-for-public-summaries-of-ai-training-content/)
- [Skadden GPAI Obligations](https://www.skadden.com/insights/publications/2025/08/eus-general-purpose-ai-obligations)
- [Jones Day Code of Practice](https://www.jonesday.com/en/insights/2025/02/european-commissions-ai-code-of-practice-and-training-data-template)

### 3.2 United States: Copyright Office Position

**Copyright and Artificial Intelligence Report Series:**

**Part 1: Digital Replicas**
- Published: July 31, 2024
- Focus: AI-generated replicas of individuals

**Part 2: Copyrightability of AI-Generated Outputs**
- Published: January 29, 2025
- Focus: Whether AI-generated content can be copyrighted

**Part 3: Generative AI Training** (MOST RELEVANT)
- Published: May 9, 2025
- Status: "Pre-publication" form
- Released one day after dismissal of Librarian of Congress
- Released one day before dismissal of Register of Copyrights
- Unusual circumstances raise questions about report's authoritative status

**Key Positions from Part 3:**

**1. No Blanket Fair Use:**

"The availability of the fair use defense should turn on the specific facts of each case, with the Office expecting that some uses of copyrighted works for generative AI training will qualify as fair use, and some will not."

**2. Spectrum of Uses:**

*Likely Fair Use:*
- Noncommercial research or analysis
- Does not enable reproducing portions of works in outputs

*Unlikely Fair Use:*
- Copying expressive works from pirate sources
- Generating unrestricted content competing in marketplace
- When licensing reasonably available

**3. Infringement Concerns:**

- Using copyrighted works to train AI models may constitute **prima facie infringement** of reproduction right
- Where outputs substantially similar to training data inputs, "strong argument" that model weights infringe reproduction and derivative work rights

**4. Rejected Arguments:**

*"Inherently Transformative" Argument:*
- Rejected claim that AI training is inherently transformative because not for expressive purposes
- Reasoning: Models absorb "essence of linguistic expression"

*"Human Learning" Analogy:*
- "The analogy to human learning rests on the faulty premise that fair use is a defense for all acts if those acts are performed for the purpose of learning"

**5. Transformativeness as "Matter of Degree":**

- Depends on model functionality and deployment
- Where model trained to produce content "sharing purpose of appealing to particular audience," use is "at best, modestly transformative"

**Congressional Action:**

- No federal AI training legislation enacted as of January 2026
- Various bills proposed but none passed
- Congressional Research Service monitoring issue

**Practical Impact:**

- Copyright Office report provides guidance but lacks force of law
- Courts not bound by Copyright Office positions
- Report influential in ongoing litigation
- Unusual release circumstances (pre-publication, leadership dismissals) may affect weight courts give to analysis

**Sources:**
- [Copyright Office AI Study Page](https://www.copyright.gov/ai/)
- [Part 3 Report PDF](https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-3-Generative-AI-Training-Report-Pre-Publication-Version.pdf)
- [Skadden Analysis](https://www.skadden.com/insights/publications/2025/05/copyright-office-report)
- [Authors Guild Summary](https://authorsguild.org/news/us-copyright-office-ai-report-part-3-what-authors-should-know/)

### 3.3 United Kingdom: Proposed Opt-Out Model

**Current Law:**

- TDM exception exists only for non-commercial scientific research
- Commercial AI training NOT permitted under current copyright law

**Government Consultation (December 2024 - February 2025):**

**Consultation Period:**
- Opened: December 17, 2024
- Closed: February 25, 2025
- Over 11,500 responses received

**Proposed Approach:**

Government's preferred model similar to EU DSM Directive Article 4:
- Permit wider use of copyright materials to train AI models
- Rightsholders can "opt out" of this regime
- Balance between AI developer access and rightsholder control

**Three Core Objectives:**

1. **Control:** Rightsholders should control and license their content
2. **Access:** AI developers should access large volumes of content lawfully
3. **Transparency:** Greater clarity about works used in AI training

**Next Steps:**

- Data (Use and Access) Act requires Secretary of State to publish:
  - Report on consultation findings
  - Economic impact assessment
  - Deadline: By March 18, 2026

- Technical working groups met November 2025:
  - Control mechanisms
  - Transparency measures
  - Support for creatives

**Stakeholder Concerns:**

- Culture, Media and Sport Committee heard "widespread concerns from creative industries"
- Issues: Works used without consent or compensation
- Tension between AI industry growth and creative sector protection

**Timeline:**

- Legislation expected 2026
- Implementation likely 2026-2027

**Comparison to EU:**

- Similar opt-out structure to EU Article 4
- Likely face similar challenges:
  - Technical opt-out standards unclear
  - Burden on rightsholders to opt out rather than opt in
  - Scalability for AI companies tracking millions of opt-outs

**Sources:**
- [UK Government Consultation](https://www.gov.uk/government/consultations/copyright-and-artificial-intelligence/copyright-and-artificial-intelligence)
- [Linklaters Analysis](https://www.linklaters.com/en/insights/blogs/digilinks/2025/january/uk-government-proposes-copyright-and-ai-reform-mirroring-eu-approach)
- [House of Commons Library Brief](https://commonslibrary.parliament.uk/research-briefings/cdp-2025-0081/)
- [CMS Law Now](https://cms-lawnow.com/en/ealerts/2025/01/copyright-and-ai-how-is-the-uk-government-proposing-to-strike-a-balance-between-the-creative-industries-and-ai-sector)

### 3.4 Japan: Permissive Stance

**Legal Framework:**

**Copyright Act Article 30-4(ii)**
- Permits uses of works "in data analysis"
- No limitation to non-commercial purposes
- No limitation to scientific research
- Commercial AI training explicitly allowed

**Key Provisions:**

*Scope:*
- Allows exploitation "in any way and to the extent considered necessary"
- When "it is not a person's purpose to personally enjoy or cause another person to enjoy the thoughts or sentiments expressed in that work"

*Broad Application:*
- Similar to EU DSM Directive Article 4
- More permissive than most jurisdictions due to lack of commercial/research distinction
- One of world's most "relaxed" copyright regimes for AI development

**Important Limitations:**

**1. Non-Enjoyment Requirement:**
- Use must be for "information analysis" NOT "enjoyment of thoughts and sentiments"
- Distinction:
  - **Allowed:** Extracting patterns, statistics, relationships
  - **Not allowed:** Consuming creative expression

**2. No Unreasonable Prejudice:**
- Exploitation must not "unreasonably prejudice interests of copyright owner"
- Provides safety valve protecting rightsholder economic interests

**3. Output Restrictions:**
- Ingestion prohibited if intention to output products perceived as creative expressions of copyrighted works
- Cannot mimic style of specific creators for commercial gain

**Government Position:**

**Copyright Office Guidance (2024):**
- Article 30-4 exception for "non-enjoyment use" generally does not harm economic interests of copyright owners
- Emphasizes distinction between training (allowed) and output (potentially infringing)

**Key Point:** Training generally permitted; liability may arise from outputs if:
- Substantially similar to copyrighted works
- Used to mimic specific creator styles
- Unreasonably prejudice rightsholder interests

**Practical Impact:**

- Japan positioned as AI development hub due to permissive copyright regime
- No opt-out mechanism required (unlike EU/proposed UK)
- Burden on rightsholders to prove outputs cause unreasonable prejudice
- Attracts AI companies seeking favorable regulatory environment

**Comparison to Other Jurisdictions:**

| Jurisdiction | Commercial Use? | Opt-Out? | Research Only? |
|--------------|----------------|----------|----------------|
| Japan | ✅ Yes | ❌ No | ❌ No |
| EU | ✅ Yes | ✅ Yes | ❌ No (Article 4) |
| UK (current) | ❌ No | N/A | ✅ Yes |
| UK (proposed) | ✅ Yes | ✅ Yes | ❌ No |
| US | ⚖️ Case-by-case | ❌ No | ⚖️ Unclear |

**Sources:**
- [Privacy World Blog Japan Guidelines](https://www.privacyworld.blog/2024/03/japans-new-draft-guidelines-on-ai-and-copyright-is-it-really-ok-to-train-ai-using-pirated-materials/)
- [Japan Copyright Office English Summary](https://www.bunka.go.jp/english/policy/copyright/pdf/94055801_01.pdf)
- [TechPolicy.Press Asia Solutions](https://www.techpolicy.press/ai-training-and-copyright-infringement-solutions-from-asia/)
- [Clifford Chance Japan Analysis](https://www.cliffordchance.com/insights/resources/blogs/talking-tech/en/articles/2023/10/Japanese-Law-Issues-Surrounding-Generative-AI.html)

### 3.5 China: Comprehensive Data Security Framework

**Regulatory Structure:**

China has implemented one of the world's most comprehensive AI regulatory frameworks, emphasizing data security, cultural alignment, and user protection.

**Key Regulations:**

#### 1. Interim Measures for Generative AI Services (2023)

*Scope:* Companies offering AI tools to Chinese users

*Requirements:*
- Service registration with Cyberspace Administration of China (CAC)
- Model filing
- Content moderation systems
- Training data quality assurance
- Labeling of AI-generated content (AIGC)
- Data protection protocols
- User rights safeguards

#### 2. National Standards (Effective November 1, 2025)

Released April 25, 2025 by State Administration for Market Regulation and Standardization Administration of China:

**GB/T 45652-2025: Security Specification for Generative AI Pre-training and Fine-tuning Data**
- Outlines requirements for ensuring security of datasets in pre-training and fine-tuning phases
- Evaluation criteria for data quality
- Security assessments

**GB/T 45674-2025: Generative AI Data Annotation Security Specification**
- Security requirements for data labeling processes
- Quality standards for training data annotation

**GB/T 45654-2025: Basic Security Requirements for Generative AI Service**
- Overall security framework for AI services

**Training Data Requirements:**

**1. Data Quality and Safety:**
- Ensure legality of training data and model
- Conduct security assessments
- Enhance data accuracy, truthfulness, objectivity, diversity

**2. Full Lifecycle Management:**
- Training data must be lawfully sourced
- Properly screened and labeled per Basic Requirements
- Responsibility for training process, output accuracy
- Security of operation and updates

**3. Cultural and Value Alignment:**
- Data must be "consistent with socialist core values"
- Reflect "excellent traditional Chinese culture"
- Lawful, traceable, value-aligned
- Protected against poisoning or tampering

**4. User Data Restrictions:**
- User interaction data and sensitive personal information generally **cannot** be used for model training without separate consent
- **Stricter requirements for minors' data**

**Labeling Requirements (Effective September 1, 2025):**

**Implicit Labels:**
- Embedded within file metadata
- Required for all AI-generated content

**Explicit Labels:**
- Easily perceived by users
- Required for:
  - Text
  - Audio
  - Images
  - Videos
  - Virtual scenes

**Compliance Requirements:**

Organizations must:
- Secure training data and follow annotation security specifications
- Conduct privacy audits
- Define audit thresholds and frequency
- File registration of generative AI services with CAC
- Maintain compliance records
- Implement content filtering aligned with Chinese values

**Enforcement:**

- CAC has authority to audit compliance
- Penalties for non-compliance (specifics not publicly detailed)
- Service suspension or termination for serious violations

**Significance:**

- Most prescriptive AI data governance regime globally
- Reflects Chinese government priorities:
  - Content control
  - Cultural values alignment
  - Data sovereignty
  - User protection (especially minors)
- Creates compliance barrier for foreign AI companies
- Domestic AI companies must balance innovation with strict controls

**Sources:**
- [Global Legal Insights China AI Laws](https://www.globallegalinsights.com/practice-areas/ai-machine-learning-and-big-data-laws-and-regulations/china/)
- [Securiti China AI Regulatory Landscape](https://securiti.ai/china-ai-regulatory-landscape/)
- [White & Case China Tracker](https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-china)
- [Chambers AI Guide China](https://practiceguides.chambers.com/practice-guides/artificial-intelligence-2025/china)

---

## 4. Terms of Service Violations

### 4.1 Platform Policies on AI Training Scraping

**Key Question:** Can platforms contractually prohibit AI training via Terms of Service?

**Legal Challenge:** Courts have questioned enforceability of ToS prohibitions on scraping when they conflict with copyright law.

**X Corp. v. Bright Data Ltd. (May 9, 2024):**
- Northern District of California held claims that data scraping breached X's ToS **impermissibly conflicted with Copyright Act**
- Significant precedent undermining ToS-based anti-scraping arguments

### 4.2 Reddit: API Monetization and AI Deals

**API Changes (2023):**

*Background:*
- Reddit decided to charge for Data API access
- Concern: AI models ingesting user-supplied content without compensation
- Result: Third-party app/service ecosystem effectively shut down due to paywall

*Rationale:*
- "AI models would start ingesting all its user-supplied content without Reddit getting a cut"

**Major AI Training Licensing Deals:**

#### Google Deal (February 2024)
- **Announced:** Same day as Reddit IPO filing
- **Value:** Reportedly **$60 million per year**
- **Terms:** Reddit provides forum content to Google for AI chatbot training/updates

#### OpenAI Deal (May 2024)
- **Announced:** May 16, 2024
- **Value:** Estimated **~$70 million per year**
- **Terms:** Reddit content to ChatGPT and new products
- **Market Reaction:** Reddit stock soared

#### Recent Renegotiation Efforts (2025)

*September 2025:*
- Reddit in early talks with Google for next content-sharing agreement
- Aim: Extract more value from future deals
- Reasoning: Reddit data plays prominent role in search results and generative AI training

*Reddit's Market Position:*
- August 2024 - June 2025: Reddit was **most cited domain** by Google AI Overviews and Perplexity
- Second most cited by ChatGPT
- Disclosed **over $200 million** in contract value tied to licensing deals with Google, OpenAI, and others

**Business Model Shift:**

- From open API to paid licensing
- Reddit positioned as premium content source for AI training
- User-generated content monetized without direct user compensation
- API pricing effectively ended third-party apps while creating lucrative licensing revenue stream

**Sources:**
- [The Register Google Deal](https://www.theregister.com/2024/02/22/reddit_google_license_ipo_altman/)
- [Bloomberg Renegotiation](https://www.bloomberg.com/news/articles/2025-09-17/reddit-seeks-to-strike-next-ai-content-pact-with-google-openai)
- [TechCrunch OpenAI Deal](https://techcrunch.com/2024/05/16/openai-inks-deal-to-train-ai-on-reddit-data/)
- [CNBC Stock Reaction](https://www.cnbc.com/2024/05/16/reddit-soars-after-announcing-openai-deal-on-ai-training-models.html)

### 4.3 Twitter/X: Terms Changes and AI Scraping Prohibition

**Terms of Service Evolution:**

#### September 2023 Update (Effective September 29, 2023)

*Previous Terms:*
- Allowed crawling in accordance with robots.txt

*New Terms:*
- **Prohibited:** Any scraping or crawling "in any form, for any purpose without prior written consent"
- Explicitly banned all unauthorized scraping/crawling

**Legal Enforceability Challenges:**

**X Corp. v. Bright Data Ltd. (May 9, 2024):**
- Northern District of California **rejected X's anti-scraping argument**
- Held ToS-based claims that scraping breached terms **impermissibly conflicted with Copyright Act**
- Major blow to contractual anti-scraping enforcement

**2024-2026 Terms Updates:**

#### November 15, 2024 Terms (Effective until January 15, 2026)

*AI Training Policy:*
- **Before November 2024:** Users had option to opt-out, prohibiting X from scraping posts
- **After November 2024:** Opt-out option removed; content used for AI training regardless of user choice

*AI Content Treatment:*
- Treats AI-era interactions as "Content" users are responsible for
- Includes "inputs, prompts, outputs"
- Information obtained or created through Services

#### Upcoming January 15, 2026 Terms

*New provisions:*
- Further clarification that AI prompts, inputs, outputs constitute user Content
- Users responsible for all AI-generated content via X

**Practical Impact:**

- X claims right to use all user content for AI training
- No effective opt-out mechanism
- Legal enforceability questionable given X Corp. v. Bright Data precedent
- Creates tension between platform claims and copyright law

**X's Position vs. Legal Reality:**

- **X claims:** ToS prohibits unauthorized scraping
- **Court reality:** ToS cannot override copyright fair use or create enforceable scraping prohibitions
- **Result:** AI companies may scrape regardless of ToS, relying on fair use defenses

**Sources:**
- [TechCrunch ToS Update](https://techcrunch.com/2023/09/08/x-updates-its-terms-to-ban-crawling-and-scraping/)
- [Skadden X Corp. v. Bright Data](https://www.skadden.com/insights/publications/2024/05/district-court-adopts-broad-view)
- [CryptoSlate AI Chat Terms](https://cryptoslate.com/how-the-new-x-terms-of-service-gives-grok-permission-to-use-anything-you-say-forever-with-no-opt-out/)
- [X Terms of Service](https://twitter.com/en/tos)

### 4.4 Stack Overflow: Licensing Dispute and User Backlash

**Background:**

*Platform Decline:*
- Traffic collapsed **76%** since ChatGPT launched (November 2022)
- Monthly questions fell to 2009 levels
- Existential crisis as AI answers coding questions

*Business Pivot:*
- Shifted to API licensing model to monetize content
- Achieved 17% revenue growth (reaching $115M) through API partnerships

**Major Licensing Deals:**

#### Google Partnership (2024)
- Stack Overflow data used to enrich Google Gemini models

#### OpenAI Partnership (May 2024)
- OpenAI uses OverflowAPI to train models on Stack Overflow's public dataset
- Access to millions of developer-contributed answers and code snippets

**User Backlash:**

*Protest Actions (May 2024):*
- Users attempted to edit or delete their posts to prevent AI training
- Goal: Withdraw consent for AI training use

*Stack Overflow Response:*
- **Banned users en masse** who edited/deleted content in protest
- **Reversed edits** within hours
- Restored content users attempted to remove

*Stack Overflow's Legal Position:*

**Terms of Service:**
"Content provided is perpetually and irrevocably licensed to Stack Overflow on a worldwide, royalty-free, non-exclusive basis"

Stack Overflow claims right to:
- Access, use, process, copy, distribute, export, display content
- **Commercially exploit** such content
- Retain rights **even if content subsequently removed** by contributor

**Legal/Ethical Questions:**

1. **Informed Consent:** Users contributed before AI training was contemplated; did they consent to this use?
2. **Irrevocable License:** Can platforms retroactively apply content to uses not disclosed at contribution time?
3. **Community Relationship:** Developer community feels betrayed; "free labor" now monetized without compensation

**User Perspective:**

- Contributed knowledge freely to help developer community
- Did not anticipate commercial AI training use
- No compensation despite Stack Overflow's AI licensing revenue
- Removal of user control over contributed content

**Stack Overflow Position:**

- License terms grant perpetual rights
- Public benefit: Improving AI tools helps all developers
- Revenue necessary for platform sustainability

**Business Context:**

- API partnerships provided financial lifeline amid AI-driven traffic collapse
- 17% revenue growth from licensing while organic traffic cratered
- Model shift: From ad-supported Q&A to AI training data marketplace

**Broader Implications:**

- Precedent for other user-generated content platforms
- Question whether ToS can grant AI training rights for content contributed before AI training existed
- Tension between platform survival and contributor rights

**Sources:**
- [The Register User Suspensions](https://www.theregister.com/2024/05/09/stack_overflow_banning_users_who/)
- [TechCrunch OpenAI Deal](https://techcrunch.com/2024/05/06/stack-overflow-signs-deal-with-openai-to-supply-data-to-its-models/)
- [Slashdot Coverage](https://developers.slashdot.org/story/24/05/08/1711205/stack-overflow-is-feeding-programmers-answers-to-ai-whether-they-like-it-or-not)
- [ByteIOTA Analysis](https://byteiota.com/stack-overflow-sells-developer-answers-to-train-ai/)

---

## 5. Opt-Out Mechanisms

### 5.1 robots.txt and AI Crawlers

**Standard:** Robots Exclusion Protocol (robots.txt)

**How It Works:**
- Text file placed at website root (e.g., `example.com/robots.txt`)
- Specifies which automated crawlers can/cannot access site
- Voluntary standard; no legal enforcement mechanism

**Major AI Training Crawlers:**

| Bot Name | Company | Purpose |
|----------|---------|---------|
| **GPTBot** | OpenAI | Training GPT models |
| **ClaudeBot** | Anthropic | Training Claude models |
| **anthropic-ai** | Anthropic | Alternative crawler |
| **Claude-Web** | Anthropic | Web browsing |
| **Google-Extended** | Google | Training Gemini (does NOT affect Google Search ranking) |
| **Google-CloudVertexBot** | Google | Cloud AI services |
| **CCBot** | Common Crawl | Dataset used by many AI companies |
| **PerplexityBot** | Perplexity | Training/retrieval for answer engine |
| **Applebot-Extended** | Apple | AI training (does NOT affect Siri/Spotlight) |
| **Meta-ExternalAgent** | Meta | Training Meta AI models |
| **Bytespider** | ByteDance | Training AI models |
| **cohere-ai** | Cohere | Training Cohere models |
| **Amazonbot** | Amazon | AI training |
| **YouBot** | You.com | AI search training |
| **DuckAssistBot** | DuckDuckGo | AI features |

**Standard robots.txt Configuration to Block AI Training:**

```
User-agent: GPTBot
Disallow: /

User-agent: ClaudeBot
Disallow: /

User-agent: anthropic-ai
Disallow: /

User-agent: Claude-Web
Disallow: /

User-agent: Google-Extended
Disallow: /

User-agent: Google-CloudVertexBot
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: PerplexityBot
Disallow: /

User-agent: Applebot-Extended
Disallow: /

User-agent: Meta-ExternalAgent
Disallow: /

User-agent: Bytespider
Disallow: /

User-agent: cohere-ai
Disallow: /

User-agent: Amazonbot
Disallow: /

User-agent: YouBot
Disallow: /

User-agent: DuckAssistBot
Disallow: /
```

**2025 Adoption Trends:**

**Publisher Adoption:**
- **79%** of top news sites block AI training bots via robots.txt
- **312 domains** disallow GPTBot (250 fully, 62 partially)
- GPTBot, CCBot, and anthropic-ai are most frequently blocked

**Crawler Traffic Surge:**
- AI crawler traffic surged dramatically in 2025
- Training-related crawling: Nearly **80%** of all AI bot activity (Cloudflare data)
- GPTBot share: Surged from 5% to 30% between May 2024 and May 2025

**Important Distinctions:**

*Does NOT Affect Search Rankings:*
- Blocking GPTBot does not affect Googlebot (search indexing)
- Blocking Google-Extended does not affect Google Search ranking
- Blocking Applebot-Extended does not affect Siri/Spotlight
- Search crawlers and AI training crawlers operate independently

**Limitations:**

1. **Voluntary Compliance:** No technical enforcement; relies on crawler honoring robots.txt
2. **Retroactive Only:** Prevents future crawling; doesn't remove already-crawled data
3. **Discovery Required:** Publishers must discover and add new AI bots as they emerge
4. **No Legal Force:** Unclear whether ignoring robots.txt violates law (see Perplexity cases)

**Perplexity Controversy:**

- NYT lawsuit alleges Perplexity "intentionally ignored" Robots Exclusion Protocol
- Circumvented "hard-block" implemented by newspaper
- Made over 175,000 access attempts in August 2025 alone
- Raises question: Is violating robots.txt legally actionable?

**Cloudflare Solutions:**

Cloudflare offers managed robots.txt services for publishers:
- Automatic blocking of known AI crawlers
- Updates as new bots emerge
- Granular control (e.g., block training but allow retrieval)

**Sources:**
- [Playwire Publisher's Guide](https://www.playwire.com/blog/how-to-block-ai-bots-with-robotstxt-the-complete-publishers-guide)
- [Cloudflare AI Bot Control](https://blog.cloudflare.com/control-content-use-for-ai-training/)
- [BuzzStream 2025 Study](https://www.buzzstream.com/blog/publishers-block-ai-study/)
- [Search Engine Journal Coverage](https://www.searchenginejournal.com/most-major-news-publishers-block-ai-training-retrieval-bots/564605/)

### 5.2 Do Not Train Registries

**Spawning's Do Not Train Registry**

*Overview:*
- Repository of data permissions delivered through Spawning API at scraping time
- Allows rightsholders to add any media with individual URL

*Features:*
- Domain-level opt-outs
- "Have I Been Trained?" search tool
- Checks if specific images/content included in training datasets
- Machine-readable opt-out signals

*Adoption:*
- Used by some AI companies voluntarily
- No legal requirement to consult registry
- Effectiveness depends on company compliance

**GitHub Opt-Out Registry (Launched February 2025)**

*Background:*
- GitHub officially launched Opt-Out Registry for AI Training
- Standardized, machine-readable protocol
- Adopted by **over 37 major AI vendors**

*Participating Companies:*
- Microsoft
- Anthropic
- Hugging Face
- Tabnine
- Replit
- OpenAI (participation unclear)
- And 30+ others

*How to Opt Out (as of February 2025):*

**Canonical Mechanism:**
- Create plaintext file named `.optout`
- Place at repository root
- Content: Exactly one line: `ai-training: false`

**Example `.optout` file:**
```
ai-training: false
```

*Enforcement:*
- Participating vendors check for `.optout` file before training
- Voluntary compliance by participating companies
- No legal penalty for non-compliance

**Significance:**

- First industry-standard opt-out mechanism for code repositories
- Addresses open-source developer concerns about code training
- Complements GitHub Copilot litigation

**Sources:**
- [Spawning Opt-Outs Substack](https://spawning.substack.com/p/opt-outs-that-work-in-the-world-of)
- [GitHub Opt-Out Registry Launch](https://www.alibaba.com/product-insights/how-to-opt-out-of-ai-training-using-your-public-github-repos-in-2025.html)
- [Digital Rights Watch Guide](https://digitalrightswatch.org.au/how-to-disable-ai-scraping/)

### 5.3 Individual Opt-Out Processes by Company

**OpenAI (GPTBot)**

*Mechanism:*
- robots.txt blocking (see 5.1)
- No individual content-level opt-out for public web content

*For ChatGPT Users:*
- Settings > Data Controls > disable "Improve the model for everyone"
- Prevents conversation data from training (going forward)
- Does not remove previously used data

**Anthropic (ClaudeBot)**

*Mechanism:*
- robots.txt blocking
- No individual content-level opt-out for public web content

*For Claude Users:*
- Privacy settings to disable conversation training
- Future-only; no retroactive removal

**Google (Gemini)**

*Mechanism:*
- robots.txt: Block `Google-Extended`
- **Does NOT affect Search ranking** (uses separate Googlebot)

*For Gemini Users:*
- Google Account settings > Data & Privacy > Web & App Activity
- Disable to prevent conversation data training
- Does not affect already-trained models

**Meta (Facebook, Instagram)**

*EU/UK Users:*
- Right to object to data scraping
- Form in privacy settings

*Other Regions:*
- Limited opt-out options
- ToS grants Meta broad rights to use content

**LinkedIn**

*October 2025 Deadline:*
- November 3, 2025: Deadline to opt out for EU, EEA, Switzerland, Canada, Hong Kong
- After deadline, data used to train AI models

*How to Opt Out:*
- Settings > Data Privacy > Data for Generative AI Improvement
- Disable setting

*Limitation:*
- Deadline-based; users who missed deadline cannot retroactively opt out
- Unclear if future opt-out options will be provided

**Apple Intelligence**

*For Public Content:*
- robots.txt: Block `Applebot-Extended`
- Does NOT affect Siri/Spotlight (uses separate Applebot)

*For User Data:*
- iPhone/iPad/Mac Settings > Apple Intelligence & Siri
- Disable features to prevent data use

**Perplexity**

*Official Mechanism:*
- robots.txt: Block `PerplexityBot`

*Controversy:*
- Multiple lawsuits allege Perplexity ignores robots.txt
- NYT: Over 175,000 access attempts in August 2025 despite blocks
- Effectiveness questioned

**Midjourney, Stability AI**

*No Official Opt-Out:*
- No company-provided opt-out mechanism
- LAION dataset (used for training) is static
- Spawning's "Have I Been Trained?" tool can check if image included
- No removal mechanism once included

**Common Limitations Across All Platforms:**

1. **Future Only:** Opt-outs prevent future use; don't remove data from already-trained models
2. **Unlearning Problem:** No technical solution to remove specific data from trained models
3. **Verification:** No way to verify compliance
4. **Discovery Burden:** Users must actively find and configure opt-outs
5. **Retroactive Application:** Content contributed before opt-outs existed already used

**The "Unlearning" Problem:**

*Technical Challenge:*
- Once data trained into model weights, removal extremely difficult
- "Machine unlearning" is active research area with no proven scalable solutions
- Metaphor: "Opt-outs close the tap so your future sessions don't flow into the training pool, but they generally do not vacuum water back out of models already trained"

*Legal Question:*
- Should companies be required to retrain models excluding opt-out content?
- No legal requirement established in any jurisdiction yet
- Practical barrier: Retraining costs millions of dollars

**Sources:**
- [LinkedIn Opt-Out Notice](https://www.theregister.com/2025/10/27/linkedin_ai_profile_scraping/)
- [Meta Opt-Out Guide](https://www.technologyreview.com/2024/06/14/1093789/how-to-opt-out-of-meta-ai-training/)
- [Digital Rights Watch Multi-Platform Guide](https://digitalrightswatch.org.au/how-to-disable-ai-scraping/)
- [Terms.Law Analysis](https://terms.law/2025/12/05/can-you-stop-ai-from-using-your-content-opt-outs-takedowns-and-what-actually-works/)

---

## 6. Licensing Deals: The Alternative to Litigation

**Trend:** While 20+ lawsuits proceed, over 100 licensing/revenue-sharing deals have been signed.

### 6.1 OpenAI Publisher Partnerships (2024-2025)

**2024 Deals:**

| Publisher | Deal Date | Reported Value | Notes |
|-----------|-----------|----------------|-------|
| **News Corp** | May 2024 | >$250 million | Wall Street Journal, Barron's, New York Post, etc. CEO called it "historic agreement" |
| **Financial Times** | April 2024 | $5-10M/year | Premium business content |
| **Dotdash Meredith** | May 2024 | ≥$16 million | People, Better Homes & Gardens, etc. |
| **Le Monde** | March 2024 | Undisclosed | French news content |
| **Prisa Media** | March 2024 | Undisclosed | El País, Cinco Días, As, El Huffpost |
| **Condé Nast** | August 2024 | Undisclosed | Vogue, Wired, The New Yorker, etc. Multi-year deal |
| **Hearst** | October 2024 | Undisclosed | 20 magazines, 40+ local newspapers |
| **Reddit** | May 2024 | ~$70M/year | User-generated content access |

**2025 Deals:**

| Publisher | Deal Date | Terms | Innovations |
|-----------|-----------|-------|-------------|
| **Axios** | 2025 | 3-year deal | First OpenAI-funded newsrooms (4 local) |
| **The Guardian** | 2025 | Undisclosed | Attribution for summaries; access to OpenAI tech |
| **The Washington Post** | 2025 | Undisclosed | First AI licensing deal; summaries, quotes, links |
| **Schibsted Media** | 2025 | Undisclosed | Norwegian publisher; AI-generated summaries |

**Total:** OpenAI has **18 licensing deals** with publishers globally as of late 2025.

**Typical Deal Structure:**

1. **Content Access:** AI company trains on publisher content
2. **Attribution:** Publisher receives attribution in AI outputs
3. **Links:** Outputs include links back to original content
4. **Technology Access:** Publisher gets access to AI company's technology
5. **Revenue:** Flat fee, revenue share, or hybrid model
6. **Exclusivity:** Varies; some deals non-exclusive

### 6.2 Google AI Partnerships

**Major Deals:**

- **Reddit** (February 2024): $60M/year
- **Stack Overflow** (2024): Undisclosed; enriches Gemini models
- Google negotiating renewal with Reddit (September 2025) for higher fees

### 6.3 Evolving Business Models

**Three-Phase Evolution:**

1. **Flat Fees (2024):** Initial deals with fixed annual payments
2. **Usage-Based (2024-2025):** Revenue tied to how often content cited/used
3. **Dynamic Models (2025+):** Hybrid of flat fees + usage + technology access + advertising revenue share

**Example: Axios Deal Innovation**

- OpenAI **funded 4 local newsrooms** as part of deal
- First time AI company invested in journalism infrastructure
- Model: Beyond content licensing to journalism sustainability

### 6.4 Why Publishers Choose Licensing Over Litigation

**Litigation Risks:**

- Years of legal uncertainty (cases won't resolve until 2026+)
- Risk of adverse fair use rulings
- High legal costs
- No guaranteed recovery

**Licensing Benefits:**

- Immediate revenue
- Attribution and traffic from AI systems
- Access to AI technology for own products
- Ongoing relationship vs. adversarial stance
- Guaranteed compensation vs. uncertain litigation outcome

**Market Reality:**

- AI companies will use content regardless (fair use claims)
- Licensing ensures compensation and attribution
- "If you can't beat them, get paid by them"

### 6.5 The NYT Paradox

**Litigation and Licensing Coexist:**

- NYT sues OpenAI (December 2023)
- NYT sues Perplexity (December 2025)
- **But:** Other major publishers license to same companies

**Strategic Difference:**

- NYT believes it has leverage (premier content, strong legal case)
- May be holding out for better terms than competitors received
- Litigation potentially bargaining tactic for favorable eventual settlement

### 6.6 Revenue Impact for Publishers

**Reddit Case Study:**

- Disclosed **>$200 million** in contract value from AI licensing deals
- August 2024 - June 2025: Most cited domain by Google AI Overviews, Perplexity
- Second most cited by ChatGPT
- API licensing offset traffic losses from AI-driven search changes

**Stack Overflow Case Study:**

- Achieved **17% revenue growth** to $115M via API partnerships
- Despite 76% traffic collapse
- Demonstrates licensing can offset organic traffic losses

**Sources:**
- [Digiday 2024 Timeline](https://digiday.com/media/2024-in-review-a-timeline-of-the-major-deals-between-publishers-and-ai-companies/)
- [Digiday 2025 Timeline](https://digiday.com/media/a-timeline-of-the-major-deals-between-publishers-and-ai-tech-companies-in-2025/)
- [Variety News Corp Deal](https://variety.com/2024/digital/news/news-corp-openai-licensing-deal-1236013734/)
- [Profound AI Partners List](https://www.tryprofound.com/resources/articles/ai-model-publisher-partners)

---

## 7. Key Takeaways and Future Outlook

### 7.1 Legal Landscape Summary

**Current State (January 2026):**

1. **No Legal Consensus:**
   - Courts split on fair use for AI training
   - Thomson Reuters v. ROSS: Rejected fair use
   - Bartz v. Anthropic: Accepted fair use (but not for pirated sources)
   - Kadrey v. Meta: Accepted fair use with market harm concerns
   - No appellate decisions yet; earliest expected summer 2026

2. **Piracy Matters:**
   - Emerging principle: Using pirated sources prevents fair use defense
   - $1.5B Anthropic settlement establishes precedent
   - Legal exposure for companies that trained on shadow library content

3. **Regulatory Divergence:**
   - EU: Mandatory transparency (effective August 2025); opt-out permitted
   - UK: Consultation on opt-out model; decision by March 2026
   - Japan: Permissive commercial use allowed
   - China: Comprehensive security/cultural alignment requirements
   - US: No legislation; judicial case-by-case approach

4. **Platform Responses:**
   - Major platforms monetizing data via API licensing (Reddit, Stack Overflow)
   - ToS prohibitions on scraping of questionable legal enforceability
   - Licensing deals (100+) outpace litigation (20+)

### 7.2 Unresolved Questions

**Legal:**

1. Will appellate courts create circuit splits on fair use?
2. Are model weights themselves infringing derivative works?
3. Does memorization capability equal copyright infringement?
4. Can ToS override copyright law to prohibit scraping?
5. What constitutes "substantial similarity" for AI outputs?

**Technical:**

1. Can "machine unlearning" remove copyrighted data from trained models?
2. Are guardrails sufficient to prevent infringement liability?
3. How to verify compliance with opt-outs at scale?

**Policy:**

1. Should US adopt EU-style transparency requirements?
2. Should opt-in replace opt-out (reversing burden)?
3. How to compensate creators whose past content already used?
4. Should there be compulsory licensing regime for AI training?

### 7.3 What to Watch in 2026

**Critical Developments:**

1. **Third Circuit Appeal in Thomson Reuters v. ROSS**
   - First appellate ruling on AI training fair use
   - Could create binding precedent for mid-Atlantic states
   - May prompt Supreme Court review if conflicts with other circuits

2. **Ninth Circuit Appeal in GitHub Copilot Case**
   - First appellate ruling on AI-generated code and DMCA § 1202(b)
   - Impacts open-source licensing in AI context

3. **Summary Judgment Motions**
   - NYT v. OpenAI, Authors Guild v. OpenAI, and others
   - Earliest summer 2026 per legal analysts
   - Will determine whether fair use decided as matter of law or goes to jury

4. **UK Copyright Reform**
   - Report due by March 18, 2026
   - Will determine whether UK adopts EU-style opt-out model
   - Impacts whether UK aligns with EU or charts different course

5. **EU AI Act Enforcement**
   - First enforcement actions expected 2026
   - Will test effectiveness of training data transparency template
   - Potential fines up to €15M or 3% global revenue

6. **Potential Settlements**
   - Anthropic settlement ($1.5B) may prompt others
   - Music industry cases (Suno resolved with WMG; Sony ongoing)
   - Visual artists' cases entering discovery

### 7.4 Implications for Stakeholders

**For AI Companies:**

- **Risk mitigation:** Avoid pirated sources; use licensed data
- **Transparency:** Prepare for EU disclosure requirements
- **Licensing strategy:** Proactive deals cheaper than litigation
- **Geographic strategy:** Consider training in permissive jurisdictions (Japan)
- **Technical safeguards:** Implement robust guardrails against memorization

**For Content Creators:**

- **Opt-out now:** Use robots.txt, registries, platform settings
- **Monitor use:** Tools like "Have I Been Trained?" to check inclusion
- **Collective action:** Join class actions or industry groups
- **Licensing opportunities:** Explore direct licensing if you have valuable datasets
- **Advocacy:** Engage in policy consultations (UK, US)

**For Publishers:**

- **Strategic choice:** Litigate (NYT approach) vs. license (most others)
- **Leverage timing:** Early licensing deals set market rates
- **Technology access:** Negotiate for AI tools to improve own products
- **Attribution:** Ensure deals include proper attribution and links
- **Monitor compliance:** Verify AI companies honor agreements

**For Developers (Open Source):**

- **Use `.optout`:** GitHub registry growing; place `.optout` in repos
- **License choice:** Consider licenses explicitly addressing AI training
- **Community standards:** Engage in open-source community AI policy discussions

**For Policymakers:**

- **Transparency requirements:** Consider EU model for training data disclosure
- **Opt-in vs. opt-out:** Fundamental choice affecting burden distribution
- **Compulsory licensing:** Whether to create statutory license regime
- **International harmonization:** Balance between attracting AI investment and protecting creators

### 7.5 The Bigger Picture

**AI Training Data as Existential Copyright Question:**

The legal battles over AI training data represent the most significant challenge to copyright law since the internet era. Key tensions:

1. **Scale:** Training uses billions of works; traditional licensing impractical
2. **Transformation:** AI creates fundamentally new technology from copyrighted inputs
3. **Substitution:** AI outputs may compete with/replace original works
4. **Retroactivity:** Most training data used before legal standards established
5. **Global variance:** No international consensus; forum shopping incentives

**Possible Futures:**

**Scenario 1: Fair Use Prevails**
- Courts broadly accept AI training as transformative fair use
- Creators lose leverage; licensing becomes optional
- Market-driven solutions (voluntary licensing) replace legal requirements
- Risk: Devalues creative work; concentrates power in AI companies

**Scenario 2: Licensing Requirements**
- Courts require licensing; fair use narrowly applied
- Statutory/compulsory licensing regimes emerge
- Creators receive compensation; AI companies have clear legal path
- Risk: High costs; barriers to entry for smaller AI companies

**Scenario 3: Hybrid Model (Most Likely)**
- Some uses fair use (research, non-commercial); others require licensing
- Opt-out/transparency requirements provide creator control
- Market develops differentiated datasets (licensed premium vs. public domain)
- Risk: Legal uncertainty persists; compliance complexity

**Economic Stakes:**

- Global AI market projected $1.8 trillion by 2030
- Training data is foundational input
- Legal uncertainty affects billions in investment
- Outcome will shape whether AI benefits concentrated or distributed

**Timeline for Clarity:**

- **2026:** First appellate decisions
- **2027-2028:** Potential Supreme Court review
- **2029-2030:** Legal standards stabilize
- **Throughout:** Parallel development of licensing markets, technical solutions, international treaties

---

## 8. Comprehensive Case Tracker Reference

**For ongoing case status tracking, consult:**

1. **BakerHostetler AI Case Tracker**
   - URL: https://www.bakerlaw.com/services/artificial-intelligence-ai/case-tracker-artificial-intelligence-copyrights-and-class-actions/
   - Features: Case overviews, statuses, legal filings

2. **McKool Smith AI Litigation Tracker**
   - URL: https://www.mckoolsmith.com/newsroom-ailitigation
   - Features: Regular updates, detailed backgrounds

3. **"Chat GPT Is Eating the World" Master Chart**
   - URL: https://chatgptiseatingtheworld.com/
   - Features: Comprehensive list with case numbers, dates, summary judgment schedules
   - Updated through October 2025

4. **Copyright Alliance AI Coverage**
   - URL: https://copyrightalliance.org/
   - Features: Policy analysis, case developments from creator perspective

5. **Sustainable Tech Partner Timeline**
   - URL: https://sustainabletechpartner.com/topics/ai/generative-ai-lawsuit-timeline/
   - Features: Visual timeline, all major cases

---

## Sources

This report synthesizes information from the following sources:

### Court Documents and Legal Resources
- [U.S. District Court for the Southern District of New York](https://www.nysd.uscourts.gov/)
- [U.S. Copyright Office AI Study](https://www.copyright.gov/ai/)
- [Copyright Office Part 3 Report (Pre-Publication)](https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-3-Generative-AI-Training-Report-Pre-Publication-Version.pdf)

### Case Law and Legal Analysis
- [Harvard Law Review - NYT v. OpenAI Analysis](https://harvardlawreview.org/blog/2024/04/nyt-v-openai-the-timess-about-face/)
- [OpenAI Response to NYT Lawsuit](https://openai.com/new-york-times/)
- [Reed Smith Fair Use Analysis](https://www.reedsmith.com/en/perspectives/2025/07/a-new-look-fair-use-anthropic-meta-copyright-ai-training)
- [Skadden AI Legal Analyses](https://www.skadden.com/insights/publications/)
- [Jones Day AI Insights](https://www.jonesday.com/en/insights/)

### Regulatory and Government
- [European Commission AI Office](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai)
- [UK Government Copyright and AI Consultation](https://www.gov.uk/government/consultations/copyright-and-artificial-intelligence/)
- [Japan Copyright Office](https://www.bunka.go.jp/english/policy/copyright/)
- [China CAC AI Regulations](https://www.cac.gov.cn/)

### Industry and News Coverage
- [NPR AI Copyright Coverage](https://www.npr.org/)
- [TechCrunch AI News](https://techcrunch.com/)
- [The Verge AI Coverage](https://www.theverge.com/)
- [Music Business Worldwide](https://www.musicbusinessworldwide.com/)
- [Publishers Weekly](https://www.publishersweekly.com/)
- [Hollywood Reporter](https://www.hollywoodreporter.com/)

### Legal Tracking Resources
- [BakerHostetler AI Case Tracker](https://www.bakerlaw.com/services/artificial-intelligence-ai/case-tracker-artificial-intelligence-copyrights-and-class-actions/)
- [McKool Smith AI Litigation Tracker](https://www.mckoolsmith.com/newsroom-ailitigation)
- [Chat GPT Is Eating the World](https://chatgptiseatingtheworld.com/)
- [Copyright Alliance](https://copyrightalliance.org/)

### Technical and Academic
- [Authors Guild AI Resources](https://authorsguild.org/advocacy/artificial-intelligence/)
- [Electronic Frontier Foundation](https://www.eff.org/)
- [Center for Art Law](https://itsartlaw.org/)

### Platform and Company Resources
- [Cloudflare AI Bot Control](https://blog.cloudflare.com/)
- [GitHub Opt-Out Registry](https://github.com/)
- [Spawning AI](https://spawning.ai/)
- [X/Twitter Terms of Service](https://twitter.com/en/tos)

---

**Report Compiled:** January 16, 2026
**Next Recommended Update:** After summer 2026 (anticipated appellate decisions)
**Living Document:** This legal landscape is rapidly evolving. Significant developments occur weekly.

---

**DISCLAIMER:** This report is for informational and research purposes only. It does not constitute legal advice. Readers should consult qualified legal counsel for specific situations.
