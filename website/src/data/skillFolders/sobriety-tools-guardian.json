{
  "name": "sobriety-tools-guardian",
  "type": "folder",
  "path": "sobriety-tools-guardian",
  "children": [
    {
      "name": "references",
      "type": "folder",
      "path": "sobriety-tools-guardian/references",
      "children": [
        {
          "name": "CRISIS_DETECTION.md",
          "type": "file",
          "path": "sobriety-tools-guardian/references/CRISIS_DETECTION.md",
          "size": 9069,
          "content": "# Crisis Detection Patterns for Recovery Apps\n\n## The Mission\n\nDetect when a user might be heading toward relapse or crisis **before they ask for help**. Surface support proactively but gently—no alarms, no judgment, just help when they need it.\n\n## Signal Sources\n\n### 1. Check-in Data (HALT Scores)\n\nHALT = Hungry, Angry, Lonely, Tired\n\n```typescript\ninterface HALTCheckin {\n  hungry_score: number;  // 1-5\n  angry_score: number;   // 1-5\n  lonely_score: number;  // 1-5\n  tired_score: number;   // 1-5\n  created_at: Date;\n}\n```\n\n**Red Flags:**\n- Any single score jumps 3+ points from 7-day average\n- Combined HALT score (sum) exceeds 16 (out of 20)\n- Angry score consistently &gt;4 for 3+ days\n- Lonely score consistently &gt;4 for 3+ days\n\n### 2. Journal Sentiment\n\n**Red Flag Keywords/Patterns:**\n\n| Pattern | Risk Level | Context |\n|---------|------------|---------|\n| Ex-partner mentions (3+/week) | High | Relationship triggers are #1 relapse factor |\n| \"Can't\" appearing frequently | Medium | Learned helplessness indicator |\n| Sleep disruption mentions | Medium | Often precedes crisis |\n| Isolation language | High | \"Nobody understands\", \"alone\", \"no one cares\" |\n| Cravings acknowledged | High | Direct trigger awareness |\n| Financial stress | Medium | Common relapse trigger |\n\n**NOT Red Flags (false positives to avoid):**\n- Discussing past use in recovery context\n- Sharing struggles in group therapy\n- Processing difficult emotions constructively\n- Gratitude journaling about sobriety\n\n### 3. Behavioral Patterns\n\n```typescript\ninterface BehavioralSignals {\n  // Time patterns\n  late_night_activity: boolean;     // 2-5am check-ins\n  missed_streak: boolean;           // Broke daily streak after 7+ days\n  time_since_last_checkin: number;  // Hours\n\n  // Usage patterns\n  safety_plan_views: number;        // Spike in views\n  sponsor_calls_attempted: number;  // Multiple attempts\n  meeting_searches: number;         // Searching but not attending\n\n  // Derived\n  engagement_drop: boolean;         // 50%+ reduction in app usage\n}\n```\n\n### 4. Time-Based Risk Factors\n\n**High Risk Windows:**\n- Weekend evenings (Friday 6pm - Sunday midnight)\n- Holidays (especially family-related)\n- Anniversary dates (sobriety date, loss dates)\n- Late night (2-5am)\n- Early month (financial stress periods)\n\n## Detection Algorithm\n\n```typescript\ninterface CrisisRiskAssessment {\n  overall_risk: 'low' | 'elevated' | 'high' | 'critical';\n  signals: CrisisSignal[];\n  recommended_actions: Action[];\n  confidence: number;  // 0-1\n}\n\ninterface CrisisSignal {\n  type: string;\n  severity: 'low' | 'medium' | 'high';\n  evidence: string;\n  timestamp: Date;\n}\n\nfunction assessCrisisRisk(userId: string): CrisisRiskAssessment {\n  const checkins = getRecentCheckins(userId, 14);  // 2 weeks\n  const journals = getRecentJournals(userId, 7);   // 1 week\n  const behavior = getUserBehavior(userId);\n\n  const signals: CrisisSignal[] = [];\n\n  // Check HALT patterns\n  if (detectAngerSpike(checkins)) {\n    signals.push({\n      type: 'halt_anger_spike',\n      severity: 'high',\n      evidence: 'Anger score increased 3+ points in 48 hours',\n      timestamp: new Date(),\n    });\n  }\n\n  if (detectIsolationPattern(checkins)) {\n    signals.push({\n      type: 'halt_isolation',\n      severity: 'high',\n      evidence: 'Lonely score &gt;4 for 3 consecutive days',\n      timestamp: new Date(),\n    });\n  }\n\n  // Check behavioral signals\n  if (behavior.late_night_activity) {\n    signals.push({\n      type: 'time_distortion',\n      severity: 'medium',\n      evidence: 'Check-ins at unusual hours (2-5am)',\n      timestamp: new Date(),\n    });\n  }\n\n  if (behavior.missed_streak && behavior.time_since_last_checkin > 72) {\n    signals.push({\n      type: 'engagement_drop',\n      severity: 'high',\n      evidence: 'Daily streak broken, no check-in for 3+ days',\n      timestamp: new Date(),\n    });\n  }\n\n  // Calculate overall risk\n  const highSeverityCount = signals.filter(s => s.severity === 'high').length;\n  const mediumSeverityCount = signals.filter(s => s.severity === 'medium').length;\n\n  let overall_risk: 'low' | 'elevated' | 'high' | 'critical';\n  if (highSeverityCount >= 2) {\n    overall_risk = 'critical';\n  } else if (highSeverityCount >= 1) {\n    overall_risk = 'high';\n  } else if (mediumSeverityCount >= 2) {\n    overall_risk = 'elevated';\n  } else {\n    overall_risk = 'low';\n  }\n\n  return {\n    overall_risk,\n    signals,\n    recommended_actions: getRecommendedActions(overall_risk, signals),\n    confidence: calculateConfidence(signals),\n  };\n}\n```\n\n## Response Actions\n\n### Critical Risk Response\n\n```typescript\nconst CRITICAL_ACTIONS = [\n  {\n    type: 'surface_sponsor',\n    message: null,  // Just show sponsor contact prominently\n    placement: 'top_of_screen',\n    persist: true,\n  },\n  {\n    type: 'surface_safety_plan',\n    message: 'Your safety plan',  // Gentle, not alarming\n    placement: 'prominent_card',\n  },\n  {\n    type: 'surface_crisis_line',\n    message: '988 Suicide & Crisis Lifeline',\n    placement: 'accessible',  // Available but not pushy\n  },\n];\n```\n\n### High Risk Response\n\n```typescript\nconst HIGH_RISK_ACTIONS = [\n  {\n    type: 'gentle_checkin',\n    message: 'How are you doing today?',\n    placement: 'notification',\n    timing: 'next_app_open',\n  },\n  {\n    type: 'suggest_meeting',\n    message: 'There\\'s a meeting near you in 30 minutes',\n    placement: 'home_screen',\n  },\n  {\n    type: 'surface_coping_tools',\n    message: null,  // Just make them more visible\n    placement: 'quick_access',\n  },\n];\n```\n\n### Elevated Risk Response\n\n```typescript\nconst ELEVATED_ACTIONS = [\n  {\n    type: 'encouragement',\n    message: 'You\\'ve got 47 days. One day at a time.',\n    placement: 'subtle',\n  },\n  {\n    type: 'highlight_support',\n    message: null,\n    placement: 'contacts_reminder',\n  },\n];\n```\n\n## UI/UX Guidelines for Crisis Features\n\n### DO:\n- **Surface help without asking** - Don't make them request it\n- **Be subtle** - A prominent contact card, not a red alert\n- **Reduce friction** - One tap to call sponsor\n- **Respect autonomy** - They choose whether to engage\n- **Cache everything** - Must work offline in crisis\n- **Fast load** - &lt;200ms for crisis resources\n\n### DON'T:\n- **Alarm or panic** - No \"WE DETECTED YOU'RE IN CRISIS\"\n- **Be preachy** - No lectures about what they \"should\" do\n- **Block features** - Don't lock them out for their \"safety\"\n- **Require login** - Crisis resources must be accessible\n- **Track intrusively** - Be transparent about what's monitored\n\n## Database Schema for Crisis Detection\n\n```sql\n-- Store risk assessments (for analysis, not shown to user)\nCREATE TABLE crisis_risk_assessments (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  user_id UUID REFERENCES profiles(id) ON DELETE CASCADE,\n  assessed_at TIMESTAMPTZ DEFAULT NOW(),\n  overall_risk TEXT CHECK (overall_risk IN ('low', 'elevated', 'high', 'critical')),\n  signals JSONB,  -- Array of CrisisSignal objects\n  actions_taken JSONB,  -- What we surfaced\n  confidence DECIMAL(3,2)\n);\n\n-- Track which interventions were shown\nCREATE TABLE crisis_interventions (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  user_id UUID REFERENCES profiles(id) ON DELETE CASCADE,\n  assessment_id UUID REFERENCES crisis_risk_assessments(id),\n  intervention_type TEXT,\n  shown_at TIMESTAMPTZ DEFAULT NOW(),\n  engaged BOOLEAN DEFAULT FALSE,  -- Did they tap the sponsor card?\n  engagement_at TIMESTAMPTZ\n);\n\n-- Index for quick lookup\nCREATE INDEX idx_risk_user_recent ON crisis_risk_assessments (user_id, assessed_at DESC);\n```\n\n## Privacy Considerations\n\n1. **Assessments are internal** - User never sees \"risk score\"\n2. **No sharing** - Crisis data never leaves the app\n3. **User control** - They can disable proactive features\n4. **Transparent** - Explain what signals we watch (in settings)\n5. **Delete on request** - Full data deletion available\n6. **No third parties** - No analytics services see this data\n\n## Testing Crisis Detection\n\n```typescript\n// Test cases for crisis detection\nconst CRISIS_TEST_CASES = [\n  {\n    name: 'anger_spike',\n    checkins: [\n      { angry_score: 2, ...baseline },\n      { angry_score: 2, ...baseline },\n      { angry_score: 5, ...baseline },  // Spike\n    ],\n    expected_risk: 'high',\n  },\n  {\n    name: 'isolation_pattern',\n    checkins: [\n      { lonely_score: 4, ...baseline },\n      { lonely_score: 5, ...baseline },\n      { lonely_score: 5, ...baseline },\n    ],\n    expected_risk: 'high',\n  },\n  {\n    name: 'engagement_drop',\n    behavior: {\n      missed_streak: true,\n      time_since_last_checkin: 96,  // 4 days\n    },\n    expected_risk: 'high',\n  },\n  {\n    name: 'stable_user',\n    checkins: baselineCheckins(14),  // 14 days of normal\n    expected_risk: 'low',\n  },\n];\n```\n\n## Future Enhancements\n\n1. **ML-based sentiment analysis** - Beyond keyword matching\n2. **Peer network analysis** - Sponsor check-in patterns\n3. **Calendar integration** - Anticipate anniversary dates\n4. **Weather correlation** - Seasonal affective patterns\n5. **Community signals** - Meeting attendance tracking (opt-in)\n"
        },
        {
          "name": "PERFORMANCE_PATTERNS.md",
          "type": "file",
          "path": "sobriety-tools-guardian/references/PERFORMANCE_PATTERNS.md",
          "size": 8016,
          "content": "# Performance Patterns for Recovery Apps\n\n## Why Performance is Life-or-Death\n\nThis isn't a business app. The user opening sobriety.tools might be:\n- A fentanyl addict with seconds before relapse\n- Someone in emotional crisis needing their sponsor's number\n- A person at 2am looking for a meeting to survive until morning\n\n**Every second of load time is a second they might give up.**\n\n## Critical Path Priorities\n\n### Tier 1: Must Load in &lt;200ms (Crisis Critical)\n1. **Contacts/Sponsors** - Phone numbers for immediate support\n2. **Safety Plan** - User's personalized coping strategies\n3. **Crisis Resources** - Hotline numbers\n\n### Tier 2: Must Load in &lt;500ms (High Priority)\n4. **Meeting Search** - Find nearby meetings\n5. **Check-in Form** - Record current state\n\n### Tier 3: Can Load in &lt;2s (Standard)\n6. **Journal** - Review past entries\n7. **Progress Charts** - Analytics and trends\n8. **Settings** - Configuration\n\n## Offline-First Architecture\n\n### Service Worker Cache Strategy\n\n```typescript\n// Workbox configuration for crisis-critical routes\nconst PRECACHE_ROUTES = [\n  '/contacts',\n  '/safety-plan',\n  '/crisis',\n  '/check-in',\n];\n\nconst CACHE_FIRST_ROUTES = [\n  '/meetings?saved=true',  // Saved meetings\n  '/api/contacts',         // Sponsor data\n];\n\nconst STALE_WHILE_REVALIDATE = [\n  '/meetings',            // General search (prefer fresh)\n  '/api/meetings',        // Meeting API\n];\n```\n\n### IndexedDB for Critical Data\n\n```typescript\n// Always cache these locally\nconst OFFLINE_CRITICAL = {\n  contacts: {\n    store: 'contacts',\n    maxAge: Infinity,  // Never expire\n    syncStrategy: 'background',\n  },\n  safetyPlan: {\n    store: 'safety_plan',\n    maxAge: Infinity,\n    syncStrategy: 'background',\n  },\n  savedMeetings: {\n    store: 'saved_meetings',\n    maxAge: 24 * 60 * 60 * 1000,  // 24 hours\n    syncStrategy: 'background',\n  },\n  recentCheckins: {\n    store: 'checkins',\n    maxAge: 7 * 24 * 60 * 60 * 1000,  // 7 days\n    syncStrategy: 'background',\n  },\n};\n```\n\n## React Query Configuration\n\n### For Crisis-Critical Data\n\n```typescript\n// Contacts query - show cached data IMMEDIATELY\nconst useContacts = () => useQuery({\n  queryKey: ['contacts'],\n  queryFn: fetchContacts,\n  initialData: () => getFromIndexedDB('contacts'),\n  staleTime: Infinity,  // Never consider stale\n  gcTime: Infinity,     // Never garbage collect\n  refetchOnMount: false,\n  refetchOnWindowFocus: false,\n  refetchOnReconnect: 'always',  // Sync when back online\n});\n\n// Meeting search - aggressive caching\nconst useMeetings = (geohash: string) => useQuery({\n  queryKey: ['meetings', 'nearby', geohash],\n  queryFn: () => fetchMeetings(geohash),\n  staleTime: 6 * 60 * 60 * 1000,  // 6 hours (match harvester schedule)\n  gcTime: 24 * 60 * 60 * 1000,    // 24 hours\n  refetchOnMount: false,\n  refetchOnWindowFocus: false,\n});\n```\n\n### For Non-Critical Data\n\n```typescript\n// Journal entries - standard caching\nconst useJournal = () => useQuery({\n  queryKey: ['journal'],\n  queryFn: fetchJournal,\n  staleTime: 5 * 60 * 1000,  // 5 minutes\n  gcTime: 30 * 60 * 1000,    // 30 minutes\n});\n```\n\n## Edge Caching with Cloudflare KV\n\n### Geohash-Based Meeting Cache\n\n```\nUser Location (45.52, -122.68)\n    ↓\nGeohash: c20 (Portland metro, ~150km cell)\n    ↓\nKV Key: meetings:c20:25 (25-mile radius)\n    ↓\nCache HIT → Return immediately (~5ms)\nCache MISS → Query Supabase → Store in KV → Return (~200-500ms)\n```\n\n### Cache Warming Strategy\n\n```typescript\n// Top 30 US metros to pre-warm after each harvest\nconst WARM_METROS = [\n  { lat: 40.71, lng: -74.01 },  // NYC\n  { lat: 34.05, lng: -118.24 }, // LA\n  { lat: 41.88, lng: -87.63 },  // Chicago\n  // ... 27 more\n];\n\n// Run after harvester completes\nasync function warmCache() {\n  for (const metro of WARM_METROS) {\n    await fetch(`/api/all?lat=${metro.lat}&lng=${metro.lng}&radius=25`);\n    await sleep(100);  // Rate limit\n  }\n}\n```\n\n## Bundle Optimization\n\n### Dynamic Imports for Non-Critical Features\n\n```typescript\n// ❌ Bad - loads everything upfront\nimport { JournalAI } from '@/components/JournalAI';\nimport { Charts } from '@/components/Charts';\nimport { CalendarExport } from '@/components/CalendarExport';\n\n// ✅ Good - loads on demand\nconst JournalAI = dynamic(() => import('@/components/JournalAI'), {\n  ssr: false,\n  loading: () => <FeatureSkeleton />,\n});\n\nconst Charts = dynamic(() => import('@/components/Charts'), {\n  ssr: false,\n  loading: () => <ChartSkeleton />,\n});\n```\n\n### Tree-Shaking Dependencies\n\n```typescript\n// ❌ Bad - imports entire library\nimport _ from 'lodash';\nimport dayjs from 'dayjs';\n\n// ✅ Good - imports only what's needed\nimport debounce from 'lodash/debounce';\nimport { format, parseISO } from 'date-fns';\n```\n\n## Database Query Optimization\n\n### PostGIS Spatial Queries\n\n```sql\n-- ❌ Slow - calculates distance for all meetings\nSELECT * FROM meetings\nORDER BY ST_Distance(geog, ST_MakePoint($lng, $lat)::geography)\nLIMIT 100;\n\n-- ✅ Fast - filters by bounding box first\nSELECT * FROM meetings\nWHERE ST_DWithin(geog, ST_MakePoint($lng, $lat)::geography, $radius_meters)\nORDER BY ST_Distance(geog, ST_MakePoint($lng, $lat)::geography)\nLIMIT 100;\n```\n\n### Index Strategy\n\n```sql\n-- Spatial index for location queries\nCREATE INDEX idx_meetings_geog ON meetings USING GIST (geog);\n\n-- Compound index for filtered searches\nCREATE INDEX idx_meetings_day_program ON meetings (day_of_week, program)\nWHERE day_of_week IS NOT NULL;\n\n-- Index for user-specific queries\nCREATE INDEX idx_contacts_user_active ON contacts (user_id)\nWHERE status = 'active';\n```\n\n## Crisis Detection Patterns\n\n### Journal Sentiment Analysis\n\n```typescript\ninterface CrisisIndicators {\n  anger_spike: boolean;      // HALT angry score jumps 3+ points\n  ex_mentions: boolean;      // Ex-partner mentioned 3+ times/week\n  isolation: boolean;        // No check-ins for 3+ days after daily streak\n  time_distortion: boolean;  // Check-ins at 2-5am\n  negative_spiral: boolean;  // Consecutive declining mood scores\n}\n\nfunction detectCrisis(recentCheckins: Checkin[], journals: Journal[]): CrisisIndicators {\n  // Implementation details...\n}\n```\n\n### Proactive Help Surfacing\n\nWhen crisis indicators are detected:\n1. **Don't alarm** - No scary warnings\n2. **Gentle nudge** - \"Your sponsor Sarah is available\"\n3. **Surface tools** - Show safety plan link prominently\n4. **Reduce friction** - One-tap call to sponsor\n\n## Monitoring & Alerting\n\n### Key Metrics\n\n| Metric | Threshold | Action |\n|--------|-----------|--------|\n| Contacts FCP | &gt;200ms | P0 - Fix immediately |\n| Meetings LCP | &gt;500ms | P1 - Fix within 24h |\n| Cache hit rate | &lt;80% | Warm cache |\n| Lighthouse perf | &lt;90 | Investigate bundle |\n| API P95 | &gt;500ms | Check Supabase |\n\n### Automated Alerts\n\n```typescript\n// In perf-audit.ts\nif (contactsFCP > 200) {\n  await createGitHubIssue({\n    title: '[CRITICAL] Contacts page FCP regression',\n    body: `FCP is ${contactsFCP}ms (threshold: 200ms).\n\nUsers in crisis cannot access sponsor numbers quickly enough.\nThis is a life-safety issue.`,\n    labels: ['critical', 'performance', 'crisis-path'],\n  });\n}\n```\n\n## Testing Checklist\n\n### Before Every Deploy\n\n- [ ] Lighthouse performance ≥90\n- [ ] Contacts page FCP &lt;200ms\n- [ ] Meeting search &lt;500ms\n- [ ] Bundle delta &lt;5KB\n- [ ] Offline mode tested (DevTools → Network → Offline)\n\n### Weekly\n\n- [ ] Review slow query logs in Supabase\n- [ ] Check KV cache hit rate (&gt;80%)\n- [ ] Test on real device with 3G throttling\n- [ ] Review RUM data for P95 load times\n\n### Monthly\n\n- [ ] Profile React renders\n- [ ] Audit third-party scripts\n- [ ] Prune unused dependencies\n- [ ] Full crisis flow test on real device\n\n## Resources\n\n- [Web Vitals](https://web.dev/vitals/)\n- [Cloudflare Workers KV](https://developers.cloudflare.com/workers/runtime-apis/kv/)\n- [PostGIS Spatial Indexing](https://postgis.net/docs/using_postgis_dbmanagement.html#idm2264)\n- [React Query Caching](https://tanstack.com/query/latest/docs/framework/react/guides/caching)\n"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "folder",
      "path": "sobriety-tools-guardian/scripts",
      "children": [
        {
          "name": "bundle-analyzer.ts",
          "type": "file",
          "path": "sobriety-tools-guardian/scripts/bundle-analyzer.ts",
          "size": 11968,
          "content": "#!/usr/bin/env npx tsx\n/**\n * Bundle Size Analyzer for sobriety.tools\n *\n * Tracks JavaScript bundle sizes over time and alerts on regressions.\n * Integrated with the build process to catch bloat before deployment.\n *\n * Usage:\n *   npx tsx scripts/bundle-analyzer.ts\n *   npx tsx scripts/bundle-analyzer.ts --compare <baseline.json>\n *   npx tsx scripts/bundle-analyzer.ts --save <output.json>\n *   npx tsx scripts/bundle-analyzer.ts --threshold 500  # Max KB for main bundle\n */\n\nimport * as fs from 'fs';\nimport * as path from 'path';\n\n// Thresholds in KB\nconst THRESHOLDS = {\n  main_bundle: 500, // Main app bundle\n  page_bundle: 150, // Individual page bundles\n  total_js: 1500, // Total JS across all bundles\n  single_chunk: 250, // Any single chunk\n  first_load: 300, // First load JS (critical path)\n};\n\ninterface ChunkInfo {\n  name: string;\n  size: number;\n  gzipSize?: number;\n  isMainBundle: boolean;\n  isPage: boolean;\n  path: string;\n}\n\ninterface BundleReport {\n  timestamp: string;\n  commitHash?: string;\n  totalSize: number;\n  totalGzipSize: number;\n  mainBundleSize: number;\n  firstLoadSize: number;\n  chunkCount: number;\n  chunks: ChunkInfo[];\n  largestChunks: ChunkInfo[];\n  violations: string[];\n  passed: boolean;\n}\n\nfunction getGitCommitHash(): string | undefined {\n  try {\n    const { execSync } = require('child_process');\n    return execSync('git rev-parse --short HEAD', { encoding: 'utf-8' }).trim();\n  } catch {\n    return undefined;\n  }\n}\n\nfunction getFileSizeKB(filePath: string): number {\n  try {\n    const stats = fs.statSync(filePath);\n    return Math.round(stats.size / 1024);\n  } catch {\n    return 0;\n  }\n}\n\nfunction findChunks(nextDir: string): ChunkInfo[] {\n  const chunks: ChunkInfo[] = [];\n\n  // Check for static chunks\n  const staticDir = path.join(nextDir, 'static', 'chunks');\n  if (fs.existsSync(staticDir)) {\n    scanDirectory(staticDir, chunks, false, false);\n  }\n\n  // Check for page chunks\n  const pagesDir = path.join(staticDir, 'pages');\n  if (fs.existsSync(pagesDir)) {\n    scanDirectory(pagesDir, chunks, false, true);\n  }\n\n  // Check for app chunks (App Router)\n  const appDir = path.join(staticDir, 'app');\n  if (fs.existsSync(appDir)) {\n    scanDirectory(appDir, chunks, false, true);\n  }\n\n  return chunks;\n}\n\nfunction scanDirectory(\n  dir: string,\n  chunks: ChunkInfo[],\n  isMain: boolean,\n  isPage: boolean\n): void {\n  const entries = fs.readdirSync(dir, { withFileTypes: true });\n\n  for (const entry of entries) {\n    const fullPath = path.join(dir, entry.name);\n\n    if (entry.isDirectory()) {\n      scanDirectory(fullPath, chunks, isMain, isPage);\n    } else if (entry.name.endsWith('.js')) {\n      const size = getFileSizeKB(fullPath);\n      const isMainBundle =\n        entry.name.includes('main') ||\n        entry.name.includes('webpack') ||\n        entry.name.includes('framework');\n\n      chunks.push({\n        name: entry.name,\n        size,\n        isMainBundle,\n        isPage,\n        path: fullPath,\n      });\n    }\n  }\n}\n\nfunction analyzeBuild(nextDir: string): BundleReport {\n  if (!fs.existsSync(nextDir)) {\n    throw new Error(`Build directory not found: ${nextDir}`);\n  }\n\n  const chunks = findChunks(nextDir);\n  const violations: string[] = [];\n\n  // Calculate totals\n  const totalSize = chunks.reduce((sum, c) => sum + c.size, 0);\n  const mainBundleChunks = chunks.filter((c) => c.isMainBundle);\n  const mainBundleSize = mainBundleChunks.reduce((sum, c) => sum + c.size, 0);\n\n  // Estimate first load size (main + framework + vendor chunks)\n  const firstLoadChunks = chunks.filter(\n    (c) =>\n      c.isMainBundle ||\n      c.name.includes('vendor') ||\n      c.name.includes('commons') ||\n      c.name.includes('framework')\n  );\n  const firstLoadSize = firstLoadChunks.reduce((sum, c) => sum + c.size, 0);\n\n  // Check thresholds\n  if (mainBundleSize > THRESHOLDS.main_bundle) {\n    violations.push(\n      `Main bundle ${mainBundleSize}KB exceeds ${THRESHOLDS.main_bundle}KB threshold`\n    );\n  }\n\n  if (totalSize > THRESHOLDS.total_js) {\n    violations.push(\n      `Total JS ${totalSize}KB exceeds ${THRESHOLDS.total_js}KB threshold`\n    );\n  }\n\n  if (firstLoadSize > THRESHOLDS.first_load) {\n    violations.push(\n      `First load JS ${firstLoadSize}KB exceeds ${THRESHOLDS.first_load}KB threshold`\n    );\n  }\n\n  // Check individual chunks\n  const largeChunks = chunks.filter((c) => c.size > THRESHOLDS.single_chunk);\n  for (const chunk of largeChunks) {\n    violations.push(\n      `Chunk \"${chunk.name}\" is ${chunk.size}KB (>${THRESHOLDS.single_chunk}KB)`\n    );\n  }\n\n  // Check page bundles\n  const largePages = chunks.filter(\n    (c) => c.isPage && c.size > THRESHOLDS.page_bundle\n  );\n  for (const page of largePages) {\n    violations.push(\n      `Page \"${page.name}\" is ${page.size}KB (>${THRESHOLDS.page_bundle}KB)`\n    );\n  }\n\n  // Sort chunks by size for reporting\n  const sortedChunks = [...chunks].sort((a, b) => b.size - a.size);\n  const largestChunks = sortedChunks.slice(0, 10);\n\n  return {\n    timestamp: new Date().toISOString(),\n    commitHash: getGitCommitHash(),\n    totalSize,\n    totalGzipSize: 0, // Would need gzip analysis\n    mainBundleSize,\n    firstLoadSize,\n    chunkCount: chunks.length,\n    chunks: sortedChunks,\n    largestChunks,\n    violations,\n    passed: violations.length === 0,\n  };\n}\n\nfunction compareReports(\n  current: BundleReport,\n  baseline: BundleReport\n): { changes: string[]; regressions: string[] } {\n  const changes: string[] = [];\n  const regressions: string[] = [];\n\n  const totalDiff = current.totalSize - baseline.totalSize;\n  const mainDiff = current.mainBundleSize - baseline.mainBundleSize;\n  const firstLoadDiff = current.firstLoadSize - baseline.firstLoadSize;\n\n  if (Math.abs(totalDiff) > 5) {\n    const direction = totalDiff > 0 ? '+' : '';\n    changes.push(`Total JS: ${direction}${totalDiff}KB`);\n    if (totalDiff > 50) {\n      regressions.push(`Total JS increased by ${totalDiff}KB`);\n    }\n  }\n\n  if (Math.abs(mainDiff) > 5) {\n    const direction = mainDiff > 0 ? '+' : '';\n    changes.push(`Main bundle: ${direction}${mainDiff}KB`);\n    if (mainDiff > 20) {\n      regressions.push(`Main bundle increased by ${mainDiff}KB`);\n    }\n  }\n\n  if (Math.abs(firstLoadDiff) > 5) {\n    const direction = firstLoadDiff > 0 ? '+' : '';\n    changes.push(`First load: ${direction}${firstLoadDiff}KB`);\n    if (firstLoadDiff > 30) {\n      regressions.push(`First load JS increased by ${firstLoadDiff}KB`);\n    }\n  }\n\n  return { changes, regressions };\n}\n\nfunction printReport(\n  report: BundleReport,\n  comparison?: { changes: string[]; regressions: string[] }\n): void {\n  console.log('='.repeat(60));\n  console.log('BUNDLE SIZE ANALYSIS');\n  console.log('='.repeat(60));\n  console.log(`Timestamp: ${report.timestamp}`);\n  if (report.commitHash) {\n    console.log(`Commit: ${report.commitHash}`);\n  }\n  console.log('');\n\n  console.log('SUMMARY');\n  console.log('-'.repeat(40));\n  console.log(`Total JS:      ${report.totalSize}KB`);\n  console.log(`Main Bundle:   ${report.mainBundleSize}KB`);\n  console.log(`First Load:    ${report.firstLoadSize}KB`);\n  console.log(`Chunk Count:   ${report.chunkCount}`);\n\n  if (comparison) {\n    console.log('');\n    console.log('CHANGES FROM BASELINE');\n    console.log('-'.repeat(40));\n    if (comparison.changes.length > 0) {\n      for (const change of comparison.changes) {\n        console.log(`  ${change}`);\n      }\n    } else {\n      console.log('  No significant changes');\n    }\n\n    if (comparison.regressions.length > 0) {\n      console.log('');\n      console.log('⚠ REGRESSIONS');\n      for (const regression of comparison.regressions) {\n        console.log(`  ✗ ${regression}`);\n      }\n    }\n  }\n\n  console.log('');\n  console.log('LARGEST CHUNKS');\n  console.log('-'.repeat(40));\n  for (const chunk of report.largestChunks) {\n    const flags = [];\n    if (chunk.isMainBundle) flags.push('main');\n    if (chunk.isPage) flags.push('page');\n    const flagStr = flags.length > 0 ? ` [${flags.join(', ')}]` : '';\n    console.log(`  ${chunk.size.toString().padStart(4)}KB  ${chunk.name}${flagStr}`);\n  }\n\n  if (report.violations.length > 0) {\n    console.log('');\n    console.log('⚠ VIOLATIONS');\n    console.log('-'.repeat(40));\n    for (const violation of report.violations) {\n      console.log(`  ✗ ${violation}`);\n    }\n  }\n\n  console.log('');\n  console.log('='.repeat(60));\n  if (report.passed) {\n    console.log('✓ Bundle sizes within thresholds');\n  } else {\n    console.log(`✗ ${report.violations.length} threshold violations`);\n  }\n  console.log('='.repeat(60));\n}\n\nfunction printSuggestions(report: BundleReport): void {\n  if (report.violations.length === 0) return;\n\n  console.log('');\n  console.log('OPTIMIZATION SUGGESTIONS');\n  console.log('-'.repeat(40));\n\n  if (report.mainBundleSize > THRESHOLDS.main_bundle) {\n    console.log(`\nMain bundle too large (${report.mainBundleSize}KB):\n  1. Run: npx @next/bundle-analyzer\n  2. Identify large dependencies\n  3. Use dynamic imports: const Heavy = dynamic(() => import('./Heavy'))\n  4. Check for accidental full library imports (e.g., lodash vs lodash-es)\n`);\n  }\n\n  if (report.firstLoadSize > THRESHOLDS.first_load) {\n    console.log(`\nFirst load JS too large (${report.firstLoadSize}KB):\n  1. Move non-critical code to dynamic imports\n  2. Use React.lazy() for route-level code splitting\n  3. Check for large CSS-in-JS libraries (prefer Tailwind)\n  4. Audit third-party scripts (analytics, chat widgets)\n`);\n  }\n\n  const largePages = report.chunks.filter(\n    (c) => c.isPage && c.size > THRESHOLDS.page_bundle\n  );\n  if (largePages.length > 0) {\n    console.log(`\nLarge page bundles detected:\n  ${largePages.map((p) => `- ${p.name}: ${p.size}KB`).join('\\n  ')}\n\nTo fix:\n  1. Move heavy components to dynamic imports\n  2. Split data fetching from rendering\n  3. Use server components where possible (Next.js 13+)\n`);\n  }\n}\n\nasync function main(): Promise<void> {\n  const args = process.argv.slice(2);\n\n  // Parse arguments\n  let baselinePath: string | undefined;\n  let savePath: string | undefined;\n  let threshold: number | undefined;\n\n  for (let i = 0; i < args.length; i++) {\n    if (args[i] === '--compare' && args[i + 1]) {\n      baselinePath = args[++i];\n    } else if (args[i] === '--save' && args[i + 1]) {\n      savePath = args[++i];\n    } else if (args[i] === '--threshold' && args[i + 1]) {\n      threshold = parseInt(args[++i], 10);\n      THRESHOLDS.main_bundle = threshold;\n    }\n  }\n\n  // Find the build directory\n  const possibleDirs = [\n    path.join(process.cwd(), '.next'),\n    path.join(process.cwd(), 'next-app', '.next'),\n    path.join(process.cwd(), 'out'),\n    path.join(process.cwd(), 'next-app', 'out'),\n  ];\n\n  let buildDir: string | undefined;\n  for (const dir of possibleDirs) {\n    if (fs.existsSync(dir)) {\n      buildDir = dir;\n      break;\n    }\n  }\n\n  if (!buildDir) {\n    console.error('No build directory found. Run `npm run build` first.');\n    process.exit(1);\n  }\n\n  console.log(`Analyzing build: ${buildDir}\\n`);\n\n  const report = analyzeBuild(buildDir);\n\n  // Compare with baseline if provided\n  let comparison: { changes: string[]; regressions: string[] } | undefined;\n  if (baselinePath && fs.existsSync(baselinePath)) {\n    const baseline = JSON.parse(fs.readFileSync(baselinePath, 'utf-8'));\n    comparison = compareReports(report, baseline);\n  }\n\n  printReport(report, comparison);\n  printSuggestions(report);\n\n  // Save report if requested\n  if (savePath) {\n    fs.writeFileSync(savePath, JSON.stringify(report, null, 2));\n    console.log(`\\nReport saved to: ${savePath}`);\n  }\n\n  // Always save to temp for CI\n  const tempPath = '/tmp/bundle-report.json';\n  fs.writeFileSync(tempPath, JSON.stringify(report, null, 2));\n\n  // Exit with error if violations\n  if (!report.passed) {\n    process.exit(1);\n  }\n\n  if (comparison && comparison.regressions.length > 0) {\n    console.error('\\n⚠ Bundle size regressions detected');\n    process.exit(1);\n  }\n}\n\nmain().catch(console.error);\n"
        },
        {
          "name": "cache-health.ts",
          "type": "file",
          "path": "sobriety-tools-guardian/scripts/cache-health.ts",
          "size": 9529,
          "content": "#!/usr/bin/env npx tsx\n/**\n * Cache Health Monitor for sobriety.tools\n *\n * Checks KV cache hit rates, staleness, and coverage for the meeting-proxy Worker.\n * Alerts on poor cache performance that could slow meeting searches.\n *\n * Usage:\n *   npx tsx scripts/cache-health.ts\n *   npx tsx scripts/cache-health.ts --verbose\n *   npx tsx scripts/cache-health.ts --warm  # Trigger cache warming\n */\n\nimport * as fs from 'fs';\n\nconst MEETING_PROXY_URL = 'https://jb4l-meeting-proxy.erich-owens.workers.dev';\nconst ORIGIN_HEADER = { Origin: 'https://sobriety.tools' };\n\n// Top 30 US metro areas with their geohash cells\nconst TOP_METROS = [\n  { name: 'New York', lat: 40.7128, lng: -74.006, geohash: 'dr5' },\n  { name: 'Los Angeles', lat: 34.0522, lng: -118.2437, geohash: '9q5' },\n  { name: 'Chicago', lat: 41.8781, lng: -87.6298, geohash: 'dp3' },\n  { name: 'Houston', lat: 29.7604, lng: -95.3698, geohash: '9vk' },\n  { name: 'Phoenix', lat: 33.4484, lng: -112.074, geohash: '9tb' },\n  { name: 'San Antonio', lat: 29.4241, lng: -98.4936, geohash: '9v4' },\n  { name: 'Dallas', lat: 32.7767, lng: -96.797, geohash: '9vg' },\n  { name: 'San Jose', lat: 37.3382, lng: -121.8863, geohash: '9q9' },\n  { name: 'Austin', lat: 30.2672, lng: -97.7431, geohash: '9v6' },\n  { name: 'San Diego', lat: 32.7157, lng: -117.1611, geohash: '9mu' },\n  { name: 'Denver', lat: 39.7392, lng: -104.9903, geohash: '9xj' },\n  { name: 'Seattle', lat: 47.6062, lng: -122.3321, geohash: 'c23' },\n  { name: 'Boston', lat: 42.3601, lng: -71.0589, geohash: 'drt' },\n  { name: 'Atlanta', lat: 33.749, lng: -84.388, geohash: 'djf' },\n  { name: 'Miami', lat: 25.7617, lng: -80.1918, geohash: 'dhw' },\n  { name: 'Washington DC', lat: 38.9072, lng: -77.0369, geohash: 'dqc' },\n  { name: 'Philadelphia', lat: 39.9526, lng: -75.1652, geohash: 'dr4' },\n  { name: 'Nashville', lat: 36.1627, lng: -86.7816, geohash: 'dn6' },\n  { name: 'Portland', lat: 45.5152, lng: -122.6784, geohash: 'c20' },\n  { name: 'Minneapolis', lat: 44.9778, lng: -93.265, geohash: 'cbf' },\n  { name: 'Louisville', lat: 38.2527, lng: -85.7585, geohash: 'dng' },\n  { name: 'Charlotte', lat: 35.2271, lng: -80.8431, geohash: 'dnq' },\n  { name: 'Tulsa', lat: 36.154, lng: -95.9928, geohash: '9yn' },\n  { name: 'Oklahoma City', lat: 35.4676, lng: -97.5164, geohash: '9y7' },\n  { name: 'Milwaukee', lat: 43.0389, lng: -87.9065, geohash: 'dp8' },\n  { name: 'Kansas City', lat: 39.0997, lng: -94.5786, geohash: '9yy' },\n  { name: 'Fort Worth', lat: 32.7555, lng: -97.3308, geohash: '9vf' },\n  { name: 'Fresno', lat: 36.7378, lng: -119.7871, geohash: '9qd' },\n  { name: 'Raleigh', lat: 35.7796, lng: -78.6382, geohash: 'dq2' },\n  { name: 'San Francisco', lat: 37.7749, lng: -122.4194, geohash: '9q8' },\n];\n\ninterface CacheCheckResult {\n  city: string;\n  geohash: string;\n  cacheStatus: 'HIT' | 'MISS' | 'ERROR';\n  responseTime: number;\n  meetingCount: number;\n  cacheAge?: number;\n  error?: string;\n}\n\ninterface HealthReport {\n  timestamp: string;\n  totalChecked: number;\n  cacheHits: number;\n  cacheMisses: number;\n  errors: number;\n  hitRate: number;\n  avgResponseTime: number;\n  slowestCity: string;\n  slowestTime: number;\n  results: CacheCheckResult[];\n  recommendations: string[];\n}\n\nasync function checkCacheForCity(\n  city: { name: string; lat: number; lng: number; geohash: string }\n): Promise<CacheCheckResult> {\n  const start = Date.now();\n\n  try {\n    const response = await fetch(\n      `${MEETING_PROXY_URL}/api/all?lat=${city.lat}&lng=${city.lng}&radius=25`,\n      { headers: ORIGIN_HEADER }\n    );\n\n    const responseTime = Date.now() - start;\n    const cacheStatus = response.headers.get('X-Cache') as 'HIT' | 'MISS' || 'MISS';\n    const geohash = response.headers.get('X-Geohash') || city.geohash;\n\n    const data = await response.json();\n    const meetingCount = data.meetings?.length || 0;\n\n    return {\n      city: city.name,\n      geohash,\n      cacheStatus,\n      responseTime,\n      meetingCount,\n    };\n  } catch (error) {\n    return {\n      city: city.name,\n      geohash: city.geohash,\n      cacheStatus: 'ERROR',\n      responseTime: Date.now() - start,\n      meetingCount: 0,\n      error: String(error),\n    };\n  }\n}\n\nasync function runHealthCheck(verbose: boolean): Promise<HealthReport> {\n  console.log('Checking cache health for top 30 US metros...\\n');\n\n  const results: CacheCheckResult[] = [];\n\n  // Check cities in batches to avoid overwhelming the worker\n  const batchSize = 5;\n  for (let i = 0; i < TOP_METROS.length; i += batchSize) {\n    const batch = TOP_METROS.slice(i, i + batchSize);\n    const batchResults = await Promise.all(batch.map(checkCacheForCity));\n    results.push(...batchResults);\n\n    if (verbose) {\n      for (const result of batchResults) {\n        const icon = result.cacheStatus === 'HIT' ? '✓' : result.cacheStatus === 'ERROR' ? '✗' : '○';\n        console.log(\n          `${icon} ${result.city.padEnd(15)} ${result.cacheStatus.padEnd(5)} ${result.responseTime}ms ${result.meetingCount} meetings`\n        );\n      }\n    }\n\n    // Small delay between batches\n    if (i + batchSize < TOP_METROS.length) {\n      await new Promise((resolve) => setTimeout(resolve, 200));\n    }\n  }\n\n  // Calculate statistics\n  const hits = results.filter((r) => r.cacheStatus === 'HIT').length;\n  const misses = results.filter((r) => r.cacheStatus === 'MISS').length;\n  const errors = results.filter((r) => r.cacheStatus === 'ERROR').length;\n  const hitRate = (hits / (hits + misses)) * 100;\n\n  const responseTimes = results\n    .filter((r) => r.cacheStatus !== 'ERROR')\n    .map((r) => r.responseTime);\n  const avgResponseTime =\n    responseTimes.reduce((a, b) => a + b, 0) / responseTimes.length;\n\n  const slowest = results.reduce((a, b) =>\n    a.responseTime > b.responseTime ? a : b\n  );\n\n  // Generate recommendations\n  const recommendations: string[] = [];\n\n  if (hitRate < 80) {\n    recommendations.push(\n      `Cache hit rate is ${hitRate.toFixed(1)}% (target: >80%). Run cache warming: curl ${MEETING_PROXY_URL}/warm`\n    );\n  }\n\n  if (avgResponseTime > 300) {\n    recommendations.push(\n      `Average response time is ${avgResponseTime.toFixed(0)}ms (target: <300ms). Check Supabase query performance.`\n    );\n  }\n\n  const missedCities = results.filter((r) => r.cacheStatus === 'MISS');\n  if (missedCities.length > 0) {\n    recommendations.push(\n      `Cache misses for: ${missedCities.map((r) => r.city).join(', ')}. These require warming.`\n    );\n  }\n\n  if (errors > 0) {\n    recommendations.push(\n      `${errors} cities failed. Check worker logs and Supabase connectivity.`\n    );\n  }\n\n  const lowMeetingCities = results.filter(\n    (r) => r.meetingCount < 10 && r.cacheStatus !== 'ERROR'\n  );\n  if (lowMeetingCities.length > 0) {\n    recommendations.push(\n      `Low meeting counts (<10) for: ${lowMeetingCities.map((r) => `${r.city}(${r.meetingCount})`).join(', ')}. Verify harvester coverage.`\n    );\n  }\n\n  return {\n    timestamp: new Date().toISOString(),\n    totalChecked: results.length,\n    cacheHits: hits,\n    cacheMisses: misses,\n    errors,\n    hitRate,\n    avgResponseTime,\n    slowestCity: slowest.city,\n    slowestTime: slowest.responseTime,\n    results,\n    recommendations,\n  };\n}\n\nasync function warmCache(): Promise<void> {\n  console.log('Triggering cache warm for all metros...\\n');\n\n  try {\n    const response = await fetch(`${MEETING_PROXY_URL}/warm`, {\n      headers: ORIGIN_HEADER,\n    });\n\n    if (response.ok) {\n      const data = await response.json();\n      console.log('Cache warming complete!');\n      console.log(`  Cities warmed: ${data.citiesWarmed || 'unknown'}`);\n      console.log(`  Duration: ${data.duration || 'unknown'}ms`);\n    } else {\n      console.error('Cache warming failed:', response.status, response.statusText);\n    }\n  } catch (error) {\n    console.error('Cache warming error:', error);\n  }\n}\n\nfunction printReport(report: HealthReport): void {\n  console.log('\\n' + '='.repeat(60));\n  console.log('CACHE HEALTH REPORT');\n  console.log('='.repeat(60));\n  console.log(`Timestamp: ${report.timestamp}`);\n  console.log('');\n  console.log(`Cache Hit Rate: ${report.hitRate.toFixed(1)}%`);\n  console.log(`  Hits: ${report.cacheHits}`);\n  console.log(`  Misses: ${report.cacheMisses}`);\n  console.log(`  Errors: ${report.errors}`);\n  console.log('');\n  console.log(`Response Times:`);\n  console.log(`  Average: ${report.avgResponseTime.toFixed(0)}ms`);\n  console.log(`  Slowest: ${report.slowestCity} (${report.slowestTime}ms)`);\n\n  if (report.recommendations.length > 0) {\n    console.log('');\n    console.log('RECOMMENDATIONS:');\n    for (const rec of report.recommendations) {\n      console.log(`  ⚠ ${rec}`);\n    }\n  } else {\n    console.log('');\n    console.log('✓ All metrics within acceptable ranges');\n  }\n\n  console.log('='.repeat(60));\n}\n\nasync function main(): Promise<void> {\n  const args = process.argv.slice(2);\n  const verbose = args.includes('--verbose') || args.includes('-v');\n  const shouldWarm = args.includes('--warm');\n\n  if (shouldWarm) {\n    await warmCache();\n    console.log('');\n  }\n\n  const report = await runHealthCheck(verbose);\n  printReport(report);\n\n  // Save report to file for CI integration\n  const reportPath = '/tmp/cache-health-report.json';\n  fs.writeFileSync(reportPath, JSON.stringify(report, null, 2));\n  console.log(`\\nFull report saved to: ${reportPath}`);\n\n  // Exit with error if hit rate is critically low\n  if (report.hitRate < 50) {\n    console.error('\\nCRITICAL: Cache hit rate below 50%!');\n    process.exit(1);\n  }\n}\n\nmain().catch(console.error);\n"
        },
        {
          "name": "crisis-path-test.ts",
          "type": "file",
          "path": "sobriety-tools-guardian/scripts/crisis-path-test.ts",
          "size": 10418,
          "content": "#!/usr/bin/env npx tsx\n/**\n * Crisis Path Testing for sobriety.tools\n *\n * Tests the critical user journeys that must work during a crisis:\n * 1. Contacts page loads instantly (sponsor numbers)\n * 2. Safety plan is accessible\n * 3. Meetings can be found\n * 4. Check-in form is interactive quickly\n *\n * These paths are life-or-death. A user in crisis has seconds, not minutes.\n *\n * Usage:\n *   npx tsx scripts/crisis-path-test.ts\n *   npx tsx scripts/crisis-path-test.ts --ci  # Exit with error on failure\n */\n\nimport { execSync } from 'child_process';\nimport * as fs from 'fs';\n\nconst SITE_URL = 'https://sobriety.tools';\n\n// Maximum acceptable times for crisis-critical paths (milliseconds)\nconst CRISIS_THRESHOLDS = {\n  // Contacts: User needs sponsor number NOW\n  contacts_fcp: 200, // First paint - see something\n  contacts_lcp: 500, // Main content - see phone numbers\n  contacts_tti: 800, // Interactive - can tap to call\n\n  // Safety Plan: User needs their coping strategies\n  safety_plan_fcp: 200,\n  safety_plan_lcp: 600,\n\n  // Meetings: User needs to find a meeting to attend\n  meetings_fcp: 300,\n  meetings_lcp: 1000,\n  meetings_search: 500, // Time to show results after location\n\n  // Check-in: User needs to record how they're feeling\n  checkin_fcp: 200,\n  checkin_tti: 400, // Can start inputting immediately\n\n  // Crisis page: Hotline numbers\n  crisis_fcp: 150,\n  crisis_lcp: 400,\n};\n\ninterface PathTestResult {\n  path: string;\n  name: string;\n  passed: boolean;\n  metrics: {\n    fcp?: number;\n    lcp?: number;\n    tti?: number;\n    cls?: number;\n  };\n  thresholds: {\n    fcp?: number;\n    lcp?: number;\n    tti?: number;\n  };\n  failures: string[];\n  isCritical: boolean;\n}\n\ninterface TestReport {\n  timestamp: string;\n  allPassed: boolean;\n  criticalFailures: number;\n  results: PathTestResult[];\n  offlineCapable: boolean;\n  serviceWorkerPresent: boolean;\n}\n\nasync function testPathWithLighthouse(\n  path: string,\n  name: string,\n  thresholds: { fcp?: number; lcp?: number; tti?: number },\n  isCritical: boolean\n): Promise<PathTestResult> {\n  const url = `${SITE_URL}${path}`;\n  const outputPath = `/tmp/lighthouse-crisis-${path.replace(/\\//g, '-') || 'home'}.json`;\n\n  try {\n    console.log(`  Testing ${name} (${path})...`);\n\n    execSync(\n      `npx lighthouse \"${url}\" --output=json --output-path=\"${outputPath}\" --chrome-flags=\"--headless --no-sandbox\" --only-categories=performance 2>/dev/null`,\n      { stdio: 'pipe', timeout: 60000 }\n    );\n\n    const report = JSON.parse(fs.readFileSync(outputPath, 'utf-8'));\n\n    const metrics = {\n      fcp: Math.round(report.audits['first-contentful-paint']?.numericValue || 0),\n      lcp: Math.round(report.audits['largest-contentful-paint']?.numericValue || 0),\n      tti: Math.round(report.audits['interactive']?.numericValue || 0),\n      cls: report.audits['cumulative-layout-shift']?.numericValue || 0,\n    };\n\n    const failures: string[] = [];\n\n    if (thresholds.fcp && metrics.fcp > thresholds.fcp) {\n      failures.push(`FCP ${metrics.fcp}ms > ${thresholds.fcp}ms threshold`);\n    }\n    if (thresholds.lcp && metrics.lcp > thresholds.lcp) {\n      failures.push(`LCP ${metrics.lcp}ms > ${thresholds.lcp}ms threshold`);\n    }\n    if (thresholds.tti && metrics.tti > thresholds.tti) {\n      failures.push(`TTI ${metrics.tti}ms > ${thresholds.tti}ms threshold`);\n    }\n    if (metrics.cls > 0.1) {\n      failures.push(`CLS ${metrics.cls.toFixed(3)} > 0.1 threshold (layout shift)`);\n    }\n\n    return {\n      path,\n      name,\n      passed: failures.length === 0,\n      metrics,\n      thresholds,\n      failures,\n      isCritical,\n    };\n  } catch (error) {\n    return {\n      path,\n      name,\n      passed: false,\n      metrics: {},\n      thresholds,\n      failures: [`Lighthouse failed: ${error}`],\n      isCritical,\n    };\n  }\n}\n\nasync function testServiceWorker(): Promise<{ present: boolean; offlineRoutes: string[] }> {\n  try {\n    const response = await fetch(`${SITE_URL}/sw.js`);\n    if (!response.ok) {\n      return { present: false, offlineRoutes: [] };\n    }\n\n    const swContent = await response.text();\n\n    // Check for crisis-critical routes in service worker\n    const crisisRoutes = ['/contacts', '/safety-plan', '/check-in', '/crisis'];\n    const offlineRoutes = crisisRoutes.filter((route) => swContent.includes(route));\n\n    return { present: true, offlineRoutes };\n  } catch {\n    return { present: false, offlineRoutes: [] };\n  }\n}\n\nasync function testMeetingSearchSpeed(): Promise<{ passed: boolean; time: number }> {\n  const proxyUrl = 'https://jb4l-meeting-proxy.erich-owens.workers.dev';\n\n  try {\n    const start = Date.now();\n    const response = await fetch(\n      `${proxyUrl}/api/all?lat=45.52&lng=-122.68&radius=25`,\n      { headers: { Origin: 'https://sobriety.tools' } }\n    );\n    const time = Date.now() - start;\n\n    if (!response.ok) {\n      return { passed: false, time };\n    }\n\n    const data = await response.json();\n    const hasMeetings = data.meetings && data.meetings.length > 0;\n\n    return {\n      passed: hasMeetings && time < CRISIS_THRESHOLDS.meetings_search,\n      time,\n    };\n  } catch {\n    return { passed: false, time: 999999 };\n  }\n}\n\nasync function runCrisisPathTests(): Promise<TestReport> {\n  console.log('='.repeat(60));\n  console.log('CRISIS PATH TESTING');\n  console.log('='.repeat(60));\n  console.log('Testing paths that must work when users are in crisis...\\n');\n\n  const results: PathTestResult[] = [];\n\n  // Test each critical path\n  console.log('Testing page load times...');\n\n  results.push(\n    await testPathWithLighthouse(\n      '/contacts',\n      'Contacts (Sponsor Numbers)',\n      {\n        fcp: CRISIS_THRESHOLDS.contacts_fcp,\n        lcp: CRISIS_THRESHOLDS.contacts_lcp,\n        tti: CRISIS_THRESHOLDS.contacts_tti,\n      },\n      true // CRITICAL\n    )\n  );\n\n  results.push(\n    await testPathWithLighthouse(\n      '/safety-plan',\n      'Safety Plan',\n      {\n        fcp: CRISIS_THRESHOLDS.safety_plan_fcp,\n        lcp: CRISIS_THRESHOLDS.safety_plan_lcp,\n      },\n      true // CRITICAL\n    )\n  );\n\n  results.push(\n    await testPathWithLighthouse(\n      '/meetings',\n      'Meeting Finder',\n      {\n        fcp: CRISIS_THRESHOLDS.meetings_fcp,\n        lcp: CRISIS_THRESHOLDS.meetings_lcp,\n      },\n      true // CRITICAL\n    )\n  );\n\n  results.push(\n    await testPathWithLighthouse(\n      '/check-in',\n      'Daily Check-in',\n      {\n        fcp: CRISIS_THRESHOLDS.checkin_fcp,\n        tti: CRISIS_THRESHOLDS.checkin_tti,\n      },\n      false // Important but not critical\n    )\n  );\n\n  // Test service worker\n  console.log('\\nTesting offline capability...');\n  const swTest = await testServiceWorker();\n\n  // Test meeting search API directly\n  console.log('Testing meeting search speed...');\n  const searchTest = await testMeetingSearchSpeed();\n\n  if (!searchTest.passed) {\n    results.push({\n      path: '/api/meetings',\n      name: 'Meeting Search API',\n      passed: false,\n      metrics: { lcp: searchTest.time },\n      thresholds: { lcp: CRISIS_THRESHOLDS.meetings_search },\n      failures: [`Search took ${searchTest.time}ms (threshold: ${CRISIS_THRESHOLDS.meetings_search}ms)`],\n      isCritical: true,\n    });\n  }\n\n  // Count failures\n  const criticalFailures = results.filter((r) => r.isCritical && !r.passed).length;\n  const allPassed = results.every((r) => r.passed) && swTest.present;\n\n  return {\n    timestamp: new Date().toISOString(),\n    allPassed,\n    criticalFailures,\n    results,\n    offlineCapable: swTest.offlineRoutes.length >= 3,\n    serviceWorkerPresent: swTest.present,\n  };\n}\n\nfunction printReport(report: TestReport): void {\n  console.log('\\n' + '='.repeat(60));\n  console.log('RESULTS');\n  console.log('='.repeat(60));\n\n  for (const result of report.results) {\n    const icon = result.passed ? '✓' : '✗';\n    const critical = result.isCritical ? '[CRITICAL]' : '';\n\n    console.log(`\\n${icon} ${result.name} ${critical}`);\n    console.log(`  Path: ${result.path}`);\n\n    if (result.metrics.fcp) {\n      const fcpOk = !result.thresholds.fcp || result.metrics.fcp <= result.thresholds.fcp;\n      console.log(`  FCP: ${result.metrics.fcp}ms ${fcpOk ? '✓' : '✗'} (threshold: ${result.thresholds.fcp || 'n/a'}ms)`);\n    }\n    if (result.metrics.lcp) {\n      const lcpOk = !result.thresholds.lcp || result.metrics.lcp <= result.thresholds.lcp;\n      console.log(`  LCP: ${result.metrics.lcp}ms ${lcpOk ? '✓' : '✗'} (threshold: ${result.thresholds.lcp || 'n/a'}ms)`);\n    }\n    if (result.metrics.tti) {\n      const ttiOk = !result.thresholds.tti || result.metrics.tti <= result.thresholds.tti;\n      console.log(`  TTI: ${result.metrics.tti}ms ${ttiOk ? '✓' : '✗'} (threshold: ${result.thresholds.tti || 'n/a'}ms)`);\n    }\n\n    if (result.failures.length > 0) {\n      for (const failure of result.failures) {\n        console.log(`  ⚠ ${failure}`);\n      }\n    }\n  }\n\n  console.log('\\n' + '-'.repeat(60));\n  console.log('OFFLINE CAPABILITY');\n  console.log('-'.repeat(60));\n  console.log(`Service Worker: ${report.serviceWorkerPresent ? '✓ Present' : '✗ Missing'}`);\n  console.log(`Offline Ready: ${report.offlineCapable ? '✓ Yes' : '✗ No'}`);\n\n  console.log('\\n' + '='.repeat(60));\n  console.log('SUMMARY');\n  console.log('='.repeat(60));\n\n  if (report.allPassed) {\n    console.log('✓ All crisis paths are performant and accessible');\n  } else {\n    console.log(`✗ ${report.criticalFailures} CRITICAL failures`);\n    console.log('');\n    console.log('CRITICAL FAILURES MEAN USERS IN CRISIS MAY NOT GET HELP');\n    console.log('Fix these issues immediately.');\n  }\n\n  console.log('='.repeat(60));\n}\n\nasync function main(): Promise<void> {\n  const args = process.argv.slice(2);\n  const ciMode = args.includes('--ci');\n\n  const report = await runCrisisPathTests();\n  printReport(report);\n\n  // Save report\n  const reportPath = '/tmp/crisis-path-report.json';\n  fs.writeFileSync(reportPath, JSON.stringify(report, null, 2));\n  console.log(`\\nFull report saved to: ${reportPath}`);\n\n  // In CI mode, exit with error if critical paths fail\n  if (ciMode && report.criticalFailures > 0) {\n    console.error(`\\nCI FAILURE: ${report.criticalFailures} critical crisis paths failed`);\n    process.exit(1);\n  }\n\n  if (!report.serviceWorkerPresent) {\n    console.warn('\\n⚠ WARNING: No service worker detected. Offline access is broken.');\n    if (ciMode) {\n      process.exit(1);\n    }\n  }\n}\n\nmain().catch(console.error);\n"
        },
        {
          "name": "perf-audit.ts",
          "type": "file",
          "path": "sobriety-tools-guardian/scripts/perf-audit.ts",
          "size": 12588,
          "content": "#!/usr/bin/env npx tsx\n/**\n * Automated Performance Audit for sobriety.tools\n *\n * Runs comprehensive performance checks and files GitHub issues for regressions.\n * Designed to run in CI or as a scheduled background task.\n *\n * Usage:\n *   npx tsx scripts/perf-audit.ts\n *   npx tsx scripts/perf-audit.ts --create-issues\n *   npx tsx scripts/perf-audit.ts --fix  # Attempt auto-fixes\n */\n\nimport { execSync } from 'child_process';\nimport * as fs from 'fs';\nimport * as path from 'path';\n\nconst SITE_URL = 'https://sobriety.tools';\nconst THRESHOLDS = {\n  lighthouse_performance: 0.9,\n  lighthouse_accessibility: 0.95,\n  fcp_ms: 1500,\n  lcp_ms: 2500,\n  tti_ms: 3500,\n  bundle_size_kb: 500,\n  meeting_search_ms: 500,\n  contacts_load_ms: 200,\n};\n\ninterface AuditResult {\n  check: string;\n  passed: boolean;\n  value: number | string;\n  threshold: number | string;\n  severity: 'critical' | 'high' | 'medium' | 'low';\n  description: string;\n  suggestedFix?: string;\n}\n\nconst results: AuditResult[] = [];\n\n// =============================================================================\n// LIGHTHOUSE AUDIT\n// =============================================================================\n\nasync function runLighthouse(): Promise<void> {\n  console.log('Running Lighthouse audit...');\n\n  const criticalPages = [\n    '/',\n    '/meetings',\n    '/my/contacts',\n    '/my/check-in',\n    '/my/safety-plan',\n  ];\n\n  for (const page of criticalPages) {\n    try {\n      const url = `${SITE_URL}${page}`;\n      const outputPath = `/tmp/lighthouse-${page.replace(/\\//g, '-') || 'home'}.json`;\n\n      execSync(\n        `npx lighthouse \"${url}\" --output=json --output-path=\"${outputPath}\" --chrome-flags=\"--headless --no-sandbox\" --only-categories=performance,accessibility 2>/dev/null`,\n        { stdio: 'pipe' }\n      );\n\n      const report = JSON.parse(fs.readFileSync(outputPath, 'utf-8'));\n      const perfScore = report.categories.performance.score;\n      const a11yScore = report.categories.accessibility.score;\n\n      results.push({\n        check: `Lighthouse Performance: ${page}`,\n        passed: perfScore >= THRESHOLDS.lighthouse_performance,\n        value: perfScore,\n        threshold: THRESHOLDS.lighthouse_performance,\n        severity: perfScore < 0.7 ? 'critical' : perfScore < 0.85 ? 'high' : 'medium',\n        description: `Performance score for ${page}: ${(perfScore * 100).toFixed(0)}%`,\n        suggestedFix: perfScore < 0.9\n          ? `Review LCP and TTI. Check for:\\n- Large images without lazy loading\\n- Render-blocking scripts\\n- Unused JavaScript`\n          : undefined,\n      });\n\n      results.push({\n        check: `Lighthouse Accessibility: ${page}`,\n        passed: a11yScore >= THRESHOLDS.lighthouse_accessibility,\n        value: a11yScore,\n        threshold: THRESHOLDS.lighthouse_accessibility,\n        severity: a11yScore < 0.8 ? 'high' : 'medium',\n        description: `Accessibility score for ${page}: ${(a11yScore * 100).toFixed(0)}%`,\n      });\n\n      // Extract specific metrics\n      const fcp = report.audits['first-contentful-paint'].numericValue;\n      const lcp = report.audits['largest-contentful-paint'].numericValue;\n      const tti = report.audits['interactive'].numericValue;\n\n      if (page === '/contacts') {\n        results.push({\n          check: `Contacts FCP (Crisis Critical)`,\n          passed: fcp < THRESHOLDS.contacts_load_ms,\n          value: Math.round(fcp),\n          threshold: THRESHOLDS.contacts_load_ms,\n          severity: fcp > 500 ? 'critical' : 'high',\n          description: `Contacts page FCP: ${Math.round(fcp)}ms. Users in crisis need instant access to sponsor numbers.`,\n          suggestedFix: fcp > 200\n            ? `CRITICAL: Contacts must render from cache first.\\n1. Implement IndexedDB cache for contacts\\n2. Show cached data immediately\\n3. Sync in background`\n            : undefined,\n        });\n      }\n\n      if (page === '/meetings') {\n        results.push({\n          check: `Meetings LCP`,\n          passed: lcp < THRESHOLDS.meeting_search_ms * 3,\n          value: Math.round(lcp),\n          threshold: THRESHOLDS.meeting_search_ms * 3,\n          severity: lcp > 2000 ? 'high' : 'medium',\n          description: `Meetings page LCP: ${Math.round(lcp)}ms`,\n        });\n      }\n    } catch (error) {\n      console.error(`Lighthouse failed for ${page}:`, error);\n    }\n  }\n}\n\n// =============================================================================\n// BUNDLE SIZE AUDIT\n// =============================================================================\n\nasync function checkBundleSize(): Promise<void> {\n  console.log('Checking bundle sizes...');\n\n  const nextDir = path.join(process.cwd(), 'next-app/.next');\n  if (!fs.existsSync(nextDir)) {\n    console.log('No .next directory found, skipping bundle check');\n    return;\n  }\n\n  try {\n    const buildManifest = JSON.parse(\n      fs.readFileSync(path.join(nextDir, 'build-manifest.json'), 'utf-8')\n    );\n\n    // Check main bundle size\n    const mainChunks = buildManifest.pages['/_app'] || [];\n    let totalSize = 0;\n\n    for (const chunk of mainChunks) {\n      const chunkPath = path.join(nextDir, 'static', chunk);\n      if (fs.existsSync(chunkPath)) {\n        totalSize += fs.statSync(chunkPath).size;\n      }\n    }\n\n    const sizeKb = Math.round(totalSize / 1024);\n    results.push({\n      check: 'Main Bundle Size',\n      passed: sizeKb < THRESHOLDS.bundle_size_kb,\n      value: sizeKb,\n      threshold: THRESHOLDS.bundle_size_kb,\n      severity: sizeKb > 750 ? 'high' : 'medium',\n      description: `Main bundle: ${sizeKb}KB (threshold: ${THRESHOLDS.bundle_size_kb}KB)`,\n      suggestedFix: sizeKb > THRESHOLDS.bundle_size_kb\n        ? `Bundle too large. Actions:\\n1. Run \\`npx @next/bundle-analyzer\\`\\n2. Identify large dependencies\\n3. Use dynamic imports for non-critical code`\n        : undefined,\n    });\n  } catch (error) {\n    console.error('Bundle size check failed:', error);\n  }\n}\n\n// =============================================================================\n// MEETING PROXY HEALTH\n// =============================================================================\n\nasync function checkMeetingProxy(): Promise<void> {\n  console.log('Checking meeting proxy health...');\n\n  const testLocations = [\n    { name: 'Portland', lat: 45.52, lng: -122.68 },\n    { name: 'Los Angeles', lat: 34.05, lng: -118.24 },\n    { name: 'New York', lat: 40.71, lng: -74.01 },\n  ];\n\n  for (const loc of testLocations) {\n    try {\n      const start = Date.now();\n      const response = await fetch(\n        `https://jb4l-meeting-proxy.erich-owens.workers.dev/api/all?lat=${loc.lat}&lng=${loc.lng}&radius=25`,\n        { headers: { Origin: 'https://sobriety.tools' } }\n      );\n      const duration = Date.now() - start;\n\n      const cacheStatus = response.headers.get('X-Cache');\n      const data = await response.json();\n\n      results.push({\n        check: `Meeting Proxy: ${loc.name}`,\n        passed: duration < THRESHOLDS.meeting_search_ms && cacheStatus === 'HIT',\n        value: `${duration}ms (${cacheStatus})`,\n        threshold: `${THRESHOLDS.meeting_search_ms}ms (HIT)`,\n        severity: duration > 1000 ? 'high' : 'medium',\n        description: `${loc.name}: ${duration}ms, cache ${cacheStatus}, ${data.meetings?.length || 0} meetings`,\n        suggestedFix: cacheStatus !== 'HIT'\n          ? `Cache miss for ${loc.name}. Run cache warm: curl https://jb4l-meeting-proxy.erich-owens.workers.dev/warm`\n          : undefined,\n      });\n    } catch (error) {\n      results.push({\n        check: `Meeting Proxy: ${loc.name}`,\n        passed: false,\n        value: 'ERROR',\n        threshold: 'Response',\n        severity: 'critical',\n        description: `Meeting proxy failed for ${loc.name}: ${error}`,\n        suggestedFix: 'Check meeting-proxy Worker logs in Cloudflare dashboard',\n      });\n    }\n  }\n}\n\n// =============================================================================\n// OFFLINE CAPABILITY CHECK\n// =============================================================================\n\nasync function checkServiceWorker(): Promise<void> {\n  console.log('Checking service worker...');\n\n  try {\n    const response = await fetch(`${SITE_URL}/sw.js`);\n    const swContent = await response.text();\n\n    const criticalRoutes = ['/my/contacts', '/my/safety-plan', '/my/check-in'];\n    const missingRoutes = criticalRoutes.filter(\n      (route) => !swContent.includes(route)\n    );\n\n    results.push({\n      check: 'Service Worker: Crisis Routes',\n      passed: missingRoutes.length === 0,\n      value: missingRoutes.length === 0 ? 'All cached' : `Missing: ${missingRoutes.join(', ')}`,\n      threshold: 'All crisis routes cached',\n      severity: missingRoutes.length > 0 ? 'critical' : 'low',\n      description: `Service worker must cache crisis-critical routes for offline access`,\n      suggestedFix: missingRoutes.length > 0\n        ? `Add these routes to SW cache: ${missingRoutes.join(', ')}\\nUsers in crisis with poor connectivity MUST access these offline.`\n        : undefined,\n    });\n  } catch (error) {\n    results.push({\n      check: 'Service Worker',\n      passed: false,\n      value: 'Not found',\n      threshold: 'Present',\n      severity: 'critical',\n      description: 'No service worker found. Offline functionality broken.',\n      suggestedFix: 'Implement service worker with Workbox or next-pwa',\n    });\n  }\n}\n\n// =============================================================================\n// GITHUB ISSUE CREATION\n// =============================================================================\n\nasync function createGitHubIssue(result: AuditResult): Promise<void> {\n  const token = process.env.GITHUB_TOKEN;\n  if (!token) {\n    console.log('No GITHUB_TOKEN, skipping issue creation');\n    return;\n  }\n\n  const body = `## Automated Performance Alert\n\n**Check**: ${result.check}\n**Severity**: ${result.severity.toUpperCase()}\n**Current Value**: ${result.value}\n**Threshold**: ${result.threshold}\n\n### Description\n${result.description}\n\n${result.suggestedFix ? `### Suggested Fix\\n${result.suggestedFix}` : ''}\n\n---\n*This issue was automatically created by the performance audit.*\n`;\n\n  try {\n    await fetch('https://api.github.com/repos/erichowens/sobriety-tools/issues', {\n      method: 'POST',\n      headers: {\n        Authorization: `token ${token}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        title: `[Perf] ${result.check}: ${result.severity}`,\n        body,\n        labels: ['performance', 'automated', result.severity],\n      }),\n    });\n    console.log(`Created issue for: ${result.check}`);\n  } catch (error) {\n    console.error('Failed to create GitHub issue:', error);\n  }\n}\n\n// =============================================================================\n// MAIN\n// =============================================================================\n\nasync function main(): Promise<void> {\n  const createIssues = process.argv.includes('--create-issues');\n\n  console.log('='.repeat(60));\n  console.log('SOBRIETY.TOOLS PERFORMANCE AUDIT');\n  console.log('='.repeat(60));\n  console.log('');\n\n  await runLighthouse();\n  await checkBundleSize();\n  await checkMeetingProxy();\n  await checkServiceWorker();\n\n  // Report results\n  console.log('\\n' + '='.repeat(60));\n  console.log('RESULTS');\n  console.log('='.repeat(60));\n\n  const failed = results.filter((r) => !r.passed);\n  const critical = failed.filter((r) => r.severity === 'critical');\n  const high = failed.filter((r) => r.severity === 'high');\n\n  for (const result of results) {\n    const icon = result.passed ? '✓' : '✗';\n    const severity = result.passed ? '' : ` [${result.severity.toUpperCase()}]`;\n    console.log(`${icon} ${result.check}${severity}`);\n    console.log(`  Value: ${result.value} (threshold: ${result.threshold})`);\n    if (!result.passed && result.suggestedFix) {\n      console.log(`  Fix: ${result.suggestedFix.split('\\n')[0]}`);\n    }\n    console.log('');\n  }\n\n  console.log('='.repeat(60));\n  console.log(`SUMMARY: ${results.length - failed.length}/${results.length} passed`);\n  console.log(`Critical: ${critical.length}, High: ${high.length}`);\n  console.log('='.repeat(60));\n\n  // Create issues for critical/high severity failures\n  if (createIssues) {\n    const issuesToCreate = failed.filter(\n      (r) => r.severity === 'critical' || r.severity === 'high'\n    );\n    for (const result of issuesToCreate) {\n      await createGitHubIssue(result);\n    }\n  }\n\n  // Exit with error if critical issues found\n  if (critical.length > 0) {\n    process.exit(1);\n  }\n}\n\nmain().catch(console.error);\n"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "sobriety-tools-guardian/SKILL.md",
      "size": 8772,
      "content": "---\nname: sobriety-tools-guardian\ndescription: Performance optimization and continuous improvement for sobriety.tools recovery app. Use for load time optimization, offline capability, crisis detection, performance monitoring, automated issue detection. Activate on \"sobriety.tools\", \"recovery app perf\", \"crisis detection\", \"offline meetings\", \"HALT check-in\", \"sponsor contacts\". NOT for general Next.js help, unrelated Cloudflare Workers, or non-recovery apps.\nallowed-tools: Read,Write,Edit,Bash,Grep,Glob,Task,WebFetch\n---\n\n# Sobriety Tools Guardian\n\n**Mission**: Keep sobriety.tools fast enough to save lives. A fentanyl addict in crisis has seconds, not minutes. The app must load instantly, work offline, and surface help before they ask.\n\n## Why Performance Is Life-or-Death\n\n```\nCRISIS TIMELINE:\n0-30 seconds:  User opens app in distress\n30-60 seconds: Looking for sponsor number or meeting\n60-120 seconds: Decision point - call someone or use\n2+ minutes:    If still searching, may give up\n\nEVERY SECOND OF LOAD TIME = LIVES AT RISK\n```\n\n**Core truth**: This isn't a business app. Slow performance isn't \"bad UX\" - it's abandonment during crisis. The user staring at a spinner might be deciding whether to live or die.\n\n## Stack-Specific Optimization Knowledge\n\n### Architecture (Know This Cold)\n```\nNext.js 15 (static export) → Cloudflare Pages\n    ↓\nSupabase (PostgREST + PostGIS)\n    ↓\nCloudflare Workers:\n  - meeting-proxy (KV cached, geohash-based)\n  - meeting-harvester (hourly cron)\n  - claude-api (AI features)\n```\n\n### Critical Performance Paths\n\n**1. Meeting Search (MUST be &lt;500ms)**\n```\nUser location → Geohash (3-char ~150km cell)\n    → KV cache lookup (edge, ~5ms)\n    → Cache HIT: Return immediately\n    → Cache MISS: Supabase RPC find_current_meetings\n        → PostGIS ST_DWithin query\n        → Store in KV, return\n```\n**Bottleneck**: Cold Supabase queries. **Fix**: Pre-warm top 30 metros via /warm endpoint.\n\n**2. Sponsor/Contact List (MUST be &lt;200ms)**\n```\nUser opens contacts → Local IndexedDB first\n    → Show cached contacts instantly\n    → Background sync with Supabase\n    → Update UI if changes\n```\n**Anti-pattern**: Waiting for network before showing contacts. In crisis, show stale data immediately.\n\n**3. Check-in Flow (MUST be &lt;100ms to first input)**\n```\nOpen check-in → Pre-rendered form shell\n    → Load previous patterns async\n    → Submit optimistically\n```\n\n### Offline-First Requirements (NON-NEGOTIABLE)\n\n```typescript\n// Service Worker must cache:\nconst CRISIS_CRITICAL = [\n  '/contacts',           // Sponsor phone numbers\n  '/safety-plan',        // User's safety plan\n  '/meetings?saved=true', // Saved meetings list\n  '/crisis',             // Crisis resources page\n];\n\n// These MUST work with zero network:\n// 1. View sponsor contacts\n// 2. View safety plan\n// 3. View saved meetings (even if stale)\n// 4. Record check-in (sync when online)\n```\n\n## Crisis Detection Patterns\n\n### Journal Sentiment Signals\n```typescript\n// RED FLAGS (surface help proactively):\nconst CRISIS_INDICATORS = {\n  anger_spike: 'HALT angry score jumps 3+ points',\n  ex_mentions: 'Mentions ex-partner 3+ times in week',\n  isolation: 'No check-ins for 3+ days after daily streak',\n  time_distortion: 'Check-ins at unusual hours (2-5am)',\n  negative_spiral: 'Consecutive declining mood scores',\n};\n\n// When detected: Surface sponsor contact, safety plan link\n// DO NOT: Be preachy or alarming. Gentle nudge only.\n```\n\n### Check-in Analysis\n```sql\n-- Detect concerning patterns\nSELECT user_id,\n  AVG(angry_score) as avg_anger,\n  AVG(angry_score) FILTER (WHERE created_at > NOW() - INTERVAL '3 days') as recent_anger,\n  COUNT(*) FILTER (WHERE EXTRACT(HOUR FROM created_at) BETWEEN 2 AND 5) as late_night_checkins\nFROM daily_checkins\nWHERE created_at > NOW() - INTERVAL '30 days'\nGROUP BY user_id\nHAVING AVG(angry_score) FILTER (WHERE created_at > NOW() - INTERVAL '3 days') >\n       AVG(angry_score) + 2;\n```\n\n## Performance Monitoring & Logging\n\n### Key Metrics to Track\n```typescript\n// Client-side (log to analytics)\nconst PERF_METRICS = {\n  ttfb: 'Time to First Byte',\n  fcp: 'First Contentful Paint',\n  lcp: 'Largest Contentful Paint',\n  tti: 'Time to Interactive',\n\n  // App-specific critical paths\n  contacts_visible: 'Time until sponsor list renders',\n  meeting_results: 'Time until first meeting card shows',\n  checkin_interactive: 'Time until check-in form accepts input',\n};\n\n// Log slow paths\nif (contactsVisibleTime > 500) {\n  logPerf('contacts_slow', { duration: contactsVisibleTime, network: navigator.connection?.effectiveType });\n}\n```\n\n### Automated Performance Regression Detection\n```bash\n# scripts/perf-audit.sh - Run in CI\nlighthouse https://sobriety.tools/meetings --output=json --output-path=./perf.json\nSCORE=$(jq '.categories.performance.score' perf.json)\nif (( $(echo \"$SCORE < 0.9\" | bc -l) )); then\n  echo \"Performance regression: $SCORE\"\n  # Create GitHub issue automatically\nfi\n```\n\n## Automated Issue Detection & Filing\n\n### Background Performance Scanner\n```typescript\n// Run hourly via Cloudflare Worker cron\nasync function performanceAudit() {\n  const checks = [\n    checkMeetingCacheHealth(),\n    checkSupabaseQueryTimes(),\n    checkStaticAssetSizes(),\n    checkServiceWorkerCoverage(),\n  ];\n\n  const issues = await Promise.all(checks);\n  const problems = issues.flat().filter(i => i.severity === 'high');\n\n  for (const problem of problems) {\n    await createGitHubIssue({\n      title: `[Auto] Perf: ${problem.title}`,\n      body: problem.description + '\\n\\n' + problem.suggestedFix,\n      labels: ['performance', 'automated'],\n    });\n  }\n}\n```\n\n## Common Anti-Patterns\n\n### 1. Network-Blocking Contact Display\n**Symptom**: Contacts page shows spinner while fetching\n**Problem**: User in crisis sees loading state instead of sponsor number\n**Solution**:\n```typescript\n// WRONG\nconst { data: contacts } = useQuery(['contacts'], fetchContacts);\n\n// RIGHT\nconst { data: contacts } = useQuery(['contacts'], fetchContacts, {\n  initialData: () => getCachedContacts(), // IndexedDB\n  staleTime: Infinity, // Never refetch automatically\n});\n```\n\n### 2. Uncached Meeting Searches\n**Symptom**: Every search hits Supabase\n**Problem**: 200-500ms latency on every search\n**Solution**: Geohash-based KV caching (already implemented in meeting-proxy)\n\n### 3. Large Bundle Blocking Interactivity\n**Symptom**: High TTI despite fast TTFB\n**Problem**: JavaScript bundle blocks main thread\n**Solution**:\n```typescript\n// Lazy load non-critical features\nconst JournalAI = dynamic(() => import('./JournalAI'), { ssr: false });\nconst Charts = dynamic(() => import('./Charts'), { loading: () => <ChartSkeleton /> });\n```\n\n### 4. Synchronous Check-in Submission\n**Symptom**: Button stays disabled during network request\n**Problem**: User thinks it didn't work, closes app\n**Solution**: Optimistic UI + background sync queue\n\n## Performance Optimization Checklist\n\n### Before Every Deploy\n- [ ] Bundle size delta &lt; 5KB\n- [ ] No new synchronous network calls in critical paths\n- [ ] Lighthouse performance score &gt;= 90\n- [ ] Offline mode tested (disable network in DevTools)\n\n### Weekly Audit\n- [ ] Review slow query logs in Supabase\n- [ ] Check KV cache hit rate (should be &gt;80%)\n- [ ] Analyze Real User Metrics (RUM) for P95 load times\n- [ ] Test on 3G throttled connection\n\n### Monthly Deep Dive\n- [ ] Profile React renders (why did this re-render?)\n- [ ] Audit third-party scripts\n- [ ] Review and prune unused dependencies\n- [ ] Test crisis flows end-to-end on real device\n\n## Scripts Available\n\n| Script | Purpose |\n|--------|---------|\n| `scripts/perf-audit.ts` | Run Lighthouse + custom checks, file issues |\n| `scripts/cache-health.ts` | Check KV cache hit rates and staleness |\n| `scripts/crisis-path-test.ts` | Automated test of crisis-critical flows |\n| `scripts/bundle-analyzer.ts` | Track bundle size over time |\n\n## Integration Points\n\n### With meeting-harvester\n- After harvest, warm cache for top metros\n- Monitor harvest duration and meeting counts\n- Alert if harvest fails (stale data = wrong meeting times)\n\n### With check-in system\n- Analyze patterns for crisis detection\n- Track submission success rate\n- Monitor offline queue depth\n\n### With contacts/sponsors\n- Ensure offline availability\n- Track time-to-display\n- Monitor sync failures\n\n## When to Escalate\n\n**File GitHub issue immediately if:**\n- Lighthouse score drops below 85\n- P95 meeting search > 1 second\n- Contacts page has any loading state > 200ms\n- Service Worker fails to cache crisis pages\n- Any user-reported \"couldn't load\" during crisis hours (evenings/weekends)\n\n**This is a recovery app. Performance isn't a feature - it's the difference between someone getting help and someone dying alone.**\n"
    }
  ]
}