{
  "name": "cost-verification-auditor",
  "type": "folder",
  "path": "cost-verification-auditor",
  "children": [
    {
      "name": "references",
      "type": "folder",
      "path": "cost-verification-auditor/references",
      "children": [
        {
          "name": "calibration-data.md",
          "type": "file",
          "path": "cost-verification-auditor/references/calibration-data.md",
          "size": 2735,
          "content": "# Calibration Data\n\nHistorical calibration data from actual API verification tests.\n\n## Calibration Run: 2026-01-30\n\n**Model**: claude-haiku-4-5-20251001\n**Target Accuracy**: ±20%\n**Result**: PASS (8.6% total cost variance)\n\n### Test Results\n\n| DAG | Complexity | Est. Input | Actual Input | Variance | Est. Output | Actual Output | Variance | Est. Cost | Actual Cost | Variance |\n|-----|------------|------------|--------------|----------|-------------|---------------|----------|-----------|-------------|----------|\n| Simple Research | simple | 102 | 112 | +9.8% | 123 | 184 | +49.6% | $0.000717 | $0.001032 | +43.9% |\n| Medium Pipeline | medium | 233 | 198 | -15.0% | 310 | 346 | +11.6% | $0.001783 | $0.001928 | +8.1% |\n| Complex Fan-Out | complex | 468 | 281 | -40.0% | 798 | 607 | -23.9% | $0.003340 | $0.003316 | -0.7% |\n| **TOTAL** | - | 803 | 591 | -26.4% | 1231 | 1137 | -7.6% | **$0.0058** | **$0.0063** | **+8.6%** |\n\n### Key Findings\n\n1. **Input estimation**: Overestimated by 26% on average\n2. **Output estimation**: Underestimated by 8% on average\n3. **Total cost**: Within target at 8.6% variance\n4. **Per-node variance**: Higher than aggregate (expected due to LLM non-determinism)\n\n### Calibration Parameters Used\n\n```typescript\nconst CHARS_PER_TOKEN = 3.5;  // Balanced for mixed text/code\nconst OVERHEAD_TOKENS = 10;    // Direct API call, no system prompt\nconst OUTPUT_MULTIPLIER = 1.2; // With 100 token minimum\n```\n\n### Prompt Characteristics\n\n| DAG | Total Chars | Nodes | Avg Chars/Node |\n|-----|-------------|-------|----------------|\n| Simple | 340 | 1 | 340 |\n| Medium | 755 | 3 | 252 |\n| Complex | 990 | 6 | 165 |\n\n### Recommendations from This Run\n\n- Input estimation is acceptable (within 20% aggregate)\n- Output estimation benefits from constrained prompts\n- Focus on total cost accuracy, not per-node accuracy\n- Consider increasing output multiplier for unconstrained prompts\n\n## Historical Trends\n\n| Date | Model | Overhead Used | Chars/Token | Total Variance | Status |\n|------|-------|---------------|-------------|----------------|--------|\n| 2026-01-30 | claude-haiku-4-5 | 10 | 3.5 | +8.6% | PASS |\n| (baseline) | - | 500 | 4.0 | +40-90% | FAIL |\n\n## Model Pricing (2026-01)\n\n| Model | Input $/M | Output $/M | Recommended For |\n|-------|-----------|------------|-----------------|\n| claude-opus-4-5 | $15.00 | $75.00 | Complex reasoning |\n| claude-sonnet-4 | $3.00 | $15.00 | Balanced tasks |\n| claude-haiku-4-5 | $1.00 | $5.00 | Cost-effective testing |\n| claude-3-5-haiku | $0.80 | $4.00 | Legacy |\n\n## Next Calibration\n\nSchedule quarterly recalibration to detect drift:\n- [ ] 2026-Q2: Re-run with updated prompts\n- [ ] 2026-Q3: Check against new model releases\n- [ ] 2026-Q4: Annual review\n"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "cost-verification-auditor/SKILL.md",
      "size": 5232,
      "content": "---\nname: cost-verification-auditor\ndescription: Audit LLM token cost estimates against actual API usage. Activate on 'cost verification', 'token estimate accuracy', 'API cost audit', 'estimation variance'. NOT for pricing lookups, budget planning, or cost optimization strategies.\nallowed-tools: Read,Write,Bash\n---\n\n# Cost Verification Auditor\n\nVerify that token cost estimates are within ±20% of actual Claude API usage.\n\n## When to Use\n\n✅ **Use for**:\n- Validating token estimation systems after implementation\n- Pre-deployment cost accuracy checks\n- Debugging unexpected API bills\n- Periodic estimation drift detection\n\n❌ **NOT for**:\n- Looking up model pricing (use pricing docs)\n- Budget planning or forecasting\n- Cost optimization strategies\n- Comparing models by price\n\n## Core Audit Process\n\n### Decision Tree\n\n```\nHas estimator? ──No──→ Build estimator first (see Calibration Guidelines)\n      │\n     Yes\n      ↓\nDefine 3+ test cases (simple/medium/complex)\n      ↓\nEstimate BEFORE execution (no peeking!)\n      ↓\nExecute against real API\n      ↓\nCalculate variance: (actual - estimated) / estimated\n      ↓\nVariance ≤ ±20%? ──Yes──→ PASS ✓\n      │\n     No\n      ↓\nApply fixes from Anti-Patterns section\n      ↓\nRe-run verification\n```\n\n### Variance Formula\n\n```typescript\nconst inputVariance = (actual.inputTokens - estimate.inputTokens) / estimate.inputTokens;\nconst outputVariance = (actual.outputTokens - estimate.outputTokens) / estimate.outputTokens;\nconst costVariance = (actual.totalCost - estimate.totalCost) / estimate.totalCost;\n\n// PASS if both input AND output within ±20%\nconst passed = Math.abs(inputVariance) <= 0.20 && Math.abs(outputVariance) <= 0.20;\n```\n\n## Common Anti-Patterns\n\n### Anti-Pattern: The 500-Token Overhead Myth\n\n**Novice thinking**: \"Claude Code adds ~500 tokens overhead, so add that to every estimate.\"\n\n**Reality**: Direct API calls have ~10 token overhead. The 500+ overhead is ONLY when using Claude Code's full context (system prompts, tools, conversation history).\n\n**Timeline**:\n- Pre-2025: Many tutorials used 500+ token estimates\n- 2025+: Direct API overhead is minimal (~10 tokens)\n\n**What to use instead**:\n| Context | Overhead |\n|---------|----------|\n| Direct API call | ~10 tokens |\n| With system prompt | 50-200 tokens |\n| With tools/functions | 100-500 tokens |\n| Claude Code full context | 500-2000 tokens |\n\n**How to detect**: Consistent 40-90% overestimation = overhead too high.\n\n---\n\n### Anti-Pattern: Per-Node Accuracy Obsession\n\n**Novice thinking**: \"Every node must be within ±20% or the estimator is broken.\"\n\n**Reality**: LLM output length is non-deterministic. Per-node output variance of 30-50% is normal. What matters is **aggregate cost accuracy**.\n\n**What to use instead**:\n- Focus on total DAG cost variance (should be ±20%)\n- Accept per-node output variance up to ±40%\n- Use constrained prompts (\"list exactly 3\") to reduce variance\n\n**How to detect**: Input estimates accurate, output varies wildly = normal LLM behavior.\n\n---\n\n### Anti-Pattern: Peeking Before Estimating\n\n**Novice thinking**: \"Let me run the API call first to see what tokens we get, then build the estimator.\"\n\n**Reality**: This produces perfectly-fitted estimates that fail on new prompts. Estimation must happen BEFORE execution.\n\n**Correct approach**:\n1. Estimate based on prompt length and heuristics\n2. Execute API call\n3. Compare variance\n4. Adjust heuristics if needed\n\n## Calibration Guidelines\n\n### Input Token Estimation\n\n```typescript\n// Calibrated 2026-01-30\nconst inputTokens = Math.ceil(prompt.length / CHARS_PER_TOKEN) + OVERHEAD;\n```\n\n| Text Type | CHARS_PER_TOKEN | Notes |\n|-----------|-----------------|-------|\n| English prose | 4.0 | Most consistent |\n| Code | 3.0-3.5 | Symbols tokenize differently |\n| Mixed | 3.5 | Balanced (recommended default) |\n| JSON/structured | 3.0 | Punctuation heavy |\n\n### Output Token Estimation\n\n| Prompt Constraint | Multiplier | Notes |\n|-------------------|------------|-------|\n| \"List exactly N items\" | 0.8x input | Highly constrained |\n| \"Brief summary\" | 1.0x input | Moderate |\n| \"Explain in detail\" | 2-3x input | Expansive |\n| Unconstrained | 1.5x input | Variable |\n\n**Always**: Minimum 100 output tokens for any meaningful response.\n\n### Model Behavior\n\n| Model | Output Tendency |\n|-------|-----------------|\n| Claude Opus | Longer, more detailed |\n| Claude Sonnet | Balanced |\n| Claude Haiku | Concise, efficient |\n\n## Quick Fixes\n\n| Symptom | Cause | Fix |\n|---------|-------|-----|\n| Overestimating by 40%+ | Overhead too high | Reduce from 500 → 10 |\n| Underestimating inputs | Chars/token too high | Reduce from 4.0 → 3.5 |\n| Output wildly varies | LLM non-determinism | Use constrained prompts |\n| Total cost accurate but per-node off | Normal aggregation | Accept it, focus on totals |\n\n## Verification Checklist\n\n- [ ] 3+ test cases (simple, medium, complex)\n- [ ] Estimates run BEFORE API calls\n- [ ] Variance formula: `(actual - estimated) / estimated`\n- [ ] Target: ±20% for input AND output\n- [ ] Report includes actionable recommendations\n\n## References\n\nSee `/references/calibration-data.md` for detailed calibration tables and historical data.\n"
    }
  ]
}