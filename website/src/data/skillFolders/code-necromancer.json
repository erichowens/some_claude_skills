{
  "name": "code-necromancer",
  "type": "folder",
  "path": "code-necromancer",
  "children": [
    {
      "name": "references",
      "type": "folder",
      "path": "code-necromancer/references",
      "children": [
        {
          "name": "archaeology-guide.md",
          "type": "file",
          "path": "code-necromancer/references/archaeology-guide.md",
          "size": 7520,
          "content": "# Code Archaeology Guide\n\nA deep dive into techniques for understanding legacy codebases.\n\n## Philosophy\n\n**\"Understand before you touch.\"**\n\nThe cardinal rule of code archaeology is to fully map and understand a system before making any changes. Premature modification leads to:\n- Breaking unknown dependencies\n- Introducing regressions in untested code\n- Missing the actual architecture (vs. assumed architecture)\n- Wasted effort on deprecated components\n\n## The Archaeological Method\n\n### 1. Surface Survey\n\nStart with the broadest possible view:\n\n```bash\n# Get organization overview\ngh repo list ORG --limit 1000 --json name,description,primaryLanguage,pushedAt,isArchived\n\n# Count repos by language\ngh repo list ORG --json primaryLanguage -q '.[].primaryLanguage.name' | sort | uniq -c\n\n# Find most recently active\ngh repo list ORG --json name,pushedAt --jq 'sort_by(.pushedAt) | reverse | .[0:5]'\n\n# Find oldest\ngh repo list ORG --json name,createdAt --jq 'sort_by(.createdAt) | .[0:5]'\n```\n\n### 2. Stratification\n\nCategorize repos into layers:\n\n**Layer 1: User-Facing**\n- Web frontends\n- Mobile apps\n- CLI tools\n- Signs: \"react\", \"vue\", \"angular\", \"flutter\", \"swift\"\n\n**Layer 2: API Gateway**\n- Main API servers\n- GraphQL endpoints\n- Signs: \"express\", \"fastapi\", \"gin\", \"/api/\", \"graphql\"\n\n**Layer 3: Services**\n- Background workers\n- Microservices\n- Signs: \"worker\", \"service\", \"processor\", \"queue\"\n\n**Layer 4: Data**\n- Database migrations\n- Data pipelines\n- Signs: \"migrations\", \"etl\", \"pipeline\", \"warehouse\"\n\n**Layer 5: Infrastructure**\n- Deployment configs\n- Terraform/CDK\n- Signs: \"infra\", \"terraform\", \"cdk\", \"k8s\", \"deploy\"\n\n**Layer 6: Libraries**\n- Shared code\n- Internal packages\n- Signs: \"@org/\", \"common\", \"shared\", \"utils\", \"lib\"\n\n### 3. Excavation\n\nDeep dive into each significant repo:\n\n#### README Analysis\n```bash\n# Check for README\nls -la README*\n\n# Extract key sections\ngrep -A 10 \"^## \" README.md\n```\n\n#### Package Manifest Analysis\n```bash\n# Node.js - Find all package.json files\nfind . -name \"package.json\" -not -path \"*/node_modules/*\"\n\n# Extract dependencies\njq '.dependencies, .devDependencies' package.json\n\n# Find internal dependencies\njq '.dependencies | keys[] | select(startswith(\"@org\"))' package.json\n\n# Python - requirements\ncat requirements*.txt\n\n# Go - modules\ncat go.mod\n```\n\n#### Configuration Discovery\n```bash\n# Find all config files\nfind . -name \"*.config.*\" -o -name \".env*\" -o -name \"*.yaml\" -o -name \"*.yml\"\n\n# Extract environment variables from code\ngrep -r \"process.env\\.\" --include=\"*.js\" --include=\"*.ts\" | \\\n  sed 's/.*process.env.\\([A-Z_]*\\).*/\\1/' | sort -u\n\n# Python env vars\ngrep -r \"os.environ\\|os.getenv\" --include=\"*.py\" | \\\n  grep -oE '\"[A-Z_]+\"' | sort -u\n```\n\n#### Database Schema Discovery\n```bash\n# Find migration files\nfind . -name \"*migration*\" -o -name \"*schema*\" -type f\n\n# Look for ORM models\ngrep -r \"class.*Model\\|@Entity\\|db.Model\" --include=\"*.py\" --include=\"*.ts\" --include=\"*.js\"\n\n# Find SQL files\nfind . -name \"*.sql\"\n```\n\n#### API Endpoint Discovery\n```bash\n# Express routes\ngrep -r \"app\\.\\(get\\|post\\|put\\|delete\\|patch\\)\" --include=\"*.js\" --include=\"*.ts\"\n\n# FastAPI/Flask routes\ngrep -r \"@app\\.\\(get\\|post\\|put\\|delete\\|route\\)\" --include=\"*.py\"\n\n# Find OpenAPI/Swagger specs\nfind . -name \"swagger*\" -o -name \"openapi*\"\n```\n\n### 4. Dating (Timeline Reconstruction)\n\n```bash\n# First commit ever\ngit log --reverse --format=\"%H %ai %s\" | head -1\n\n# Last commit\ngit log -1 --format=\"%H %ai %s\"\n\n# Commits per month over project lifetime\ngit log --format=\"%ai\" | cut -d'-' -f1,2 | sort | uniq -c\n\n# Most active contributors\ngit shortlog -sn --all\n\n# When was each file last modified?\ngit ls-tree -r --name-only HEAD | while read f; do\n  echo \"$(git log -1 --format=\"%ai\" -- \"$f\") $f\"\ndone | sort -r\n```\n\n### 5. Cross-Referencing\n\nFind how repos connect:\n\n```bash\n# Find internal package references\ngrep -r \"@org/\" --include=\"package.json\" | grep -v node_modules\n\n# Find API calls between services\ngrep -r \"http://\\|https://\\|localhost:\" --include=\"*.js\" --include=\"*.ts\" --include=\"*.py\"\n\n# Find shared database names\ngrep -r \"DATABASE_URL\\|DB_NAME\\|MONGO_URI\" --include=\"*.env*\" --include=\"*.yaml\"\n```\n\n## Pattern Recognition\n\n### Common Architecture Patterns\n\n**Monolith Signs:**\n- Single repo with /api, /frontend, /workers directories\n- Single package.json with many scripts\n- Single database connection\n\n**Microservices Signs:**\n- Multiple repos with similar structure\n- Service discovery config (consul, eureka)\n- Message queues (RabbitMQ, Kafka, SQS)\n- API gateway repo\n\n**Monorepo Signs:**\n- Lerna/Nx/Turborepo config\n- packages/ or apps/ directory\n- Shared workspace dependencies\n\n**JAMstack Signs:**\n- Static site generators (Gatsby, Next, Hugo)\n- Netlify/Vercel configs\n- Headless CMS references\n\n### Common Problems to Look For\n\n**Dependency Hell:**\n- Multiple versions of same package\n- Circular dependencies between repos\n- Pinned versions that are EOL\n\n**Configuration Sprawl:**\n- Environment variables everywhere\n- No .env.example files\n- Hardcoded values in code\n\n**Documentation Rot:**\n- README refers to non-existent files\n- Installation instructions don't work\n- API docs don't match code\n\n**Test Desert:**\n- No test files\n- Empty test directories\n- Tests that don't run\n\n## Tools of the Trade\n\n### Essential CLI Tools\n\n```bash\n# Code statistics\ncloc .                    # Count lines of code\ntokei .                   # Faster alternative\n\n# Dependency analysis\nnpm ls --all              # Node dependency tree\npipdeptree                # Python dependency tree\ngo mod graph              # Go dependency graph\n\n# Security scanning\nnpm audit                 # Node vulnerabilities\nsafety check              # Python vulnerabilities\ngovulncheck ./...         # Go vulnerabilities\n\n# Git archaeology\ngit-fame                  # Contributor statistics\ngit log --graph --oneline # Visual history\n```\n\n### Visualization Tools\n\n- **Mermaid**: For architecture diagrams\n- **D2**: For more complex diagrams\n- **Graphviz**: For dependency graphs\n- **PlantUML**: For UML diagrams\n\n### Analysis Scripts\n\nSee `scripts/` directory for automated analysis tools.\n\n## Documentation Templates\n\n### Repo Profile Template\n\n```markdown\n# [Repo Name]\n\n## Purpose\n[One sentence description]\n\n## Category\n[core|support|library|deprecated|unknown]\n\n## Tech Stack\n- Language:\n- Framework:\n- Database:\n- Runtime:\n\n## Dependencies\n- Internal: [@org/lib1, @org/lib2]\n- External critical: [express, mongoose, ...]\n\n## Environment\n- Required vars: [LIST]\n- Config files: [LIST]\n\n## Status\n- Last active: [DATE]\n- Maturity: [1-5]\n- Test coverage: [%]\n\n## Notes\n[Anything notable discovered]\n```\n\n## Anti-Patterns to Avoid\n\n1. **Premature Optimization**: Don't start fixing things before understanding the whole\n2. **Tunnel Vision**: Don't focus too long on one interesting repo\n3. **Assumption Bias**: Don't assume you know what something does—verify\n4. **Documentation Trust**: Don't trust old docs—verify against code\n5. **Recency Bias**: Old repos may be more important than recent ones\n\n## Checklist: Is Archaeology Complete?\n\n- [ ] All repos identified and cataloged\n- [ ] Primary language/framework per repo known\n- [ ] Inter-repo dependencies mapped\n- [ ] External service dependencies listed\n- [ ] Database schemas identified\n- [ ] API surfaces documented\n- [ ] Environment requirements known\n- [ ] Core vs peripheral repos identified\n- [ ] Development timeline understood\n- [ ] Missing pieces documented\n- [ ] Architecture diagram created\n"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "folder",
      "path": "code-necromancer/scripts",
      "children": [
        {
          "name": "analyze-repo.sh",
          "type": "file",
          "path": "code-necromancer/scripts/analyze-repo.sh",
          "size": 12411,
          "content": "#!/bin/bash\n\n# Code Necromancer - Single Repository Analyzer\n# Deep analysis of a single repository\n\nset -e\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nCYAN='\\033[0;36m'\nNC='\\033[0m'\n\nusage() {\n    echo \"Usage: $0 <repo-path> [output-file]\"\n    echo \"\"\n    echo \"Performs deep analysis of a repository\"\n    echo \"\"\n    echo \"Arguments:\"\n    echo \"  repo-path   Path to cloned repository\"\n    echo \"  output-file Output JSON file (default: repo-analysis.json)\"\n}\n\nanalyze_repo() {\n    local REPO_PATH=$1\n    local OUTPUT_FILE=${2:-\"repo-analysis.json\"}\n\n    if [ ! -d \"$REPO_PATH\" ]; then\n        echo -e \"${RED}Error: Directory not found: $REPO_PATH${NC}\"\n        exit 1\n    fi\n\n    cd \"$REPO_PATH\"\n    local REPO_NAME=$(basename \"$REPO_PATH\")\n\n    echo -e \"${BLUE}═══════════════════════════════════════════════════════════${NC}\"\n    echo -e \"${BLUE}  Analyzing: $REPO_NAME${NC}\"\n    echo -e \"${BLUE}═══════════════════════════════════════════════════════════${NC}\"\n    echo \"\"\n\n    # Initialize JSON output\n    echo \"{\" > \"$OUTPUT_FILE\"\n    echo \"  \\\"name\\\": \\\"$REPO_NAME\\\",\" >> \"$OUTPUT_FILE\"\n    echo \"  \\\"analyzed_at\\\": \\\"$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\\\",\" >> \"$OUTPUT_FILE\"\n\n    # Git info\n    echo -e \"${CYAN}[1/10] Git History...${NC}\"\n    if [ -d \".git\" ]; then\n        FIRST_COMMIT=$(git log --reverse --format=\"%ai\" 2>/dev/null | head -1 || echo \"unknown\")\n        LAST_COMMIT=$(git log -1 --format=\"%ai\" 2>/dev/null || echo \"unknown\")\n        TOTAL_COMMITS=$(git rev-list --count HEAD 2>/dev/null || echo \"0\")\n        CONTRIBUTORS=$(git shortlog -sn --all 2>/dev/null | wc -l | tr -d ' ')\n        BRANCHES=$(git branch -a 2>/dev/null | wc -l | tr -d ' ')\n\n        echo \"  \\\"git\\\": {\" >> \"$OUTPUT_FILE\"\n        echo \"    \\\"first_commit\\\": \\\"$FIRST_COMMIT\\\",\" >> \"$OUTPUT_FILE\"\n        echo \"    \\\"last_commit\\\": \\\"$LAST_COMMIT\\\",\" >> \"$OUTPUT_FILE\"\n        echo \"    \\\"total_commits\\\": $TOTAL_COMMITS,\" >> \"$OUTPUT_FILE\"\n        echo \"    \\\"contributors\\\": $CONTRIBUTORS,\" >> \"$OUTPUT_FILE\"\n        echo \"    \\\"branches\\\": $BRANCHES\" >> \"$OUTPUT_FILE\"\n        echo \"  },\" >> \"$OUTPUT_FILE\"\n\n        echo \"    First commit: $FIRST_COMMIT\"\n        echo \"    Last commit: $LAST_COMMIT\"\n        echo \"    Total commits: $TOTAL_COMMITS\"\n    else\n        echo \"  \\\"git\\\": null,\" >> \"$OUTPUT_FILE\"\n        echo \"    Not a git repository\"\n    fi\n\n    # File structure\n    echo -e \"${CYAN}[2/10] File Structure...${NC}\"\n    TOTAL_FILES=$(find . -type f -not -path \"*/node_modules/*\" -not -path \"*/.git/*\" -not -path \"*/venv/*\" -not -path \"*/__pycache__/*\" 2>/dev/null | wc -l | tr -d ' ')\n    echo \"  \\\"total_files\\\": $TOTAL_FILES,\" >> \"$OUTPUT_FILE\"\n    echo \"    Files (excl. node_modules, .git): $TOTAL_FILES\"\n\n    # Language detection\n    echo -e \"${CYAN}[3/10] Languages...${NC}\"\n    echo \"  \\\"languages\\\": {\" >> \"$OUTPUT_FILE\"\n    FIRST=true\n    for ext in js ts jsx tsx py go java rb rs php; do\n        COUNT=$(find . -name \"*.$ext\" -not -path \"*/node_modules/*\" -not -path \"*/.git/*\" 2>/dev/null | wc -l | tr -d ' ')\n        if [ \"$COUNT\" -gt 0 ]; then\n            if [ \"$FIRST\" = true ]; then\n                FIRST=false\n            else\n                echo \",\" >> \"$OUTPUT_FILE\"\n            fi\n            echo -n \"    \\\"$ext\\\": $COUNT\" >> \"$OUTPUT_FILE\"\n            echo \"    $ext: $COUNT files\"\n        fi\n    done\n    echo \"\" >> \"$OUTPUT_FILE\"\n    echo \"  },\" >> \"$OUTPUT_FILE\"\n\n    # Framework detection\n    echo -e \"${CYAN}[4/10] Framework Detection...${NC}\"\n    FRAMEWORKS=\"\"\n\n    # Node.js / JavaScript\n    if [ -f \"package.json\" ]; then\n        if grep -q '\"react\"' package.json 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS React\"; fi\n        if grep -q '\"vue\"' package.json 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS Vue\"; fi\n        if grep -q '\"angular\"' package.json 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS Angular\"; fi\n        if grep -q '\"express\"' package.json 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS Express\"; fi\n        if grep -q '\"next\"' package.json 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS Next.js\"; fi\n        if grep -q '\"nest\"' package.json 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS NestJS\"; fi\n        if grep -q '\"electron\"' package.json 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS Electron\"; fi\n    fi\n\n    # Python\n    if [ -f \"requirements.txt\" ] || [ -f \"setup.py\" ] || [ -f \"pyproject.toml\" ]; then\n        if grep -qE \"django|Django\" requirements.txt setup.py pyproject.toml 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS Django\"; fi\n        if grep -qE \"flask|Flask\" requirements.txt setup.py pyproject.toml 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS Flask\"; fi\n        if grep -qE \"fastapi|FastAPI\" requirements.txt setup.py pyproject.toml 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS FastAPI\"; fi\n    fi\n\n    # Go\n    if [ -f \"go.mod\" ]; then\n        if grep -q \"gin-gonic\" go.mod 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS Gin\"; fi\n        if grep -q \"echo\" go.mod 2>/dev/null; then FRAMEWORKS=\"$FRAMEWORKS Echo\"; fi\n    fi\n\n    FRAMEWORKS=$(echo \"$FRAMEWORKS\" | xargs)  # Trim\n    echo \"  \\\"frameworks\\\": \\\"$FRAMEWORKS\\\",\" >> \"$OUTPUT_FILE\"\n    echo \"    Detected: ${FRAMEWORKS:-None detected}\"\n\n    # Configuration files\n    echo -e \"${CYAN}[5/10] Configuration Files...${NC}\"\n    echo \"  \\\"config_files\\\": [\" >> \"$OUTPUT_FILE\"\n    FIRST=true\n    for cf in package.json tsconfig.json webpack.config.js vite.config.js rollup.config.js \\\n              requirements.txt setup.py pyproject.toml setup.cfg \\\n              go.mod Cargo.toml Gemfile pom.xml build.gradle \\\n              Dockerfile docker-compose.yml docker-compose.yaml \\\n              .env.example .env.sample \\\n              .github/workflows .travis.yml .circleci jenkins* \\\n              terraform*.tf serverless.yml sam.yaml; do\n        if [ -e \"$cf\" ]; then\n            if [ \"$FIRST\" = true ]; then\n                FIRST=false\n            else\n                echo \",\" >> \"$OUTPUT_FILE\"\n            fi\n            echo -n \"    \\\"$cf\\\"\" >> \"$OUTPUT_FILE\"\n            echo \"    Found: $cf\"\n        fi\n    done\n    echo \"\" >> \"$OUTPUT_FILE\"\n    echo \"  ],\" >> \"$OUTPUT_FILE\"\n\n    # Environment variables\n    echo -e \"${CYAN}[6/10] Environment Variables...${NC}\"\n    echo \"  \\\"env_vars\\\": [\" >> \"$OUTPUT_FILE\"\n\n    # Extract from various sources\n    ENV_VARS=\"\"\n\n    # From .env.example\n    if [ -f \".env.example\" ]; then\n        ENV_VARS=\"$ENV_VARS $(grep -E \"^[A-Z_]+=\" .env.example 2>/dev/null | cut -d= -f1 || true)\"\n    fi\n\n    # From JS/TS files\n    ENV_VARS=\"$ENV_VARS $(grep -rh \"process\\.env\\.\" --include=\"*.js\" --include=\"*.ts\" 2>/dev/null | \\\n        grep -oE \"process\\.env\\.[A-Z_]+\" | sed 's/process.env.//' | sort -u || true)\"\n\n    # From Python files\n    ENV_VARS=\"$ENV_VARS $(grep -rhE \"os\\.environ|os\\.getenv\" --include=\"*.py\" 2>/dev/null | \\\n        grep -oE '\"[A-Z_]+\"' | tr -d '\"' | sort -u || true)\"\n\n    # Deduplicate and format\n    ENV_VARS=$(echo \"$ENV_VARS\" | tr ' ' '\\n' | sort -u | grep -v \"^$\")\n\n    FIRST=true\n    for var in $ENV_VARS; do\n        if [ \"$FIRST\" = true ]; then\n            FIRST=false\n        else\n            echo \",\" >> \"$OUTPUT_FILE\"\n        fi\n        echo -n \"    \\\"$var\\\"\" >> \"$OUTPUT_FILE\"\n    done\n    echo \"\" >> \"$OUTPUT_FILE\"\n    echo \"  ],\" >> \"$OUTPUT_FILE\"\n\n    ENV_COUNT=$(echo \"$ENV_VARS\" | wc -w | tr -d ' ')\n    echo \"    Found $ENV_COUNT unique environment variables\"\n\n    # Database detection\n    echo -e \"${CYAN}[7/10] Database Detection...${NC}\"\n    DATABASES=\"\"\n\n    # Check package.json\n    if [ -f \"package.json\" ]; then\n        if grep -qE \"pg|postgres\" package.json 2>/dev/null; then DATABASES=\"$DATABASES PostgreSQL\"; fi\n        if grep -q \"mysql\" package.json 2>/dev/null; then DATABASES=\"$DATABASES MySQL\"; fi\n        if grep -q \"mongodb\\|mongoose\" package.json 2>/dev/null; then DATABASES=\"$DATABASES MongoDB\"; fi\n        if grep -q \"redis\" package.json 2>/dev/null; then DATABASES=\"$DATABASES Redis\"; fi\n        if grep -q \"sqlite\" package.json 2>/dev/null; then DATABASES=\"$DATABASES SQLite\"; fi\n    fi\n\n    # Check requirements.txt\n    if [ -f \"requirements.txt\" ]; then\n        if grep -qE \"psycopg|asyncpg\" requirements.txt 2>/dev/null; then DATABASES=\"$DATABASES PostgreSQL\"; fi\n        if grep -q \"pymysql\\|mysqlclient\" requirements.txt 2>/dev/null; then DATABASES=\"$DATABASES MySQL\"; fi\n        if grep -q \"pymongo\" requirements.txt 2>/dev/null; then DATABASES=\"$DATABASES MongoDB\"; fi\n        if grep -q \"redis\" requirements.txt 2>/dev/null; then DATABASES=\"$DATABASES Redis\"; fi\n    fi\n\n    DATABASES=$(echo \"$DATABASES\" | tr ' ' '\\n' | sort -u | xargs)\n    echo \"  \\\"databases\\\": \\\"$DATABASES\\\",\" >> \"$OUTPUT_FILE\"\n    echo \"    Detected: ${DATABASES:-None detected}\"\n\n    # Tests\n    echo -e \"${CYAN}[8/10] Test Detection...${NC}\"\n    TEST_FILES=$(find . -name \"*test*.js\" -o -name \"*test*.ts\" -o -name \"*test*.py\" -o -name \"*_test.go\" \\\n        -not -path \"*/node_modules/*\" -not -path \"*/.git/*\" 2>/dev/null | wc -l | tr -d ' ')\n    SPEC_FILES=$(find . -name \"*.spec.*\" -not -path \"*/node_modules/*\" 2>/dev/null | wc -l | tr -d ' ')\n\n    HAS_JEST=$(grep -q '\"jest\"' package.json 2>/dev/null && echo \"true\" || echo \"false\")\n    HAS_MOCHA=$(grep -q '\"mocha\"' package.json 2>/dev/null && echo \"true\" || echo \"false\")\n    HAS_PYTEST=$(grep -q \"pytest\" requirements.txt 2>/dev/null && echo \"true\" || echo \"false\")\n\n    echo \"  \\\"tests\\\": {\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"test_files\\\": $TEST_FILES,\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"spec_files\\\": $SPEC_FILES,\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"jest\\\": $HAS_JEST,\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"mocha\\\": $HAS_MOCHA,\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"pytest\\\": $HAS_PYTEST\" >> \"$OUTPUT_FILE\"\n    echo \"  },\" >> \"$OUTPUT_FILE\"\n    echo \"    Test files: $TEST_FILES, Spec files: $SPEC_FILES\"\n\n    # Documentation\n    echo -e \"${CYAN}[9/10] Documentation...${NC}\"\n    HAS_README=$([ -f \"README.md\" ] || [ -f \"README.rst\" ] || [ -f \"README\" ] && echo \"true\" || echo \"false\")\n    HAS_DOCS=$([ -d \"docs\" ] && echo \"true\" || echo \"false\")\n    HAS_CHANGELOG=$([ -f \"CHANGELOG.md\" ] || [ -f \"CHANGELOG\" ] && echo \"true\" || echo \"false\")\n    HAS_CONTRIBUTING=$([ -f \"CONTRIBUTING.md\" ] && echo \"true\" || echo \"false\")\n\n    echo \"  \\\"documentation\\\": {\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"readme\\\": $HAS_README,\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"docs_folder\\\": $HAS_DOCS,\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"changelog\\\": $HAS_CHANGELOG,\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"contributing\\\": $HAS_CONTRIBUTING\" >> \"$OUTPUT_FILE\"\n    echo \"  },\" >> \"$OUTPUT_FILE\"\n    echo \"    README: $HAS_README, /docs: $HAS_DOCS, CHANGELOG: $HAS_CHANGELOG\"\n\n    # CI/CD\n    echo -e \"${CYAN}[10/10] CI/CD...${NC}\"\n    HAS_GH_ACTIONS=$([ -d \".github/workflows\" ] && echo \"true\" || echo \"false\")\n    HAS_TRAVIS=$([ -f \".travis.yml\" ] && echo \"true\" || echo \"false\")\n    HAS_CIRCLE=$([ -d \".circleci\" ] && echo \"true\" || echo \"false\")\n    HAS_DOCKER=$([ -f \"Dockerfile\" ] && echo \"true\" || echo \"false\")\n    HAS_COMPOSE=$([ -f \"docker-compose.yml\" ] || [ -f \"docker-compose.yaml\" ] && echo \"true\" || echo \"false\")\n\n    echo \"  \\\"ci_cd\\\": {\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"github_actions\\\": $HAS_GH_ACTIONS,\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"travis\\\": $HAS_TRAVIS,\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"circleci\\\": $HAS_CIRCLE,\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"dockerfile\\\": $HAS_DOCKER,\" >> \"$OUTPUT_FILE\"\n    echo \"    \\\"docker_compose\\\": $HAS_COMPOSE\" >> \"$OUTPUT_FILE\"\n    echo \"  }\" >> \"$OUTPUT_FILE\"\n    echo \"}\" >> \"$OUTPUT_FILE\"\n\n    echo \"    GitHub Actions: $HAS_GH_ACTIONS, Docker: $HAS_DOCKER\"\n\n    echo \"\"\n    echo -e \"${GREEN}═══════════════════════════════════════════════════════════${NC}\"\n    echo -e \"${GREEN}  Analysis Complete!${NC}\"\n    echo -e \"${GREEN}═══════════════════════════════════════════════════════════${NC}\"\n    echo \"\"\n    echo \"Output: $OUTPUT_FILE\"\n}\n\n# Main\nif [ $# -lt 1 ]; then\n    usage\n    exit 1\nfi\n\nanalyze_repo \"$1\" \"${2:-repo-analysis.json}\"\n"
        },
        {
          "name": "scan-repos.sh",
          "type": "file",
          "path": "code-necromancer/scripts/scan-repos.sh",
          "size": 6183,
          "content": "#!/bin/bash\n\n# Code Necromancer - Repository Scanner\n# Scans a GitHub organization and creates initial inventory\n\nset -e\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\n# Check for required tools\ncheck_requirements() {\n    echo -e \"${BLUE}Checking requirements...${NC}\"\n\n    if ! command -v gh &> /dev/null; then\n        echo -e \"${RED}Error: GitHub CLI (gh) is not installed${NC}\"\n        echo \"Install with: brew install gh\"\n        exit 1\n    fi\n\n    if ! command -v jq &> /dev/null; then\n        echo -e \"${RED}Error: jq is not installed${NC}\"\n        echo \"Install with: brew install jq\"\n        exit 1\n    fi\n\n    # Check gh auth status\n    if ! gh auth status &> /dev/null; then\n        echo -e \"${RED}Error: Not authenticated with GitHub CLI${NC}\"\n        echo \"Run: gh auth login\"\n        exit 1\n    fi\n\n    echo -e \"${GREEN}All requirements met${NC}\"\n}\n\n# Usage\nusage() {\n    echo \"Usage: $0 <org-name> [output-dir]\"\n    echo \"\"\n    echo \"Scans a GitHub organization and creates inventory files\"\n    echo \"\"\n    echo \"Arguments:\"\n    echo \"  org-name    GitHub organization name\"\n    echo \"  output-dir  Directory for output files (default: ./archaeology-output)\"\n    echo \"\"\n    echo \"Example:\"\n    echo \"  $0 dolphin-ai ./dolphin-archaeology\"\n}\n\n# Main scan function\nscan_organization() {\n    local ORG=$1\n    local OUTPUT_DIR=$2\n\n    echo -e \"${BLUE}═══════════════════════════════════════════════════════════${NC}\"\n    echo -e \"${BLUE}  Code Necromancer - Repository Scanner${NC}\"\n    echo -e \"${BLUE}═══════════════════════════════════════════════════════════${NC}\"\n    echo \"\"\n    echo -e \"Organization: ${GREEN}$ORG${NC}\"\n    echo -e \"Output: ${GREEN}$OUTPUT_DIR${NC}\"\n    echo \"\"\n\n    mkdir -p \"$OUTPUT_DIR\"\n\n    # Phase 1: List all repos\n    echo -e \"${YELLOW}Phase 1: Listing repositories...${NC}\"\n\n    gh repo list \"$ORG\" --limit 1000 --json \\\n        name,description,primaryLanguage,pushedAt,createdAt,isArchived,isFork,url,sshUrl,diskUsage,defaultBranchRef \\\n        > \"$OUTPUT_DIR/repos-raw.json\"\n\n    REPO_COUNT=$(jq 'length' \"$OUTPUT_DIR/repos-raw.json\")\n    echo -e \"  Found ${GREEN}$REPO_COUNT${NC} repositories\"\n\n    # Phase 2: Basic categorization\n    echo -e \"${YELLOW}Phase 2: Categorizing by language...${NC}\"\n\n    jq -r '.[].primaryLanguage.name // \"Unknown\"' \"$OUTPUT_DIR/repos-raw.json\" | \\\n        sort | uniq -c | sort -rn > \"$OUTPUT_DIR/languages.txt\"\n\n    echo \"  Language distribution:\"\n    cat \"$OUTPUT_DIR/languages.txt\" | while read count lang; do\n        echo \"    $lang: $count\"\n    done\n\n    # Phase 3: Activity analysis\n    echo -e \"${YELLOW}Phase 3: Analyzing activity...${NC}\"\n\n    # Most recently active\n    jq -r 'sort_by(.pushedAt) | reverse | .[0:5] | .[] | \"\\(.pushedAt)\\t\\(.name)\"' \\\n        \"$OUTPUT_DIR/repos-raw.json\" > \"$OUTPUT_DIR/recent-activity.txt\"\n\n    echo \"  Most recently active:\"\n    cat \"$OUTPUT_DIR/recent-activity.txt\" | while read line; do\n        echo \"    $line\"\n    done\n\n    # Oldest repos\n    jq -r 'sort_by(.createdAt) | .[0:5] | .[] | \"\\(.createdAt)\\t\\(.name)\"' \\\n        \"$OUTPUT_DIR/repos-raw.json\" > \"$OUTPUT_DIR/oldest-repos.txt\"\n\n    # Archived repos\n    ARCHIVED=$(jq '[.[] | select(.isArchived == true)] | length' \"$OUTPUT_DIR/repos-raw.json\")\n    echo -e \"  Archived repositories: ${YELLOW}$ARCHIVED${NC}\"\n\n    # Forked repos\n    FORKED=$(jq '[.[] | select(.isFork == true)] | length' \"$OUTPUT_DIR/repos-raw.json\")\n    echo -e \"  Forked repositories: ${YELLOW}$FORKED${NC}\"\n\n    # Phase 4: Generate summary\n    echo -e \"${YELLOW}Phase 4: Generating summary...${NC}\"\n\n    LAST_ACTIVITY=$(jq -r 'sort_by(.pushedAt) | reverse | .[0].pushedAt' \"$OUTPUT_DIR/repos-raw.json\")\n    FIRST_REPO=$(jq -r 'sort_by(.createdAt) | .[0].createdAt' \"$OUTPUT_DIR/repos-raw.json\")\n    TOTAL_SIZE=$(jq '[.[].diskUsage] | add' \"$OUTPUT_DIR/repos-raw.json\")\n\n    cat > \"$OUTPUT_DIR/summary.md\" << EOF\n# Organization Scan Summary: $ORG\n\n**Scan Date**: $(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\n**Scanner**: Code Necromancer\n\n## Overview\n\n| Metric | Value |\n|--------|-------|\n| Total Repositories | $REPO_COUNT |\n| Archived | $ARCHIVED |\n| Forked | $FORKED |\n| Total Size | ${TOTAL_SIZE:-0} KB |\n| First Repository | $FIRST_REPO |\n| Last Activity | $LAST_ACTIVITY |\n\n## Language Distribution\n\n\\`\\`\\`\n$(cat \"$OUTPUT_DIR/languages.txt\")\n\\`\\`\\`\n\n## Most Recently Active\n\n| Date | Repository |\n|------|------------|\n$(cat \"$OUTPUT_DIR/recent-activity.txt\" | awk -F'\\t' '{print \"| \"$1\" | \"$2\" |\"}')\n\n## Repository List\n\n| Name | Language | Last Push | Archived |\n|------|----------|-----------|----------|\n$(jq -r '.[] | \"| \\(.name) | \\(.primaryLanguage.name // \"?\") | \\(.pushedAt | split(\"T\")[0]) | \\(.isArchived) |\"' \"$OUTPUT_DIR/repos-raw.json\")\n\n## Next Steps\n\n1. Review the repository list above\n2. Identify which repos are \"core\" vs \"peripheral\"\n3. Run detailed analysis on priority repos\n4. Create dependency graph between repos\nEOF\n\n    echo -e \"${GREEN}═══════════════════════════════════════════════════════════${NC}\"\n    echo -e \"${GREEN}  Scan Complete!${NC}\"\n    echo -e \"${GREEN}═══════════════════════════════════════════════════════════${NC}\"\n    echo \"\"\n    echo \"Output files:\"\n    echo \"  - $OUTPUT_DIR/summary.md (start here)\"\n    echo \"  - $OUTPUT_DIR/repos-raw.json (full data)\"\n    echo \"  - $OUTPUT_DIR/languages.txt\"\n    echo \"  - $OUTPUT_DIR/recent-activity.txt\"\n    echo \"  - $OUTPUT_DIR/oldest-repos.txt\"\n    echo \"\"\n    echo \"Next: Review summary.md and run analyze-repo.sh on key repositories\"\n}\n\n# Main\nif [ $# -lt 1 ]; then\n    usage\n    exit 1\nfi\n\nORG=$1\nOUTPUT_DIR=${2:-\"./archaeology-output\"}\n\ncheck_requirements\nscan_organization \"$ORG\" \"$OUTPUT_DIR\"\n"
        }
      ]
    },
    {
      "name": "templates",
      "type": "folder",
      "path": "code-necromancer/templates",
      "children": [
        {
          "name": "archaeology-report.md",
          "type": "file",
          "path": "code-necromancer/templates/archaeology-report.md",
          "size": 6391,
          "content": "# Archaeology Report: [PROJECT_NAME]\n\n**Organization**: [ORG_NAME]\n**Scan Date**: [DATE]\n**Analyst**: [NAME]\n\n---\n\n## Executive Summary\n\n[2-3 paragraph summary of findings: what the system is, how it's structured, and what state it's in]\n\n---\n\n## System Overview\n\n### What Is This?\n\n[Describe the product/system in plain English. What does it do? Who uses it?]\n\n### Architecture at a Glance\n\n```mermaid\ngraph TB\n    %% Replace with actual architecture\n    subgraph \"User-Facing\"\n        A[Component 1]\n    end\n    subgraph \"Backend\"\n        B[Component 2]\n    end\n    A --> B\n```\n\n### Key Statistics\n\n| Metric | Value |\n|--------|-------|\n| Total Repositories | X |\n| Primary Languages | Lang1, Lang2 |\n| Total Lines of Code | ~X,XXX |\n| Last Active | YYYY-MM-DD |\n| Dormancy Period | X years, X months |\n\n---\n\n## Repository Inventory\n\n### Core Systems\n\nThese repositories form the heart of the application:\n\n| Repo | Purpose | Tech Stack | Status | Maturity |\n|------|---------|------------|--------|----------|\n| repo-1 | Main API | Node.js/Express | Dormant | Medium |\n| repo-2 | Web Frontend | React | Dormant | High |\n\n### Supporting Services\n\nThese repos provide supporting functionality:\n\n| Repo | Purpose | Tech Stack | Status | Maturity |\n|------|---------|------------|--------|----------|\n| repo-3 | Auth Service | Python/Flask | Dormant | Low |\n\n### Libraries & Shared Code\n\nInternal packages and shared utilities:\n\n| Repo | Purpose | Used By |\n|------|---------|---------|\n| shared-lib | Common utilities | repo-1, repo-2 |\n\n### Deprecated / Abandoned\n\nThese appear to be deprecated or abandoned:\n\n| Repo | Last Activity | Notes |\n|------|---------------|-------|\n| old-repo | 2018-03-15 | Superseded by repo-2 |\n\n### Unknown / Unclear\n\nPurpose unclear, needs investigation:\n\n| Repo | Notes |\n|------|-------|\n| mystery-repo | No README, sparse commits |\n\n---\n\n## Dependency Graph\n\n### Inter-Repository Dependencies\n\n```mermaid\ngraph LR\n    %% Replace with actual dependencies\n    A[frontend] --> B[api]\n    B --> C[auth-service]\n    B --> D[database]\n    C --> D\n```\n\n### External Service Dependencies\n\n| Service | Used By | Purpose | Status |\n|---------|---------|---------|--------|\n| AWS S3 | repo-1 | File storage | Unknown |\n| PostgreSQL | repo-1, repo-3 | Primary database | Unknown |\n| Redis | repo-1 | Caching/sessions | Unknown |\n| Stripe | repo-1 | Payments | Unknown |\n\n---\n\n## Technology Stack\n\n### Languages\n\n| Language | Repos | Percentage |\n|----------|-------|------------|\n| TypeScript | 8 | 40% |\n| Python | 5 | 25% |\n| Go | 3 | 15% |\n| Other | 4 | 20% |\n\n### Frameworks\n\n| Framework | Version Found | Current Version | Gap |\n|-----------|---------------|-----------------|-----|\n| React | 16.8.0 | 18.x | 2 major |\n| Express | 4.17.0 | 4.18.x | Minor |\n| Flask | 1.1.0 | 3.x | 2 major |\n\n### Runtime Versions\n\n| Runtime | Version Found | Current LTS | Support Status |\n|---------|---------------|-------------|----------------|\n| Node.js | 12.x | 20.x | EOL |\n| Python | 3.7 | 3.12 | EOL |\n\n---\n\n## Maturity Assessment\n\n### Scoring Criteria\n\n- **Documentation** (1-5): README quality, inline comments, API docs\n- **Test Coverage** (1-5): Presence and quality of tests\n- **Code Quality** (1-5): Linting, typing, architecture\n- **Activity** (1-5): Recent commits, active development\n- **Maintainability** (1-5): Complexity, dependency health\n\n### Repository Scores\n\n| Repo | Doc | Tests | Quality | Activity | Maintain | Overall |\n|------|-----|-------|---------|----------|----------|---------|\n| repo-1 | 3 | 2 | 4 | 1 | 3 | 2.6 |\n| repo-2 | 4 | 3 | 4 | 1 | 4 | 3.2 |\n\n### Overall Assessment\n\n**System Maturity**: [LOW / MEDIUM / HIGH]\n\n[Explanation of overall system state]\n\n---\n\n## Missing Pieces\n\n### Identified Gaps\n\n1. **[Gap 1]**: [Description of what's missing and impact]\n2. **[Gap 2]**: [Description]\n\n### Orphaned Components\n\n[Components that seem disconnected from the main system]\n\n### Documentation Gaps\n\n- [ ] No API documentation found\n- [ ] No deployment guide\n- [ ] No architecture decision records\n\n---\n\n## Configuration & Environment\n\n### Environment Variables Required\n\n| Variable | Used By | Purpose | Type |\n|----------|---------|---------|------|\n| DATABASE_URL | repo-1, repo-3 | Database connection | Secret |\n| JWT_SECRET | repo-1, repo-3 | Auth tokens | Secret |\n| AWS_ACCESS_KEY | repo-1 | S3 access | Secret |\n| NODE_ENV | repo-1, repo-2 | Environment flag | Config |\n\n### Configuration Files\n\n| File | Found In | Purpose |\n|------|----------|---------|\n| .env.example | repo-1 | Environment template |\n| config.yaml | repo-3 | Service configuration |\n\n---\n\n## Infrastructure\n\n### Cloud Resources (Detected/Suspected)\n\n- AWS Region: [if detected]\n- Services: S3, RDS, EC2, etc.\n- Databases: PostgreSQL, Redis, etc.\n\n### CI/CD\n\n| Repo | CI System | Status |\n|------|-----------|--------|\n| repo-1 | GitHub Actions | Likely broken |\n| repo-2 | Travis CI | Unknown |\n\n---\n\n## Development History\n\n### Timeline\n\n```\n2017 ─────────────────────────────────────────────────── 2024\n     │                                                    │\n     ├─ [2017-06] Initial commit (repo-1)                │\n     ├─ [2018-03] Frontend added (repo-2)                │\n     ├─ [2019-01] Auth service added (repo-3)            │\n     ├─ [2020-08] Last significant feature               │\n     └─ [2021-03] Last commit                            │\n                                                          │\n                      [3+ years dormancy]                 │\n```\n\n### Key Contributors (Historical)\n\n| Contributor | Commits | Primary Repos |\n|-------------|---------|---------------|\n| dev1@company.com | 500 | repo-1, repo-2 |\n| dev2@company.com | 300 | repo-3 |\n\n---\n\n## Recommendations\n\n### Immediate Actions\n\n1. **[Action 1]**: [Specific recommendation]\n2. **[Action 2]**: [Specific recommendation]\n\n### Before Resurrection\n\n1. [Pre-requisite 1]\n2. [Pre-requisite 2]\n\n### Key Risks\n\n1. **[Risk 1]**: [Description and mitigation]\n2. **[Risk 2]**: [Description and mitigation]\n\n---\n\n## Appendices\n\n### A. Full Repository List\n\n[Complete list with all metadata]\n\n### B. Dependency Trees\n\n[Detailed dependency information per repo]\n\n### C. API Surface Area\n\n[All detected endpoints and their status]\n"
        },
        {
          "name": "repo-inventory.json",
          "type": "file",
          "path": "code-necromancer/templates/repo-inventory.json",
          "size": 2682,
          "content": "{\n  \"$schema\": \"repo-inventory-schema\",\n  \"organization\": \"ORGANIZATION_NAME\",\n  \"scan_date\": \"YYYY-MM-DD\",\n  \"total_repos\": 0,\n  \"repos\": [\n    {\n      \"name\": \"repo-name\",\n      \"description\": \"Repository description\",\n      \"url\": \"https://github.com/org/repo\",\n      \"primary_language\": \"TypeScript\",\n      \"languages\": {\n        \"TypeScript\": 80,\n        \"JavaScript\": 15,\n        \"CSS\": 5\n      },\n      \"framework\": {\n        \"name\": \"React\",\n        \"version\": \"16.8.0\",\n        \"detected_from\": \"package.json\"\n      },\n      \"runtime\": {\n        \"name\": \"Node.js\",\n        \"version\": \"12.x\",\n        \"detected_from\": \".nvmrc\"\n      },\n      \"last_commit\": {\n        \"date\": \"2021-03-15T10:30:00Z\",\n        \"author\": \"developer@company.com\",\n        \"message\": \"Last commit message\"\n      },\n      \"commit_stats\": {\n        \"total_commits\": 1500,\n        \"contributors\": 8,\n        \"first_commit\": \"2018-01-15T00:00:00Z\",\n        \"commits_last_year\": 0,\n        \"commits_last_6_months\": 0\n      },\n      \"size\": {\n        \"files\": 500,\n        \"lines_of_code\": 45000,\n        \"disk_mb\": 25\n      },\n      \"has\": {\n        \"readme\": true,\n        \"dockerfile\": true,\n        \"docker_compose\": true,\n        \"ci_cd\": \"github_actions\",\n        \"tests\": true,\n        \"env_example\": false\n      },\n      \"dependencies\": {\n        \"count\": 45,\n        \"outdated\": 30,\n        \"vulnerable\": 5,\n        \"internal_deps\": [\"@org/shared-lib\", \"@org/auth-client\"]\n      },\n      \"env_vars\": [\n        \"DATABASE_URL\",\n        \"REDIS_URL\",\n        \"JWT_SECRET\",\n        \"AWS_ACCESS_KEY_ID\"\n      ],\n      \"api_endpoints\": {\n        \"count\": 25,\n        \"documented\": false,\n        \"openapi_spec\": false\n      },\n      \"databases\": [\"PostgreSQL\", \"Redis\"],\n      \"external_services\": [\"AWS S3\", \"Stripe\", \"SendGrid\"],\n      \"category\": \"core|support|deprecated|unknown\",\n      \"maturity\": {\n        \"score\": 3,\n        \"max\": 5,\n        \"factors\": {\n          \"documentation\": 2,\n          \"test_coverage\": 3,\n          \"code_quality\": 4,\n          \"activity\": 1,\n          \"maintainability\": 3\n        }\n      },\n      \"notes\": \"Free-form notes about this repo\",\n      \"depends_on\": [\"repo-2\", \"repo-3\"],\n      \"depended_by\": [\"repo-4\"]\n    }\n  ],\n  \"summary\": {\n    \"by_language\": {\n      \"TypeScript\": 8,\n      \"Python\": 5,\n      \"Go\": 3,\n      \"Other\": 4\n    },\n    \"by_category\": {\n      \"core\": 5,\n      \"support\": 8,\n      \"deprecated\": 4,\n      \"unknown\": 3\n    },\n    \"by_maturity\": {\n      \"high\": 3,\n      \"medium\": 10,\n      \"low\": 7\n    },\n    \"oldest_repo\": \"repo-name\",\n    \"newest_repo\": \"repo-name\",\n    \"most_active\": \"repo-name\",\n    \"least_active\": \"repo-name\"\n  }\n}\n"
        },
        {
          "name": "resurrection-plan.md",
          "type": "file",
          "path": "code-necromancer/templates/resurrection-plan.md",
          "size": 5626,
          "content": "# Resurrection Plan: [PROJECT_NAME]\n\n**Based on Archaeology Report**: [DATE]\n**Plan Created**: [DATE]\n\n---\n\n## Executive Summary\n\n[Brief summary of what needs to happen to get the system running]\n\n---\n\n## Resurrection Readiness Score\n\n| Component | Ready | Blockers |\n|-----------|-------|----------|\n| repo-1 | 40% | 3 critical |\n| repo-2 | 60% | 1 critical |\n| repo-3 | 20% | 5 critical |\n| **Overall** | **35%** | **9 critical** |\n\n---\n\n## Critical Blockers\n\n### Blocker 1: [Title]\n\n**Severity**: Critical / High / Medium\n**Component**: repo-1\n**Category**: Dependency / Infrastructure / Configuration / Code\n\n**Description**:\n[What the blocker is]\n\n**Impact**:\n[What won't work without fixing this]\n\n**Resolution**:\n```bash\n# Steps to resolve\nnpm install new-package@version\n```\n\n**Estimated Effort**: [X hours/days]\n**Dependencies**: [Other blockers that must be resolved first]\n\n---\n\n### Blocker 2: [Title]\n\n[Repeat for each blocker]\n\n---\n\n## Dependency Audit\n\n### Critical Updates Required\n\n| Package | Current | Required | Breaking Changes |\n|---------|---------|----------|------------------|\n| react | 16.8.0 | 18.x | Yes - Concurrent mode |\n| node | 12.x | 18.x+ | Yes - ESM, APIs |\n\n### Security Vulnerabilities\n\n| Severity | Count | Action |\n|----------|-------|--------|\n| Critical | 5 | Immediate |\n| High | 12 | Before production |\n| Medium | 23 | Soon |\n| Low | 45 | When convenient |\n\n### Deprecated Packages\n\n| Package | Status | Replacement |\n|---------|--------|-------------|\n| request | Deprecated | axios or fetch |\n| moment | Maintenance | dayjs or date-fns |\n\n---\n\n## Environment Setup\n\n### Required Environment Variables\n\n| Variable | Required For | How to Obtain | Status |\n|----------|--------------|---------------|--------|\n| DATABASE_URL | repo-1, repo-3 | Create new DB | Pending |\n| JWT_SECRET | repo-1, repo-3 | Generate new | Pending |\n| AWS_ACCESS_KEY | repo-1 | AWS Console | Unknown |\n| STRIPE_API_KEY | repo-1 | Stripe Dashboard | Unknown |\n\n### Secrets Inventory\n\n| Secret Type | Count | Status |\n|-------------|-------|--------|\n| API Keys | 5 | Need renewal |\n| Certificates | 2 | Expired |\n| OAuth Credentials | 3 | Unknown |\n\n---\n\n## Infrastructure Requirements\n\n### Cloud Resources Needed\n\n| Resource | Purpose | Status | Action |\n|----------|---------|--------|--------|\n| PostgreSQL DB | Primary data | Unknown | Verify or create |\n| Redis | Caching | Unknown | Verify or create |\n| S3 Bucket | File storage | Unknown | Verify or create |\n\n### Local Development Setup\n\n```bash\n# Prerequisites\n- Docker Desktop\n- Node.js 18+\n- Python 3.11+\n- PostgreSQL 15+\n- Redis 7+\n\n# Setup steps\n1. Clone all repos\n2. Copy .env.example files\n3. Start infrastructure (docker-compose)\n4. Install dependencies\n5. Run migrations\n6. Seed data (if available)\n7. Start services\n```\n\n---\n\n## Resurrection Order\n\nBased on dependencies, resurrect in this order:\n\n```\nPhase 1: Infrastructure\n├── Set up local databases\n├── Configure environment variables\n└── Verify cloud access\n\nPhase 2: Foundation\n├── repo-shared-lib (no dependencies)\n├── repo-database (migrations)\n└── repo-auth (minimal deps)\n\nPhase 3: Core Services\n├── repo-api (depends on auth, db)\n└── repo-workers (depends on api)\n\nPhase 4: User Facing\n├── repo-frontend (depends on api)\n└── repo-mobile (depends on api)\n\nPhase 5: Integration\n├── End-to-end testing\n└── Full system verification\n```\n\n---\n\n## Integration Tests\n\n### Resurrection Verification Tests\n\nThese tests verify each phase of resurrection:\n\n#### Phase 1 Tests: Infrastructure\n- [ ] Can connect to PostgreSQL\n- [ ] Can connect to Redis\n- [ ] Can access S3 bucket\n- [ ] Environment variables loaded correctly\n\n#### Phase 2 Tests: Foundation\n- [ ] Shared library imports work\n- [ ] Database migrations run successfully\n- [ ] Auth service starts\n- [ ] Auth service responds to health check\n\n#### Phase 3 Tests: Core Services\n- [ ] API service starts\n- [ ] API service connects to database\n- [ ] API service connects to auth\n- [ ] Worker service starts\n- [ ] Worker service processes test job\n\n#### Phase 4 Tests: User Facing\n- [ ] Frontend builds successfully\n- [ ] Frontend loads in browser\n- [ ] Frontend can authenticate\n- [ ] Basic user flow works\n\n#### Phase 5 Tests: Integration\n- [ ] Full user signup flow\n- [ ] Full user login flow\n- [ ] Core feature #1 works\n- [ ] Core feature #2 works\n\n---\n\n## Risk Assessment\n\n### High Risk Items\n\n1. **[Risk]**: [Description]\n   - Mitigation: [Plan]\n   - Fallback: [Alternative if mitigation fails]\n\n### Data Concerns\n\n- [ ] Old database needs migration\n- [ ] User data needs to be preserved\n- [ ] PII handling compliance\n\n---\n\n## Timeline Estimate\n\n| Phase | Tasks | Effort Range |\n|-------|-------|--------------|\n| Phase 1: Infrastructure | 5 | Low-Medium |\n| Phase 2: Foundation | 8 | Medium |\n| Phase 3: Core | 12 | Medium-High |\n| Phase 4: User Facing | 6 | Medium |\n| Phase 5: Integration | 4 | Medium |\n| **Total** | **35** | **Medium-High** |\n\n*Note: Estimates assume minimal unexpected blockers*\n\n---\n\n## Success Criteria\n\nThe system is considered \"resurrected\" when:\n\n- [ ] All services start without errors\n- [ ] Services can communicate with each other\n- [ ] Database connections work\n- [ ] Authentication works end-to-end\n- [ ] At least one core user flow works\n- [ ] Integration tests pass\n- [ ] A user can [primary use case]\n\n---\n\n## Next Steps\n\n1. [ ] Obtain/renew required credentials\n2. [ ] Set up development infrastructure\n3. [ ] Begin Phase 1 resurrection\n4. [ ] Document any additional blockers found\n5. [ ] Update this plan as needed\n"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "code-necromancer/SKILL.md",
      "size": 10017,
      "content": "---\nname: code-necromancer\ndescription: Systematic framework for resurrecting and modernizing legacy codebases through archaeology, resurrection, and rejuvenation phases. Activate on \"legacy code\", \"inherited codebase\", \"no documentation\", \"technical debt\", \"resurrect\", \"modernize\". NOT for greenfield projects or well-documented active codebases.\nallowed-tools: Read,Write,Edit,Bash,WebFetch,Grep,Glob\n---\n\n# Code Necromancer\n\n**Tagline**: Raise dead codebases from the grave\n\n**Category**: Development Archaeology & Legacy Resurrection\n\n## Purpose\n\nCode Necromancer is a systematic framework for understanding, resurrecting, and modernizing legacy codebases. It guides practitioners through three phases:\n\n1. **ARCHAEOLOGY** - Understanding what exists in a multi-repo legacy system\n2. **RESURRECTION** - Getting the system running again after years of dormancy\n3. **REJUVENATION** - Modernizing the stack for current standards\n\n## When to Activate\n\nUse this skill when:\n- Inheriting a codebase with 5+ repos and no documentation\n- Resurrecting a product that hasn't been maintained for 2+ years\n- Joining a company with significant technical debt and tribal knowledge loss\n- Performing due diligence on acquired codebases\n- Modernizing legacy systems without breaking existing functionality\n\n## Phase 1: ARCHAEOLOGY\n\n### Objective\nCreate a complete map of the system before touching anything.\n\n### Outputs\n1. **Repo Inventory** (`repo-inventory.json`)\n   - All repositories with metadata\n   - Primary language/framework per repo\n   - Last activity date\n   - Commit frequency analysis\n   - README summary\n\n2. **Dependency Graph** (`dependency-graph.mmd`)\n   - Inter-repo dependencies\n   - External service dependencies\n   - Database connections\n   - API integrations\n\n3. **Architecture Diagram** (`architecture-diagram.mmd`)\n   - Visual system architecture\n   - Data flow between components\n   - External integrations\n   - Infrastructure topology\n\n4. **Tech Stack Matrix** (`tech-stack-matrix.md`)\n   - Language versions per repo\n   - Framework versions\n   - Database technologies\n   - Cloud services used\n\n5. **Maturity Assessment** (`maturity-assessment.md`)\n   - Development status of each component\n   - Code quality indicators\n   - Test coverage (if detectable)\n   - Documentation quality\n\n6. **Missing Pieces** (`missing-pieces.md`)\n   - Identified gaps in the system\n   - Orphaned repos\n   - Dead dependencies\n   - Broken integrations\n\n### Archaeology Process\n\n```\n1. INVENTORY\n   └── List all repos in org/folder\n   └── Extract basic metadata (language, size, last commit)\n   └── Categorize by apparent purpose\n\n2. DEEP SCAN (per repo)\n   └── Identify framework(s)\n   └── Parse dependency files (package.json, requirements.txt, etc.)\n   └── Find configuration files\n   └── Extract environment variable requirements\n   └── Identify database schemas\n   └── Map API endpoints\n\n3. CROSS-REFERENCE\n   └── Build dependency graph between repos\n   └── Identify shared libraries\n   └── Find service-to-service calls\n   └── Map data flow\n\n4. VISUALIZE\n   └── Generate architecture diagrams\n   └── Create dependency trees\n   └── Build timeline of development activity\n\n5. ASSESS\n   └── Rate maturity of each component\n   └── Identify the \"core\" vs \"peripheral\"\n   └── Document tribal knowledge gaps\n```\n\n## Phase 2: RESURRECTION\n\n### Objective\nGet the system running in a development environment.\n\n### Outputs\n1. **Dependency Audit** (`dependency-audit.md`)\n   - Outdated packages\n   - Security vulnerabilities\n   - Breaking changes in dependencies\n   - Deprecated APIs\n\n2. **Environment Map** (`environment-variables.md`)\n   - All required environment variables\n   - Which are secrets vs configuration\n   - Default values where safe\n\n3. **Secrets Inventory** (`secrets-needed.md`)\n   - API keys needed\n   - Certificates required\n   - License keys\n   - OAuth credentials\n\n4. **Infrastructure Status** (`infrastructure-status.md`)\n   - Cloud resources that exist\n   - Resources that have been deleted\n   - Resources that need updating\n   - Cost analysis\n\n5. **Resurrection Blockers** (`resurrection-blockers.md`)\n   - Critical issues preventing launch\n   - Prioritized by severity\n   - Suggested fixes for each\n\n6. **Integration Tests** (`integration-tests/`)\n   - Tests that verify each component works\n   - Tests that verify components communicate\n   - Health check endpoints\n\n### Resurrection Process\n\n```\n1. AUDIT DEPENDENCIES\n   └── Run security audits (npm audit, safety check, etc.)\n   └── Identify major version jumps needed\n   └── Check for yanked/removed packages\n\n2. MAP ENVIRONMENT\n   └── Extract all env vars from code\n   └── Categorize by service/purpose\n   └── Identify which are missing\n\n3. CHECK INFRASTRUCTURE\n   └── Inventory cloud resources\n   └── Check certificate expirations\n   └── Verify DNS records\n   └── Test database connectivity\n\n4. CREATE RESURRECTION TESTS\n   └── Write tests for each service startup\n   └── Write tests for inter-service communication\n   └── Write tests for external integrations\n\n5. DOCUMENT BLOCKERS\n   └── List everything preventing launch\n   └── Prioritize by effort/impact\n   └── Create actionable fix plans\n```\n\n## Phase 3: REJUVENATION\n\n### Objective\nModernize the system while maintaining feature parity.\n\n### Outputs\n1. **Security Recommendations** (`security-recommendations.md`)\n   - Vulnerability fixes\n   - Security best practices\n   - Compliance requirements\n\n2. **Modernization Roadmap** (`modernization-roadmap.md`)\n   - Prioritized upgrades\n   - Framework migrations\n   - Architecture improvements\n   - Estimated effort levels\n\n3. **Architecture Improvements** (`architecture-improvements.md`)\n   - Scalability enhancements\n   - Performance optimizations\n   - Maintainability improvements\n\n### Rejuvenation Process\n\n```\n1. SECURITY FIRST\n   └── Fix all critical vulnerabilities\n   └── Update authentication/authorization\n   └── Implement security best practices\n\n2. INFRASTRUCTURE\n   └── Containerize if not already\n   └── Set up CI/CD\n   └── Implement infrastructure as code\n\n3. CODE QUALITY\n   └── Add linting/formatting\n   └── Improve test coverage\n   └── Add type safety where missing\n\n4. ARCHITECTURE\n   └── Identify refactoring opportunities\n   └── Plan microservice boundaries\n   └── Design for scale\n```\n\n## Key Commands and Tools\n\n### GitHub Organization Scanning\n```bash\n# List all repos in an org\ngh repo list ORG_NAME --limit 1000 --json name,description,primaryLanguage,pushedAt,isArchived\n\n# Clone all repos\ngh repo list ORG_NAME --limit 1000 --json sshUrl -q '.[].sshUrl' | xargs -I {} git clone {}\n```\n\n### Dependency Analysis\n```bash\n# Node.js\nnpm outdated\nnpm audit\nnpx depcheck\n\n# Python\npip list --outdated\nsafety check\npipdeptree\n\n# Go\ngo mod graph\ngo list -m -versions all\n```\n\n### Architecture Diagram Generation\nUse Mermaid for portable diagrams:\n```mermaid\ngraph TB\n    subgraph \"Frontend\"\n        A[Web App]\n        B[Mobile App]\n    end\n    subgraph \"Backend\"\n        C[API Gateway]\n        D[Auth Service]\n        E[Core Service]\n    end\n    subgraph \"Data\"\n        F[(PostgreSQL)]\n        G[(Redis)]\n    end\n    A --> C\n    B --> C\n    C --> D\n    C --> E\n    D --> F\n    E --> F\n    E --> G\n```\n\n## Anti-Patterns to Avoid\n\n1. **Premature Resurrection**: Don't try to run code before understanding it\n2. **Scope Creep**: Complete archaeology before starting resurrection\n3. **Big Bang Updates**: Update dependencies incrementally, not all at once\n4. **Ignoring Tests**: Write resurrection tests to measure progress\n5. **Undocumented Changes**: Document everything you learn and change\n\n## Success Metrics\n\n### Archaeology Complete When:\n- [ ] All repos cataloged with metadata\n- [ ] Dependency graph visualized\n- [ ] Architecture diagram created\n- [ ] Core vs peripheral repos identified\n- [ ] Missing pieces documented\n\n### Resurrection Complete When:\n- [ ] All services start locally\n- [ ] Services can communicate with each other\n- [ ] Integration tests pass\n- [ ] At least one full user flow works\n\n### Rejuvenation Complete When:\n- [ ] No critical security vulnerabilities\n- [ ] All dependencies reasonably current\n- [ ] CI/CD pipeline working\n- [ ] Documentation current\n- [ ] Team can develop new features\n\n## Example Workflow\n\n```\n# 1. Start Archaeology\nUse this skill when the user says things like:\n- \"I inherited this codebase with 20 repos...\"\n- \"This system hasn't been touched in 3 years...\"\n- \"No one knows how this works anymore...\"\n\n# 2. Generate Inventory\nScan all repos, create repo-inventory.json\n\n# 3. Deep Analysis\nFor each significant repo, analyze:\n- Tech stack\n- Dependencies\n- Configuration\n- API surface\n\n# 4. Map Dependencies\nCreate dependency-graph.mmd showing how repos connect\n\n# 5. Visualize Architecture\nCreate architecture-diagram.mmd showing system topology\n\n# 6. Assess Status\nRate each component's maturity and identify gaps\n\n# 7. Plan Resurrection\nCreate prioritized plan for getting things running\n\n# 8. Execute Resurrection\nWork through blockers, writing tests as you go\n\n# 9. Plan Rejuvenation\nCreate modernization roadmap for long-term health\n```\n\n## References\n\n- `references/archaeology-guide.md` - Deep dive on code archaeology techniques\n- `references/dependency-patterns.md` - Common dependency detection patterns\n- `references/framework-detection.md` - Identifying frameworks and stacks\n- `references/infrastructure-mapping.md` - Cloud resource detection\n- `references/integration-test-patterns.md` - Resurrection test patterns\n\n## Templates\n\n- `templates/repo-inventory.json` - Repository catalog template\n- `templates/archaeology-report.md` - Phase 1 output template\n- `templates/resurrection-plan.md` - Phase 2 output template\n- `templates/rejuvenation-roadmap.md` - Phase 3 output template\n"
    }
  ]
}