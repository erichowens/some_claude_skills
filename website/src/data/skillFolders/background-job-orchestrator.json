{
  "name": "background-job-orchestrator",
  "type": "folder",
  "path": "background-job-orchestrator",
  "children": [
    {
      "name": "references",
      "type": "folder",
      "path": "background-job-orchestrator/references",
      "children": [
        {
          "name": "bullmq-patterns.md",
          "type": "file",
          "path": "background-job-orchestrator/references/bullmq-patterns.md",
          "size": 7621,
          "content": "# Advanced BullMQ Patterns\n\nProduction patterns for complex job orchestration with BullMQ.\n\n## Pattern 1: Job Chaining (Sequential Workflows)\n\nExecute jobs in sequence, passing results between steps.\n\n```typescript\n// Parent job spawns child jobs\nawait queue.add('process-order', {\n  orderId: 123\n}, {\n  attempts: 3\n});\n\nworker.process('process-order', async (job) => {\n  const { orderId } = job.data;\n\n  // Step 1: Validate inventory\n  const inventoryJob = await queue.add('check-inventory', {\n    orderId\n  }, {\n    parent: {\n      id: job.id,\n      queue: job.queueName\n    }\n  });\n\n  await inventoryJob.waitUntilFinished(queueEvents);\n\n  // Step 2: Charge payment\n  const paymentJob = await queue.add('charge-payment', {\n    orderId\n  }, {\n    parent: {\n      id: job.id,\n      queue: job.queueName\n    }\n  });\n\n  await paymentJob.waitUntilFinished(queueEvents);\n\n  // Step 3: Ship order\n  return await queue.add('ship-order', {\n    orderId\n  }, {\n    parent: {\n      id: job.id,\n      queue: job.queueName\n    }\n  });\n});\n```\n\n## Pattern 2: Fan-Out/Fan-In\n\nProcess multiple jobs in parallel, then aggregate results.\n\n```typescript\n// Fan-out: Create parallel jobs\nconst userIds = [1, 2, 3, 4, 5];\n\nconst jobs = await Promise.all(\n  userIds.map(userId =>\n    queue.add('send-notification', {\n      userId\n    }, {\n      parent: { id: 'batch-123', queue: 'aggregator' }\n    })\n  )\n);\n\n// Fan-in: Aggregate when all complete\nconst aggregatorWorker = new Worker('aggregator', async (job) => {\n  const children = await job.getChildrenValues();\n\n  const successCount = Object.values(children).filter(\n    r => r.status === 'sent'\n  ).length;\n\n  console.log(`Sent ${successCount}/${userIds.length} notifications`);\n});\n```\n\n## Pattern 3: Rate-Limited API Calls\n\nRespect third-party API rate limits.\n\n```typescript\n// Configure rate limiter\nconst apiQueue = new Queue('external-api', {\n  connection,\n  limiter: {\n    max: 100,        // Max 100 requests\n    duration: 60000, // Per 60 seconds\n    groupKey: 'apiKey' // Rate limit per API key\n  }\n});\n\n// Group jobs by API key\nawait apiQueue.add('fetch-data', {\n  endpoint: '/users',\n  apiKey: 'key123'\n}, {\n  rateLimiter: {\n    groupKey: 'key123' // This key gets 100 req/min\n  }\n});\n```\n\n## Pattern 4: Priority Queues\n\nProcess high-priority jobs first.\n\n```typescript\n// Add jobs with priority (lower number = higher priority)\nawait queue.add('send-email', {\n  to: 'premium@user.com'\n}, {\n  priority: 1  // Premium users\n});\n\nawait queue.add('send-email', {\n  to: 'free@user.com'\n}, {\n  priority: 10  // Free users\n});\n\n// Worker processes priority 1 jobs before priority 10\nconst worker = new Worker('email-queue', processEmail, {\n  connection,\n  concurrency: 5\n});\n```\n\n## Pattern 5: Delayed Jobs\n\nSchedule jobs for future execution.\n\n```typescript\n// Send reminder email in 24 hours\nawait queue.add('send-reminder', {\n  userId: 123\n}, {\n  delay: 24 * 60 * 60 * 1000 // 24 hours in ms\n});\n\n// Or: Specific timestamp\nconst scheduledTime = new Date('2026-01-15T09:00:00Z');\nawait queue.add('daily-report', {\n  type: 'sales'\n}, {\n  delay: scheduledTime.getTime() - Date.now()\n});\n```\n\n## Pattern 6: Repeatable Jobs (Cron)\n\nSchedule recurring jobs with cron syntax.\n\n```typescript\n// Daily at 9 AM\nawait queue.add('daily-digest', {\n  recipients: ['admin@company.com']\n}, {\n  repeat: {\n    pattern: '0 9 * * *',  // Cron syntax\n    tz: 'America/New_York'\n  }\n});\n\n// Every 15 minutes\nawait queue.add('health-check', {\n  service: 'api'\n}, {\n  repeat: {\n    every: 15 * 60 * 1000 // 15 minutes in ms\n  }\n});\n```\n\n## Pattern 7: Job Progress Tracking\n\nUpdate progress for long-running jobs.\n\n```typescript\nworker.process('video-transcode', async (job) => {\n  const { videoId, formats } = job.data;\n\n  for (let i = 0; i < formats.length; i++) {\n    const progress = ((i + 1) / formats.length) * 100;\n\n    // Update progress\n    await job.updateProgress(progress);\n\n    // Log current step\n    await job.log(`Transcoding ${formats[i]}...`);\n\n    await transcodeVideo(videoId, formats[i]);\n  }\n\n  return { completed: formats.length };\n});\n\n// Client polls progress\nconst job = await queue.getJob(jobId);\nconsole.log(`Progress: ${job.progress}%`);\n\n// Or: Listen to progress events\nqueueEvents.on('progress', ({ jobId, data }) => {\n  console.log(`Job ${jobId}: ${data}%`);\n});\n```\n\n## Pattern 8: Conditional Job Execution\n\nExecute jobs based on previous results.\n\n```typescript\nworker.process('process-upload', async (job) => {\n  const { fileUrl } = job.data;\n\n  // Download file\n  const file = await downloadFile(fileUrl);\n\n  // Conditional: Only process if valid\n  if (!isValidFile(file)) {\n    await job.log('Invalid file, skipping processing');\n    return { skipped: true };\n  }\n\n  // Process valid files\n  const result = await processFile(file);\n\n  // Add follow-up job only if needed\n  if (result.needsTranscoding) {\n    await queue.add('transcode', {\n      fileId: result.fileId\n    }, {\n      parent: { id: job.id, queue: job.queueName }\n    });\n  }\n\n  return result;\n});\n```\n\n## Pattern 9: Graceful Shutdown\n\nHandle in-flight jobs during shutdown.\n\n```typescript\nlet isShuttingDown = false;\n\nconst worker = new Worker('email-queue', async (job) => {\n  if (isShuttingDown) {\n    throw new Error('Shutting down, job will be requeued');\n  }\n\n  await processEmail(job.data);\n}, {\n  connection\n});\n\n// Graceful shutdown handler\nprocess.on('SIGTERM', async () => {\n  console.log('Received SIGTERM, shutting down gracefully...');\n\n  isShuttingDown = true;\n\n  // Stop accepting new jobs\n  await worker.pause();\n\n  // Wait for active jobs to complete (max 30 seconds)\n  await worker.close();\n\n  console.log('All jobs completed, exiting');\n  process.exit(0);\n});\n```\n\n## Pattern 10: Dead Letter Queue Recovery\n\nRetry failed jobs with modified data.\n\n```typescript\n// Get all failed jobs\nconst failedJobs = await queue.getFailed();\n\n// Analyze and retry with fixes\nfor (const job of failedJobs) {\n  const { failedReason } = job;\n\n  if (failedReason.includes('Invalid email')) {\n    // Fix email and retry\n    const fixedEmail = sanitizeEmail(job.data.email);\n\n    await queue.add('send-email', {\n      ...job.data,\n      email: fixedEmail\n    }, {\n      attempts: 1 // Only 1 more attempt\n    });\n\n    // Remove original failed job\n    await job.remove();\n  }\n}\n```\n\n## Production Checklist\n\n```\nâ–¡ Dead letter queue monitoring\nâ–¡ Exponential backoff configured\nâ–¡ Job timeouts set appropriately\nâ–¡ Rate limiting for external APIs\nâ–¡ Idempotency keys for critical jobs\nâ–¡ Worker concurrency tuned\nâ–¡ Graceful shutdown implemented\nâ–¡ Queue depth alerts configured\nâ–¡ Failed job inspection workflow\nâ–¡ Redis persistence enabled\nâ–¡ Job data sanitized (no PII in logs)\nâ–¡ Progress tracking for long jobs\n```\n\n## Performance Tips\n\n1. **Use bulk operations**: `queue.addBulk()` is 10x faster than individual `add()` calls\n2. **Tune concurrency**: Start with `CPU cores * 2`, adjust based on job type\n3. **Remove completed jobs**: Set `removeOnComplete` to prevent Redis bloat\n4. **Use priorities sparingly**: Too many priority levels hurt performance\n5. **Partition queues**: Separate queues for different job types improves isolation\n6. **Monitor Redis memory**: Set `maxmemory-policy` to `allkeys-lru` for Redis\n\n## Common Pitfalls\n\n1. **Not handling job failures**: Always have dead letter queue inspection\n2. **Forgetting idempotency**: Jobs can run twice, design for it\n3. **Blocking workers**: Don't do synchronous I/O in workers\n4. **Not monitoring queue depth**: Set up alerts before it's too late\n5. **Over-using repeatable jobs**: They create Redis bloat, use sparingly\n"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "folder",
      "path": "background-job-orchestrator/scripts",
      "children": [
        {
          "name": "queue_health_check.ts",
          "type": "file",
          "path": "background-job-orchestrator/scripts/queue_health_check.ts",
          "size": 4366,
          "content": "#!/usr/bin/env node\n/**\n * Queue Health Check Dashboard\n *\n * Monitors BullMQ queue metrics and provides health status.\n *\n * Usage: npx ts-node queue_health_check.ts [queue-name]\n *\n * Dependencies: npm install bullmq ioredis chalk\n */\n\nimport { Queue } from 'bullmq';\nimport Redis from 'ioredis';\nimport chalk from 'chalk';\n\ninterface QueueMetrics {\n  waiting: number;\n  active: number;\n  completed: number;\n  failed: number;\n  delayed: number;\n  paused: boolean;\n}\n\ninterface HealthStatus {\n  status: 'healthy' | 'degraded' | 'critical';\n  metrics: QueueMetrics;\n  warnings: string[];\n}\n\nasync function getQueueHealth(queueName: string): Promise<HealthStatus> {\n  const connection = new Redis({\n    host: process.env.REDIS_HOST || 'localhost',\n    port: parseInt(process.env.REDIS_PORT || '6379'),\n    maxRetriesPerRequest: null\n  });\n\n  const queue = new Queue(queueName, { connection });\n\n  try {\n    const [waiting, active, completed, failed, delayed, paused] = await Promise.all([\n      queue.getWaitingCount(),\n      queue.getActiveCount(),\n      queue.getCompletedCount(),\n      queue.getFailedCount(),\n      queue.getDelayedCount(),\n      queue.isPaused()\n    ]);\n\n    const metrics: QueueMetrics = {\n      waiting,\n      active,\n      completed,\n      failed,\n      delayed,\n      paused\n    };\n\n    const warnings: string[] = [];\n    let status: 'healthy' | 'degraded' | 'critical' = 'healthy';\n\n    // Health checks\n    if (waiting > 1000) {\n      warnings.push(`High queue depth: ${waiting} jobs waiting`);\n      status = 'degraded';\n    }\n\n    if (failed > 100) {\n      warnings.push(`High failure rate: ${failed} failed jobs`);\n      status = 'degraded';\n    }\n\n    if (waiting > 5000 || failed > 500) {\n      status = 'critical';\n    }\n\n    if (paused) {\n      warnings.push('Queue is paused!');\n      status = 'critical';\n    }\n\n    return { status, metrics, warnings };\n  } finally {\n    await queue.close();\n    await connection.quit();\n  }\n}\n\nasync function displayDashboard(queueName: string) {\n  console.clear();\n  console.log(chalk.bold.cyan(`\\nðŸ“Š Queue Health Dashboard: ${queueName}\\n`));\n\n  const health = await getQueueHealth(queueName);\n\n  // Status badge\n  const statusColor = {\n    healthy: chalk.green,\n    degraded: chalk.yellow,\n    critical: chalk.red\n  }[health.status];\n\n  console.log(statusColor(`Status: ${health.status.toUpperCase()}\\n`));\n\n  // Metrics\n  console.log(chalk.bold('Metrics:'));\n  console.log(`  Waiting:   ${chalk.cyan(health.metrics.waiting.toString().padStart(8))}`);\n  console.log(`  Active:    ${chalk.blue(health.metrics.active.toString().padStart(8))}`);\n  console.log(`  Completed: ${chalk.green(health.metrics.completed.toString().padStart(8))}`);\n  console.log(`  Failed:    ${chalk.red(health.metrics.failed.toString().padStart(8))}`);\n  console.log(`  Delayed:   ${chalk.magenta(health.metrics.delayed.toString().padStart(8))}`);\n  console.log(`  Paused:    ${health.metrics.paused ? chalk.red('YES') : chalk.green('NO')}\\n`);\n\n  // Warnings\n  if (health.warnings.length > 0) {\n    console.log(chalk.bold.yellow('âš ï¸  Warnings:'));\n    health.warnings.forEach(warning => {\n      console.log(chalk.yellow(`  â€¢ ${warning}`));\n    });\n    console.log('');\n  }\n\n  // Recommendations\n  if (health.status === 'degraded') {\n    console.log(chalk.bold.yellow('ðŸ’¡ Recommendations:'));\n    if (health.metrics.waiting > 1000) {\n      console.log(chalk.yellow('  â€¢ Scale up workers to process backlog'));\n    }\n    if (health.metrics.failed > 100) {\n      console.log(chalk.yellow('  â€¢ Investigate failed jobs: await queue.getFailed()'));\n    }\n    console.log('');\n  }\n\n  if (health.status === 'critical') {\n    console.log(chalk.bold.red('ðŸš¨ CRITICAL - IMMEDIATE ACTION REQUIRED'));\n    console.log(chalk.red('  â€¢ Queue is severely degraded'));\n    console.log(chalk.red('  â€¢ Check worker processes are running'));\n    console.log(chalk.red('  â€¢ Review logs for errors'));\n    console.log('');\n  }\n\n  console.log(chalk.dim(`Last updated: ${new Date().toLocaleTimeString()}`));\n}\n\n// Main\nconst queueName = process.argv[2] || 'email-queue';\n\nconsole.log(chalk.dim('Starting queue health monitor...'));\nconsole.log(chalk.dim('Press Ctrl+C to exit\\n'));\n\n// Initial display\ndisplayDashboard(queueName);\n\n// Refresh every 5 seconds\nsetInterval(() => {\n  displayDashboard(queueName);\n}, 5000);\n"
        },
        {
          "name": "setup_bullmq.sh",
          "type": "file",
          "path": "background-job-orchestrator/scripts/setup_bullmq.sh",
          "size": 2752,
          "content": "#!/bin/bash\n# Setup BullMQ with Redis for background job processing\n# Usage: ./setup_bullmq.sh\n\nset -e\n\necho \"ðŸš€ Setting up BullMQ with Redis...\"\n\n# Check if npm is installed\nif ! command -v npm &> /dev/null; then\n    echo \"âŒ npm not found. Install Node.js first.\"\n    exit 1\nfi\n\n# Install BullMQ dependencies\necho \"ðŸ“¦ Installing BullMQ and dependencies...\"\nnpm install --save bullmq ioredis\nnpm install --save-dev @types/node\n\n# Check if Redis is running\necho \"ðŸ” Checking Redis connection...\"\nif command -v redis-cli &> /dev/null; then\n    if redis-cli ping &> /dev/null; then\n        echo \"âœ… Redis is running\"\n    else\n        echo \"âš ï¸  Redis is installed but not running\"\n        echo \"Start Redis with: redis-server\"\n    fi\nelse\n    echo \"âš ï¸  Redis not found. Install with:\"\n    echo \"  macOS: brew install redis\"\n    echo \"  Ubuntu: sudo apt-get install redis-server\"\n    echo \"  Docker: docker run -d -p 6379:6379 redis:alpine\"\nfi\n\n# Create basic queue setup\necho \"ðŸ“ Creating queue configuration...\"\ncat > queue.config.ts << 'EOF'\nimport { Queue, Worker, QueueEvents } from 'bullmq';\nimport Redis from 'ioredis';\n\n// Redis connection\nconst connection = new Redis({\n  host: process.env.REDIS_HOST || 'localhost',\n  port: parseInt(process.env.REDIS_PORT || '6379'),\n  maxRetriesPerRequest: null\n});\n\n// Create queue\nexport const emailQueue = new Queue('email-queue', {\n  connection,\n  defaultJobOptions: {\n    attempts: 3,\n    backoff: {\n      type: 'exponential',\n      delay: 2000\n    },\n    removeOnComplete: 100,\n    removeOnFail: false\n  }\n});\n\n// Create worker\nexport const emailWorker = new Worker('email-queue', async (job) => {\n  console.log(`Processing job ${job.id}:`, job.data);\n\n  // Your job processing logic here\n  await new Promise(resolve => setTimeout(resolve, 1000));\n\n  return { processed: true, timestamp: new Date().toISOString() };\n}, {\n  connection,\n  concurrency: 5\n});\n\n// Queue events for monitoring\nconst queueEvents = new QueueEvents('email-queue', { connection });\n\nqueueEvents.on('completed', ({ jobId }) => {\n  console.log(`âœ… Job ${jobId} completed`);\n});\n\nqueueEvents.on('failed', ({ jobId, failedReason }) => {\n  console.error(`âŒ Job ${jobId} failed:`, failedReason);\n});\n\n// Graceful shutdown\nprocess.on('SIGTERM', async () => {\n  console.log('Shutting down gracefully...');\n  await emailWorker.close();\n  await emailQueue.close();\n  await connection.quit();\n  process.exit(0);\n});\nEOF\n\necho \"âœ… Setup complete!\"\necho \"\"\necho \"Next steps:\"\necho \"1. Start Redis (if not running)\"\necho \"2. Import queue in your code: import { emailQueue } from './queue.config'\"\necho \"3. Add jobs: await emailQueue.add('send', { to: 'user@example.com' })\"\necho \"4. Worker will process jobs automatically\"\n"
        }
      ]
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "background-job-orchestrator/SKILL.md",
      "size": 12531,
      "content": "---\nname: background-job-orchestrator\ndescription: Expert in background job processing with Bull/BullMQ (Redis), Celery, and cloud queues. Implements retries, scheduling, priority queues, and worker management. Use for async task processing, email campaigns, report generation, batch operations. Activate on \"background job\", \"async task\", \"queue\", \"worker\", \"BullMQ\", \"Celery\". NOT for real-time WebSocket communication, synchronous API calls, or simple setTimeout operations.\nallowed-tools: Read,Write,Edit,Bash(npm:*,pip:*)\n---\n\n# Background Job Orchestrator\n\nExpert in designing and implementing production-grade background job systems that handle long-running tasks without blocking API responses.\n\n## When to Use\n\nâœ… **Use for**:\n- Long-running tasks (email sends, report generation, image processing)\n- Batch operations (bulk imports, exports, data migrations)\n- Scheduled tasks (daily digests, cleanup jobs, recurring reports)\n- Tasks requiring retry logic (external API calls, flaky operations)\n- Priority-based processing (premium users first, critical alerts)\n- Rate-limited operations (API quotas, third-party service limits)\n\nâŒ **NOT for**:\n- Real-time bidirectional communication (use WebSockets)\n- Sub-second latency requirements (use in-memory caching)\n- Simple delays (setTimeout is fine for &lt;5 seconds)\n- Synchronous API responses (keep logic in request handler)\n\n## Quick Decision Tree\n\n```\nDoes this task:\nâ”œâ”€â”€ Take &gt;5 seconds? â†’ Background job\nâ”œâ”€â”€ Need to retry on failure? â†’ Background job\nâ”œâ”€â”€ Run on a schedule? â†’ Background job (cron pattern)\nâ”œâ”€â”€ Block user interaction? â†’ Background job\nâ”œâ”€â”€ Process in batches? â†’ Background job\nâ””â”€â”€ Return immediately? â†’ Keep synchronous\n```\n\n---\n\n## Technology Selection\n\n### Node.js: BullMQ (Recommended 2024+)\n\n**When to use**:\n- TypeScript project\n- Redis already in stack\n- Need advanced features (rate limiting, priorities, repeatable jobs)\n\n**Why BullMQ over Bull**:\n- Bull (v3) â†’ BullMQ (v4+): Complete rewrite in TypeScript\n- Better Redis connection handling\n- Improved concurrency and performance\n- Active maintenance (Bull is in maintenance mode)\n\n### Python: Celery\n\n**When to use**:\n- Python/Django project\n- Need distributed task execution\n- Complex workflows (chains, groups, chords)\n\n**Alternatives**:\n- **RQ** (Redis Queue): Simpler, fewer features\n- **Dramatiq**: Modern, less ecosystem\n- **Huey**: Lightweight, good for small projects\n\n### Cloud-Native: AWS SQS, Google Cloud Tasks\n\n**When to use**:\n- Serverless architecture\n- Don't want to manage Redis/RabbitMQ\n- Need guaranteed delivery and dead-letter queues\n\n---\n\n## Common Anti-Patterns\n\n### Anti-Pattern 1: No Dead Letter Queue\n\n**Novice thinking**: \"Retry 3 times, then fail silently\"\n\n**Problem**: Failed jobs disappear with no visibility or recovery path.\n\n**Correct approach**:\n```typescript\n// BullMQ with dead letter queue\nconst queue = new Queue('email-queue', {\n  connection: redis,\n  defaultJobOptions: {\n    attempts: 3,\n    backoff: {\n      type: 'exponential',\n      delay: 2000\n    },\n    removeOnComplete: 100, // Keep last 100 successful\n    removeOnFail: false     // Keep all failed for inspection\n  }\n});\n\n// Monitor failed jobs\nconst failedJobs = await queue.getFailed();\n```\n\n**Timeline**:\n- Pre-2020: Retry and forget\n- 2020+: Dead letter queues standard\n- 2024+: Observability for job failures required\n\n---\n\n### Anti-Pattern 2: Synchronous Job Processing\n\n**Symptom**: API endpoint waits for job completion\n\n**Problem**:\n```typescript\n// âŒ WRONG - Blocks API response\napp.post('/send-email', async (req, res) => {\n  await sendEmail(req.body.to, req.body.subject);\n  res.json({ success: true });\n});\n```\n\n**Why wrong**: Timeout, poor UX, wastes server resources\n\n**Correct approach**:\n```typescript\n// âœ… RIGHT - Queue and return immediately\napp.post('/send-email', async (req, res) => {\n  const job = await emailQueue.add('send', {\n    to: req.body.to,\n    subject: req.body.subject\n  });\n\n  res.json({\n    success: true,\n    jobId: job.id,\n    status: 'queued'\n  });\n});\n\n// Separate worker processes the job\nworker.process('send', async (job) => {\n  await sendEmail(job.data.to, job.data.subject);\n});\n```\n\n---\n\n### Anti-Pattern 3: No Idempotency\n\n**Problem**: Job runs twice â†’ duplicate charges, double emails\n\n**Why it happens**:\n- Redis connection drops mid-processing\n- Worker crashes before job completion\n- Job timeout triggers retry while still running\n\n**Correct approach**:\n```typescript\n// âœ… Idempotent job with deduplication key\nawait queue.add('charge-payment', {\n  userId: 123,\n  amount: 50.00\n}, {\n  jobId: `payment-${orderId}`, // Prevents duplicates\n  attempts: 3\n});\n\n// In worker: Check if already processed\nworker.process('charge-payment', async (job) => {\n  const { userId, amount } = job.data;\n\n  // Check idempotency\n  const existing = await db.payments.findOne({\n    jobId: job.id\n  });\n  if (existing) {\n    return existing; // Already processed\n  }\n\n  // Process payment\n  const result = await stripe.charges.create({...});\n\n  // Store idempotency record\n  await db.payments.create({\n    jobId: job.id,\n    result\n  });\n\n  return result;\n});\n```\n\n---\n\n### Anti-Pattern 4: No Rate Limiting\n\n**Problem**: Overwhelm third-party APIs or exhaust quotas\n\n**Symptom**: \"Rate limit exceeded\" errors from Sendgrid, Stripe, etc.\n\n**Correct approach**:\n```typescript\n// BullMQ rate limiting\nconst queue = new Queue('api-calls', {\n  limiter: {\n    max: 100,        // Max 100 jobs\n    duration: 60000  // Per 60 seconds\n  }\n});\n\n// Or: Priority-based rate limits\nawait queue.add('send-email', data, {\n  priority: user.isPremium ? 1 : 10,\n  rateLimiter: {\n    max: user.isPremium ? 1000 : 100,\n    duration: 3600000 // Per hour\n  }\n});\n```\n\n---\n\n### Anti-Pattern 5: Forgetting Worker Scaling\n\n**Problem**: Single worker can't keep up with queue depth\n\n**Symptom**: Queue backs up, jobs delayed hours/days\n\n**Correct approach**:\n```typescript\n// Horizontal scaling with multiple workers\nconst worker = new Worker('email-queue', async (job) => {\n  await processEmail(job.data);\n}, {\n  connection: redis,\n  concurrency: 5  // Process 5 jobs concurrently per worker\n});\n\n// Run multiple worker processes (PM2, Kubernetes, etc.)\n// Each worker processes concurrency * num_workers jobs\n```\n\n**Monitoring**:\n```typescript\n// Set up alerts for queue depth\nsetInterval(async () => {\n  const waiting = await queue.getWaitingCount();\n  if (waiting > 1000) {\n    alert('Queue depth exceeds 1000, scale workers!');\n  }\n}, 60000);\n```\n\n---\n\n## Implementation Patterns\n\n### Pattern 1: Email Campaigns\n\n```typescript\n// Queue setup\nconst emailQueue = new Queue('email-campaign', { connection: redis });\n\n// Enqueue batch\nasync function sendCampaign(userIds: number[], template: string) {\n  const jobs = userIds.map(userId => ({\n    name: 'send',\n    data: { userId, template },\n    opts: {\n      attempts: 3,\n      backoff: { type: 'exponential', delay: 5000 }\n    }\n  }));\n\n  await emailQueue.addBulk(jobs);\n}\n\n// Worker with retry logic\nconst worker = new Worker('email-campaign', async (job) => {\n  const { userId, template } = job.data;\n\n  const user = await db.users.findById(userId);\n  const email = renderTemplate(template, user);\n\n  try {\n    await sendgrid.send({\n      to: user.email,\n      subject: email.subject,\n      html: email.body\n    });\n  } catch (error) {\n    if (error.code === 'ECONNREFUSED') {\n      throw error; // Retry\n    }\n    // Invalid email, don't retry\n    console.error(`Invalid email for user ${userId}`);\n  }\n}, {\n  connection: redis,\n  concurrency: 10\n});\n```\n\n### Pattern 2: Scheduled Reports\n\n```typescript\n// Daily report at 9 AM\nawait queue.add('daily-report', {\n  type: 'sales',\n  recipients: ['admin@company.com']\n}, {\n  repeat: {\n    pattern: '0 9 * * *', // Cron syntax\n    tz: 'America/New_York'\n  }\n});\n\n// Worker generates and emails report\nworker.process('daily-report', async (job) => {\n  const { type, recipients } = job.data;\n\n  const data = await generateReport(type);\n  const pdf = await createPDF(data);\n\n  await emailQueue.add('send', {\n    to: recipients,\n    subject: `Daily ${type} Report`,\n    attachments: [{ filename: 'report.pdf', content: pdf }]\n  });\n});\n```\n\n### Pattern 3: Video Transcoding Pipeline\n\n```typescript\n// Multi-stage job with progress tracking\nawait videoQueue.add('transcode', {\n  videoId: 123,\n  formats: ['720p', '1080p', '4k']\n}, {\n  attempts: 2,\n  timeout: 3600000 // 1 hour timeout\n});\n\nworker.process('transcode', async (job) => {\n  const { videoId, formats } = job.data;\n\n  for (let i = 0; i < formats.length; i++) {\n    const format = formats[i];\n\n    // Update progress\n    await job.updateProgress((i / formats.length) * 100);\n\n    // Transcode\n    await ffmpeg.transcode(videoId, format);\n  }\n\n  await job.updateProgress(100);\n});\n\n// Client polls for progress\napp.get('/videos/:id/status', async (req, res) => {\n  const job = await queue.getJob(req.params.jobId);\n  res.json({\n    state: await job.getState(),\n    progress: job.progress\n  });\n});\n```\n\n---\n\n## Monitoring & Observability\n\n### Essential Metrics\n\n```typescript\n// Queue health dashboard\nasync function getQueueMetrics() {\n  const [waiting, active, completed, failed, delayed] = await Promise.all([\n    queue.getWaitingCount(),\n    queue.getActiveCount(),\n    queue.getCompletedCount(),\n    queue.getFailedCount(),\n    queue.getDelayedCount()\n  ]);\n\n  return {\n    waiting,    // Jobs waiting to be processed\n    active,     // Jobs currently processing\n    completed,  // Successfully completed\n    failed,     // Failed after retries\n    delayed,    // Scheduled for future\n    health: waiting < 1000 && failed < 100 ? 'healthy' : 'degraded'\n  };\n}\n```\n\n### BullMQ Board (UI)\n\n```typescript\n// Development: Monitor jobs visually\nimport { createBullBoard } from '@bull-board/api';\nimport { BullMQAdapter } from '@bull-board/api/bullMQAdapter';\nimport { ExpressAdapter } from '@bull-board/express';\n\nconst serverAdapter = new ExpressAdapter();\n\ncreateBullBoard({\n  queues: [\n    new BullMQAdapter(emailQueue),\n    new BullMQAdapter(videoQueue)\n  ],\n  serverAdapter\n});\n\napp.use('/admin/queues', serverAdapter.getRouter());\n// Visit http://localhost:3000/admin/queues\n```\n\n---\n\n## Production Checklist\n\n```\nâ–¡ Dead letter queue configured\nâ–¡ Retry strategy with exponential backoff\nâ–¡ Job timeout limits set\nâ–¡ Rate limiting for third-party APIs\nâ–¡ Idempotency keys for critical operations\nâ–¡ Worker concurrency tuned (CPU cores * 2)\nâ–¡ Horizontal scaling configured (multiple workers)\nâ–¡ Queue depth monitoring with alerts\nâ–¡ Failed job inspection workflow\nâ–¡ Job data doesn't contain PII in logs\nâ–¡ Redis persistence enabled (AOF or RDB)\nâ–¡ Graceful shutdown handling (SIGTERM)\n```\n\n---\n\n## When to Use vs Avoid\n\n| Scenario | Use Background Jobs? |\n|----------|---------------------|\n| Send welcome email on signup | âœ… Yes - can take 2-5 seconds |\n| Charge credit card | âš ï¸ Maybe - depends on payment provider latency |\n| Generate PDF report (30 seconds) | âœ… Yes - definitely background |\n| Fetch user profile from DB | âŒ No - milliseconds, keep synchronous |\n| Process video upload (5 minutes) | âœ… Yes - always background |\n| Validate form input | âŒ No - synchronous validation |\n| Daily cron job | âœ… Yes - use repeatable jobs |\n| Real-time chat message | âŒ No - use WebSockets |\n\n---\n\n## Technology Comparison\n\n| Feature | BullMQ | Celery | AWS SQS |\n|---------|--------|--------|---------|\n| Language | Node.js | Python | Any (HTTP API) |\n| Backend | Redis | Redis/RabbitMQ/SQS | Managed |\n| Priorities | âœ… | âœ… | âœ… |\n| Rate Limiting | âœ… | âŒ | âœ… (via attributes) |\n| Repeat/Cron | âœ… | âœ… (celery-beat) | âŒ (use EventBridge) |\n| UI Dashboard | Bull Board | Flower | CloudWatch |\n| Workflows | âŒ | âœ… (chains, groups) | âŒ |\n| Learning Curve | Medium | Medium | Low |\n| Cost | Redis hosting | Redis hosting | $0.40/million requests |\n\n---\n\n## References\n\n- `/references/bullmq-patterns.md` - Advanced BullMQ patterns and examples\n- `/references/celery-workflows.md` - Celery chains, groups, and chords\n- `/references/job-observability.md` - Monitoring, alerting, and debugging\n\n## Scripts\n\n- `scripts/setup_bullmq.sh` - Initialize BullMQ with Redis\n- `scripts/queue_health_check.ts` - Queue metrics dashboard\n- `scripts/retry_failed_jobs.ts` - Bulk retry failed jobs\n\n---\n\n**This skill guides**: Background job implementation | Queue architecture | Retry strategies | Worker scaling | Job observability\n"
    }
  ]
}