{
  "name": "skill-architect",
  "type": "folder",
  "path": "skill-architect",
  "children": [
    {
      "name": "references",
      "type": "folder",
      "path": "skill-architect/references",
      "children": [
        {
          "name": "antipatterns.md",
          "type": "file",
          "path": "skill-architect/references/antipatterns.md",
          "size": 14614,
          "content": "# Skill Anti-Patterns: The Shibboleths\n\nThis document catalogs **domain-specific knowledge that separates novices from experts** - the things LLMs get wrong because their training data includes outdated patterns, oversimplified tutorials, or cargo-culted code.\n\n## Table of Contents\n\n1. [ML/AI Model Selection](#mlai-model-selection)\n2. [Framework Evolution](#framework-evolution)\n3. [Tool Architecture](#tool-architecture)\n4. [Skill Design](#skill-design)\n\n---\n\n## ML/AI Model Selection\n\n### Anti-Pattern: CLIP for Everything\n\n**Novice thinking**: \"CLIP is pre-trained on 400M image-text pairs and does zero-shot classification. Use it for all image-text tasks!\"\n\n**Reality**: CLIP has **fundamental geometric limitations**. Research from 2023-2025 proves it cannot simultaneously handle:\n\n1. Basic descriptions\n2. Attribute binding (\"red car AND blue truck\" vs \"blue car AND red truck\")\n3. Spatial relationships (\"cat left of dog\" vs \"dog left of cat\")\n4. Negation (\"not a cat\")\n\n**What CLIP fails at**:\n- ❌ Counting objects in images\n- ❌ Fine-grained classification (celebrity ID, car models, flower species)\n- ❌ Compositional reasoning\n- ❌ Spatial understanding\n- ❌ Handwritten text (MNIST-style)\n\n**When to use alternatives**:\n\n| Task | Use Instead | Why |\n|------|-------------|-----|\n| Counting objects | DETR, Faster R-CNN | Object detection models built for counting |\n| Fine-grained classification | EfficientNet + task head | Transfer learning on specific domain |\n| Compositional reasoning | DCSMs, PC-CLIP | Preserve patch/token topology |\n| Spatial relationships | GQA models, SWIG | Built for spatial understanding |\n| Attribute binding | PC-CLIP (pairwise) | Trained on comparative data |\n\n**Timeline**:\n- 2021: Original CLIP released\n- 2022-2023: Limitations discovered in research\n- 2024: DCSMs (Dense Cosine Similarity Maps) paper\n- 2024: PC-CLIP (Pairwise Comparison CLIP)\n- 2025: SpLiCE (Sparse Linear Concept Embeddings)\n\n**LLM mistake**: LLMs trained on 2021-2023 data will suggest CLIP for everything because limitations weren't widely known yet.\n\n---\n\n### Anti-Pattern: Single Embedding Model\n\n**Novice thinking**: \"Pick one embedding model and use it everywhere\"\n\n**Expert knowledge**: Different tasks need different models:\n\n**Text embeddings**:\n- Semantic search: `text-embedding-3-large`, `voyage-2`\n- Code search: `voyage-code-2`, `text-embedding-ada-002`\n- Multi-lingual: `multilingual-e5-large`\n- Long documents: `jina-embeddings-v2` (8k tokens)\n\n**Image embeddings**:\n- General: CLIP ViT-L/14\n- Fine-grained: DINOv2\n- Medical: BiomedCLIP\n- Faces: ArcFace, CosFace\n\n**Multi-modal**:\n- Image-text: CLIP, BLIP-2\n- Video: X-CLIP, VideoCLIP\n- 3D: ULIP, PointCLIP\n\n**Why this matters**: Embedding quality directly impacts retrieval accuracy. Using the wrong model can drop accuracy by 20-40%.\n\n---\n\n### Anti-Pattern: Ignoring Model Versioning\n\n**Problem**: \"We're using `text-embedding-ada-002`\" (doesn't specify when)\n\n**Why wrong**: Models evolve:\n- `text-embedding-ada-002` (Dec 2022) vs `text-embedding-3-small` (Jan 2024)\n- CLIP ViT-B/32 vs ViT-L/14 vs ViT-g-14\n- Different training data, different capabilities\n\n**Best practice**: Pin versions, document when you adopted them:\n```python\n# embeddings.py\nMODEL = \"text-embedding-3-large\"  # Adopted: 2024-03-15\nMODEL_DIMENSIONS = 3072\nTRAINING_CUTOFF = \"2023-09\"  # Approximate\n```\n\n---\n\n## Framework Evolution\n\n### Anti-Pattern: Pages Router in App Router Projects\n\n**Context**: Next.js 13 (Oct 2022) introduced App Router, fundamentally changing architecture.\n\n**Outdated pattern** (Pages Router):\n```javascript\n// pages/api/users.js\nexport default function handler(req, res) {\n  res.json({ users: [] })\n}\n\n// pages/users.js\nexport async function getServerSideProps() {\n  return { props: { users: [] } }\n}\n```\n\n**Current pattern** (App Router):\n```javascript\n// app/api/users/route.js\nexport async function GET() {\n  return Response.json({ users: [] })\n}\n\n// app/users/page.js\nasync function UsersPage() {\n  const users = await fetchUsers()  // Server Component\n  return <UserList users={users} />\n}\n```\n\n**Why it matters**: Pages Router patterns don't work in App Router and vice versa.\n\n**LLM mistake**: Training data from 2020-2023 overwhelmingly shows Pages Router. LLMs will default to old patterns unless specifically prompted.\n\n**Timeline**:\n- 2016-2022: Pages Router only\n- Oct 2022: App Router introduced (beta)\n- May 2023: App Router stable\n- 2024+: App Router is default\n\n---\n\n### Anti-Pattern: Redux for Everything\n\n**Novice thinking**: \"Global state needs Redux\"\n\n**Timeline**:\n- 2015-2020: Redux dominated\n- 2019: Context API improved in React 16.3\n- 2020: Zustand, Jotai emerged\n- 2023: React Server Components changed the game\n\n**Current wisdom**:\n- **Local UI state**: `useState`, `useReducer`\n- **Derived state**: `useMemo`, selectors\n- **Global state (simple)**: Context API\n- **Global state (complex)**: Zustand, Jotai\n- **Server state**: React Query, SWR\n- **URL state**: Next.js searchParams\n- **Redux**: Only if you need time-travel debugging or complex middleware\n\n**Why Redux fell out of favor**:\n- Boilerplate heavy\n- Server Components make much state \"server-native\"\n- Simpler alternatives emerged\n\n**LLM mistake**: LLMs will suggest Redux by default because 80% of training data predates alternatives.\n\n---\n\n### Anti-Pattern: Class Components\n\n**Timeline**:\n- 2013-2018: Class components only\n- Feb 2019: Hooks introduced (React 16.8)\n- 2020+: Functional components are standard\n\n**Outdated**:\n```javascript\nclass UserProfile extends React.Component {\n  state = { user: null }\n  \n  componentDidMount() {\n    fetchUser().then(user => this.setState({ user }))\n  }\n  \n  render() {\n    return <div>{this.state.user?.name}</div>\n  }\n}\n```\n\n**Current**:\n```javascript\nfunction UserProfile() {\n  const [user, setUser] = useState(null)\n  \n  useEffect(() => {\n    fetchUser().then(setUser)\n  }, [])\n  \n  return <div>{user?.name}</div>\n}\n```\n\n**When class components are still valid**:\n- Error boundaries (no hook equivalent yet)\n- Legacy codebases\n\n**LLM mistake**: Will generate class components for complex state management\n\n---\n\n## Tool Architecture\n\n### Anti-Pattern: MCP for Everything\n\n**Novice thinking**: \"MCP is the new standard, make everything an MCP!\"\n\n**Expert reality**: MCPs have overhead. Use them strategically.\n\n**Use MCP when**:\n- ✅ External API with authentication\n- ✅ Stateful connections (WebSocket, database)\n- ✅ Real-time data streams\n- ✅ Security boundaries (credentials, OAuth)\n\n**Use Scripts when**:\n- ✅ Local file operations\n- ✅ Batch transformations\n- ✅ Stateless computations\n- ✅ CLI wrappers\n\n**Example - Wrong**:\n```python\n# mcp_server_for_json_parsing.py - OVERKILL!\n@mcp.tool()\ndef parse_json(file_path: str):\n    with open(file_path) as f:\n        return json.load(f)\n```\n\n**Example - Right**:\n```python\n# scripts/parse_json.py - Simple script!\nimport json\nimport sys\n\nwith open(sys.argv[1]) as f:\n    data = json.load(f)\n    print(json.dumps(data, indent=2))\n```\n\n**Philosophy**: \"MCP's job isn't to abstract reality for the agent; its job is to manage the auth, networking, and security boundaries and then get out of the way.\"\n\n---\n\n### Anti-Pattern: Premature Abstraction\n\n**Problem**: Building a complex MCP before understanding the use case\n\n**Better approach**: Start with scripts, graduate to MCP when you need:\n1. Auth/security boundaries\n2. Multiple tools in same domain\n3. State management\n4. Error handling standardization\n\n**Evolution path**:\n```\nScript → Multiple Scripts → Helper Library → MCP Server\n```\n\nOnly promote to MCP when complexity justifies it.\n\n---\n\n## Skill Design\n\n### Anti-Pattern: Skill as Documentation Dump\n\n**Bad**:\n```markdown\n---\nname: react-guide\ndescription: Everything about React\n---\n\n# React Guide\n\nReact is a JavaScript library for building user interfaces...\n[50 pages of tutorial content]\n```\n\n**Why wrong**: Not progressive disclosure, not actionable, not targeted.\n\n**Good**:\n```markdown\n---\nname: react-server-components\ndescription: Use React Server Components correctly. Use when working with Next.js App Router, async components, or server-side data fetching.\n---\n\n# React Server Components\n\n## Quick Decision Tree\n\nIs your component:\n- Fetching data? → Server Component\n- Using hooks/events? → Client Component\n- Both? → Server Component wrapper + Client Component child\n\n## Common Anti-Pattern: Everything is 'use client'\n\n❌ **Wrong**:\n```jsx\n'use client'\nasync function Page() {  // This doesn't work!\n  const data = await fetch(...)\n  return <div>{data}</div>\n}\n```\n\n✅ **Right**:\n```jsx\n// Server Component (default)\nasync function Page() {\n  const data = await fetchData()\n  return <ClientComponent data={data} />\n}\n\n// client-component.jsx\n'use client'\nfunction ClientComponent({ data }) {\n  const [count, setCount] = useState(0)\n  return <div onClick={() => setCount(count + 1)}>{data}</div>\n}\n```\n\n## When This Pattern Changed\n\n- Pre-Next.js 13: All components are client-side\n- Next.js 13+: Server Components by default\n- LLM confusion: Will add 'use client' everywhere because older patterns\n\nSee /references/server-components-deep-dive.md for more.\n```\n\n---\n\n### Anti-Pattern: Missing \"When NOT to Use\"\n\n**Problem**: Skills activate on false positives\n\n**Example - Without negatives**:\n```yaml\ndescription: Processes images using computer vision techniques\n```\nActivates for: image resizing, image generation, image editing, OCR, face detection, etc.\n\n**Example - With negatives**:\n```yaml\ndescription: Semantic image search using CLIP embeddings. Use for finding similar images, zero-shot classification. NOT for image generation, editing, or OCR. NOT for counting objects or fine-grained classification.\n```\n\n**Pattern**: Always include \"NOT for X, Y, Z\" to prevent false activation.\n\n---\n\n### Anti-Pattern: No Validation Script\n\n**Problem**: Skill gives instructions but no way to check correctness\n\n**Better**: Include validation\n\n```python\n# scripts/validate.py\ndef validate_setup():\n    \"\"\"Check if environment is configured correctly.\"\"\"\n    checks = {\n        \"Node version\": check_node_version(),\n        \"Dependencies\": check_dependencies(),\n        \"API keys\": check_api_keys(),\n    }\n    \n    for name, passed in checks.items():\n        print(f\"{'✅' if passed else '❌'} {name}\")\n    \n    return all(checks.values())\n```\n\n---\n\n### Anti-Pattern: Overly Permissive Tools\n\n**Bad**:\n```yaml\nallowed-tools: Bash\n```\n\n**Why**: Can execute ANY bash command\n\n**Better**:\n```yaml\nallowed-tools: Bash(git:*,npm:run,npm:install),Read,Write\n```\n\n**Principle**: Least privilege - only grant what's needed\n\n---\n\n## Temporal Knowledge Patterns\n\nWhen documenting anti-patterns, always include:\n\n1. **Timeline**: When was this practice common?\n2. **Why deprecated**: What replaced it and why?\n3. **LLM confusion**: Why will LLMs suggest the old pattern?\n4. **Migration path**: How to update from old to new?\n\n**Template**:\n```markdown\n### Anti-Pattern: [Pattern Name]\n\n**Used**: [Date range]\n**Replaced by**: [New approach]\n**Why deprecated**: [Reason]\n\n**Old way**:\n[code example]\n\n**New way**:\n[code example]\n\n**LLM mistake**: [Why LLM suggests old pattern]\n**How to detect**: [Validation rule]\n```\n\n---\n\n---\n\n## Real-World Failure Case Studies\n\n### Case Study 1: The Photo Expert Explosion\n\n**Skill**: `photo-expert` (v1.0)\n**Problem**: Single skill for ALL photo operations\n\n**Symptoms**:\n- Activated on \"photo\" anywhere in query\n- 800+ lines of instructions\n- Slow loading, high token usage\n- Wrong advice given (composition advice when user wanted color theory)\n\n**Root Cause**: Everything Skill anti-pattern\n\n**Resolution**: Split into 5 focused skills:\n- `clip-aware-embeddings` - semantic search\n- `photo-composition-critic` - aesthetic analysis\n- `color-theory-palette-harmony-expert` - color science\n- `collage-layout-expert` - arrangement algorithms\n- `event-detection-temporal-intelligence-expert` - clustering\n\n**Lesson**: One domain ≠ one skill. Split by expertise type.\n\n---\n\n### Case Study 2: The Phantom MCP\n\n**Skill**: `github-workflow-helper` (v1.1)\n**Problem**: Referenced MCP server that didn't exist\n\n**SKILL.md said**:\n```markdown\nUse the included MCP server for GitHub API access.\nRun: `npx github-helper-mcp`\n```\n\n**Reality**: No `mcp-server/` directory existed\n\n**Symptoms**:\n- Claude confidently told users to run non-existent commands\n- Users filed bug reports\n- Trust in skill ecosystem damaged\n\n**Root Cause**: Reference Illusion anti-pattern\n\n**Resolution**:\n1. Added `check_self_contained.py` to detect phantom tools\n2. Either create the MCP or remove the reference\n3. Added validation to CI\n\n**Lesson**: Don't promise tools you don't deliver.\n\n---\n\n### Case Study 3: The Time Bomb\n\n**Skill**: `react-hooks-expert` (v2.0)\n**Problem**: Temporal knowledge became stale\n\n**Original content (2023)**:\n```markdown\nUse useEffect with empty deps for componentDidMount behavior\n```\n\n**By 2024**: This caused issues with React 18 Strict Mode double-mounting\n\n**Symptoms**:\n- Users followed advice → got bugs\n- Skill became actively harmful\n- No CHANGELOG to track when content was written\n\n**Root Cause**: Missing temporal knowledge markers\n\n**Resolution**:\n```markdown\n## Temporal Context\n- **Pre-React 18**: useEffect with [] = componentDidMount\n- **React 18+**: useEffect with [] runs TWICE in dev (Strict Mode)\n- **Current best practice**: Use refs for \"run once\" patterns\n```\n\n**Lesson**: Date your knowledge. Update quarterly.\n\n---\n\n### Case Study 4: The Activation Black Hole\n\n**Skill**: `api-design-expert` (v1.0)\n**Problem**: Never activated when needed\n\n**Description**:\n```yaml\ndescription: Expert guidance for API design\n```\n\n**Symptoms**:\n- User: \"How should I structure my REST endpoints?\"\n- Skill: *silence*\n- User confused why skill existed but never helped\n\n**Root Cause**: Missing Exclusions + no keywords\n\n**Resolution**:\n```yaml\ndescription: REST/GraphQL API design patterns. Activate on \"API design\",\n\"endpoint structure\", \"REST architecture\", \"GraphQL schema\".\nNOT for API implementation, SDK generation, or documentation.\n```\n\n**Lesson**: Generic descriptions = zero activations\n\n---\n\n## Contributing\n\nWhen you discover a new anti-pattern:\n\n1. Document what looks right but is wrong\n2. Explain the fundamental reason it's wrong\n3. Show the correct approach\n4. Include temporal context (when did this change?)\n5. Note why LLMs make this mistake\n6. Add detection/validation if possible\n\n**Remember**: The goal is to encode the knowledge that separates \"it compiles\" from \"it's correct\" - the shibboleths that reveal expertise.\n"
        },
        {
          "name": "mcp-template.md",
          "type": "file",
          "path": "skill-architect/references/mcp-template.md",
          "size": 5274,
          "content": "# Minimal MCP Server Template\n\nProduction-ready starter template for MCP servers.\n\n## File Structure\n\n```\nmcp-server/\n├── src/\n│   └── index.ts       # Server implementation\n├── package.json       # Dependencies and scripts\n├── tsconfig.json      # TypeScript configuration\n└── README.md          # Installation instructions\n```\n\n## src/index.ts\n\n```typescript\nimport { Server } from \"@modelcontextprotocol/sdk/server/index.js\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\n\n// Server metadata\nconst server = new Server(\n  {\n    name: \"my-skill-mcp\",\n    version: \"1.0.0\"\n  },\n  {\n    capabilities: {\n      tools: {}\n    }\n  }\n);\n\n// Define available tools\nserver.setRequestHandler(\"tools/list\", async () => ({\n  tools: [\n    {\n      name: \"example_tool\",\n      description: \"Example tool that demonstrates the pattern\",\n      inputSchema: {\n        type: \"object\",\n        properties: {\n          input: {\n            type: \"string\",\n            description: \"Input parameter description\"\n          }\n        },\n        required: [\"input\"]\n      }\n    }\n  ]\n}));\n\n// Handle tool calls\nserver.setRequestHandler(\"tools/call\", async (request) => {\n  const { name, arguments: args } = request.params;\n\n  if (name === \"example_tool\") {\n    try {\n      // Your tool implementation here\n      const result = await processInput(args.input);\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: JSON.stringify(result, null, 2)\n          }\n        ]\n      };\n    } catch (error) {\n      throw new Error(`Failed to process: ${error.message}`);\n    }\n  }\n\n  throw new Error(`Unknown tool: ${name}`);\n});\n\n// Helper function (example)\nasync function processInput(input: string): Promise<any> {\n  // Implement your logic here\n  return {\n    processed: input,\n    timestamp: new Date().toISOString()\n  };\n}\n\n// Start server\nconst transport = new StdioServerTransport();\nawait server.connect(transport);\n```\n\n## package.json\n\n```json\n{\n  \"name\": \"my-skill-mcp\",\n  \"version\": \"1.0.0\",\n  \"description\": \"MCP server for [domain] operations\",\n  \"type\": \"module\",\n  \"bin\": {\n    \"my-skill-mcp\": \"dist/index.js\"\n  },\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"start\": \"node dist/index.js\",\n    \"watch\": \"tsc --watch\"\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"^1.0.0\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^20.0.0\",\n    \"typescript\": \"^5.0.0\"\n  }\n}\n```\n\n## tsconfig.json\n\n```json\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"Node16\",\n    \"moduleResolution\": \"Node16\",\n    \"outDir\": \"dist\",\n    \"rootDir\": \"src\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"resolveJsonModule\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\n## README.md\n\n```markdown\n# My Skill MCP Server\n\nMCP server for [domain] operations.\n\n## Features\n\n- [Feature 1]\n- [Feature 2]\n- [Feature 3]\n\n## Installation\n\n\\`\\`\\`bash\ncd mcp-server\nnpm install\nnpm run build\n\\`\\`\\`\n\n## Configuration\n\nAdd to your Claude Code MCP settings (`~/.config/claude/config.json`):\n\n\\`\\`\\`json\n{\n  \"mcpServers\": {\n    \"my-skill\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/mcp-server/dist/index.js\"],\n      \"env\": {\n        \"API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n\\`\\`\\`\n\n## Tools\n\n### example_tool\n\nDescription of what this tool does.\n\n**Parameters**:\n- `input` (string, required): Description of input parameter\n\n**Example**:\n\\`\\`\\`json\n{\n  \"input\": \"test value\"\n}\n\\`\\`\\`\n\n## Development\n\n\\`\\`\\`bash\nnpm run watch  # Auto-rebuild on changes\n\\`\\`\\`\n\n## Testing\n\nTest the server manually:\n\\`\\`\\`bash\necho '{\"jsonrpc\":\"2.0\",\"method\":\"tools/list\",\"id\":1}' | npm start\n\\`\\`\\`\n```\n\n## Best Practices\n\n1. **Error Handling**: Always wrap tool implementations in try-catch\n2. **Validation**: Validate inputs before processing\n3. **Logging**: Use structured logging for debugging\n4. **Secrets**: Use environment variables for API keys\n5. **Types**: Use TypeScript for type safety\n6. **Documentation**: Keep README up to date with tool changes\n\n## Common Patterns\n\n### Authentication\n\n```typescript\nconst API_KEY = process.env.API_KEY;\nif (!API_KEY) {\n  throw new Error(\"API_KEY environment variable required\");\n}\n```\n\n### Rate Limiting\n\n```typescript\nimport pLimit from 'p-limit';\nconst limit = pLimit(5); // Max 5 concurrent requests\n\nasync function processWithLimit(items: string[]) {\n  return Promise.all(\n    items.map(item => limit(() => processItem(item)))\n  );\n}\n```\n\n### Caching\n\n```typescript\nconst cache = new Map<string, any>();\n\nasync function getCached(key: string, fetcher: () => Promise<any>) {\n  if (cache.has(key)) {\n    return cache.get(key);\n  }\n  const value = await fetcher();\n  cache.set(key, value);\n  return value;\n}\n```\n\n## Troubleshooting\n\n**Server won't start**:\n- Check that `npm run build` completed successfully\n- Verify absolute path in config.json\n- Check environment variables are set\n\n**Tool not found**:\n- Ensure tool name in `tools/list` matches `tools/call` handler\n- Check for typos in tool names\n\n**Authentication errors**:\n- Verify API_KEY environment variable is set correctly\n- Check API key has necessary permissions\n"
        },
        {
          "name": "self-contained-tools.md",
          "type": "file",
          "path": "skill-architect/references/self-contained-tools.md",
          "size": 8974,
          "content": "# Self-Contained Tools\n\nImplementation patterns for scripts, MCP servers, and subagents that make skills immediately useful.\n\n## Philosophy\n\n**The best skill is one where the user can start working immediately.**\n\n| Approach | Result |\n|----------|--------|\n| \"Here's how to build a CLIP embedder\" | User spends 2 hours implementing |\n| \"Here's a working CLIP embedder, run it\" | User is productive in 2 minutes |\n\nSkills should encode expertise AND provide working tools to apply that expertise.\n\n---\n\n## Scripts\n\n### When to Include Scripts\n\n- Skill describes repeatable operations (analysis, validation, transformation)\n- Domain has specific algorithms that should be implemented correctly\n- Pre-flight checks would prevent common errors\n\n### Script Requirements\n\n1. **Actually work** - Not templates, not pseudocode\n2. **Minimal dependencies** - Prefer stdlib, document any pip/npm installs\n3. **Clear interface** - CLI args or stdin/stdout\n4. **Error handling** - Graceful failures with helpful messages\n5. **README** - How to install and run\n\n### Example: Domain Analysis Script\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nPhoto Composition Analyzer\nAnalyzes images for composition quality using rule of thirds,\nvisual weight distribution, and color harmony.\n\nUsage: python analyze_composition.py <image_path>\nDependencies: pip install pillow numpy\n\"\"\"\n\nimport sys\nfrom pathlib import Path\n\ndef analyze_composition(image_path: str) -> dict:\n    \"\"\"Analyze composition and return scores.\"\"\"\n    # Import here to give helpful error if missing\n    try:\n        from PIL import Image\n        import numpy as np\n    except ImportError:\n        print(\"Install dependencies: pip install pillow numpy\")\n        sys.exit(1)\n\n    img = Image.open(image_path)\n    # ... actual implementation ...\n\n    return {\n        \"rule_of_thirds\": 0.85,\n        \"visual_balance\": 0.72,\n        \"color_harmony\": 0.91,\n        \"overall\": 0.83\n    }\n\nif __name__ == \"__main__\":\n    if len(sys.argv) != 2:\n        print(f\"Usage: {sys.argv[0]} <image_path>\")\n        sys.exit(1)\n\n    result = analyze_composition(sys.argv[1])\n    for metric, score in result.items():\n        print(f\"{metric}: {score:.2f}\")\n```\n\n### Example: Validation Script\n\n```bash\n#!/bin/bash\n# validate_skill.sh - Pre-flight checks for skill quality\n# Usage: ./validate_skill.sh /path/to/skill\n\nSKILL_DIR=\"$1\"\n\nif [ -z \"$SKILL_DIR\" ]; then\n    echo \"Usage: $0 <skill_directory>\"\n    exit 1\nfi\n\nerrors=0\n\n# Check SKILL.md exists\nif [ ! -f \"$SKILL_DIR/SKILL.md\" ]; then\n    echo \"❌ Missing SKILL.md\"\n    ((errors++))\nelse\n    echo \"✅ SKILL.md exists\"\nfi\n\n# Check line count\nlines=$(wc -l < \"$SKILL_DIR/SKILL.md\")\nif [ \"$lines\" -gt 500 ]; then\n    echo \"⚠️  SKILL.md is $lines lines (target: &lt;500)\"\nelse\n    echo \"✅ SKILL.md is $lines lines\"\nfi\n\n# Check for NOT clause in description\nif grep -q \"NOT for\" \"$SKILL_DIR/SKILL.md\"; then\n    echo \"✅ Description has NOT clause\"\nelse\n    echo \"❌ Missing NOT clause in description\"\n    ((errors++))\nfi\n\nexit $errors\n```\n\n---\n\n## MCP Servers\n\n### When to Build an MCP\n\n- Skill needs external API access (GitHub, Figma, databases, etc.)\n- OAuth or API key authentication required\n- Stateful connections (websockets, streaming)\n- Rate limiting or caching needed\n\n### MCP Server Structure\n\n```\nmcp-server/\n├── src/\n│   └── index.ts       # Server implementation\n├── package.json       # Dependencies and scripts\n├── tsconfig.json      # TypeScript config\n└── README.md          # Installation instructions\n```\n\n### Example: Minimal MCP Server\n\n```typescript\n// src/index.ts\nimport { Server } from \"@modelcontextprotocol/sdk/server/index.js\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\n\nconst server = new Server(\n  { name: \"my-skill-mcp\", version: \"1.0.0\" },\n  { capabilities: { tools: {} } }\n);\n\n// Define tools\nserver.setRequestHandler(\"tools/list\", async () => ({\n  tools: [\n    {\n      name: \"analyze_repo\",\n      description: \"Analyze a GitHub repository structure\",\n      inputSchema: {\n        type: \"object\",\n        properties: {\n          repo: { type: \"string\", description: \"owner/repo format\" }\n        },\n        required: [\"repo\"]\n      }\n    }\n  ]\n}));\n\nserver.setRequestHandler(\"tools/call\", async (request) => {\n  const { name, arguments: args } = request.params;\n\n  if (name === \"analyze_repo\") {\n    // Actual implementation\n    const result = await analyzeRepo(args.repo);\n    return { content: [{ type: \"text\", text: JSON.stringify(result) }] };\n  }\n\n  throw new Error(`Unknown tool: ${name}`);\n});\n\n// Start server\nconst transport = new StdioServerTransport();\nawait server.connect(transport);\n```\n\n### package.json\n\n```json\n{\n  \"name\": \"my-skill-mcp\",\n  \"version\": \"1.0.0\",\n  \"type\": \"module\",\n  \"bin\": { \"my-skill-mcp\": \"dist/index.js\" },\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"start\": \"node dist/index.js\"\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"^1.0.0\"\n  },\n  \"devDependencies\": {\n    \"typescript\": \"^5.0.0\"\n  }\n}\n```\n\n### README Template\n\n```markdown\n# My Skill MCP Server\n\nMCP server for [domain] operations.\n\n## Installation\n\n\\`\\`\\`bash\ncd mcp-server\nnpm install\nnpm run build\n\\`\\`\\`\n\n## Configuration\n\nAdd to your Claude Code MCP settings:\n\n\\`\\`\\`json\n{\n  \"mcpServers\": {\n    \"my-skill\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-server/dist/index.js\"],\n      \"env\": {\n        \"API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n\\`\\`\\`\n\n## Tools\n\n- `analyze_repo` - Analyze a GitHub repository structure\n- `fetch_issues` - Get open issues with labels\n```\n\n---\n\n## Subagents\n\n### When to Define Subagents\n\n- Skill involves multi-step workflows\n- Different phases need different tool access\n- Orchestration logic is complex enough to warrant isolation\n\n### Subagent Definition Format\n\n```markdown\n# agents/research-workflow.md\n\n## Agent: Research Coordinator\n\n### Purpose\nOrchestrate multi-source research with synthesis.\n\n### System Prompt\nYou are a research coordinator. Your job is to:\n1. Break down research questions into searchable queries\n2. Dispatch searches to appropriate sources\n3. Synthesize findings into coherent answers\n\n### Tools Required\n- WebSearch\n- WebFetch\n- Read\n- Write\n\n### Workflow\n1. Receive research question\n2. Generate 3-5 search queries\n3. Execute searches in parallel\n4. Read and extract relevant content\n5. Synthesize into final answer\n\n### Success Criteria\n- All claims have citations\n- Multiple sources corroborate findings\n- Contradictions are explicitly noted\n```\n\n### Multi-Agent Orchestration Pattern\n\n```markdown\n# agents/orchestrator.md\n\n## Pipeline: Code Review\n\n### Agents\n1. **security-scanner** - Check for vulnerabilities\n2. **style-checker** - Verify code style\n3. **architecture-reviewer** - Assess design patterns\n\n### Orchestration\n\\`\\`\\`\nparallel:\n  - security-scanner → security_report\n  - style-checker → style_report\nthen:\n  - architecture-reviewer(security_report, style_report) → final_review\n\\`\\`\\`\n\n### Handoff Protocol\nEach agent produces structured output:\n- `status`: pass | warn | fail\n- `findings`: list of issues\n- `recommendations`: suggested fixes\n```\n\n---\n\n## Anti-Patterns\n\n### Phantom Tools\n**What it looks like**: SKILL.md references `scripts/analyze.py` but file doesn't exist\n\n**Why it's wrong**: Users try to run non-existent code, lose trust in skill\n\n**Fix**: Only reference tools that actually exist and work\n\n### Template Soup\n**What it looks like**: Scripts are templates with `# TODO: implement` comments\n\n**Why it's wrong**: User still has to do the implementation work\n\n**Fix**: Ship working code or don't ship at all\n\n### Dependency Hell\n**What it looks like**: Script requires 15 pip packages, specific Python version, system libraries\n\n**Why it's wrong**: Most users won't complete setup\n\n**Fix**: Minimize dependencies, prefer stdlib, document clearly\n\n### MCP Without Purpose\n**What it looks like**: MCP server for operations that could be a simple script\n\n**Why it's wrong**: Over-engineering; MCP has setup overhead\n\n**Fix**: Use MCP only when you need: auth, state, external APIs, or caching\n\n---\n\n## Checklist: Is My Skill Self-Contained?\n\n```\n□ Can a user start using this skill immediately?\n□ Are all referenced scripts/tools actually present and working?\n□ Do scripts have clear installation instructions?\n□ Do scripts handle errors gracefully?\n□ If MCP needed, is server implementation complete?\n□ If subagents needed, are prompts and workflows defined?\n□ Is there a validation script to check environment?\n□ Does README explain how to set everything up?\n```\n\n---\n\n## Examples of Self-Contained Skills\n\n| Skill | Tools Included |\n|-------|----------------|\n| clip-aware-embeddings | `scripts/validate_clip_usage.py` |\n| site-reliability-engineer | `scripts/validate-brackets.js`, `scripts/validate-liquid.js` |\n| skill-coach | `scripts/validate_skill.py` |\n\n**Goal**: Every skill with repeatable operations should have working tools.\n"
        },
        {
          "name": "subagent-template.md",
          "type": "file",
          "path": "skill-architect/references/subagent-template.md",
          "size": 8387,
          "content": "# Subagent Definition Template\n\nTemplate for defining specialized subagents for complex workflows.\n\n## Single Agent Definition\n\n```markdown\n# agents/agent-name.md\n\n## Agent: [Agent Name]\n\n### Purpose\n[What this agent does in 1-2 sentences]\n\n### System Prompt\nYou are [role description]. Your job is to:\n1. [Primary responsibility]\n2. [Secondary responsibility]\n3. [Tertiary responsibility]\n\n[Specific domain knowledge or constraints]\n\n### Tools Required\n- [Tool 1]\n- [Tool 2]\n- [Tool 3]\n\n### Workflow\n1. [Step 1 description]\n2. [Step 2 description]\n3. [Step 3 description]\n4. [Final step description]\n\n### Success Criteria\n- [Criterion 1]\n- [Criterion 2]\n- [Criterion 3]\n\n### Output Format\n[Expected output structure]\n\n### Example\n**Input**: [Example input]\n**Process**: [How it's processed]\n**Output**: [Expected output]\n```\n\n## Multi-Agent Orchestration Pattern\n\n```markdown\n# agents/orchestrator.md\n\n## Pipeline: [Pipeline Name]\n\n### Agents\n\n1. **agent-1** - [Brief description]\n   - Tools: [Tool list]\n   - Input: [What it receives]\n   - Output: [What it produces]\n\n2. **agent-2** - [Brief description]\n   - Tools: [Tool list]\n   - Input: [What it receives]\n   - Output: [What it produces]\n\n3. **agent-3** - [Brief description]\n   - Tools: [Tool list]\n   - Input: [What it receives]\n   - Output: [What it produces]\n\n### Orchestration Flow\n\n\\`\\`\\`\nparallel:\n  - agent-1 → output_1\n  - agent-2 → output_2\n\nsequential:\n  - agent-3(output_1, output_2) → final_result\n\\`\\`\\`\n\n### Handoff Protocol\n\nEach agent produces structured output:\n- `status`: [Status values]\n- `data`: [Data structure]\n- `metadata`: [Metadata structure]\n\n### Error Handling\n\nIf any agent fails:\n1. [Retry strategy]\n2. [Fallback approach]\n3. [User notification]\n\n### Example Execution\n\n**Input**: [Example input]\n\n**Agent 1 Output**:\n\\`\\`\\`json\n{\n  \"status\": \"success\",\n  \"data\": {...}\n}\n\\`\\`\\`\n\n**Agent 2 Output**:\n\\`\\`\\`json\n{\n  \"status\": \"success\",\n  \"data\": {...}\n}\n\\`\\`\\`\n\n**Final Result**:\n\\`\\`\\`json\n{\n  \"status\": \"success\",\n  \"findings\": [...],\n  \"recommendations\": [...]\n}\n\\`\\`\\`\n```\n\n## Real-World Example: Code Review Pipeline\n\n```markdown\n# agents/code-review-pipeline.md\n\n## Pipeline: Code Review\n\n### Purpose\nAutomated code review with security, style, and architecture analysis.\n\n### Agents\n\n1. **security-scanner**\n   - Purpose: Check for vulnerabilities\n   - Tools: Read, Grep, Bash(semgrep:*)\n   - Output: Security report with severity ratings\n\n2. **style-checker**\n   - Purpose: Verify code style compliance\n   - Tools: Read, Bash(eslint:*, prettier:*)\n   - Output: Style violations with fix suggestions\n\n3. **architecture-reviewer**\n   - Purpose: Assess design patterns and maintainability\n   - Tools: Read, Grep, Glob\n   - Output: Architecture recommendations\n\n### Orchestration Flow\n\n\\`\\`\\`\nparallel:\n  - security-scanner → security_report\n  - style-checker → style_report\n\nthen:\n  - architecture-reviewer(security_report, style_report) → final_review\n\\`\\`\\`\n\n### Handoff Protocol\n\nEach agent produces:\n\\`\\`\\`json\n{\n  \"status\": \"pass\" | \"warn\" | \"fail\",\n  \"findings\": [\n    {\n      \"severity\": \"high\" | \"medium\" | \"low\",\n      \"file\": \"path/to/file.ts\",\n      \"line\": 42,\n      \"message\": \"Description of issue\",\n      \"recommendation\": \"How to fix\"\n    }\n  ],\n  \"summary\": {\n    \"total_issues\": 5,\n    \"high\": 1,\n    \"medium\": 2,\n    \"low\": 2\n  }\n}\n\\`\\`\\`\n\n### Success Criteria\n- All high-severity issues resolved\n- No security vulnerabilities\n- Code style compliance &gt;95%\n- Architecture review approves design\n\n### Example Execution\n\n**Input**: Pull request with 5 changed files\n\n**Security Scanner Output**:\n\\`\\`\\`json\n{\n  \"status\": \"warn\",\n  \"findings\": [\n    {\n      \"severity\": \"medium\",\n      \"file\": \"src/auth.ts\",\n      \"line\": 23,\n      \"message\": \"Hardcoded secret detected\",\n      \"recommendation\": \"Use environment variable\"\n    }\n  ],\n  \"summary\": {\"total_issues\": 1, \"medium\": 1}\n}\n\\`\\`\\`\n\n**Style Checker Output**:\n\\`\\`\\`json\n{\n  \"status\": \"pass\",\n  \"findings\": [],\n  \"summary\": {\"total_issues\": 0}\n}\n\\`\\`\\`\n\n**Architecture Reviewer Output**:\n\\`\\`\\`json\n{\n  \"status\": \"pass\",\n  \"findings\": [\n    {\n      \"severity\": \"low\",\n      \"file\": \"src/auth.ts\",\n      \"message\": \"Consider extracting validation to separate module\",\n      \"recommendation\": \"Create src/validators/auth.ts\"\n    }\n  ],\n  \"summary\": {\"total_issues\": 1, \"low\": 1}\n}\n\\`\\`\\`\n\n**Final Review**: \"APPROVED with recommendations - Fix hardcoded secret before merge\"\n```\n\n## Research Workflow Example\n\n```markdown\n# agents/research-workflow.md\n\n## Agent: Research Coordinator\n\n### Purpose\nOrchestrate multi-source research with synthesis and fact-checking.\n\n### System Prompt\nYou are a research coordinator. Your job is to:\n1. Break down research questions into searchable queries\n2. Dispatch searches to appropriate sources (web, docs, code)\n3. Cross-reference findings for accuracy\n4. Synthesize coherent answers with citations\n\nAlways cite sources. Flag contradictory information.\n\n### Tools Required\n- WebSearch\n- WebFetch\n- Read\n- Grep\n- Write\n\n### Workflow\n1. Receive research question from user\n2. Generate 3-5 targeted search queries\n3. Execute searches in parallel\n4. Read and extract relevant content\n5. Cross-check facts across sources\n6. Synthesize findings into coherent answer\n7. Add citations for all claims\n\n### Success Criteria\n- All claims have citations\n- Multiple sources corroborate key findings\n- Contradictions are explicitly noted\n- Answer is comprehensive but concise\n\n### Output Format\n\\`\\`\\`markdown\n# [Question]\n\n## Summary\n[2-3 sentence answer]\n\n## Detailed Findings\n\n### [Topic 1]\n[Explanation with citations]\n\nSources:\n- [Source 1 with link]\n- [Source 2 with link]\n\n### [Topic 2]\n[Explanation with citations]\n\nSources:\n- [Source 3 with link]\n\n## Contradictory Information\n[If any sources disagree, explain the discrepancy]\n\n## Confidence Assessment\n[High/Medium/Low] - [Reasoning]\n\\`\\`\\`\n\n### Example\n**Input**: \"How do React Server Components affect bundle size?\"\n\n**Process**:\n1. Generate queries: \"React Server Components bundle size\", \"RSC vs Client Components\", \"Next.js App Router performance\"\n2. Search web + official docs\n3. Extract findings from 5+ sources\n4. Cross-reference performance claims\n5. Note any contradictions\n\n**Output**:\n\\`\\`\\`markdown\n# How React Server Components Affect Bundle Size\n\n## Summary\nReact Server Components reduce client-side bundle size by 20-40% on average by rendering components on the server and sending only HTML to the client. Dynamic interactivity requires selective use of Client Components.\n\n## Detailed Findings\n\n### Bundle Size Reduction\nServer Components don't include their code in the client bundle. A typical conversion reduces bundle by 30% (Vercel case study, Next.js docs).\n\nSources:\n- [Next.js App Router Documentation](https://nextjs.org/docs/app)\n- [Vercel Case Study: 33% Reduction](https://vercel.com/blog/rsc-performance)\n\n### Trade-offs\nClient Components still require client-side JavaScript. Overuse of 'use client' negates benefits.\n\nSources:\n- [React RFC: Server Components](https://github.com/reactjs/rfcs/blob/main/text/0188-server-components.md)\n\n## Confidence Assessment\nHigh - Multiple authoritative sources (React team, Next.js team, real-world case studies) corroborate findings.\n\\`\\`\\`\n```\n\n## Agent Communication Patterns\n\n### Request-Response\n\n```typescript\n// Parent to Agent\n{\n  \"task\": \"analyze_code\",\n  \"input\": {\n    \"files\": [\"src/auth.ts\", \"src/users.ts\"],\n    \"focus\": \"security\"\n  }\n}\n\n// Agent to Parent\n{\n  \"status\": \"complete\",\n  \"results\": {...},\n  \"metadata\": {\"duration_ms\": 2500}\n}\n```\n\n### Streaming Updates\n\n```typescript\n// Agent sends incremental updates\n{\n  \"type\": \"progress\",\n  \"step\": \"analyzing_file\",\n  \"file\": \"src/auth.ts\",\n  \"progress\": 0.5\n}\n\n{\n  \"type\": \"finding\",\n  \"severity\": \"high\",\n  \"message\": \"SQL injection risk\"\n}\n\n{\n  \"type\": \"complete\",\n  \"summary\": {...}\n}\n```\n\n## Best Practices\n\n1. **Clear Responsibilities**: Each agent should have a single, well-defined purpose\n2. **Structured Output**: Use consistent JSON schemas for agent communication\n3. **Error Handling**: Define fallback strategies for agent failures\n4. **Parallelization**: Run independent agents concurrently\n5. **Handoff Protocol**: Standardize how agents pass data\n6. **Success Criteria**: Define measurable completion conditions\n7. **Documentation**: Keep agent definitions up to date\n"
        }
      ]
    },
    {
      "name": "CHANGELOG.md",
      "type": "file",
      "path": "skill-architect/CHANGELOG.md",
      "size": 1199,
      "content": "# Changelog: skill-architect\n\n## v1.0.0 (2026-01-14)\n\n### Created\n- **Unified meta-skill** combining skill-coach and skill-creator\n- Merged systematic workflow from skill-creator\n- Merged domain expertise encoding from skill-coach\n- Consolidated best practices from both skills\n\n### Features\n- 6-step skill creation process\n- Shibboleth encoding (expert knowledge patterns)\n- Anti-pattern catalog with case studies\n- Self-contained tool implementation (scripts, MCP, subagents)\n- Progressive disclosure design principles\n- Activation debugging workflows\n- Comprehensive validation checklists\n\n### References Added\n- `antipatterns.md` - Shibboleths and anti-pattern catalog\n- `self-contained-tools.md` - Scripts, MCP, and subagent patterns\n- `mcp-template.md` - Minimal MCP server starter\n- `subagent-template.md` - Agent definition format\n\n### Philosophy\n\"Great skills are progressive disclosure machines that encode real domain expertise, not just surface instructions.\"\n\n### Replaces\n- skill-coach (v2.x) - Expertise encoding focus\n- skill-creator (v1.x) - Systematic workflow focus\n\n### Migration\nUsers of skill-coach or skill-creator should switch to skill-architect for the unified experience.\n"
    },
    {
      "name": "README.md",
      "type": "file",
      "path": "skill-architect/README.md",
      "size": 3837,
      "content": "# Skill Architect\n\nThe authoritative meta-skill for creating, auditing, and improving Agent Skills.\n\n## What It Does\n\nSkill Architect combines:\n- **Systematic workflow** from skill-creator (6-step process)\n- **Domain expertise encoding** from skill-coach (shibboleths, anti-patterns)\n\nInto one unified authority for skill development.\n\n## Quick Start\n\n**Creating a new skill**:\n1. Gather 3-5 concrete examples\n2. Plan reusable contents (scripts, references, assets)\n3. Initialize: `scripts/init_skill.py <skill-name>`\n4. Edit SKILL.md (keep &lt;500 lines)\n5. Validate: `scripts/validate_skill.py <path>`\n6. Package: `scripts/package_skill.py <path>`\n\n**Improving an existing skill**:\n1. Add NOT clause to description\n2. Check line count (&lt;500 lines)\n3. Add 1-2 anti-patterns\n4. Remove dead files\n5. Test activation\n\n## What Makes a Great Skill\n\n1. **Activates precisely** - Keywords + NOT clause\n2. **Encodes shibboleths** - Expert knowledge\n3. **Surfaces anti-patterns** - Common mistakes\n4. **Captures temporal knowledge** - \"Pre-2024 vs 2024+\"\n5. **Knows its limits** - \"Use for X, NOT for Y\"\n6. **Provides decision trees** - Not templates\n7. **Stays under 500 lines** - Progressive disclosure\n\n## Key Concepts\n\n### Progressive Disclosure\n- **Level 1**: Metadata (~100 tokens) - Always in context\n- **Level 2**: SKILL.md (&lt;5k tokens) - When skill triggers\n- **Level 3**: Resources (unlimited) - As needed\n\n### Shibboleths\nExpert knowledge that separates novices from experts:\n- Framework evolution (React: Classes → Hooks → Server Components)\n- Model limitations (CLIP can't count objects)\n- Tool architecture (when to use MCP vs Scripts)\n- Temporal knowledge (what changed and when)\n\n### Self-Contained Tools\nSkills with working tools are immediately useful:\n- **Scripts**: Repeatable operations\n- **MCP Servers**: External APIs with auth\n- **Subagents**: Multi-step workflows\n- **Assets**: Templates and boilerplate\n\n## Structure\n\n```\nskill-architect/\n├── SKILL.md                       # Core instructions (&lt;500 lines)\n├── CHANGELOG.md                   # Version history\n├── README.md                      # This file\n└── references/\n    ├── antipatterns.md            # Shibboleths and case studies\n    ├── self-contained-tools.md    # Scripts, MCP, subagent patterns\n    ├── mcp-template.md            # Minimal MCP starter\n    └── subagent-template.md       # Agent definition format\n```\n\n## Philosophy\n\n**The best skill is one where the user can start working immediately.**\n\n| Approach | Result |\n|----------|--------|\n| \"Here's how to build X\" | User spends 2 hours implementing |\n| \"Here's a working X, run it\" | User is productive in 2 minutes |\n\n## Examples\n\n### Good Description\n```yaml\ndescription: CLIP semantic search. Use for image-text matching, zero-shot classification.\n  Activate on 'CLIP', 'embeddings', 'similarity'.\n  NOT for counting objects, spatial reasoning, or fine-grained classification.\n```\n\n### Good Anti-Pattern\n```markdown\n### Anti-Pattern: CLIP for Everything\n\n**Novice thinking**: \"CLIP does zero-shot classification, use it for all image tasks!\"\n\n**Reality**: CLIP has fundamental geometric limitations. Cannot handle:\n- Counting objects\n- Spatial relationships (\"cat left of dog\")\n- Fine-grained classification (celebrity faces)\n\n**Timeline**: 2021: CLIP released. 2024: Limitations well-documented.\n\n**LLM mistake**: Training data predates limitation discoveries.\n```\n\n## Success Metrics\n\n| Metric | Target |\n|--------|--------|\n| Correct activation | &gt;90% |\n| False positive rate | &lt;5% |\n| Token usage | &lt;5k |\n| Time to productive | &lt;5 min |\n\n## Replaces\n\nThis skill unifies and replaces:\n- **skill-coach** - Expertise encoding\n- **skill-creator** - Systematic workflow\n\n## License\n\nSee LICENSE.txt for complete terms.\n"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "skill-architect/SKILL.md",
      "size": 18147,
      "content": "---\nname: skill-architect\ndescription: Authoritative meta-skill for creating, auditing, and improving Agent Skills. Combines skill-coach expertise with skill-creator workflows. Use for skill creation, validation, improvement, activation debugging, and progressive disclosure design. NOT for general Claude Code features, runtime debugging, or non-skill coding.\nallowed-tools: Read,Write,Edit,Bash\n---\n\n# Skill Architect: The Authoritative Meta-Skill\n\nThe unified authority for creating expert-level Agent Skills. Combines systematic workflow from skill-creator with domain expertise encoding from skill-coach.\n\n## Philosophy\n\n**Great skills are progressive disclosure machines** that encode real domain expertise (shibboleths), not just surface instructions. They activate precisely, teach efficiently, and make users productive immediately.\n\n---\n\n## When to Use This Skill\n\n✅ **Use for**:\n- Creating new skills from scratch\n- Auditing/reviewing existing skills\n- Improving activation rates\n- Adding domain expertise\n- Debugging why skills don't activate\n- Encoding anti-patterns and shibboleths\n- Building self-contained tools (scripts, MCPs, subagents)\n\n❌ **NOT for**:\n- General Claude Code features (slash commands, MCPs)\n- Non-skill coding advice\n- Debugging runtime errors (use domain-specific skills)\n- Template generation without domain expertise\n\n---\n\n## Quick Wins (Immediate Improvements)\n\nFor existing skills, apply these in order:\n\n1. **Add NOT clause** → Prevent false activation\n2. **Check line count** → SKILL.md should be &lt;500 lines\n3. **Add 1-2 anti-patterns** → Prevent common mistakes\n4. **Remove dead files** → Delete unreferenced scripts/references\n5. **Test activation** → Write queries that should/shouldn't trigger\n\nRun validation:\n```bash\npython scripts/validate_skill.py <path>\npython scripts/check_self_contained.py <path>\n```\n\n---\n\n## What Makes a Great Skill\n\nGreat skills have these 7 qualities:\n\n1. **Activate precisely** - Specific keywords + NOT clause\n2. **Encode shibboleths** - Expert knowledge that separates novice from expert\n3. **Surface anti-patterns** - \"If you see X, that's wrong because Y, use Z\"\n4. **Capture temporal knowledge** - \"Pre-2024: X. 2024+: Y\"\n5. **Know their limits** - \"Use for A, B, C. NOT for D, E, F\"\n6. **Provide decision trees** - Not templates, but \"If X then A, if Y then B\"\n7. **Stay under 500 lines** - Core in SKILL.md, deep dives in `/references`\n\n---\n\n## Progressive Disclosure Principle\n\nSkills use a three-level loading system:\n\n| Level | Content | Size | When Loaded |\n|-------|---------|------|-------------|\n| 1. Metadata | `name` + `description` | ~100 tokens | Always in context |\n| 2. SKILL.md | Core instructions | &lt;5k tokens | When skill triggers |\n| 3. Resources | Scripts, references, assets | Unlimited | As Claude needs them |\n\n**Critical**: Keep SKILL.md under 500 lines. Move details to `/references`.\n\n---\n\n## Skill Structure\n\n### Mandatory\n```\nyour-skill/\n└── SKILL.md           # Core instructions (max 500 lines)\n```\n\n### Strongly Recommended (Self-Contained Skills)\n```\n├── scripts/           # Working code - NOT templates\n├── mcp-server/        # Custom MCP if external APIs needed\n├── agents/            # Subagent definitions for orchestration\n├── references/        # Deep dives on domain knowledge\n└── CHANGELOG.md       # Version history\n```\n\n**Philosophy**: Skills with working tools are immediately useful.\n\n---\n\n## SKILL.md Template\n\n```markdown\n---\nname: your-skill-name\ndescription: [What] [When] [Triggers]. NOT for [Exclusions].\nallowed-tools: Read,Write  # Minimal only\n---\n\n# Skill Name\n[One sentence purpose]\n\n## When to Use\n✅ Use for: [A, B, C with specific keywords]\n❌ NOT for: [D, E, F - be explicit]\n\n## Core Instructions\n[Step-by-step decision trees, not templates]\n\n## Common Anti-Patterns\n### [Pattern Name]\n**Novice thinking**: [Wrong assumption]\n**Reality**: [Why it's wrong]\n**Correct approach**: [Better way]\n**Timeline**: [When this changed]\n\n## References\n- `/references/deep-dive.md` - [When to consult]\n```\n\n---\n\n## Description Formula\n\n**[What] [When] [Keywords] NOT for [Exclusions]**\n\n**Examples**:\n\n❌ **Bad**: \"Helps with images\"\n⚠️ **Better**: \"Image processing with CLIP\"\n✅ **Good**: \"CLIP semantic search. Use for image-text matching, zero-shot classification. Activate on 'CLIP', 'embeddings', 'similarity'. NOT for counting objects, spatial reasoning, or fine-grained classification.\"\n\n---\n\n## Frontmatter Rules (CRITICAL)\n\n**Only these keys are allowed by Claude's skill marketplace:**\n\n| Key | Required | Purpose |\n|-----|----------|---------|\n| `name` | ✅ | Lowercase-hyphenated identifier |\n| `description` | ✅ | Activation keywords + NOT clause |\n| `allowed-tools` | ⚠️ | Comma-separated tool names |\n| `license` | ❌ | e.g., \"MIT\" |\n| `metadata` | ❌ | Custom key-value pairs |\n\n**Invalid keys that WILL FAIL upload**:\n```yaml\n# ❌ WRONG - These break skill upload\nintegrates_with: [...]\ntriggers: [...]\ntools: Read,Write  # Use 'allowed-tools' instead\noutputs: [...]\ncoordinates_with: [...]\npython_dependencies: [...]\n```\n\n**Move custom info to body** under appropriate headings.\n\n---\n\n## The 6-Step Skill Creation Process\n\n### Step 1: Understand with Concrete Examples\n\nSkip only if usage patterns are already clear.\n\n**Ask**:\n- \"What functionality should this skill support?\"\n- \"Can you give examples of how it would be used?\"\n- \"What would trigger this skill?\"\n\n**Example queries** (for an image-editor skill):\n- \"Remove red-eye from this image\"\n- \"Rotate this photo 90 degrees\"\n- \"Adjust brightness and contrast\"\n\nConclude when you have 3-5 concrete examples.\n\n---\n\n### Step 2: Plan Reusable Contents\n\nFor each example, analyze:\n1. How to execute from scratch\n2. What scripts/references/assets would help with repeated execution\n\n**Example analyses**:\n\n| Skill | Example | Needs |\n|-------|---------|-------|\n| pdf-editor | \"Rotate this PDF\" | `scripts/rotate_pdf.py` |\n| frontend-builder | \"Build a todo app\" | `assets/hello-world/` template |\n| big-query | \"How many users logged in?\" | `references/schema.md` |\n| photo-expert | \"Improve composition\" | `scripts/analyze_composition.py` |\n\n**Shibboleths to encode**:\n- Domain-specific algorithms\n- Common pitfalls and anti-patterns\n- Temporal knowledge (what changed when)\n- Framework evolution patterns\n\n---\n\n### Step 3: Initialize the Skill\n\n**For new skills**, run the init script:\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThis creates:\n- SKILL.md template with proper frontmatter\n- Example `scripts/`, `references/`, `assets/` directories\n- TODO placeholders to customize\n\n**For existing skills**, skip to Step 4.\n\n---\n\n### Step 4: Edit the Skill\n\n#### Write in Imperative/Infinitive Form\nUse objective, instructional language:\n- ✅ \"To accomplish X, do Y\"\n- ✅ \"When Z occurs, execute A\"\n- ❌ \"You should do X\"\n- ❌ \"If you need to do Z\"\n\n#### Start with Reusable Contents\n\nImplement in this order:\n1. **Scripts** (`scripts/`) - Working code for repeatable operations\n2. **References** (`references/`) - Domain knowledge, schemas, detailed guides\n3. **Assets** (`assets/`) - Templates, boilerplate, files used in output\n\n**Delete example files** that aren't needed.\n\n#### Update SKILL.md\n\nAnswer these questions:\n1. **Purpose**: What is this skill for? (1-2 sentences)\n2. **When to use**: Specific triggers and exclusions\n3. **How to use**: Reference all bundled resources so Claude knows they exist\n4. **Anti-patterns**: What mistakes do novices make?\n5. **Temporal context**: What changed and when?\n\n---\n\n### Step 5: Validate and Package\n\n```bash\n# Validate structure and content\npython scripts/validate_skill.py <path>\n\n# Check self-contained tool completeness\npython scripts/check_self_contained.py <path>\n\n# Package for distribution (validates first)\npython scripts/package_skill.py <path/to/skill-folder>\n```\n\nFix all ERRORS, then WARNINGS, then SUGGESTIONS.\n\n---\n\n### Step 6: Iterate\n\nAfter real-world use:\n1. Notice struggles or inefficiencies\n2. Identify how SKILL.md or bundled resources should improve\n3. Implement changes and test again\n4. Update CHANGELOG.md\n\n**Recursive self-improvement**: Use this skill to improve skills.\n\n---\n\n## Encoding Shibboleths (Expert Knowledge)\n\n### What Are Shibboleths?\n\nKnowledge that separates novices from experts - things LLMs get wrong because training data includes:\n- Outdated patterns\n- Oversimplified tutorials\n- Cargo-culted code\n\n### Shibboleth Template\n\n```markdown\n### Anti-Pattern: [Name]\n\n**Novice thinking**: \"[Wrong assumption]\"\n\n**Reality**: [Fundamental reason it's wrong, with research/data]\n\n**Timeline**:\n- [Date range]: [Old approach] was common\n- [Date]: [Change event]\n- [Current]: [New approach]\n\n**What to use instead**:\n| Task | Tool | Why |\n|------|------|-----|\n| [Use case] | [Correct tool] | [Reason] |\n\n**LLM mistake**: [Why LLMs suggest old pattern]\n**How to detect**: [Validation rule]\n```\n\n### Example Shibboleths to Encode\n\n1. **Framework Evolution**\n   - React: Class components → Hooks → Server Components\n   - Next.js: Pages Router → App Router\n   - State management: Redux → Zustand/Jotai/React Query\n\n2. **Model Selection**\n   - CLIP limitations (can't count, can't do spatial reasoning)\n   - Embedding model specialization (text vs code vs multi-lingual)\n   - Model versioning (ada-002 vs text-embedding-3-large)\n\n3. **Tool Architecture**\n   - When to use MCP vs Scripts vs Subagents\n   - Premature abstraction anti-pattern\n   - Self-contained tool benefits\n\n---\n\n## Self-Contained Tools\n\n### Decision Matrix\n\n| Need | Use |\n|------|-----|\n| External API + auth | MCP Server |\n| Multi-step workflow | Subagents |\n| Repeatable operation | Scripts |\n| Domain validation | Scripts |\n| Templates/boilerplate | Assets |\n| Deep reference docs | References |\n\n### Scripts\n\n**Requirements**:\n1. Actually work (not templates or pseudocode)\n2. Minimal dependencies (prefer stdlib)\n3. Clear interface (CLI args or stdin/stdout)\n4. Error handling (graceful failures)\n5. README (how to install and run)\n\n**Example**:\n```python\n#!/usr/bin/env python3\n\"\"\"\nDomain Analyzer\nUsage: python analyze.py <input>\nDependencies: pip install numpy\n\"\"\"\nimport sys\n\ndef analyze(input_path):\n    # Import here for helpful error\n    try:\n        import numpy as np\n    except ImportError:\n        print(\"Install: pip install numpy\")\n        sys.exit(1)\n\n    # Actual implementation\n    result = {\"score\": 0.85}\n    return result\n\nif __name__ == \"__main__\":\n    if len(sys.argv) != 2:\n        print(f\"Usage: {sys.argv[0]} <input>\")\n        sys.exit(1)\n\n    result = analyze(sys.argv[1])\n    for k, v in result.items():\n        print(f\"{k}: {v}\")\n```\n\n### MCP Servers\n\n**When to build**:\n- External API with authentication\n- Stateful connections (WebSocket, database)\n- Real-time data streams\n- Security boundaries (credentials, OAuth)\n\n**Structure**:\n```\nmcp-server/\n├── src/index.ts       # Server implementation\n├── package.json       # Dependencies\n├── tsconfig.json      # Config\n└── README.md          # Setup instructions\n```\n\n**Minimal MCP template**: See `/references/mcp-template.md`\n\n### Subagents\n\n**When to define**:\n- Multi-step workflows\n- Different phases need different tool access\n- Orchestration logic is complex\n\n**Definition format**: See `/references/subagent-template.md`\n\n---\n\n## Common Workflows\n\n### Create Skill from Expertise\n\n1. Define scope: What expertise? Keywords? Exclusions?\n2. Write description with keywords and NOT clause\n3. Encode anti-patterns and shibboleths\n4. Add decision trees (not just instructions)\n5. Build working tools (scripts/MCP/subagents)\n6. Test activation thoroughly\n\n### Debug Activation Issues\n\n**Flowchart**:\n```\nSkill not activating?\n├── Check description has specific keywords\n│   ├── NO → Add \"Activate on: keyword1, keyword2\"\n│   └── YES → Query contains those keywords?\n│       ├── NO → Add missing variations\n│       └── YES → Conflicting NOT clause?\n│           ├── YES → Narrow exclusions\n│           └── NO → Check file structure\n│               └── Wrong location → Move to .claude/skills/\n\nSkill activating when it shouldn't?\n├── Missing NOT clause?\n│   ├── YES → Add \"NOT for: exclusion1, exclusion2\"\n│   └── NO → NOT clause too narrow\n│       └── Expand based on false positives\n```\n\nRun: `python scripts/test_activation.py <path>`\n\n### Improve Existing Skill\n\n1. Run `python scripts/validate_skill.py <path>`\n2. Run `python scripts/check_self_contained.py <path>`\n3. Address ERRORS → WARNINGS → SUGGESTIONS\n4. Add missing shibboleths and anti-patterns\n5. Ensure &lt;500 lines in SKILL.md\n6. Re-validate until clean\n7. Update CHANGELOG.md\n\n---\n\n## Tool Permissions\n\n**Guidelines**:\n- Read-only: `Read,Grep,Glob`\n- File modifier: `Read,Write,Edit`\n- Build integration: `Read,Write,Bash(npm:*,git:*)`\n- ⚠️ **Never**: Unrestricted `Bash` for untrusted skills\n\n**Principle**: Least privilege - only grant what's needed.\n\n---\n\n## Decision Trees\n\n### When to Create a NEW Skill?\n\n✅ **Create when**:\n- Domain expertise not in existing skills\n- Pattern repeats across 3+ projects\n- Anti-patterns you want to prevent\n- Shibboleths to encode\n\n❌ **Don't create when**:\n- One-time task → Just do it directly\n- Existing skill could be extended → Improve that one\n- No real expertise to encode → Not worth it\n\n### Skill vs Subagent vs MCP vs Script?\n\n| Type | Purpose | State | Auth | Example |\n|------|---------|-------|------|---------|\n| **Skill** | Domain expertise, decision trees | None | None | react-server-components |\n| **Script** | Repeatable operations | None | None | validate_skill.py |\n| **Subagent** | Multi-step workflows | Session | Inherited | research-coordinator |\n| **MCP** | External APIs, auth | Persistent | Required | github-mcp-server |\n\n---\n\n## Anti-Patterns to Avoid\n\n### 1. Skill as Documentation Dump\n\n❌ **Wrong**: 50-page tutorial in SKILL.md\n✅ **Right**: Decision trees + anti-patterns in SKILL.md, details in `/references`\n\n### 2. Missing \"When NOT to Use\"\n\n❌ **Wrong**: `description: \"Processes images using computer vision\"`\n✅ **Right**: `description: \"CLIP semantic search. NOT for generation, editing, OCR, counting.\"`\n\n### 3. Phantom Tools\n\n❌ **Wrong**: SKILL.md references `scripts/analyze.py` that doesn't exist\n✅ **Right**: Only reference tools that exist and work\n\n### 4. Template Soup\n\n❌ **Wrong**: Scripts with `# TODO: implement` comments\n✅ **Right**: Ship working code or don't ship at all\n\n### 5. No Validation Script\n\n❌ **Wrong**: Instructions with no way to check correctness\n✅ **Right**: Include `scripts/validate.py` for pre-flight checks\n\n### 6. Overly Permissive Tools\n\n❌ **Wrong**: `allowed-tools: Bash`\n✅ **Right**: `allowed-tools: Bash(git:*,npm:run),Read,Write`\n\n### 7. Ignoring Temporal Knowledge\n\n❌ **Wrong**: \"Use useEffect for componentDidMount\"\n✅ **Right**: \"Pre-React 18: useEffect=didMount. React 18+: runs TWICE in dev. Use refs for run-once.\"\n\n---\n\n## Success Metrics\n\n| Metric | Target | How to Measure |\n|--------|--------|----------------|\n| Correct activation | &gt;90% | Test queries that should trigger |\n| False positive rate | &lt;5% | Test queries that shouldn't trigger |\n| Token usage | &lt;5k | SKILL.md size + typical reference loads |\n| Time to productive | &lt;5 min | User can start working immediately |\n| Anti-pattern prevention | &gt;80% | Users avoid documented mistakes |\n\n---\n\n## Validation Checklist\n\nBefore packaging a skill:\n\n```\n□ SKILL.md exists and is &lt;500 lines\n□ Frontmatter has name, description, allowed-tools\n□ Description includes specific keywords\n□ Description includes NOT clause for exclusions\n□ At least 1 anti-pattern documented\n□ All referenced scripts/tools actually exist\n□ Scripts have clear installation instructions\n□ Scripts handle errors gracefully\n□ If MCP needed, server is complete and tested\n□ If subagents needed, prompts are defined\n□ CHANGELOG.md exists with version history\n□ Validation scripts pass without errors\n```\n\n---\n\n## Reference Files\n\nFor deep dives on specific topics:\n\n| File | Contents |\n|------|----------|\n| `references/antipatterns.md` | Shibboleths and case studies |\n| `references/self-contained-tools.md` | Scripts, MCP, subagent patterns |\n| `references/validation-checklist.md` | Complete review guide |\n| `references/scoring-rubric.md` | Quantitative evaluation (0-10) |\n| `references/mcp-template.md` | Minimal MCP server starter |\n| `references/subagent-template.md` | Agent definition format |\n\n---\n\n## Real-World Case Studies\n\n### Case Study 1: Photo Expert Explosion\n\n**Problem**: Single skill for ALL photo operations (800+ lines)\n**Symptoms**: Activated on \"photo\" anywhere, wrong advice given\n**Root cause**: \"Everything Skill\" anti-pattern\n**Resolution**: Split into 5 focused skills (CLIP, composition, color theory, collage, event detection)\n**Lesson**: One domain ≠ one skill. Split by expertise type.\n\n### Case Study 2: The Phantom MCP\n\n**Problem**: SKILL.md referenced non-existent MCP server\n**Symptoms**: Users ran commands that didn't exist\n**Root cause**: Reference Illusion anti-pattern\n**Resolution**: Added `check_self_contained.py` to CI\n**Lesson**: Don't promise tools you don't deliver.\n\n### Case Study 3: The Time Bomb\n\n**Problem**: Temporal knowledge became stale (React hooks advice from 2023)\n**Symptoms**: Skill became actively harmful in 2024\n**Root cause**: Missing temporal markers\n**Resolution**: Added \"Pre-React 18 vs React 18+\" sections\n**Lesson**: Date your knowledge. Update quarterly.\n\n---\n\n## This Skill Guides\n\n- ✅ Skill creation from expertise\n- ✅ Skill auditing and improvement\n- ✅ Anti-pattern detection and prevention\n- ✅ Progressive disclosure design\n- ✅ Domain expertise encoding (shibboleths)\n- ✅ Self-contained tool implementation\n- ✅ Activation debugging and optimization\n- ✅ Validation and packaging workflows\n\n**Use this skill to create skills that make users immediately productive.**\n"
    }
  ]
}