{
  "name": "color-theory-palette-harmony-expert",
  "type": "folder",
  "path": "color-theory-palette-harmony-expert",
  "children": [
    {
      "name": "references",
      "type": "folder",
      "path": "color-theory-palette-harmony-expert/references",
      "children": [
        {
          "name": "arrangement-patterns.md",
          "type": "file",
          "path": "color-theory-palette-harmony-expert/references/arrangement-patterns.md",
          "size": 11988,
          "content": "# Color Arrangement Patterns\n\n## Neutral-with-Splash-of-Color Pattern\n\n**Design Principle:** Create visual impact by surrounding neutral/muted photos with occasional vibrant accents.\n\n### Metrics\n\n**Chroma (Colorfulness):**\n```python\ndef compute_average_chroma(palette_LCH):\n    \"\"\"Average chroma weighted by pixel abundance.\"\"\"\n    total_weight = sum(w for L, C, H, w in palette_LCH)\n    avg_chroma = sum(C * w for L, C, H, w in palette_LCH) / total_weight\n    return avg_chroma\n```\n\n**Classification:**\n```\nChroma < 20: Neutral/Muted\n20 ≤ Chroma < 50: Moderate\nChroma ≥ 50: Vivid/Saturated\n```\n\n### Arrangement Algorithm\n\n```python\ndef neutral_with_accents_pattern(photos_with_palettes, accent_ratio=0.15):\n    \"\"\"\n    Arrange photos with neutral background and vivid accents.\n\n    Args:\n        photos_with_palettes: [(photo_id, palette_LCH), ...]\n        accent_ratio: Target proportion of vivid photos (e.g., 0.15 = 15%)\n\n    Returns:\n        List of photo_ids with accents strategically placed\n    \"\"\"\n    # Classify by chroma\n    neutral = []  # Chroma < 20\n    moderate = []  # 20 ≤ Chroma < 50\n    vivid = []  # Chroma ≥ 50\n\n    for photo_id, palette in photos_with_palettes:\n        avg_chroma = compute_average_chroma(palette)\n\n        if avg_chroma < 20:\n            neutral.append((photo_id, avg_chroma))\n        elif avg_chroma < 50:\n            moderate.append((photo_id, avg_chroma))\n        else:\n            vivid.append((photo_id, avg_chroma))\n\n    # Sort vivid by chroma (most saturated first)\n    vivid.sort(key=lambda x: -x[1])\n\n    # Determine number of accents\n    total_photos = len(neutral) + len(moderate) + len(vivid)\n    target_accents = int(total_photos * accent_ratio)\n    accents = [pid for pid, _ in vivid[:target_accents]]\n\n    # Remaining vivid become moderate\n    moderate.extend((pid, c) for pid, c in vivid[target_accents:])\n\n    # Create base arrangement (neutral + moderate)\n    base = [pid for pid, _ in neutral] + [pid for pid, _ in moderate]\n    random.shuffle(base)\n\n    # Insert accents evenly\n    result = []\n    accent_step = len(base) / (len(accents) + 1) if accents else 0\n\n    base_idx = 0\n    accent_idx = 0\n\n    for i in range(total_photos):\n        if accent_idx < len(accents) and i >= (accent_idx + 1) * accent_step:\n            result.append(accents[accent_idx])\n            accent_idx += 1\n        elif base_idx < len(base):\n            result.append(base[base_idx])\n            base_idx += 1\n\n    return result\n```\n\n**Visual Effect:** Neutral photos form calm baseline, vivid photos create \"pops\" of visual interest at regular intervals.\n\n---\n\n## Palette Compatibility Scoring\n\n**Goal:** Given two photos, compute how well their palettes work together in a collage.\n\n### Multi-Factor Score\n\n```python\ndef palette_compatibility(palette1_LAB, palette2_LAB):\n    \"\"\"\n    Comprehensive palette compatibility score.\n\n    Returns:\n        float: 0-1 score (higher = more compatible)\n        dict: Breakdown of sub-scores\n    \"\"\"\n    # Convert to LCH for hue analysis\n    palette1_LCH = lab_to_lch(palette1_LAB)\n    palette2_LCH = lab_to_lch(palette2_LAB)\n\n    scores = {}\n\n    # 1. EMD (Wasserstein) distance in LAB space\n    emd = sinkhorn_emd(palette1_LAB, palette2_LAB, epsilon=0.1)\n    scores['emd_similarity'] = np.exp(-emd / 50)  # Convert to similarity\n\n    # 2. Hue harmony (complementary, analogous, etc.)\n    scores['hue_harmony'] = compute_hue_harmony(palette1_LCH, palette2_LCH)\n\n    # 3. Lightness balance\n    avg_L1 = np.mean([L for L, C, H, w in palette1_LCH])\n    avg_L2 = np.mean([L for L, C, H, w in palette2_LCH])\n    scores['lightness_balance'] = 1 - abs(avg_L1 - avg_L2) / 100\n\n    # 4. Chroma balance\n    avg_C1 = np.mean([C for L, C, H, w in palette1_LCH])\n    avg_C2 = np.mean([C for L, C, H, w in palette2_LCH])\n    scores['chroma_balance'] = 1 - abs(avg_C1 - avg_C2) / 100\n\n    # 5. Temperature compatibility (prefer contrast)\n    temp1 = temperature_score_LAB(palette1_LAB)\n    temp2 = temperature_score_LAB(palette2_LAB)\n    temp_diff = abs(temp1 - temp2)\n    scores['temperature_contrast'] = temp_diff  # Higher contrast = better\n\n    # 6. Overall compatibility (weighted sum)\n    compatibility = (\n        scores['emd_similarity'] * 0.35 +\n        scores['hue_harmony'] * 0.25 +\n        scores['lightness_balance'] * 0.15 +\n        scores['chroma_balance'] * 0.10 +\n        scores['temperature_contrast'] * 0.15\n    )\n\n    return compatibility, scores\n```\n\n---\n\n## Hue Harmony Analysis\n\n```python\ndef compute_hue_harmony(palette1_LCH, palette2_LCH):\n    \"\"\"\n    Score hue relationships (complementary, analogous, triadic).\n    \"\"\"\n    # Extract dominant hues (weight by chroma)\n    hues1 = [H for L, C, H, w in palette1_LCH if C > 10]\n    hues2 = [H for L, C, H, w in palette2_LCH if C > 10]\n\n    if not hues1 or not hues2:\n        return 0.5  # Neutral score for near-grayscale\n\n    best_harmony = 0\n\n    for h1 in hues1[:3]:  # Check top 3 hues\n        for h2 in hues2[:3]:\n            diff = abs(h1 - h2)\n            if diff > 180:\n                diff = 360 - diff\n\n            # Complementary (180° ± 30°)\n            if 150 < diff < 210:\n                harmony = 1.0 - abs(diff - 180) / 30\n                best_harmony = max(best_harmony, harmony)\n\n            # Analogous (0-60°)\n            elif diff < 60:\n                harmony = 1.0 - diff / 60\n                best_harmony = max(best_harmony, harmony * 0.8)  # Slightly lower score\n\n            # Triadic (120° ± 20°)\n            elif 100 < diff < 140:\n                harmony = 1.0 - abs(diff - 120) / 20\n                best_harmony = max(best_harmony, harmony * 0.9)\n\n    return best_harmony\n```\n\n---\n\n## Global Color Grading for Collage Cohesion\n\n**Problem:** Even with good local matches, collages can feel disjointed due to different white balance, exposure, saturation across photos.\n\n**Solution:** Apply global color grading pass.\n\n### Method 1: Histogram Matching\n\n```python\ndef match_histogram_LAB(source_image, target_palette):\n    \"\"\"\n    Adjust source image to match target color distribution.\n\n    Uses cumulative histogram matching in LAB space.\n    \"\"\"\n    # Convert source to LAB\n    source_LAB = rgb_to_lab(source_image)\n\n    # Extract LAB channels\n    L, a, b = cv2.split(source_LAB)\n\n    # Compute CDFs\n    source_L_cdf = compute_cdf(L)\n    source_a_cdf = compute_cdf(a)\n    source_b_cdf = compute_cdf(b)\n\n    # Target CDFs (from target palette)\n    target_L_cdf = palette_to_cdf(target_palette, channel='L')\n    target_a_cdf = palette_to_cdf(target_palette, channel='a')\n    target_b_cdf = palette_to_cdf(target_palette, channel='b')\n\n    # Match histograms\n    L_matched = match_cdf(L, source_L_cdf, target_L_cdf)\n    a_matched = match_cdf(a, source_a_cdf, target_a_cdf)\n    b_matched = match_cdf(b, source_b_cdf, target_b_cdf)\n\n    # Merge and convert back to RGB\n    matched_LAB = cv2.merge([L_matched, a_matched, b_matched])\n    matched_RGB = lab_to_rgb(matched_LAB)\n\n    return matched_RGB\n```\n\n### Method 2: Affine Color Transform\n\nUsing optimal transport, find affine transform T(x) = Mx + b that maps source palette to target:\n\n```python\ndef compute_affine_color_transform(source_palette, target_palette):\n    \"\"\"\n    Find affine transform in LAB space using Wasserstein regression.\n    \"\"\"\n    # Extract colors and weights\n    source_colors = np.array([c for c, w in source_palette])  # (N, 3)\n    target_colors = np.array([c for c, w in target_palette])  # (M, 3)\n    source_weights = np.array([w for c, w in source_palette])\n    target_weights = np.array([w for c, w in target_palette])\n\n    # Compute transport plan via Sinkhorn\n    gamma = sinkhorn_transport_plan(source_palette, target_palette)\n\n    # Compute centroids\n    source_centroid = np.average(source_colors, weights=source_weights, axis=0)\n    target_centroid = np.average(target_colors, weights=target_weights, axis=0)\n\n    # Center data\n    X = source_colors - source_centroid  # (N, 3)\n    Y = target_colors - target_centroid  # (M, 3)\n\n    # Weighted covariance\n    C = Y.T @ gamma @ X  # (3, 3)\n\n    # Solve for M: M = C (Σᵢⱼ γᵢⱼ xᵢ xᵢᵀ)⁻¹\n    X_cov = X.T @ np.diag(source_weights) @ X  # (3, 3)\n    M = C @ np.linalg.inv(X_cov)\n\n    # Solve for b\n    b = target_centroid - M @ source_centroid\n\n    return M, b\n\n\ndef apply_affine_color_transform(image, M, b):\n    \"\"\"Apply affine transform to all pixels in LAB space.\"\"\"\n    # Convert to LAB\n    image_LAB = rgb_to_lab(image)\n    h, w, _ = image_LAB.shape\n    pixels = image_LAB.reshape(-1, 3)  # (H*W, 3)\n\n    # Apply transform\n    transformed = (M @ pixels.T).T + b  # (H*W, 3)\n\n    # Clip to valid LAB range\n    transformed[:, 0] = np.clip(transformed[:, 0], 0, 100)      # L\n    transformed[:, 1] = np.clip(transformed[:, 1], -128, 127)   # a\n    transformed[:, 2] = np.clip(transformed[:, 2], -128, 127)   # b\n\n    # Reshape and convert back\n    transformed_LAB = transformed.reshape(h, w, 3)\n    transformed_RGB = lab_to_rgb(transformed_LAB)\n\n    return transformed_RGB\n```\n\n**Regularization (Preserve Local Structure):**\n\nAdd penalty to keep M close to identity:\n```\nminimize:   W₂(T#μ, ν)² + λ ‖M - I‖²_F\n```\n\nThis prevents extreme color shifts that destroy local structure.\n\n---\n\n## Complete Example: Collage Assembly with Color Harmony\n\n```python\ndef assemble_collage_with_color_harmony(\n    photo_database,\n    seed_photo_id,\n    target_size=(10, 10),\n    diversity_lambda=0.7,\n    temperature_pattern='alternating'  # 'alternating', 'wave', 'neutral-accent'\n):\n    \"\"\"\n    Complete collage assembly with advanced color harmony.\n    \"\"\"\n    # 1. Extract global target palette from seed\n    seed_palette = photo_database.get_palette(seed_photo_id)\n    global_palette = seed_palette.copy()\n\n    # 2. Select photos using MMR for diversity\n    all_photos = photo_database.get_all_photos()\n\n    # Filter by basic compatibility\n    compatible = []\n    for photo_id, palette in all_photos:\n        if photo_id == seed_photo_id:\n            continue\n\n        compat, _ = palette_compatibility(seed_palette, palette)\n        if compat > 0.4:\n            compatible.append((photo_id, palette, compat))\n\n    # Select using MMR\n    n_photos = target_size[0] * target_size[1] - 1\n    selected = select_photos_with_mmr(\n        compatible,\n        global_palette,\n        k=n_photos,\n        lambda_param=diversity_lambda\n    )\n\n    # 3. Arrange according to temperature pattern\n    all_photos_with_palettes = [(seed_photo_id, seed_palette)] + [\n        (pid, photo_database.get_palette(pid)) for pid in selected\n    ]\n\n    if temperature_pattern == 'alternating':\n        ordered = arrange_warm_cool_alternation(all_photos_with_palettes)\n    elif temperature_pattern == 'wave':\n        ordered = temperature_wave_pattern(all_photos_with_palettes, wave_length=5)\n    elif temperature_pattern == 'neutral-accent':\n        ordered = neutral_with_accents_pattern(all_photos_with_palettes, accent_ratio=0.15)\n    elif temperature_pattern == 'hue-sorted':\n        ordered = sort_photos_by_hue(all_photos_with_palettes)\n    else:\n        ordered = [pid for pid, _ in all_photos_with_palettes]\n\n    # 4. Place in grid\n    canvas = Canvas(target_size)\n    for idx, photo_id in enumerate(ordered):\n        row = idx // target_size[1]\n        col = idx % target_size[1]\n        canvas.place_photo(photo_id, position=(row, col))\n\n    # 5. Global color grading pass\n    global_palette = aggregate_palettes([\n        photo_database.get_palette(pid) for pid in ordered\n    ])\n\n    for photo_id in ordered:\n        image = photo_database.get_image(photo_id)\n        palette = photo_database.get_palette(photo_id)\n\n        M, b = compute_affine_color_transform(palette, global_palette)\n        graded = apply_affine_color_transform(image, M, b)\n        blended = 0.7 * image + 0.3 * graded  # 30% correction\n\n        canvas.update_photo(photo_id, blended)\n\n    # 6. Refine boundaries (Poisson blending)\n    canvas.refine_boundaries()\n\n    return canvas.render()\n```\n"
        },
        {
          "name": "diversity-algorithms.md",
          "type": "file",
          "path": "color-theory-palette-harmony-expert/references/diversity-algorithms.md",
          "size": 8468,
          "content": "# Diversity Algorithms: Preventing Color Monotony\n\n## Problem\n\nWithout diversity constraints, optimization may select all similar colors (e.g., all blue skies).\n\n**Goal:** Encourage variety in selected photo palettes while maintaining harmony.\n\n---\n\n## Method 1: Maximal Marginal Relevance (MMR)\n\n**Concept:** Select photos that are both relevant (harmonious) and diverse (different from already selected).\n\n### Formula\n\n```\nScore(photo_i) = λ · Harmony(photo_i, global_palette)\n                 - (1 - λ) · max_j∈Selected Similarity(photo_i, photo_j)\n```\n\nWhere:\n- λ ∈ [0, 1]: Diversity parameter (0.7 = 70% harmony, 30% diversity)\n- Harmony: How well photo_i fits global palette (negative EMD)\n- Similarity: Max similarity to any already-selected photo\n\n### Greedy Algorithm\n\n```python\ndef select_photos_with_mmr(candidate_photos, target_palette, k, lambda_param=0.7):\n    \"\"\"\n    Select k photos using Maximal Marginal Relevance.\n\n    Balances harmony with target palette and diversity among selected photos.\n\n    Args:\n        candidate_photos: [(photo_id, palette_LAB), ...]\n        target_palette: Global target palette\n        k: Number of photos to select\n        lambda_param: 0.7 = prefer harmony, 0.3 = prefer diversity\n\n    Returns:\n        List of k selected photo_ids\n    \"\"\"\n    selected = []\n    remaining = list(candidate_photos)\n\n    # Select first photo: highest harmony\n    best_photo = max(remaining,\n                     key=lambda x: -sinkhorn_emd(x[1], target_palette))\n    selected.append(best_photo)\n    remaining.remove(best_photo)\n\n    # Select remaining k-1 photos\n    for _ in range(k - 1):\n        best_score = -float('inf')\n        best_photo = None\n\n        for photo_id, palette in remaining:\n            # Harmony term (negative EMD = high harmony)\n            harmony = -sinkhorn_emd(palette, target_palette)\n\n            # Diversity term (max similarity to any selected photo)\n            max_similarity = 0\n            for selected_id, selected_palette in selected:\n                # Similarity = negative EMD (closer = more similar)\n                similarity = -sinkhorn_emd(palette, selected_palette)\n                max_similarity = max(max_similarity, similarity)\n\n            # MMR score\n            mmr_score = lambda_param * harmony - (1 - lambda_param) * max_similarity\n\n            if mmr_score > best_score:\n                best_score = mmr_score\n                best_photo = (photo_id, palette)\n\n        if best_photo:\n            selected.append(best_photo)\n            remaining.remove(best_photo)\n\n    return [photo_id for photo_id, _ in selected]\n```\n\n### Tuning λ\n\n- λ = 1.0: Pure harmony, no diversity (may select all blues)\n- λ = 0.7: Balanced (recommended for collages)\n- λ = 0.5: Equal harmony and diversity\n- λ = 0.3: Heavy diversity (may sacrifice harmony)\n- λ = 0.0: Pure diversity (maximally different palettes)\n\n---\n\n## Method 2: Determinantal Point Processes (DPPs)\n\n**Concept:** Probabilistic model that encodes both quality and diversity via a kernel matrix.\n\n### Kernel Matrix\n\n```\nK[i, j] = Quality(i) · Quality(j) · Similarity(i, j)\n```\n\nWhere:\n- Quality(i): How good photo i is (aesthetic score, harmony with target)\n- Similarity(i, j): How similar photos i and j are (negative EMD)\n\n### Key Property\n\nDPP naturally repels similar items. Probability of selecting a set S:\n```\nP(S) ∝ det(K_S)\n```\n\nWhere K_S is the submatrix of K indexed by S.\n\n**Intuition:** Determinant is large when rows/columns are linearly independent → diverse sets favored.\n\n### Sampling Algorithm\n\n```python\ndef sample_diverse_subset_dpp(photos_with_palettes, target_palette, k):\n    \"\"\"\n    Sample k photos using Determinantal Point Process.\n\n    Automatically balances quality and diversity.\n\n    Args:\n        photos_with_palettes: [(photo_id, palette, aesthetic_score), ...]\n        target_palette: Global palette to match\n        k: Number of photos to sample\n\n    Returns:\n        List of k sampled photo_ids\n    \"\"\"\n    n = len(photos_with_palettes)\n\n    # Compute quality scores\n    qualities = np.zeros(n)\n    for i, (pid, palette, aesthetic) in enumerate(photos_with_palettes):\n        harmony = -sinkhorn_emd(palette, target_palette)  # Higher = better\n        qualities[i] = aesthetic * 0.5 + harmony * 0.5  # Combine aesthetic & harmony\n\n    # Normalize qualities to [0, 1]\n    qualities = (qualities - qualities.min()) / (qualities.max() - qualities.min())\n\n    # Compute similarity matrix (negative EMD)\n    S = np.zeros((n, n))\n    for i in range(n):\n        for j in range(i, n):\n            if i == j:\n                S[i, j] = 1.0\n            else:\n                emd = sinkhorn_emd(photos_with_palettes[i][1],\n                                   photos_with_palettes[j][1])\n                similarity = np.exp(-emd / 50)  # Convert distance to similarity\n                S[i, j] = S[j, i] = similarity\n\n    # Kernel matrix K = Q · S · Q (element-wise)\n    Q = np.diag(qualities)\n    K = Q @ S @ Q\n\n    # Sample k items using DPP\n    selected_indices = dpp_sample(K, k)\n\n    return [photos_with_palettes[i][0] for i in selected_indices]\n\n\ndef dpp_sample(K, k):\n    \"\"\"\n    Sample k items from DPP with kernel K.\n\n    Uses eigenvalue decomposition method.\n    \"\"\"\n    # Eigenvalue decomposition\n    eigenvalues, eigenvectors = np.linalg.eigh(K)\n\n    # Sample elementary DPP\n    selected = []\n    for i in range(len(eigenvalues) - 1, -1, -1):\n        if len(selected) >= k:\n            break\n        # Include eigenvalue with probability proportional to its magnitude\n        if np.random.rand() < eigenvalues[i] / (1 + eigenvalues[i]):\n            selected.append(i)\n\n    # Project to original space\n    items = np.random.choice(len(K), k, replace=False)\n    return items\n```\n\n### Advantages over MMR\n\n- Probabilistic: Can sample multiple diverse sets\n- Theoretically principled: Negative correlation built into model\n- Handles quality and diversity jointly\n\n### Disadvantages\n\n- More complex to implement\n- Requires eigenvalue decomposition (O(n³))\n- Less intuitive to tune\n\n**Recommendation:** Use MMR for simplicity and control, DPPs for elegant probabilistic diversity.\n\n---\n\n## Method 3: Submodular Maximization\n\n**Concept:** Define a submodular function (diminishing returns property) and greedily maximize it.\n\n### Submodular Function\n\n```\nF(S) = Harmony(S, target) + Diversity(S)\n```\n\nWhere:\n- Harmony(S, target): How well set S matches target palette\n- Diversity(S): Spread of colors in S (entropy, determinant, etc.)\n\n**Key Property:** Greedy algorithm achieves (1 - 1/e) ≈ 63% of optimal for submodular functions.\n\n### Example\n\n```python\ndef submodular_photo_selection(photos, target_palette, k):\n    \"\"\"\n    Select k photos via submodular maximization.\n\n    Objective: F(S) = α·Harmony(S) + β·Diversity(S)\n    \"\"\"\n    selected = []\n\n    def marginal_gain(photo, selected):\n        \"\"\"Gain from adding photo to selected set.\"\"\"\n        # Harmony term: How much closer to target?\n        current_palette = aggregate_palettes([p[1] for p in selected])\n        new_palette = aggregate_palettes([p[1] for p in selected + [photo]])\n\n        harmony_gain = (sinkhorn_emd(current_palette, target_palette)\n                       - sinkhorn_emd(new_palette, target_palette))\n\n        # Diversity term: How different from selected?\n        if not selected:\n            diversity_gain = 1.0  # First photo always diverse\n        else:\n            diversity_gain = min(\n                sinkhorn_emd(photo[1], s[1]) for s in selected\n            ) / 50  # Normalize\n\n        return 0.5 * harmony_gain + 0.5 * diversity_gain\n\n    # Greedy selection\n    remaining = list(photos)\n    for _ in range(k):\n        best_photo = max(remaining, key=lambda p: marginal_gain(p, selected))\n        selected.append(best_photo)\n        remaining.remove(best_photo)\n\n    return [photo_id for photo_id, _ in selected]\n```\n\n---\n\n## Comparison Summary\n\n| Method | Complexity | Control | Use Case |\n|--------|-----------|---------|----------|\n| **MMR** | O(k·n) | λ parameter | Real-time, tunable |\n| **DPP** | O(n³) | Kernel design | Sampling multiple sets |\n| **Submodular** | O(k·n) | Function weights | Theoretical guarantees |\n\n**Recommendation:** Start with MMR (λ=0.7) for most collage applications.\n\n---\n\n## Troubleshooting\n\n### Issue: Collage feels monotonous despite diversity penalty\n\n**Solution:** Increase MMR diversity parameter (lower λ from 0.7 to 0.5) or use DPP sampling.\n"
        },
        {
          "name": "implementation-guide.md",
          "type": "file",
          "path": "color-theory-palette-harmony-expert/references/implementation-guide.md",
          "size": 6771,
          "content": "# Implementation Guide\n\n## Python Dependencies\n\n```bash\npip install colormath opencv-python numpy scipy scikit-image scikit-learn pot hnswlib\n```\n\n| Package | Purpose |\n|---------|---------|\n| `colormath` | CIEDE2000 implementation, LAB/LCH conversions |\n| `opencv-python` | Image color extraction, histogram analysis |\n| `scikit-image` | deltaE calculations, color space transforms |\n| `numpy` | Numerical computing |\n| `scipy` | Optimization for EMD/Wasserstein |\n| `scikit-learn` | K-means for palette extraction |\n| `pot` | Python Optimal Transport |\n| `hnswlib` | Fast k-NN search |\n\n---\n\n## Performance Targets\n\n**Swift/Metal implementation:**\n\n```\nPalette extraction (5 colors): < 50ms per photo\nSinkhorn EMD (5×5 palettes, ε=0.1): < 5ms\nMS-SWD (100 projections, 3 scales): < 20ms\nMMR selection (1000 candidates, k=100): < 500ms\nGlobal color grading (1000×1000 image): < 100ms\nFull collage assembly (100 photos): < 10 seconds\n```\n\n---\n\n## GPU Acceleration (Metal Shaders)\n\n### Compute EMD in Parallel (Cost Matrix)\n\n```metal\nkernel void compute_cost_matrix(\n    constant float3 *palette1 [[buffer(0)]],\n    constant float3 *palette2 [[buffer(1)]],\n    device float *cost_matrix [[buffer(2)]],\n    uint2 gid [[thread_position_in_grid]]\n) {\n    uint i = gid.x;\n    uint j = gid.y;\n\n    // CIEDE2000 distance (simplified)\n    float3 c1 = palette1[i];\n    float3 c2 = palette2[j];\n\n    float dL = c1.x - c2.x;\n    float da = c1.y - c2.y;\n    float db = c1.z - c2.z;\n\n    float delta_e = sqrt(dL*dL + da*da + db*db);\n    cost_matrix[i * palette2_size + j] = delta_e * delta_e;\n}\n```\n\n### Sinkhorn Iterations on GPU\n\n```metal\nkernel void sinkhorn_iteration_u(\n    constant float *K [[buffer(0)]],\n    constant float *v [[buffer(1)]],\n    constant float *a [[buffer(2)]],\n    device float *u [[buffer(3)]],\n    uint i [[thread_position_in_grid]]\n) {\n    // u[i] = a[i] / (K[i, :] @ v)\n    float sum = 0.0;\n    for (uint j = 0; j < v_size; j++) {\n        sum += K[i * v_size + j] * v[j];\n    }\n    u[i] = a[i] / sum;\n}\n```\n\n---\n\n## Caching\n\n```python\nclass PaletteCache:\n    \"\"\"Cache extracted palettes to avoid recomputation.\"\"\"\n\n    def __init__(self):\n        self.cache = {}  # photo_id -> palette_LAB\n\n    def get_or_extract(self, photo_id, image):\n        if photo_id not in self.cache:\n            self.cache[photo_id] = extract_palette(image)\n        return self.cache[photo_id]\n```\n\n---\n\n## Common Patterns\n\n### Pattern 1: Progressive Color Matching\n\n```python\n# Start with dominant color match, refine with full palette\ndef find_matches_progressive(query_palette, candidates, k=20):\n    # Stage 1: Filter by dominant color (fast)\n    dom_matches = [c for c in candidates\n                   if ciede2000(query_palette[0], c.palette[0]) < 30]\n\n    # Stage 2: Full EMD on remaining (slower)\n    scored = [(sinkhorn_emd(query_palette, c.palette), c)\n              for c in dom_matches]\n    scored.sort()\n\n    return [c for _, c in scored[:k]]\n```\n\n### Pattern 2: Hierarchical Palette Matching\n\n```python\n# Cluster photos by dominant hue, search within cluster first\ndef cluster_photos_by_hue(photos):\n    hues = [dominant_hue(palette) for _, palette in photos]\n\n    # K-means clustering in circular hue space\n    from sklearn.cluster import KMeans\n\n    # Convert hue angles to 2D points on unit circle\n    hue_points = np.array([[np.cos(np.radians(h)), np.sin(np.radians(h))]\n                           for h in hues])\n\n    kmeans = KMeans(n_clusters=12, random_state=42)  # 12 = clock positions\n    labels = kmeans.fit_predict(hue_points)\n\n    # Group photos by cluster\n    clusters = {}\n    for (photo_id, palette), label in zip(photos, labels):\n        clusters.setdefault(label, []).append((photo_id, palette))\n\n    return clusters\n```\n\n---\n\n## Advanced Techniques\n\n### Dynamic Palette Evolution\n\nTrack global palette as collage grows, adjust target:\n\n```python\nglobal_palette = seed_palette.copy()\n\nfor iteration in range(n_photos):\n    # Select next photo matching current global palette\n    next_photo = select_best_match(global_palette, candidates, diversity_lambda)\n\n    # Update global palette (exponential moving average)\n    alpha = 0.1  # Learning rate\n    global_palette = (1 - alpha) * global_palette + alpha * next_photo.palette\n```\n\n### Color Mood Transfer\n\nGiven a reference artwork, extract mood and apply:\n\n```python\ndef extract_color_mood(reference_image):\n    \"\"\"Extract color mood from reference (e.g., Rothko painting).\"\"\"\n    palette = extract_palette(reference_image, n_colors=5)\n    palette_lch = lab_to_lch(palette)\n\n    avg_L = np.mean([L for L, C, H, w in palette_lch])\n    avg_C = np.mean([C for L, C, H, w in palette_lch])\n    hue_variance = np.var([H for L, C, H, w in palette_lch])\n\n    return {\n        'target_palette': palette,\n        'lightness': avg_L,\n        'saturation': avg_C,\n        'hue_diversity': hue_variance\n    }\n\ndef apply_mood_to_collage(photos, mood):\n    \"\"\"Select and grade photos to match mood.\"\"\"\n    # Select photos with similar lightness/saturation\n    filtered = [p for p in photos\n                if abs(avg_lightness(p.palette) - mood['lightness']) < 20\n                and abs(avg_chroma(p.palette) - mood['saturation']) < 20]\n\n    # Apply color grading to match target palette\n    for photo in filtered:\n        M, b = compute_affine_color_transform(photo.palette, mood['target_palette'])\n        photo.image = apply_affine_color_transform(photo.image, M, b)\n\n    return filtered\n```\n\n### Color Constancy Correction\n\nPhotos from different cameras/lighting have different white balance. Normalize:\n\n```python\ndef normalize_white_balance(image):\n    \"\"\"Estimate and correct white balance using gray world assumption.\"\"\"\n    # Convert to LAB\n    lab = rgb_to_lab(image)\n\n    # Compute mean a, b (should be ~0 for neutral)\n    mean_a = np.mean(lab[:, :, 1])\n    mean_b = np.mean(lab[:, :, 2])\n\n    # Subtract mean (shift to neutral)\n    lab[:, :, 1] -= mean_a\n    lab[:, :, 2] -= mean_b\n\n    return lab_to_rgb(lab)\n```\n\n---\n\n## Troubleshooting\n\n### Issue: EMD too slow for large palettes\n\n**Solution:** Use Multiscale Sliced Wasserstein instead of Sinkhorn for O(M log M) complexity.\n\n### Issue: Photos look washed out after color grading\n\n**Solution:** Reduce alpha blend strength or add chroma boost:\n```python\ngraded_image[:, :, 1:] *= 1.1  # Boost a, b channels by 10%\n```\n\n---\n\n## References\n\n1. Peyré, G., & Cuturi, M. (2019). \"Computational Optimal Transport.\"\n2. Sharma, G., et al. (2005). \"The CIEDE2000 color-difference formula.\"\n3. \"Multiscale Sliced Wasserstein Distances\" (ECCV 2024)\n4. Kulesza, A., & Taskar, B. (2012). \"Determinantal Point Processes for Machine Learning.\"\n5. Itten, J. (1970). \"The Elements of Color.\"\n6. Fairchild, M. D. (2013). \"Color Appearance Models\" (3rd ed.).\n"
        },
        {
          "name": "optimal-transport.md",
          "type": "file",
          "path": "color-theory-palette-harmony-expert/references/optimal-transport.md",
          "size": 8217,
          "content": "# Optimal Transport for Color Matching\n\n## Earth-Mover Distance (Wasserstein Metric)\n\n### The Palette Matching Problem\n\nGiven two photos with color distributions μ and ν, how \"different\" are they perceptually?\n\n**Naïve Approach:** Compare dominant colors pairwise → **WRONG**\n- Ignores color abundance (weight)\n- Arbitrary pairing\n- Doesn't capture overall distribution shift\n\n**Correct Approach:** Earth-Mover Distance (EMD) / Wasserstein Metric\n\n### Intuition\n\nImagine color histograms as piles of dirt. How much work (distance × amount) to transform one pile into the other?\n\n### Mathematical Formulation\n\nThe **2-Wasserstein distance** between distributions μ and ν is:\n```\nW₂(μ, ν)² = inf{γ ∈ Π(μ,ν)} ∫∫ ‖x - y‖² dγ(x,y)\n```\n\nWhere:\n- Π(μ,ν): Set of all joint probability measures with marginals μ, ν\n- γ: Transport plan (how much mass to move from color x to color y)\n- ‖x - y‖²: Squared distance in LAB space (or CIEDE2000)\n\n### Discrete Form (for implementation)\n\nPhotos represented as color palettes:\n```\nμ = {(c₁, w₁), (c₂, w₂), ..., (cₙ, wₙ)}  where Σwᵢ = 1\nν = {(d₁, v₁), (d₂, v₂), ..., (dₘ, vₘ)}  where Σvⱼ = 1\n```\n\nEMD becomes a linear programming problem:\n```\nminimize:   Σᵢⱼ Cost(cᵢ, dⱼ) · γᵢⱼ\nsubject to: Σⱼ γᵢⱼ = wᵢ  ∀i    (row sums = source weights)\n            Σᵢ γᵢⱼ = vⱼ  ∀j    (column sums = target weights)\n            γᵢⱼ ≥ 0\n```\n\nWhere Cost(cᵢ, dⱼ) = CIEDE2000(cᵢ, dⱼ)² (squared perceptual distance).\n\n**Problem:** O(N²M) variables for general LP solvers → expensive!\n\n---\n\n## Sinkhorn Algorithm: Fast Entropic EMD\n\n### Entropic Regularization\n\nAdd entropy term to smooth the transport plan:\n```\nminimize:   Σᵢⱼ Cost(cᵢ, dⱼ) · γᵢⱼ + ε · H(γ)\n```\n\nWhere H(γ) = -Σᵢⱼ γᵢⱼ log(γᵢⱼ) is entropy.\n\n**Effect:** As ε → 0, recovers exact EMD. For ε > 0, transport plan is \"spread out\" but computation is much faster.\n\n### Sinkhorn's Algorithm\n\n```python\ndef sinkhorn_emd(palette1, palette2, epsilon=0.1, max_iters=100):\n    \"\"\"\n    Compute approximate EMD using Sinkhorn algorithm.\n\n    Args:\n        palette1: List of (color, weight) tuples in LAB space\n        palette2: List of (color, weight) tuples in LAB space\n        epsilon: Entropic regularization parameter (smaller = more accurate)\n        max_iters: Maximum iterations\n\n    Returns:\n        float: Approximate earth-mover distance\n    \"\"\"\n    N = len(palette1)\n    M = len(palette2)\n\n    # Extract colors and weights\n    colors1 = np.array([c for c, w in palette1])\n    colors2 = np.array([c for c, w in palette2])\n    a = np.array([w for c, w in palette1])\n    b = np.array([w for c, w in palette2])\n\n    # Compute cost matrix (CIEDE2000 distances squared)\n    C = np.zeros((N, M))\n    for i in range(N):\n        for j in range(M):\n            C[i, j] = ciede2000_squared(colors1[i], colors2[j])\n\n    # Kernel matrix K = exp(-C / ε)\n    K = np.exp(-C / epsilon)\n\n    # Sinkhorn iterations\n    u = np.ones(N)\n    v = np.ones(M)\n\n    for iteration in range(max_iters):\n        u_prev = u.copy()\n        u = a / (K @ v)\n        v = b / (K.T @ u)\n\n        # Check convergence\n        if np.max(np.abs(u - u_prev)) < 1e-6:\n            break\n\n    # Optimal transport plan\n    gamma = np.diag(u) @ K @ np.diag(v)\n\n    # Compute EMD\n    emd = np.sum(gamma * C)\n\n    return np.sqrt(emd)  # Return distance, not squared distance\n```\n\n**Convergence:** Exponentially fast, typically 10-50 iterations.\n\n**Complexity:** O(NM) per iteration (just matrix-vector products).\n\n### Choosing ε\n\n- ε = 0.01: Nearly exact EMD, slower convergence (50-100 iterations)\n- ε = 0.1: Good approximation, fast (10-20 iterations)\n- ε = 1.0: Very approximate, instant (&lt;5 iterations)\n\n**For collage assembly:** ε = 0.1 is recommended balance.\n\n---\n\n## Multiscale Sliced Wasserstein Distance (2024-2025 Cutting Edge)\n\n**New Research (ECCV 2024):** Multiscale Sliced Wasserstein Distance (MS-SWD) offers:\n- **Faster computation:** O(M log M) vs O(M^2.5) for standard Wasserstein\n- **Handles misalignment:** Compares patch distributions, not co-located pixels\n- **Metric properties:** Satisfies non-negativity, symmetry, triangle inequality\n- **Better than CIEDE2000 for non-aligned images**\n\n### How It Works\n\n1. **Slicing:** Project high-dimensional color distributions onto 1D lines\n2. **1D Wasserstein:** Compute EMD in 1D (cheap: just sort and compare)\n3. **Integration:** Average over many random projection directions\n4. **Multiscale:** Repeat at different image pyramid levels\n\n### Algorithm\n\n```python\ndef multiscale_sliced_wasserstein(palette1, palette2, n_projections=100, n_scales=3):\n    \"\"\"\n    Compute MS-SWD between two color palettes.\n\n    Based on: \"Multiscale Sliced Wasserstein Distances as Perceptual\n    Color Difference Measures\" (ECCV 2024)\n\n    Args:\n        palette1: [(color_LAB, weight), ...] for photo 1\n        palette2: [(color_LAB, weight), ...] for photo 2\n        n_projections: Number of random 1D projections\n        n_scales: Number of pyramid scales\n\n    Returns:\n        float: MS-SWD distance\n    \"\"\"\n    total_distance = 0.0\n\n    for scale in range(n_scales):\n        # At each scale, compute sliced Wasserstein\n        scale_distance = 0.0\n\n        for _ in range(n_projections):\n            # Random unit vector in 3D LAB space\n            theta = np.random.randn(3)\n            theta /= np.linalg.norm(theta)\n\n            # Project colors onto this direction\n            proj1 = [(np.dot(c, theta), w) for c, w in palette1]\n            proj2 = [(np.dot(c, theta), w) for c, w in palette2]\n\n            # Sort by projection value\n            proj1.sort(key=lambda x: x[0])\n            proj2.sort(key=lambda x: x[0])\n\n            # 1D Wasserstein = area between CDFs\n            distance_1d = earth_movers_distance_1d(proj1, proj2)\n            scale_distance += distance_1d\n\n        scale_distance /= n_projections\n        total_distance += scale_distance * (2 ** (-scale))  # Weight by scale\n\n    return total_distance\n```\n\n### When to Use MS-SWD vs Sinkhorn\n\n- **MS-SWD:** When photos might have same colors but different spatial distributions\n- **Sinkhorn EMD:** When you care only about color histogram match (ignores spatial structure)\n- **CIEDE2000 + Sinkhorn:** Best for palette-to-palette comparison in collage assembly\n\n---\n\n## Sinkhorn Algorithm Tuning\n\n```python\n# For collage assembly (real-time):\nepsilon = 0.1  # Good approximation, fast\nmax_iters = 50  # Typically converges in 10-20\n\n# For final color grading (offline):\nepsilon = 0.01  # More accurate\nmax_iters = 200  # Allow more iterations\n\n# For quick preview:\nepsilon = 1.0   # Very approximate but instant\nmax_iters = 10\n```\n\n---\n\n## Approximate EMD for Large Palettes\n\n```python\ndef fast_palette_distance(palette1, palette2):\n    \"\"\"\n    O(N log N) approximate EMD using dominant colors only.\n\n    For real-time preview, use top 3 colors instead of full palette.\n    \"\"\"\n    # Keep only top 3 colors by weight\n    top1 = sorted(palette1, key=lambda x: x[1], reverse=True)[:3]\n    top2 = sorted(palette2, key=lambda x: x[1], reverse=True)[:3]\n\n    # Renormalize weights\n    total1 = sum(w for c, w in top1)\n    total2 = sum(w for c, w in top2)\n    top1 = [(c, w/total1) for c, w in top1]\n    top2 = [(c, w/total2) for c, w in top2]\n\n    # Compute EMD on small palettes (fast)\n    return sinkhorn_emd(top1, top2, epsilon=0.5, max_iters=20)\n```\n\n---\n\n## Adaptive Epsilon for Sinkhorn\n\n```python\ndef adaptive_sinkhorn(palette1, palette2):\n    \"\"\"Start with high epsilon for rough estimate, refine if needed.\"\"\"\n    # Quick estimate\n    rough_emd = sinkhorn_emd(palette1, palette2, epsilon=1.0, max_iters=10)\n\n    if rough_emd < 20:  # Very similar\n        return rough_emd\n    elif rough_emd > 80:  # Very different\n        return rough_emd\n    else:  # Uncertain, refine\n        return sinkhorn_emd(palette1, palette2, epsilon=0.05, max_iters=100)\n```\n\n---\n\n## References\n\n- Peyré, G., & Cuturi, M. (2019). \"Computational Optimal Transport.\" Foundations and Trends in Machine Learning.\n- \"Multiscale Sliced Wasserstein Distances as Perceptual Color Difference Measures\" (ECCV 2024)\n"
        },
        {
          "name": "perceptual-color-spaces.md",
          "type": "file",
          "path": "color-theory-palette-harmony-expert/references/perceptual-color-spaces.md",
          "size": 4318,
          "content": "# Perceptual Color Spaces\n\n## Why LAB/LCH Instead of RGB/HSV?\n\nRGB and HSV are device-dependent and not perceptually uniform. A ΔE of 10 in one region looks different than ΔE of 10 in another.\n\n## CIELAB (LAB) Space\n\n```\nL: Lightness (0 = black, 100 = white)\na: Green (-128) to Red (+128)\nb: Blue (-128) to Yellow (+128)\n```\n\n**Key Property:** Euclidean distance approximates perceived color difference:\n```\nΔE*ab = √((L₂ - L₁)² + (a₂ - a₁)² + (b₂ - b₁)²)\n```\n\n## CIE LCH (Cylindrical Representation of LAB)\n\n```\nL: Lightness (same as LAB)\nC: Chroma = √(a² + b²)  (colorfulness, 0-180)\nH: Hue = atan2(b, a)    (angle in degrees, 0-360)\n```\n\n**Why LCH for Color Harmony?**\n- Hue angle directly corresponds to color wheel position\n- Chroma separates colorfulness from hue (easier to classify \"vivid\" vs \"muted\")\n- Lightness separates brightness independently\n\n**Conversion Chain:**\n```python\nRGB → sRGB (gamma correction) → XYZ (D65 illuminant) → LAB → LCH\n```\n\n---\n\n## CIEDE2000: The Superior Perceptual Metric\n\nThe original ΔE*ab formula has perceptual non-uniformities. **CIEDE2000 (published 2001, refined 2025)** addresses:\n- Lightness weighting (darker colors appear more different)\n- Chroma weighting (high-chroma colors more sensitive)\n- Hue rotation (blue region compressed)\n- Interaction between lightness, chroma, and hue\n\n**Formula (simplified conceptual form):**\n```\nΔE₀₀ = √[(ΔL'/k_L·S_L)² + (ΔC'/k_C·S_C)² + (ΔH'/k_H·S_H)² + R_T·(ΔC'/k_C·S_C)·(ΔH'/k_H·S_H)]\n```\n\nWhere:\n- ΔL', ΔC', ΔH': Weighted lightness, chroma, hue differences\n- S_L, S_C, S_H: Weighting functions based on sample location\n- k_L, k_C, k_H: Parametric factors (typically 1.0)\n- R_T: Rotation term for blue region\n\n**Implementation Notes (Sharma et al., 2005):**\n- Use small-angle approximations carefully\n- Handle hue discontinuity at 360°/0°\n- Numerical stability around neutral axis (C ≈ 0)\n\n**Performance:**\n- CIEDE2000 correlates better with human perception (r > 0.95)\n- Recommended for all palette distance calculations\n- Python: `colormath` library has vetted implementation\n- Swift/Metal: Port from Sharma reference implementation\n\n---\n\n## Practical Implementation\n\n**Color Space Conversions:**\n\nUse vetted libraries to avoid bugs:\n```python\n# Python: colormath\nfrom colormath.color_objects import sRGBColor, LabColor\nfrom colormath.color_conversions import convert_color\n\nrgb = sRGBColor(0.5, 0.3, 0.8)\nlab = convert_color(rgb, LabColor)\n\n# Swift/Metal: Custom shaders\n```\n\n**CIEDE2000 Implementation:**\n\n```python\n# Python: colormath has vetted implementation\nfrom colormath.color_diff import delta_e_cie2000\n\ndelta_e = delta_e_cie2000(lab1, lab2)\n\n# Or use skimage\nfrom skimage.color import deltaE_ciede2000\ndelta_e = deltaE_ciede2000(lab1, lab2)\n```\n\n**Palette Extraction:**\n\nK-means in LAB space with smart initialization:\n```python\nfrom sklearn.cluster import KMeans\n\n# Convert image to LAB\nimage_lab = rgb_to_lab(image)\npixels = image_lab.reshape(-1, 3)\n\n# Sample pixels (for large images)\nif len(pixels) > 10000:\n    indices = np.random.choice(len(pixels), 10000, replace=False)\n    pixels = pixels[indices]\n\n# K-means with k-means++ initialization\nkmeans = KMeans(n_clusters=5, init='k-means++', n_init=10, random_state=42)\nkmeans.fit(pixels)\n\n# Palette = cluster centers\npalette = kmeans.cluster_centers_  # (5, 3) in LAB space\n\n# Weights = cluster sizes\nlabels = kmeans.labels_\nweights = np.bincount(labels) / len(labels)\n```\n\n---\n\n## Handling Edge Cases\n\n```python\n# Grayscale images (low chroma)\nif avg_chroma < 5:\n    # Treat as neutral, use lightness-based matching only\n    return lightness_only_compatibility(palette1, palette2)\n\n# Single-color images (very low entropy)\nif palette_entropy(palette) < 0.5:\n    # Dominant color match\n    return dominant_color_distance(palette1[0], palette2[0])\n\n# Very dark/light images (extreme lightness)\nif avg_lightness < 10 or avg_lightness > 90:\n    # Relax lightness balance constraint\n    scores['lightness_balance'] *= 0.5\n```\n\n---\n\n## References\n\n- Sharma, G., Wu, W., & Dalal, E. N. (2005). \"The CIEDE2000 color-difference formula: Implementation notes, supplementary test data, and mathematical observations.\" Color Research & Application.\n- Fairchild, M. D. (2013). \"Color Appearance Models\" (3rd ed.).\n"
        },
        {
          "name": "temperature-classification.md",
          "type": "file",
          "path": "color-theory-palette-harmony-expert/references/temperature-classification.md",
          "size": 8188,
          "content": "# Warm/Cool Temperature Classification\n\n## Problem\n\nGiven a photo, classify its dominant temperature as warm, cool, or neutral.\n\n---\n\n## LCH Hue Angle Approach\n\n```python\ndef classify_temperature(palette_LCH):\n    \"\"\"\n    Classify palette as warm, cool, or neutral.\n\n    Args:\n        palette_LCH: List of (L, C, H, weight) tuples\n\n    Returns:\n        str: \"warm\", \"cool\", or \"neutral\"\n        float: Temperature score (-1 = cool, +1 = warm)\n    \"\"\"\n    warm_score = 0.0\n    cool_score = 0.0\n\n    for L, C, H, weight in palette_LCH:\n        # Chroma weighting: More saturated colors contribute more\n        chroma_weight = C / 100.0\n        effective_weight = weight * chroma_weight\n\n        # Warm hues: Red (0-30°), Orange (30-60°), Yellow (60-90°)\n        if 0 <= H < 90:\n            warm_score += effective_weight\n\n        # Cool hues: Green (120-180°), Cyan (180-210°), Blue (210-270°)\n        elif 120 <= H < 270:\n            cool_score += effective_weight\n\n        # Transitional: Yellow-Green (90-120°), Purple (270-330°)\n        # Count as half warm, half cool\n        elif 90 <= H < 120:\n            warm_score += effective_weight * 0.3\n            cool_score += effective_weight * 0.7\n        elif 270 <= H < 330:\n            warm_score += effective_weight * 0.5\n            cool_score += effective_weight * 0.5\n\n        # Magenta (330-360°): Warm\n        else:\n            warm_score += effective_weight\n\n    # Normalize\n    total = warm_score + cool_score\n    if total < 0.1:\n        return \"neutral\", 0.0\n\n    temperature = (warm_score - cool_score) / total\n\n    if temperature > 0.3:\n        return \"warm\", temperature\n    elif temperature < -0.3:\n        return \"cool\", temperature\n    else:\n        return \"neutral\", temperature\n```\n\n---\n\n## LAB b-axis Approach\n\nUse LAB b-axis as temperature proxy (more robust for low-chroma colors):\n\n```\nb > 20: Warm (yellow-biased)\nb < -20: Cool (blue-biased)\n-20 ≤ b ≤ 20: Neutral\n```\n\n**Weighted Temperature Score:**\n\n```python\ndef temperature_score_LAB(palette_LAB):\n    \"\"\"\n    Compute temperature using LAB b-axis.\n\n    More robust than hue-based for low-chroma colors.\n    \"\"\"\n    total_weight = sum(w for c, w in palette_LAB)\n    weighted_b = sum(c[2] * w for c, w in palette_LAB) / total_weight\n\n    # Normalize to [-1, 1]\n    # Typical b range: [-128, 128]\n    return np.clip(weighted_b / 64, -1.0, 1.0)\n```\n\n---\n\n## Hue-Sorted Photo Sequences\n\n**Goal:** Arrange photos in hue order to create rainbow gradients or smooth color transitions.\n\n### Algorithm\n\n```python\ndef sort_photos_by_hue(photos_with_palettes):\n    \"\"\"\n    Sort photos by dominant hue for rainbow effect.\n\n    Args:\n        photos_with_palettes: [(photo_id, palette_LCH), ...]\n\n    Returns:\n        List of photo_ids in hue-sorted order\n    \"\"\"\n    def dominant_hue(palette_LCH):\n        # Weight by chroma * weight (ignore low-saturation colors)\n        weighted_hues = []\n        for L, C, H, weight in palette_LCH:\n            if C > 10:  # Ignore near-neutral colors\n                weighted_hues.append((H, C * weight))\n\n        if not weighted_hues:\n            return 0.0  # Default for neutral images\n\n        # Circular mean of hue (handles 359° + 1° = 0° correctly)\n        sin_sum = sum(w * np.sin(np.radians(h)) for h, w in weighted_hues)\n        cos_sum = sum(w * np.cos(np.radians(h)) for h, w in weighted_hues)\n\n        mean_hue = np.degrees(np.arctan2(sin_sum, cos_sum)) % 360\n        return mean_hue\n\n    # Compute dominant hue for each photo\n    photo_hues = [(photo_id, dominant_hue(palette))\n                  for photo_id, palette in photos_with_palettes]\n\n    # Sort by hue\n    photo_hues.sort(key=lambda x: x[1])\n\n    return [photo_id for photo_id, hue in photo_hues]\n```\n\n### Circular Hue Handling\n\nHue is circular (0° = 360° = red). Sorting naïvely by angle breaks at the red boundary.\n\n**Solution:** Choose rotation that minimizes total angular difference:\n\n```python\ndef optimize_hue_rotation(hues):\n    \"\"\"\n    Find rotation that minimizes sum of adjacent hue differences.\n\n    This ensures smooth transitions across the red boundary.\n    \"\"\"\n    best_rotation = 0\n    min_total_diff = float('inf')\n\n    # Try 36 rotations (every 10 degrees)\n    for rotation in range(0, 360, 10):\n        rotated_hues = [(h + rotation) % 360 for h in hues]\n        rotated_hues.sort()\n\n        # Compute total adjacent difference\n        total_diff = sum(abs(rotated_hues[i+1] - rotated_hues[i])\n                        for i in range(len(rotated_hues) - 1))\n\n        # Add wrap-around difference\n        total_diff += min(\n            abs(rotated_hues[0] - rotated_hues[-1]),\n            360 - abs(rotated_hues[0] - rotated_hues[-1])\n        )\n\n        if total_diff < min_total_diff:\n            min_total_diff = total_diff\n            best_rotation = rotation\n\n    # Apply best rotation\n    return [(h + best_rotation) % 360 for h in hues]\n```\n\n---\n\n## Warm/Cool Alternation Pattern\n\n**Design Pattern:** Alternate warm and cool photos for visual rhythm and contrast.\n\n### Algorithm\n\n```python\ndef arrange_warm_cool_alternation(photos_with_palettes):\n    \"\"\"\n    Arrange photos in alternating warm/cool pattern.\n\n    Creates visual rhythm and prevents color monotony.\n\n    Args:\n        photos_with_palettes: [(photo_id, palette_LAB), ...]\n\n    Returns:\n        List of photo_ids in alternating order\n    \"\"\"\n    # Classify each photo\n    photos_classified = []\n    for photo_id, palette in photos_with_palettes:\n        temp_type, temp_score = classify_temperature(palette)\n        photos_classified.append((photo_id, temp_type, temp_score))\n\n    # Separate into warm, cool, neutral\n    warm_photos = [(pid, score) for pid, t, score in photos_classified if t == \"warm\"]\n    cool_photos = [(pid, score) for pid, t, score in photos_classified if t == \"cool\"]\n    neutral_photos = [(pid, score) for pid, t, score in photos_classified if t == \"neutral\"]\n\n    # Sort by temperature intensity (most extreme first)\n    warm_photos.sort(key=lambda x: -x[1])  # Descending\n    cool_photos.sort(key=lambda x: x[1])   # Ascending (most negative first)\n\n    # Alternate warm and cool\n    result = []\n    while warm_photos or cool_photos:\n        if warm_photos:\n            result.append(warm_photos.pop(0)[0])\n        if cool_photos:\n            result.append(cool_photos.pop(0)[0])\n\n    # Intersperse neutrals evenly\n    if neutral_photos:\n        step = len(result) / (len(neutral_photos) + 1)\n        for i, (pid, _) in enumerate(neutral_photos):\n            insert_pos = int((i + 1) * step)\n            result.insert(insert_pos, pid)\n\n    return result\n```\n\n### Gradual Temperature Progression\n\nInstead of strict alternation, create smooth warm → cool → warm waves:\n\n```python\ndef temperature_wave_pattern(photos, wave_length=5):\n    \"\"\"\n    Arrange photos in sinusoidal warm/cool pattern.\n\n    Args:\n        photos: [(photo_id, temperature_score), ...]\n        wave_length: Period of temperature oscillation\n\n    Returns:\n        List of photo_ids\n    \"\"\"\n    # Sort by temperature\n    photos.sort(key=lambda x: x[1])\n\n    # Assign target temperature based on sine wave\n    n = len(photos)\n    target_temps = [np.sin(2 * np.pi * i / wave_length) for i in range(n)]\n\n    # Match photos to target temperatures (greedy assignment)\n    result = []\n    used = set()\n\n    for target in target_temps:\n        # Find unused photo closest to target\n        best_photo = None\n        best_diff = float('inf')\n\n        for photo_id, temp_score in photos:\n            if photo_id not in used:\n                diff = abs(temp_score - target)\n                if diff < best_diff:\n                    best_diff = diff\n                    best_photo = photo_id\n\n        if best_photo:\n            result.append(best_photo)\n            used.add(best_photo)\n\n    return result\n```\n\n---\n\n## Troubleshooting\n\n### Issue: Warm/cool classification fails for sunset photos\n\n**Solution:** Use both hue angle and LAB b-axis, combine:\n```python\ntemp_score = 0.5 * hue_based_temp(palette) + 0.5 * b_axis_temp(palette)\n```\n\n### Issue: Hue-sorted sequence has jarring transitions\n\n**Solution:** Apply hue rotation optimization to minimize angular jumps.\n"
        }
      ]
    },
    {
      "name": "CHANGELOG.md",
      "type": "file",
      "path": "color-theory-palette-harmony-expert/CHANGELOG.md",
      "size": 3962,
      "content": "# Changelog\n\nAll notable changes to the color-theory-palette-harmony-expert skill will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [2.0.0] - 2025-11-26\n\n### Changed\n- **BREAKING**: Refactored from single 1716-line file to modular structure\n- Reduced SKILL.md from 1716 lines to 258 lines (85% reduction)\n- Moved detailed implementations to `/references/` directory\n- Updated frontmatter from custom YAML to standard `allowed-tools` format\n- Simplified description with proper NOT clause and activation keywords\n\n### Added\n- **When to Use This Skill** section with clear scope boundaries\n- **Do NOT use for** section with skill alternatives\n- **MCP Integrations** section (Firecrawl, Stability AI)\n- Created `/references/perceptual-color-spaces.md`:\n  - CIELAB (LAB) and CIE LCH color space explanations\n  - CIEDE2000 metric (2001, refined 2025)\n  - Conversion chain and implementation notes\n  - Edge case handling (grayscale, single-color, extreme lightness)\n  - Python library recommendations\n- Created `/references/optimal-transport.md`:\n  - Earth-Mover Distance (Wasserstein) mathematical formulation\n  - Sinkhorn algorithm with full Python implementation\n  - ε parameter tuning guide\n  - Multiscale Sliced Wasserstein Distance (ECCV 2024)\n  - Adaptive epsilon strategy\n  - Approximate EMD for large palettes\n- Created `/references/temperature-classification.md`:\n  - LCH hue angle approach with hue ranges\n  - LAB b-axis approach (more robust)\n  - Hue-sorted photo sequences with circular mean\n  - Hue rotation optimization\n  - Warm/cool alternation pattern\n  - Temperature wave pattern (sinusoidal)\n- Created `/references/arrangement-patterns.md`:\n  - Neutral-with-splash-of-color pattern\n  - Chroma classification (neutral/moderate/vivid)\n  - Multi-factor palette compatibility scoring\n  - Hue harmony analysis (complementary, analogous, triadic)\n  - Global color grading methods (histogram matching, affine transform)\n  - Complete collage assembly example\n- Created `/references/diversity-algorithms.md`:\n  - Maximal Marginal Relevance (MMR) with λ tuning guide\n  - Determinantal Point Processes (DPPs)\n  - Submodular maximization\n  - Comparison table (complexity, control, use case)\n- Created `/references/implementation-guide.md`:\n  - Python dependencies with purpose\n  - Performance targets table\n  - Metal shader examples (cost matrix, Sinkhorn iterations)\n  - Caching patterns\n  - Progressive color matching\n  - Hierarchical palette matching\n  - Dynamic palette evolution\n  - Color mood transfer\n  - Color constancy correction\n  - Troubleshooting guide\n\n### Removed\n- Custom YAML frontmatter format (tools, triggers, integrates_with, python_dependencies)\n- 1458+ lines of detailed implementations (moved to references)\n- Inline version info (moved to CHANGELOG)\n\n### Improved\n- Progressive disclosure: essential concepts in SKILL.md, full code in references\n- Quick reference tables for algorithms and parameters\n- Cross-references to related skills (collage-layout-expert, design-system-creator, vaporwave-glassomorphic-ui-designer, photo-composition-critic)\n\n## [1.0.0] - 2024-XX-XX\n\n### Added\n- Initial color-theory-palette-harmony-expert skill\n- Perceptual color space documentation (LAB, LCH)\n- CIEDE2000 color difference metric\n- Earth-Mover Distance (Wasserstein) for palette matching\n- Sinkhorn algorithm implementation\n- Multiscale Sliced Wasserstein Distance (MS-SWD)\n- Warm/cool temperature classification\n- Hue-sorted photo sequences\n- Warm/cool alternation patterns\n- Neutral-with-accent arrangements\n- Diversity algorithms (MMR, DPP, submodular)\n- Palette compatibility scoring\n- Global color grading techniques\n- Metal shader examples\n- Python dependencies and performance targets\n- Complete collage assembly example\n- Integration guidance for Compositional Collider project\n"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "color-theory-palette-harmony-expert/SKILL.md",
      "size": 7874,
      "content": "---\nname: color-theory-palette-harmony-expert\ndescription: Expert in color theory, palette harmony, and perceptual color science for computational photo composition. Specializes in earth-mover distance optimization, warm/cool alternation, diversity-aware palette selection, and hue-based photo sequencing. Activate on \"color palette\", \"color harmony\", \"warm cool\", \"earth mover distance\", \"Wasserstein\", \"LAB space\", \"hue sorted\", \"palette matching\". NOT for basic RGB manipulation (use standard image processing), single-photo color grading (use native-app-designer), UI color schemes (use vaporwave-glassomorphic-ui-designer), or color blindness simulation (accessibility specialists).\nallowed-tools: Read,Write,Edit,Bash,mcp__stability-ai__stability-ai-generate-image,mcp__firecrawl__firecrawl_search,WebFetch\n---\n\n# Color Theory & Palette Harmony Expert\n\nYou are a world-class expert in **perceptual color science** for computational photo composition. You combine classical color theory with modern optimal transport methods for collage creation.\n\n## When to Use This Skill\n\n✅ **Use for:**\n- Palette-based photo selection for collages\n- Warm/cool color alternation algorithms\n- Hue-sorted photo sequences (rainbow gradients)\n- Palette compatibility using earth-mover distance\n- Diversity penalties to avoid color monotony\n- Global color harmony across photo collections\n- Neutral-with-splash-of-color patterns\n- Perceptual color space transformations (RGB → LAB → LCH)\n\n❌ **Do NOT use for:**\n- Basic RGB color manipulation → use standard image processing\n- Single-photo color grading → use **native-app-designer**\n- UI color scheme generation → use **vaporwave-glassomorphic-ui-designer**\n- Color blindness simulation → specialized accessibility skill\n\n## MCP Integrations\n\n| MCP | Purpose |\n|-----|---------|\n| **Firecrawl** | Research color theory papers, optimal transport algorithms |\n| **Stability AI** | Generate reference palettes, test color harmony visually |\n\n---\n\n## Quick Reference\n\n### Perceptual Color Spaces\n\n**Why LAB/LCH Instead of RGB?**\n- RGB/HSV are device-dependent, not perceptually uniform\n- LAB Euclidean distance ≈ perceived color difference\n- LCH separates Hue (color wheel position) from Chroma (saturation)\n\n```python\n# CIELAB (LAB) Space\nL: Lightness (0-100)\na: Green (-128) to Red (+128)\nb: Blue (-128) to Yellow (+128)\n\n# CIE LCH (Cylindrical)\nL: Lightness (same)\nC: Chroma = √(a² + b²)  # Colorfulness\nH: Hue = atan2(b, a)    # Angle 0-360°\n```\n\n**CIEDE2000** is the gold-standard perceptual distance metric:\n- Correlates with human perception (r > 0.95)\n- Use `colormath` or `skimage.color.deltaE_ciede2000`\n\n→ Full details: `/references/perceptual-color-spaces.md`\n\n---\n\n### Earth-Mover Distance (Wasserstein)\n\n**Problem:** How different are two photo color distributions perceptually?\n\n**Sinkhorn Algorithm** - Fast O(NM) entropic EMD:\n\n```python\ndef sinkhorn_emd(palette1, palette2, epsilon=0.1, max_iters=100):\n    # Kernel K = exp(-CostMatrix / epsilon)\n    # Iterate: u = a / (K @ v), v = b / (K.T @ u)\n    # EMD = sqrt(sum(gamma * Cost))\n```\n\n**Choosing ε:**\n| ε | Accuracy | Speed |\n|---|----------|-------|\n| 0.01 | Nearly exact | 50-100 iters |\n| 0.1 | Good (recommended) | 10-20 iters |\n| 1.0 | Very rough | &lt;5 iters |\n\n**Multiscale Sliced Wasserstein (2024):**\n- O(M log M) vs O(M²·⁵) for standard Wasserstein\n- Better for spatial distribution differences\n\n→ Full details: `/references/optimal-transport.md`\n\n---\n\n### Warm/Cool Classification\n\n**LCH Hue Approach:**\n```\nWarm: Red (0-30°), Orange (30-60°), Yellow (60-90°), Magenta (330-360°)\nCool: Green (120-180°), Cyan (180-210°), Blue (210-270°)\nTransitional: Yellow-Green (90-120°), Purple (270-330°)\n```\n\n**LAB b-axis Approach (more robust):**\n```\nb > 20: Warm (yellow-biased)\nb < -20: Cool (blue-biased)\n-20 ≤ b ≤ 20: Neutral\n```\n\n→ Full details: `/references/temperature-classification.md`\n\n---\n\n### Arrangement Patterns\n\n| Pattern | Description |\n|---------|-------------|\n| **Hue-sorted** | Rainbow gradient, circular mean handling |\n| **Warm/cool alternation** | Visual rhythm, prevent monotony |\n| **Temperature wave** | Sinusoidal warm → cool → warm |\n| **Neutral-with-accent** | 85% muted + 15% vivid pops |\n\n**Palette Compatibility Score:**\n```python\ncompatibility = (\n    emd_similarity * 0.35 +\n    hue_harmony * 0.25 +      # Complementary, analogous, triadic\n    lightness_balance * 0.15 +\n    chroma_balance * 0.10 +\n    temperature_contrast * 0.15\n)\n```\n\n→ Full details: `/references/arrangement-patterns.md`\n\n---\n\n### Diversity Algorithms\n\n**Problem:** Without constraints, optimization selects all similar colors.\n\n**Method 1: Maximal Marginal Relevance (MMR)**\n```\nScore = λ · Harmony(photo, target) - (1-λ) · max(Similarity to selected)\n```\n- λ = 0.7: Balanced (recommended)\n- λ = 1.0: Pure harmony (may select all blues)\n- λ = 0.5: Equal harmony/diversity\n\n**Method 2: Determinantal Point Processes (DPP)**\n- Probabilistic: P(S) ∝ det(K_S)\n- Automatically repels similar items\n- Better for sampling multiple diverse sets\n\n**Method 3: Submodular Maximization**\n- Greedy achieves 63% of optimal\n- Theoretical guarantees\n\n→ Full details: `/references/diversity-algorithms.md`\n\n---\n\n### Global Color Grading\n\n**Problem:** Different white balance/exposure across photos = disjointed collage.\n\n**Affine Color Transform:**\n```python\n# Find M, b where transformed = M @ LAB_color + b\nM, b = compute_affine_color_transform(source_palette, target_palette)\ngraded = apply_affine_color_transform(image, M, b)\n\n# Blend subtly (30% correction)\nresult = 0.7 * original + 0.3 * graded\n```\n\n→ Full details: `/references/arrangement-patterns.md`\n\n---\n\n## Implementation Summary\n\n### Python Dependencies\n\n```bash\npip install colormath opencv-python numpy scipy scikit-image pot hnswlib\n```\n\n| Package | Purpose |\n|---------|---------|\n| `colormath` | CIEDE2000, LAB/LCH conversions |\n| `pot` | Python Optimal Transport |\n| `scikit-image` | deltaE calculations |\n\n### Performance Targets\n\n| Operation | Target |\n|-----------|--------|\n| Palette extraction (5 colors) | &lt;50ms |\n| Sinkhorn EMD (5×5, ε=0.1) | &lt;5ms |\n| MMR selection (1000 candidates, k=100) | &lt;500ms |\n| Full collage assembly (100 photos) | &lt;10s |\n\n→ Full details: `/references/implementation-guide.md`\n\n---\n\n## Your Expertise in Action\n\nWhen a user asks for help with color-based composition:\n\n1. **Assess Intent:**\n   - Palette matching for collage?\n   - Color temperature arrangement?\n   - Diversity-aware selection?\n\n2. **Choose Approach:**\n   - Sinkhorn EMD for palette compatibility\n   - MMR with λ=0.7 for diverse selection\n   - Appropriate arrangement pattern\n\n3. **Implement Rigorously:**\n   - Use LAB/LCH spaces (never raw RGB)\n   - CIEDE2000 for perceptual distances\n   - Cache palette extractions\n\n4. **Optimize:**\n   - Adaptive ε for Sinkhorn\n   - Progressive matching (dominant → full)\n   - Hierarchical clustering by hue\n\n---\n\n## Reference Files\n\n| File | Content |\n|------|---------|\n| `/references/perceptual-color-spaces.md` | LAB, LCH, CIEDE2000, conversions |\n| `/references/optimal-transport.md` | EMD, Sinkhorn, MS-SWD algorithms |\n| `/references/temperature-classification.md` | Warm/cool, hue sorting, alternation |\n| `/references/arrangement-patterns.md` | Neutral-accent, compatibility, grading |\n| `/references/diversity-algorithms.md` | MMR, DPP, submodular maximization |\n| `/references/implementation-guide.md` | Python deps, Metal shaders, caching |\n\n---\n\n## Related Skills\n\n- **collage-layout-expert** - Color harmonization for collages\n- **design-system-creator** - Color tokens in design systems\n- **vaporwave-glassomorphic-ui-designer** - UI color palettes\n- **photo-composition-critic** - Aesthetic scoring\n\n---\n\n*Where perceptual color science meets computational composition.*\n"
    }
  ]
}