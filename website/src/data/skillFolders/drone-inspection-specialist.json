{
  "name": "drone-inspection-specialist",
  "type": "folder",
  "path": "drone-inspection-specialist",
  "children": [
    {
      "name": "references",
      "type": "folder",
      "path": "drone-inspection-specialist/references",
      "children": [
        {
          "name": "fire-detection.md",
          "type": "file",
          "path": "drone-inspection-specialist/references/fire-detection.md",
          "size": 21100,
          "content": "# Forest Fire Detection Reference\n\n## Multi-Modal Fire Detection Pipeline\n\n```python\nimport cv2\nimport numpy as np\nimport torch\nfrom ultralytics import YOLO\nfrom typing import List, Dict, Tuple, Optional\nfrom dataclasses import dataclass\nimport time\n\n@dataclass\nclass FireAlert:\n    alert_type: str  # 'CONFIRMED_FIRE', 'HOTSPOT', 'SMOKE'\n    confidence: float\n    bbox: Tuple[int, int, int, int]\n    gps_coords: Optional[Tuple[float, float]] = None\n    temperature: Optional[float] = None\n    timestamp: float = 0.0\n    priority: str = 'MEDIUM'\n\n\nclass ForestFireDetector:\n    \"\"\"\n    Multi-modal fire detection combining RGB and thermal imagery.\n    Designed for real-time drone deployment.\n    \"\"\"\n    def __init__(self,\n                 thermal_model_path: str = 'fire_thermal_yolov8.pt',\n                 smoke_model_path: str = 'smoke_detection_yolov8.pt',\n                 device: str = 'cuda'):\n        # Thermal camera fire detection\n        self.thermal_model = YOLO(thermal_model_path)\n        self.thermal_model.to(device)\n\n        # RGB smoke detection\n        self.smoke_model = YOLO(smoke_model_path)\n        self.smoke_model.to(device)\n\n        # Temperature thresholds\n        self.temp_threshold = 60  # Celsius - potential hotspot\n        self.fire_threshold = 150  # Celsius - confirmed fire\n        self.alert_threshold = 0.7\n\n        # Alert cooldown to prevent spam\n        self.last_alert_time = {}\n        self.alert_cooldown = 5.0  # seconds\n\n    def process_frame(self, rgb_frame: np.ndarray,\n                      thermal_frame: np.ndarray) -> List[FireAlert]:\n        \"\"\"\n        Process both RGB and thermal frames simultaneously.\n\n        Args:\n            rgb_frame: BGR image from visible camera\n            thermal_frame: Temperature array from thermal camera (Celsius)\n\n        Returns:\n            List of fire alerts with location and confidence\n        \"\"\"\n        alerts = []\n\n        # Smoke detection in RGB\n        smoke_dets = self._detect_smoke(rgb_frame)\n\n        # Hotspot detection in thermal\n        hotspots = self._detect_hotspots(thermal_frame)\n\n        # Fire detection using thermal model\n        fire_dets = self._detect_thermal_fire(thermal_frame)\n\n        # Multi-modal fusion\n        alerts = self._fuse_detections(smoke_dets, fire_dets, hotspots)\n\n        return alerts\n\n    def _detect_smoke(self, rgb_frame: np.ndarray) -> List[Dict]:\n        \"\"\"Detect smoke plumes in RGB image\"\"\"\n        results = self.smoke_model(rgb_frame, conf=0.5, verbose=False)[0]\n\n        detections = []\n        for box in results.boxes:\n            det = {\n                'bbox': tuple(map(int, box.xyxy[0].cpu().numpy())),\n                'confidence': float(box.conf[0].item()),\n                'class': 'smoke'\n            }\n            detections.append(det)\n\n        return detections\n\n    def _detect_hotspots(self, thermal_frame: np.ndarray) -> List[Dict]:\n        \"\"\"Detect temperature anomalies in thermal image\"\"\"\n        # Create binary mask for hot regions\n        hot_mask = (thermal_frame > self.temp_threshold).astype(np.uint8)\n\n        # Find contours\n        contours, _ = cv2.findContours(\n            hot_mask,\n            cv2.RETR_EXTERNAL,\n            cv2.CHAIN_APPROX_SIMPLE\n        )\n\n        hotspots = []\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < 100:  # Skip tiny regions (noise)\n                continue\n\n            x, y, w, h = cv2.boundingRect(contour)\n            region = thermal_frame[y:y+h, x:x+w]\n\n            hotspots.append({\n                'bbox': (x, y, x+w, y+h),\n                'max_temp': float(np.max(region)),\n                'mean_temp': float(np.mean(region)),\n                'area': area,\n                'class': 'hotspot'\n            })\n\n        return hotspots\n\n    def _detect_thermal_fire(self, thermal_frame: np.ndarray) -> List[Dict]:\n        \"\"\"Run fire detection model on thermal image\"\"\"\n        # Normalize for model input\n        thermal_normalized = self._normalize_thermal(thermal_frame)\n\n        results = self.thermal_model(thermal_normalized, conf=0.6, verbose=False)[0]\n\n        detections = []\n        for box in results.boxes:\n            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n\n            # Get actual temperature from thermal data\n            region = thermal_frame[y1:y2, x1:x2]\n            max_temp = float(np.max(region)) if region.size > 0 else 0\n\n            det = {\n                'bbox': (x1, y1, x2, y2),\n                'confidence': float(box.conf[0].item()),\n                'max_temp': max_temp,\n                'class': 'fire'\n            }\n            detections.append(det)\n\n        return detections\n\n    def _normalize_thermal(self, thermal: np.ndarray) -> np.ndarray:\n        \"\"\"Normalize thermal data to 0-255 for model input\"\"\"\n        # Clip to expected range\n        thermal_clipped = np.clip(thermal, -20, 300)\n        # Normalize\n        normalized = ((thermal_clipped + 20) / 320 * 255).astype(np.uint8)\n        # Convert to 3-channel for YOLO\n        return cv2.cvtColor(normalized, cv2.COLOR_GRAY2BGR)\n\n    def _fuse_detections(self, smoke: List[Dict], fire: List[Dict],\n                         hotspots: List[Dict]) -> List[FireAlert]:\n        \"\"\"\n        Multi-modal fusion for high-confidence fire alerts.\n        Priority: Fire+Smoke > Fire-only > Hotspot\n        \"\"\"\n        alerts = []\n        current_time = time.time()\n\n        # High priority: Thermal fire detection + RGB smoke\n        for fire_det in fire:\n            for smoke_det in smoke:\n                iou = self._calculate_iou(fire_det['bbox'], smoke_det['bbox'])\n                if iou > 0.2:  # Overlapping detections\n                    combined_conf = (fire_det['confidence'] + smoke_det['confidence']) / 2\n                    alert = FireAlert(\n                        alert_type='CONFIRMED_FIRE',\n                        confidence=min(0.98, combined_conf + 0.2),  # Boost for multi-modal\n                        bbox=fire_det['bbox'],\n                        temperature=fire_det.get('max_temp'),\n                        timestamp=current_time,\n                        priority='CRITICAL'\n                    )\n                    alerts.append(alert)\n\n        # Medium priority: Thermal fire without smoke\n        for fire_det in fire:\n            # Skip if already in confirmed fire\n            already_confirmed = any(\n                self._calculate_iou(fire_det['bbox'], a.bbox) > 0.5\n                for a in alerts if a.alert_type == 'CONFIRMED_FIRE'\n            )\n            if not already_confirmed:\n                alert = FireAlert(\n                    alert_type='FIRE_THERMAL',\n                    confidence=fire_det['confidence'],\n                    bbox=fire_det['bbox'],\n                    temperature=fire_det.get('max_temp'),\n                    timestamp=current_time,\n                    priority='HIGH'\n                )\n                alerts.append(alert)\n\n        # Lower priority: Hotspots above fire threshold\n        for hotspot in hotspots:\n            if hotspot['max_temp'] > self.fire_threshold:\n                alert = FireAlert(\n                    alert_type='HOTSPOT_CRITICAL',\n                    confidence=0.8,\n                    bbox=hotspot['bbox'],\n                    temperature=hotspot['max_temp'],\n                    timestamp=current_time,\n                    priority='HIGH'\n                )\n                alerts.append(alert)\n            elif hotspot['max_temp'] > 80:  # Significant but not fire\n                alert = FireAlert(\n                    alert_type='HOTSPOT',\n                    confidence=0.6,\n                    bbox=hotspot['bbox'],\n                    temperature=hotspot['max_temp'],\n                    timestamp=current_time,\n                    priority='MEDIUM'\n                )\n                alerts.append(alert)\n\n        # Smoke-only alerts (could be early fire)\n        for smoke_det in smoke:\n            already_reported = any(\n                self._calculate_iou(smoke_det['bbox'], a.bbox) > 0.3\n                for a in alerts\n            )\n            if not already_reported:\n                alert = FireAlert(\n                    alert_type='SMOKE',\n                    confidence=smoke_det['confidence'],\n                    bbox=smoke_det['bbox'],\n                    timestamp=current_time,\n                    priority='MEDIUM'\n                )\n                alerts.append(alert)\n\n        return alerts\n\n    def _calculate_iou(self, box1: Tuple, box2: Tuple) -> float:\n        \"\"\"Calculate Intersection over Union\"\"\"\n        x1 = max(box1[0], box2[0])\n        y1 = max(box1[1], box2[1])\n        x2 = min(box1[2], box2[2])\n        y2 = min(box1[3], box2[3])\n\n        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n        union = area1 + area2 - intersection\n\n        return intersection / union if union > 0 else 0\n\n\nclass FireAlertSystem:\n    \"\"\"\n    Georeferencing and dispatch system for fire alerts.\n    \"\"\"\n    def __init__(self, camera_fov: Tuple[float, float] = (84, 58)):\n        self.fov_h, self.fov_v = camera_fov  # degrees\n        self.alert_history = []\n        self.dispatch_endpoint = None\n\n    def generate_georeferenced_alert(self, alert: FireAlert,\n                                     drone_lat: float, drone_lon: float,\n                                     drone_alt: float, gimbal_pitch: float,\n                                     drone_heading: float,\n                                     frame_size: Tuple[int, int] = (1920, 1080)) -> FireAlert:\n        \"\"\"\n        Convert image-space detection to GPS coordinates.\n\n        Args:\n            alert: Fire alert with bbox in image coordinates\n            drone_lat, drone_lon: Drone GPS position\n            drone_alt: Altitude AGL in meters\n            gimbal_pitch: Camera pitch angle (negative = looking down)\n            drone_heading: Drone heading in degrees (0 = North)\n            frame_size: Image dimensions (width, height)\n\n        Returns:\n            Alert with GPS coordinates added\n        \"\"\"\n        img_w, img_h = frame_size\n        x1, y1, x2, y2 = alert.bbox\n\n        # Center of detection\n        center_x = (x1 + x2) / 2\n        center_y = (y1 + y2) / 2\n\n        # Angle from image center\n        angle_x = (center_x - img_w/2) / img_w * self.fov_h\n        angle_y = (center_y - img_h/2) / img_h * self.fov_v\n\n        # Adjust for gimbal pitch\n        effective_pitch = gimbal_pitch + angle_y\n\n        # Ground distance calculation\n        if effective_pitch >= -5:  # Looking too horizontal\n            return alert  # Can't estimate ground position\n\n        ground_dist = drone_alt / np.tan(np.radians(-effective_pitch))\n\n        # Horizontal offset from drone nadir\n        ground_offset_x = ground_dist * np.tan(np.radians(angle_x))\n\n        # Convert to North-East offsets (accounting for heading)\n        heading_rad = np.radians(drone_heading)\n        north_offset = ground_dist * np.cos(heading_rad) - ground_offset_x * np.sin(heading_rad)\n        east_offset = ground_dist * np.sin(heading_rad) + ground_offset_x * np.cos(heading_rad)\n\n        # Convert to GPS (rough approximation)\n        # 1 degree latitude ≈ 111km\n        # 1 degree longitude ≈ 111km * cos(latitude)\n        dlat = north_offset / 111000\n        dlon = east_offset / (111000 * np.cos(np.radians(drone_lat)))\n\n        alert.gps_coords = (drone_lat + dlat, drone_lon + dlon)\n        return alert\n\n    def send_to_dispatch(self, alert: FireAlert):\n        \"\"\"Send alert to fire dispatch system\"\"\"\n        payload = {\n            'type': alert.alert_type,\n            'priority': alert.priority,\n            'confidence': alert.confidence,\n            'location': {\n                'lat': alert.gps_coords[0] if alert.gps_coords else None,\n                'lon': alert.gps_coords[1] if alert.gps_coords else None\n            },\n            'temperature': alert.temperature,\n            'timestamp': alert.timestamp\n        }\n\n        # Log for later\n        self.alert_history.append(payload)\n\n        # Send to dispatch (implementation depends on system)\n        if self.dispatch_endpoint:\n            import requests\n            requests.post(self.dispatch_endpoint, json=payload)\n\n        return payload\n```\n\n## Thermal Camera Integration\n\n```python\nimport numpy as np\nfrom typing import Tuple, Optional\nimport struct\n\nclass ThermalCameraInterface:\n    \"\"\"\n    Interface for FLIR thermal cameras commonly used on drones.\n    Supports radiometric temperature extraction.\n    \"\"\"\n    def __init__(self, emissivity: float = 0.95,\n                 reflected_temp: float = 25.0,\n                 atmospheric_temp: float = 25.0,\n                 distance: float = 50.0):\n        self.emissivity = emissivity\n        self.reflected_temp = reflected_temp\n        self.atmospheric_temp = atmospheric_temp\n        self.distance = distance\n\n        # Planck constants for FLIR cameras (typical values)\n        self.planck_r1 = 21106.77\n        self.planck_r2 = 0.012545258\n        self.planck_b = 1501.0\n        self.planck_f = 1.0\n        self.planck_o = -7340\n\n    def raw_to_temperature(self, raw_value: int) -> float:\n        \"\"\"\n        Convert raw radiometric value to temperature in Celsius.\n        Uses FLIR's planck equation.\n        \"\"\"\n        # Atmospheric correction\n        tau = self._atmospheric_transmission()\n\n        # Object signal\n        raw_obj = (raw_value - self.planck_o) / self.emissivity / tau\n\n        # Correct for reflected temperature\n        raw_refl = self.planck_r1 / (self.planck_r2 * (np.exp(self.planck_b / (self.reflected_temp + 273.15)) - self.planck_f)) - self.planck_o\n        raw_obj -= (1 - self.emissivity) * raw_refl / self.emissivity\n\n        # Convert to temperature\n        temp_k = self.planck_b / np.log(self.planck_r1 / (self.planck_r2 * (raw_obj + self.planck_o)) + self.planck_f)\n        return temp_k - 273.15\n\n    def _atmospheric_transmission(self) -> float:\n        \"\"\"Calculate atmospheric transmission based on distance\"\"\"\n        # Simplified model - real implementation uses humidity, etc.\n        alpha = 0.006\n        return np.exp(-alpha * self.distance)\n\n    def process_thermal_frame(self, raw_frame: np.ndarray) -> np.ndarray:\n        \"\"\"Convert entire raw frame to temperature array\"\"\"\n        # Vectorized conversion\n        tau = self._atmospheric_transmission()\n        raw_obj = (raw_frame.astype(np.float64) - self.planck_o) / self.emissivity / tau\n\n        raw_refl = self.planck_r1 / (self.planck_r2 * (np.exp(self.planck_b / (self.reflected_temp + 273.15)) - self.planck_f)) - self.planck_o\n        raw_obj -= (1 - self.emissivity) * raw_refl / self.emissivity\n\n        temp_k = self.planck_b / np.log(self.planck_r1 / (self.planck_r2 * (raw_obj + self.planck_o)) + self.planck_f)\n        return temp_k - 273.15\n\n\nclass FLIRBosonInterface(ThermalCameraInterface):\n    \"\"\"Specific interface for FLIR Boson cameras\"\"\"\n    def __init__(self, serial_port: str = '/dev/ttyUSB0'):\n        super().__init__()\n        self.serial_port = serial_port\n        self.frame_width = 640\n        self.frame_height = 512\n\n    def capture_frame(self) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Capture both radiometric and visual thermal frame.\n\n        Returns:\n            temperature_frame: Float array of temperatures in Celsius\n            visual_frame: 8-bit colorized frame for display\n        \"\"\"\n        # Implementation depends on specific camera SDK\n        # This is a template for the interface\n        raw_frame = self._read_raw_frame()\n        temp_frame = self.process_thermal_frame(raw_frame)\n        visual_frame = self._colorize(temp_frame)\n        return temp_frame, visual_frame\n\n    def _colorize(self, temp_frame: np.ndarray,\n                  vmin: float = -20, vmax: float = 150) -> np.ndarray:\n        \"\"\"Apply colormap to temperature data\"\"\"\n        import cv2\n        normalized = np.clip((temp_frame - vmin) / (vmax - vmin), 0, 1)\n        normalized = (normalized * 255).astype(np.uint8)\n        return cv2.applyColorMap(normalized, cv2.COLORMAP_INFERNO)\n\n    def _read_raw_frame(self) -> np.ndarray:\n        \"\"\"Read raw frame from camera - implementation specific\"\"\"\n        # Placeholder - actual implementation uses camera SDK\n        return np.zeros((self.frame_height, self.frame_width), dtype=np.uint16)\n```\n\n## Fire Progression Tracking\n\n```python\nimport numpy as np\nfrom typing import List, Dict, Tuple\nfrom collections import deque\nimport time\n\nclass FireProgressionTracker:\n    \"\"\"\n    Track fire spread over time using consecutive detections.\n    Estimates spread rate and direction.\n    \"\"\"\n    def __init__(self, history_length: int = 100):\n        self.detection_history: deque = deque(maxlen=history_length)\n        self.fire_zones: Dict[str, List[Dict]] = {}\n\n    def update(self, alerts: List, timestamp: float = None) -> Dict:\n        \"\"\"\n        Update tracker with new alerts.\n\n        Returns:\n            Analysis dict with spread rate, direction, and predictions\n        \"\"\"\n        timestamp = timestamp or time.time()\n\n        # Record current detections\n        current_state = {\n            'timestamp': timestamp,\n            'alerts': alerts,\n            'total_area': sum(self._bbox_area(a.bbox) for a in alerts)\n        }\n        self.detection_history.append(current_state)\n\n        if len(self.detection_history) < 2:\n            return {'status': 'insufficient_data'}\n\n        # Analyze progression\n        analysis = self._analyze_progression()\n        return analysis\n\n    def _analyze_progression(self) -> Dict:\n        \"\"\"Analyze fire spread from history\"\"\"\n        recent = list(self.detection_history)[-10:]\n\n        if len(recent) < 2:\n            return {'status': 'insufficient_data'}\n\n        # Area change rate\n        areas = [s['total_area'] for s in recent]\n        timestamps = [s['timestamp'] for s in recent]\n\n        dt = timestamps[-1] - timestamps[0]\n        if dt > 0:\n            area_rate = (areas[-1] - areas[0]) / dt  # pixels^2/second\n        else:\n            area_rate = 0\n\n        # Centroid movement\n        centroids = []\n        for state in recent:\n            if state['alerts']:\n                cx = np.mean([self._bbox_center(a.bbox)[0] for a in state['alerts']])\n                cy = np.mean([self._bbox_center(a.bbox)[1] for a in state['alerts']])\n                centroids.append((cx, cy, state['timestamp']))\n\n        spread_direction = None\n        spread_speed = 0\n\n        if len(centroids) >= 2:\n            dx = centroids[-1][0] - centroids[0][0]\n            dy = centroids[-1][1] - centroids[0][1]\n            dt = centroids[-1][2] - centroids[0][2]\n\n            if dt > 0:\n                spread_speed = np.sqrt(dx**2 + dy**2) / dt\n                spread_direction = np.degrees(np.arctan2(dy, dx))\n\n        return {\n            'status': 'tracking',\n            'area_change_rate': area_rate,\n            'spread_speed_pixels': spread_speed,\n            'spread_direction_degrees': spread_direction,\n            'trend': 'growing' if area_rate > 100 else 'stable' if area_rate > -100 else 'shrinking',\n            'num_observations': len(recent)\n        }\n\n    def _bbox_area(self, bbox: Tuple) -> float:\n        return (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n\n    def _bbox_center(self, bbox: Tuple) -> Tuple[float, float]:\n        return ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)\n\n    def predict_spread(self, time_horizon: float = 300) -> Dict:\n        \"\"\"\n        Predict fire position in `time_horizon` seconds.\n\n        Returns:\n            Predicted fire extent and confidence\n        \"\"\"\n        analysis = self._analyze_progression()\n\n        if analysis['status'] != 'tracking':\n            return {'status': 'cannot_predict'}\n\n        if self.detection_history:\n            last_alerts = self.detection_history[-1]['alerts']\n            current_centroids = [self._bbox_center(a.bbox) for a in last_alerts]\n\n            if current_centroids and analysis['spread_direction_degrees'] is not None:\n                # Simple linear extrapolation\n                speed = analysis['spread_speed_pixels']\n                direction = np.radians(analysis['spread_direction_degrees'])\n\n                predicted_dx = speed * time_horizon * np.cos(direction)\n                predicted_dy = speed * time_horizon * np.sin(direction)\n\n                avg_centroid = np.mean(current_centroids, axis=0)\n                predicted_centroid = (\n                    avg_centroid[0] + predicted_dx,\n                    avg_centroid[1] + predicted_dy\n                )\n\n                return {\n                    'status': 'predicted',\n                    'current_centroid': tuple(avg_centroid),\n                    'predicted_centroid': predicted_centroid,\n                    'time_horizon_seconds': time_horizon,\n                    'confidence': 0.7 if speed > 0 else 0.3\n                }\n\n        return {'status': 'cannot_predict'}\n```\n"
        },
        {
          "name": "gaussian-splatting-3d.md",
          "type": "file",
          "path": "drone-inspection-specialist/references/gaussian-splatting-3d.md",
          "size": 25260,
          "content": "# Gaussian Splatting 3D Reconstruction Reference\n\n## Pipeline Overview\n\n```python\nimport subprocess\nimport os\nimport json\nimport numpy as np\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n@dataclass\nclass ReconstructionQuality:\n    psnr: float           # Peak Signal-to-Noise Ratio\n    ssim: float           # Structural Similarity\n    lpips: float          # Learned Perceptual Image Patch Similarity\n    num_gaussians: int\n    training_time_min: float\n\n\nclass GaussianSplattingReconstructor:\n    \"\"\"\n    3D Gaussian Splatting pipeline for inspection applications.\n    Creates photorealistic 3D models from drone imagery.\n    \"\"\"\n    def __init__(self, colmap_path: str = \"colmap\",\n                 gs_path: str = \"gaussian-splatting\"):\n        self.colmap_path = colmap_path\n        self.gs_train_script = os.path.join(gs_path, \"train.py\")\n        self.gs_render_script = os.path.join(gs_path, \"render.py\")\n\n    def reconstruct_from_drone_video(self, video_path: str,\n                                      output_dir: str,\n                                      config: Optional[Dict] = None) -> Dict:\n        \"\"\"\n        Full reconstruction pipeline from drone video.\n\n        Args:\n            video_path: Path to drone video file\n            output_dir: Output directory for all artifacts\n            config: Optional configuration overrides\n\n        Returns:\n            Reconstruction results with paths and quality metrics\n        \"\"\"\n        config = config or self._default_config()\n\n        # Create directory structure\n        paths = self._setup_directories(output_dir)\n\n        # Step 1: Extract frames\n        print(\"Extracting frames...\")\n        frame_count = self._extract_frames(video_path, paths['frames'], config)\n\n        # Step 2: Run COLMAP Structure-from-Motion\n        print(\"Running COLMAP SfM...\")\n        sfm_result = self._run_colmap_sfm(paths['frames'], paths['colmap'])\n\n        if not sfm_result['success']:\n            return {'success': False, 'error': sfm_result['error']}\n\n        # Step 3: Train Gaussian Splatting\n        print(\"Training Gaussian Splatting model...\")\n        gs_result = self._train_gaussian_splatting(\n            paths['colmap'], paths['model'], config\n        )\n\n        # Step 4: Export for viewers\n        print(\"Exporting for web viewer...\")\n        self._export_web_viewer(paths['model'], paths['viewer'])\n\n        # Step 5: Calculate quality metrics\n        quality = self._evaluate_quality(paths['model'], paths['frames'])\n\n        return {\n            'success': True,\n            'paths': paths,\n            'frame_count': frame_count,\n            'sfm_stats': sfm_result,\n            'training_stats': gs_result,\n            'quality_metrics': quality,\n            'viewer_url': f\"file://{paths['viewer']}/index.html\"\n        }\n\n    def _default_config(self) -> Dict:\n        \"\"\"Default configuration for inspection-quality reconstruction\"\"\"\n        return {\n            'frame_extraction': {\n                'fps': 2,                    # Extract 2 frames per second\n                'min_frames': 50,            # Minimum frames needed\n                'max_frames': 500,           # Maximum to process\n                'quality': 95                # JPEG quality\n            },\n            'colmap': {\n                'camera_model': 'OPENCV',\n                'single_camera': True,       # Drone typically has one camera\n                'exhaustive_matching': False, # Sequential matching faster\n                'gpu_index': '0'\n            },\n            'gaussian_splatting': {\n                'iterations': 30000,\n                'densify_until_iter': 15000,\n                'densification_interval': 100,\n                'opacity_reset_interval': 3000,\n                'position_lr_max_steps': 30000,\n                'sh_degree': 3               # Spherical harmonics degree\n            },\n            'output': {\n                'render_resolution': 1920,\n                'export_ply': True,\n                'export_web': True\n            }\n        }\n\n    def _setup_directories(self, output_dir: str) -> Dict[str, str]:\n        \"\"\"Create output directory structure\"\"\"\n        paths = {\n            'root': output_dir,\n            'frames': os.path.join(output_dir, 'frames'),\n            'colmap': os.path.join(output_dir, 'colmap'),\n            'model': os.path.join(output_dir, 'gaussian_model'),\n            'viewer': os.path.join(output_dir, 'web_viewer'),\n            'renders': os.path.join(output_dir, 'renders')\n        }\n\n        for path in paths.values():\n            os.makedirs(path, exist_ok=True)\n\n        return paths\n\n    def _extract_frames(self, video_path: str, output_dir: str,\n                        config: Dict) -> int:\n        \"\"\"Extract frames from video at specified rate\"\"\"\n        import cv2\n\n        cap = cv2.VideoCapture(video_path)\n        video_fps = cap.get(cv2.CAP_PROP_FPS)\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n        extract_fps = config['frame_extraction']['fps']\n        frame_interval = int(video_fps / extract_fps)\n\n        extracted = 0\n        frame_idx = 0\n\n        while True:\n            ret, frame = cap.read()\n            if not ret:\n                break\n\n            if frame_idx % frame_interval == 0:\n                # Save frame\n                filename = os.path.join(output_dir, f\"frame_{extracted:05d}.jpg\")\n                cv2.imwrite(filename, frame,\n                           [cv2.IMWRITE_JPEG_QUALITY, config['frame_extraction']['quality']])\n                extracted += 1\n\n                if extracted >= config['frame_extraction']['max_frames']:\n                    break\n\n            frame_idx += 1\n\n        cap.release()\n        return extracted\n\n    def _run_colmap_sfm(self, images_dir: str, output_dir: str) -> Dict:\n        \"\"\"Run COLMAP Structure-from-Motion pipeline\"\"\"\n        database_path = os.path.join(output_dir, \"database.db\")\n        sparse_path = os.path.join(output_dir, \"sparse\")\n        os.makedirs(sparse_path, exist_ok=True)\n\n        try:\n            # Feature extraction\n            subprocess.run([\n                self.colmap_path, \"feature_extractor\",\n                \"--database_path\", database_path,\n                \"--image_path\", images_dir,\n                \"--ImageReader.camera_model\", \"OPENCV\",\n                \"--ImageReader.single_camera\", \"1\",\n                \"--SiftExtraction.use_gpu\", \"1\"\n            ], check=True, capture_output=True)\n\n            # Sequential matching (faster for video sequences)\n            subprocess.run([\n                self.colmap_path, \"sequential_matcher\",\n                \"--database_path\", database_path,\n                \"--SequentialMatching.overlap\", \"10\"\n            ], check=True, capture_output=True)\n\n            # Sparse reconstruction\n            subprocess.run([\n                self.colmap_path, \"mapper\",\n                \"--database_path\", database_path,\n                \"--image_path\", images_dir,\n                \"--output_path\", sparse_path\n            ], check=True, capture_output=True)\n\n            # Find the reconstruction (usually in sparse/0)\n            recon_path = os.path.join(sparse_path, \"0\")\n            if os.path.exists(recon_path):\n                # Get stats\n                images_txt = os.path.join(recon_path, \"images.txt\")\n                points_txt = os.path.join(recon_path, \"points3D.txt\")\n\n                num_images = self._count_colmap_images(images_txt)\n                num_points = self._count_colmap_points(points_txt)\n\n                return {\n                    'success': True,\n                    'num_registered_images': num_images,\n                    'num_points': num_points,\n                    'reconstruction_path': recon_path\n                }\n            else:\n                return {'success': False, 'error': 'No reconstruction created'}\n\n        except subprocess.CalledProcessError as e:\n            return {'success': False, 'error': str(e)}\n\n    def _train_gaussian_splatting(self, colmap_dir: str, output_dir: str,\n                                   config: Dict) -> Dict:\n        \"\"\"Train Gaussian Splatting model\"\"\"\n        import time\n\n        gs_config = config['gaussian_splatting']\n        sparse_path = os.path.join(colmap_dir, \"sparse\", \"0\")\n\n        start_time = time.time()\n\n        try:\n            cmd = [\n                \"python\", self.gs_train_script,\n                \"-s\", sparse_path,\n                \"-m\", output_dir,\n                \"--iterations\", str(gs_config['iterations']),\n                \"--densify_until_iter\", str(gs_config['densify_until_iter']),\n                \"--densification_interval\", str(gs_config['densification_interval']),\n                \"--opacity_reset_interval\", str(gs_config['opacity_reset_interval']),\n                \"--position_lr_max_steps\", str(gs_config['position_lr_max_steps']),\n                \"--sh_degree\", str(gs_config['sh_degree'])\n            ]\n\n            subprocess.run(cmd, check=True, capture_output=True)\n\n            training_time = (time.time() - start_time) / 60\n\n            return {\n                'success': True,\n                'training_time_min': training_time,\n                'iterations': gs_config['iterations'],\n                'model_path': output_dir\n            }\n\n        except subprocess.CalledProcessError as e:\n            return {'success': False, 'error': str(e)}\n\n    def _export_web_viewer(self, model_dir: str, viewer_dir: str):\n        \"\"\"Export model for web-based viewing\"\"\"\n        # Export PLY file\n        ply_path = os.path.join(model_dir, \"point_cloud\", \"iteration_30000\", \"point_cloud.ply\")\n\n        if os.path.exists(ply_path):\n            # Copy to viewer directory\n            import shutil\n            shutil.copy(ply_path, os.path.join(viewer_dir, \"model.ply\"))\n\n            # Create simple HTML viewer\n            html_content = self._generate_viewer_html()\n            with open(os.path.join(viewer_dir, \"index.html\"), 'w') as f:\n                f.write(html_content)\n\n    def _generate_viewer_html(self) -> str:\n        \"\"\"Generate HTML for WebGL Gaussian Splatting viewer\"\"\"\n        return '''\n<!DOCTYPE html>\n<html>\n<head>\n    <title&gt;3D Gaussian Splatting Viewer</title>\n    <script src=\"https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.min.js\"></script>\n    <script src=\"https://cdn.jsdelivr.net/npm/three@0.160.0/examples/js/controls/OrbitControls.js\"></script>\n    <style>\n        body { margin: 0; overflow: hidden; }\n        canvas { display: block; }\n        #info { position: absolute; top: 10px; left: 10px; color: white; font-family: sans-serif; }\n    </style>\n</head>\n<body>\n    <div id=\"info\">Use mouse to orbit, scroll to zoom</div>\n    <script type=\"module\">\n        // Gaussian Splatting WebGL renderer\n        // Implementation would load model.ply and render splats\n        // This is a placeholder - real implementation uses specialized shaders\n\n        import * as THREE from 'three';\n        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';\n\n        const scene = new THREE.Scene();\n        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);\n        const renderer = new THREE.WebGLRenderer();\n\n        renderer.setSize(window.innerWidth, window.innerHeight);\n        document.body.appendChild(renderer.domElement);\n\n        const controls = new OrbitControls(camera, renderer.domElement);\n        camera.position.z = 5;\n\n        function animate() {\n            requestAnimationFrame(animate);\n            controls.update();\n            renderer.render(scene, camera);\n        }\n        animate();\n    </script>\n</body>\n</html>\n'''\n\n    def _evaluate_quality(self, model_dir: str, images_dir: str) -> Dict:\n        \"\"\"Evaluate reconstruction quality\"\"\"\n        # In practice, render test views and compare to held-out images\n        # This is a simplified version\n\n        ply_path = os.path.join(model_dir, \"point_cloud\", \"iteration_30000\", \"point_cloud.ply\")\n\n        if os.path.exists(ply_path):\n            num_gaussians = self._count_gaussians(ply_path)\n        else:\n            num_gaussians = 0\n\n        return {\n            'num_gaussians': num_gaussians,\n            'estimated_psnr': 28.0,  # Typical for good reconstruction\n            'estimated_ssim': 0.92,\n            'note': 'Run render.py with test set for accurate metrics'\n        }\n\n    def _count_gaussians(self, ply_path: str) -> int:\n        \"\"\"Count number of Gaussians in PLY file\"\"\"\n        with open(ply_path, 'rb') as f:\n            # Read header to find vertex count\n            line = f.readline().decode('ascii')\n            while 'element vertex' not in line:\n                line = f.readline().decode('ascii')\n                if not line:\n                    return 0\n            return int(line.split()[-1])\n\n    def _count_colmap_images(self, images_txt: str) -> int:\n        \"\"\"Count registered images in COLMAP output\"\"\"\n        count = 0\n        with open(images_txt, 'r') as f:\n            for line in f:\n                if line.startswith('#'):\n                    continue\n                if len(line.strip()) > 0:\n                    count += 1\n        return count // 2  # Each image has 2 lines\n\n    def _count_colmap_points(self, points_txt: str) -> int:\n        \"\"\"Count 3D points in COLMAP output\"\"\"\n        count = 0\n        with open(points_txt, 'r') as f:\n            for line in f:\n                if not line.startswith('#'):\n                    count += 1\n        return count\n```\n\n## Inspection-Specific 3DGS Applications\n\n```python\nimport numpy as np\nfrom typing import Dict, List, Tuple, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass MeasurementPoint:\n    id: str\n    position_3d: Tuple[float, float, float]\n    confidence: float\n\n\nclass InspectionMeasurement:\n    \"\"\"\n    Extract measurements from Gaussian Splatting reconstructions.\n    Useful for roof area, damage size, and property dimensions.\n    \"\"\"\n    def __init__(self, model_path: str):\n        self.gaussians = self._load_gaussians(model_path)\n        self.scale_factor = 1.0  # Meters per unit\n\n    def calibrate_scale(self, known_distance: float,\n                        point1: Tuple[float, float, float],\n                        point2: Tuple[float, float, float]):\n        \"\"\"Calibrate scale using known real-world distance\"\"\"\n        model_distance = np.linalg.norm(np.array(point1) - np.array(point2))\n        self.scale_factor = known_distance / model_distance\n\n    def measure_distance(self, point1: Tuple, point2: Tuple) -> float:\n        \"\"\"Measure distance between two points in meters\"\"\"\n        model_dist = np.linalg.norm(np.array(point1) - np.array(point2))\n        return model_dist * self.scale_factor\n\n    def measure_area(self, polygon_points: List[Tuple]) -> float:\n        \"\"\"Calculate area of polygon in square meters\"\"\"\n        # Project to 2D (assuming roughly horizontal surface)\n        points_2d = np.array([(p[0], p[1]) for p in polygon_points])\n\n        # Shoelace formula\n        n = len(points_2d)\n        area = 0.0\n        for i in range(n):\n            j = (i + 1) % n\n            area += points_2d[i][0] * points_2d[j][1]\n            area -= points_2d[j][0] * points_2d[i][1]\n\n        return abs(area) / 2.0 * (self.scale_factor ** 2)\n\n    def extract_roof_plane(self) -> Dict:\n        \"\"\"Extract dominant roof plane from Gaussians\"\"\"\n        positions = self.gaussians['positions']\n\n        # RANSAC to find dominant plane\n        best_plane = None\n        best_inliers = 0\n        threshold = 0.1  # 10cm inlier threshold\n\n        for _ in range(1000):  # RANSAC iterations\n            # Random 3 points\n            idx = np.random.choice(len(positions), 3, replace=False)\n            p1, p2, p3 = positions[idx]\n\n            # Plane normal\n            v1 = p2 - p1\n            v2 = p3 - p1\n            normal = np.cross(v1, v2)\n            normal = normal / np.linalg.norm(normal)\n\n            # Count inliers\n            d = -np.dot(normal, p1)\n            distances = np.abs(np.dot(positions, normal) + d)\n            inliers = np.sum(distances < threshold)\n\n            if inliers > best_inliers:\n                best_inliers = inliers\n                best_plane = {'normal': normal, 'd': d, 'inliers': inliers}\n\n        if best_plane:\n            # Calculate slope\n            horizontal = np.array([0, 0, 1])\n            slope_rad = np.arccos(np.abs(np.dot(best_plane['normal'], horizontal)))\n            slope_deg = np.degrees(slope_rad)\n\n            return {\n                'normal': best_plane['normal'].tolist(),\n                'slope_degrees': slope_deg,\n                'inlier_count': best_plane['inliers'],\n                'inlier_ratio': best_plane['inliers'] / len(positions)\n            }\n\n        return {'error': 'No plane found'}\n\n    def detect_damage_in_3d(self, damage_detections_2d: List[Dict],\n                            camera_poses: List[np.ndarray]) -> List[Dict]:\n        \"\"\"\n        Project 2D damage detections to 3D space.\n\n        Args:\n            damage_detections_2d: List of {image_id, bbox, type}\n            camera_poses: Camera poses from reconstruction\n\n        Returns:\n            3D locations of damages\n        \"\"\"\n        damage_3d = []\n\n        for det in damage_detections_2d:\n            image_id = det['image_id']\n            bbox = det['bbox']\n\n            if image_id < len(camera_poses):\n                pose = camera_poses[image_id]\n\n                # Project bbox center to ray\n                center_2d = ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)\n\n                # Find intersection with Gaussian cloud\n                position_3d = self._raycast_to_gaussians(center_2d, pose)\n\n                if position_3d is not None:\n                    damage_3d.append({\n                        'type': det['type'],\n                        'position': position_3d,\n                        'source_image': image_id,\n                        'confidence': det.get('confidence', 0.5)\n                    })\n\n        return damage_3d\n\n    def _load_gaussians(self, model_path: str) -> Dict:\n        \"\"\"Load Gaussian parameters from PLY file\"\"\"\n        # Simplified - real implementation parses full PLY format\n        ply_path = f\"{model_path}/point_cloud/iteration_30000/point_cloud.ply\"\n\n        positions = []\n        # Parse PLY file for positions\n        # ... implementation details ...\n\n        return {\n            'positions': np.array(positions) if positions else np.zeros((0, 3)),\n            'count': len(positions)\n        }\n\n    def _raycast_to_gaussians(self, pixel: Tuple, pose: np.ndarray) -> Optional[Tuple]:\n        \"\"\"Find Gaussian intersection with ray from camera through pixel\"\"\"\n        # Implementation would trace ray through Gaussian field\n        # and find closest intersection\n        return None  # Placeholder\n\n\nclass ChangeDetection3D:\n    \"\"\"\n    Detect changes between two 3DGS reconstructions.\n    Useful for before/after damage assessment.\n    \"\"\"\n    def __init__(self, model_before: str, model_after: str):\n        self.gaussians_before = self._load_gaussians(model_before)\n        self.gaussians_after = self._load_gaussians(model_after)\n\n    def detect_changes(self, threshold: float = 0.2) -> Dict:\n        \"\"\"\n        Detect geometric changes between reconstructions.\n\n        Args:\n            threshold: Distance threshold for change detection (meters)\n\n        Returns:\n            Change analysis with added, removed, and modified regions\n        \"\"\"\n        pos_before = self.gaussians_before['positions']\n        pos_after = self.gaussians_after['positions']\n\n        # Build KD-tree for efficient nearest neighbor\n        from scipy.spatial import cKDTree\n\n        tree_before = cKDTree(pos_before)\n        tree_after = cKDTree(pos_after)\n\n        # Find points in 'after' not in 'before' (new/added)\n        distances_to_before, _ = tree_before.query(pos_after)\n        added_mask = distances_to_before > threshold\n        added_points = pos_after[added_mask]\n\n        # Find points in 'before' not in 'after' (removed/damaged)\n        distances_to_after, _ = tree_after.query(pos_before)\n        removed_mask = distances_to_after > threshold\n        removed_points = pos_before[removed_mask]\n\n        return {\n            'added_regions': self._cluster_points(added_points),\n            'removed_regions': self._cluster_points(removed_points),\n            'added_point_count': len(added_points),\n            'removed_point_count': len(removed_points),\n            'total_change_volume': self._estimate_change_volume(added_points, removed_points)\n        }\n\n    def _cluster_points(self, points: np.ndarray, eps: float = 0.5) -> List[Dict]:\n        \"\"\"Cluster change points into regions\"\"\"\n        if len(points) == 0:\n            return []\n\n        from sklearn.cluster import DBSCAN\n\n        clustering = DBSCAN(eps=eps, min_samples=10).fit(points)\n\n        regions = []\n        for label in set(clustering.labels_):\n            if label == -1:  # Noise\n                continue\n\n            cluster_points = points[clustering.labels_ == label]\n            centroid = np.mean(cluster_points, axis=0)\n            extent = np.max(cluster_points, axis=0) - np.min(cluster_points, axis=0)\n\n            regions.append({\n                'centroid': centroid.tolist(),\n                'extent': extent.tolist(),\n                'point_count': len(cluster_points)\n            })\n\n        return regions\n\n    def _estimate_change_volume(self, added: np.ndarray, removed: np.ndarray) -> float:\n        \"\"\"Estimate total volume of changes\"\"\"\n        # Simplified: use convex hull volume\n        from scipy.spatial import ConvexHull\n\n        total_volume = 0\n\n        if len(added) >= 4:\n            try:\n                hull = ConvexHull(added)\n                total_volume += hull.volume\n            except:\n                pass\n\n        if len(removed) >= 4:\n            try:\n                hull = ConvexHull(removed)\n                total_volume += hull.volume\n            except:\n                pass\n\n        return total_volume\n\n    def _load_gaussians(self, model_path: str) -> Dict:\n        \"\"\"Load Gaussians from model\"\"\"\n        # Same as InspectionMeasurement._load_gaussians\n        return {'positions': np.zeros((0, 3))}\n```\n\n## Optimization for Drone Data\n\n```python\nclass DroneGSOptimizer:\n    \"\"\"\n    Optimize Gaussian Splatting for drone-collected imagery.\n    Handles specific challenges: high altitude, motion blur, GPS metadata.\n    \"\"\"\n\n    @staticmethod\n    def optimal_flight_for_3dgs() -> Dict:\n        \"\"\"Recommended flight parameters for 3DGS reconstruction\"\"\"\n        return {\n            'altitude_m': {\n                'min': 20,\n                'max': 50,\n                'optimal': 30,\n                'note': 'Lower altitude = more detail, higher = wider coverage'\n            },\n            'speed': {\n                'max_ms': 3,\n                'optimal_ms': 2,\n                'note': 'Slower = less motion blur, better feature matching'\n            },\n            'overlap': {\n                'frontal_pct': 80,\n                'side_pct': 70,\n                'note': 'Higher overlap improves reconstruction but increases processing time'\n            },\n            'pattern': {\n                'type': 'double_grid',\n                'angles': [0, 90],\n                'note': 'Cross-hatch pattern captures all surfaces'\n            },\n            'camera_settings': {\n                'shutter_priority': True,\n                'min_shutter': '1/500',\n                'iso_auto_max': 800,\n                'note': 'Fast shutter prevents motion blur'\n            },\n            'lighting': {\n                'optimal_time': 'overcast or 2hrs before/after solar noon',\n                'avoid': 'harsh shadows, directly into sun',\n                'note': 'Even lighting improves reconstruction quality'\n            }\n        }\n\n    @staticmethod\n    def training_config_by_quality(quality: str) -> Dict:\n        \"\"\"Get training configuration by quality level\"\"\"\n        configs = {\n            'preview': {\n                'iterations': 7000,\n                'densify_until_iter': 3000,\n                'sh_degree': 1,\n                'estimated_time_min': 5,\n                'note': 'Quick preview, lower quality'\n            },\n            'standard': {\n                'iterations': 30000,\n                'densify_until_iter': 15000,\n                'sh_degree': 3,\n                'estimated_time_min': 30,\n                'note': 'Good balance of quality and speed'\n            },\n            'high_quality': {\n                'iterations': 50000,\n                'densify_until_iter': 25000,\n                'sh_degree': 4,\n                'estimated_time_min': 60,\n                'note': 'High quality, longer training'\n            },\n            'inspection_detail': {\n                'iterations': 100000,\n                'densify_until_iter': 50000,\n                'sh_degree': 4,\n                'densification_interval': 50,\n                'estimated_time_min': 180,\n                'note': 'Maximum detail for damage inspection'\n            }\n        }\n        return configs.get(quality, configs['standard'])\n```\n"
        },
        {
          "name": "insurance-risk-assessment.md",
          "type": "file",
          "path": "drone-inspection-specialist/references/insurance-risk-assessment.md",
          "size": 42743,
          "content": "# Insurance & Risk Assessment Reference\n\n## Hail Damage Detection System\n\n```python\nimport cv2\nimport numpy as np\nfrom ultralytics import YOLO\nfrom typing import List, Dict, Tuple, Optional\nfrom dataclasses import dataclass\nfrom enum import Enum\nimport datetime\n\nclass HailDamageType(Enum):\n    DENT = 'dent'                    # Impact dent on metal/shingle\n    CRACK = 'crack'                  # Impact crack\n    GRANULE_LOSS = 'granule_loss'    # Asphalt shingle granule displacement\n    BRUISE = 'bruise'                # Soft spot from impact\n    PUNCTURE = 'puncture'            # Complete penetration\n\nclass DamagePattern(Enum):\n    RANDOM = 'random'                # True hail pattern (random distribution)\n    LINEAR = 'linear'                # Foot traffic or other cause\n    CLUSTERED = 'clustered'          # Localized damage\n    AGE_RELATED = 'age_related'      # Wear, not hail\n\n\n@dataclass\nclass HailImpact:\n    damage_type: HailDamageType\n    diameter_mm: float              # Estimated impact diameter\n    confidence: float\n    bbox: Tuple[int, int, int, int]\n    severity_score: float           # 0-1 scale\n\n\nclass HailDamageDetector:\n    \"\"\"\n    Detect and classify hail damage on roofing materials.\n    Critical for insurance claims validation.\n    \"\"\"\n    def __init__(self, model_path: str = 'hail_damage_yolov8.pt'):\n        self.model = YOLO(model_path)\n\n        # Hail size categories (diameter in mm)\n        self.hail_categories = {\n            'pea': (6, 10),\n            'marble': (10, 15),\n            'quarter': (25, 30),\n            'golf_ball': (40, 45),\n            'tennis_ball': (65, 70),\n            'softball': (100, 115)\n        }\n\n    def detect_hail_damage(self, image: np.ndarray,\n                           pixels_per_mm: float = 2.0) -> Dict:\n        \"\"\"\n        Detect hail damage and estimate hail size.\n\n        Args:\n            image: BGR image of roof surface\n            pixels_per_mm: Scale factor (depends on altitude and camera)\n\n        Returns:\n            Analysis with damage count, pattern, and hail size estimate\n        \"\"\"\n        results = self.model(image, conf=0.3, verbose=False)[0]\n\n        impacts = []\n        for box in results.boxes:\n            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n            class_id = int(box.cls[0].item())\n            confidence = float(box.conf[0].item())\n\n            # Estimate impact diameter\n            width_px = x2 - x1\n            height_px = y2 - y1\n            diameter_px = (width_px + height_px) / 2\n            diameter_mm = diameter_px / pixels_per_mm\n\n            impact = HailImpact(\n                damage_type=self._classify_damage(class_id),\n                diameter_mm=diameter_mm,\n                confidence=confidence,\n                bbox=(x1, y1, x2, y2),\n                severity_score=self._calculate_severity(diameter_mm, class_id)\n            )\n            impacts.append(impact)\n\n        # Analyze pattern\n        pattern = self._analyze_pattern(impacts, image.shape)\n\n        # Estimate hail size from impacts\n        hail_size = self._estimate_hail_size(impacts)\n\n        return {\n            'total_impacts': len(impacts),\n            'impacts': impacts,\n            'pattern': pattern.value,\n            'is_consistent_with_hail': pattern == DamagePattern.RANDOM,\n            'estimated_hail_size': hail_size,\n            'damage_density': len(impacts) / (image.shape[0] * image.shape[1]) * 1e6,\n            'recommended_action': self._get_recommendation(impacts, pattern)\n        }\n\n    def _classify_damage(self, class_id: int) -> HailDamageType:\n        mapping = {\n            0: HailDamageType.DENT,\n            1: HailDamageType.CRACK,\n            2: HailDamageType.GRANULE_LOSS,\n            3: HailDamageType.BRUISE,\n            4: HailDamageType.PUNCTURE\n        }\n        return mapping.get(class_id, HailDamageType.DENT)\n\n    def _calculate_severity(self, diameter_mm: float, class_id: int) -> float:\n        \"\"\"Calculate damage severity score 0-1\"\"\"\n        # Base score from size\n        size_score = min(diameter_mm / 50, 1.0)\n\n        # Damage type multiplier\n        type_multipliers = {0: 0.6, 1: 0.8, 2: 0.5, 3: 0.7, 4: 1.0}\n        type_mult = type_multipliers.get(class_id, 0.5)\n\n        return min(size_score * type_mult * 1.5, 1.0)\n\n    def _analyze_pattern(self, impacts: List[HailImpact],\n                         img_shape: Tuple) -> DamagePattern:\n        \"\"\"Analyze spatial distribution of impacts\"\"\"\n        if len(impacts) < 5:\n            return DamagePattern.CLUSTERED\n\n        # Extract centroids\n        centroids = np.array([\n            ((i.bbox[0] + i.bbox[2])/2, (i.bbox[1] + i.bbox[3])/2)\n            for i in impacts\n        ])\n\n        # Calculate nearest neighbor distances\n        from scipy.spatial import distance_matrix\n        distances = distance_matrix(centroids, centroids)\n        np.fill_diagonal(distances, np.inf)\n        nn_distances = np.min(distances, axis=1)\n\n        # Check for randomness using coefficient of variation\n        cv = np.std(nn_distances) / np.mean(nn_distances)\n\n        # True hail has relatively random distribution\n        if 0.3 < cv < 0.8:\n            return DamagePattern.RANDOM\n\n        # Very uniform spacing suggests artificial\n        if cv < 0.3:\n            return DamagePattern.LINEAR\n\n        return DamagePattern.CLUSTERED\n\n    def _estimate_hail_size(self, impacts: List[HailImpact]) -> Dict:\n        \"\"\"Estimate hail size from impact diameters\"\"\"\n        if not impacts:\n            return {'category': 'unknown', 'diameter_mm': 0}\n\n        diameters = [i.diameter_mm for i in impacts]\n        median_diameter = np.median(diameters)\n        max_diameter = np.max(diameters)\n\n        # Find closest category\n        for name, (min_d, max_d) in self.hail_categories.items():\n            if min_d <= median_diameter <= max_d:\n                return {\n                    'category': name,\n                    'median_diameter_mm': median_diameter,\n                    'max_diameter_mm': max_diameter,\n                    'estimated_impact_force': self._impact_force(median_diameter)\n                }\n\n        return {\n            'category': 'unknown',\n            'median_diameter_mm': median_diameter,\n            'max_diameter_mm': max_diameter\n        }\n\n    def _impact_force(self, diameter_mm: float) -> str:\n        \"\"\"Estimate impact force category\"\"\"\n        if diameter_mm < 15:\n            return 'minimal'\n        elif diameter_mm < 30:\n            return 'moderate'\n        elif diameter_mm < 50:\n            return 'significant'\n        else:\n            return 'severe'\n\n    def _get_recommendation(self, impacts: List[HailImpact],\n                            pattern: DamagePattern) -> str:\n        if not impacts:\n            return \"No damage detected - document current condition\"\n\n        if pattern != DamagePattern.RANDOM:\n            return \"Damage pattern inconsistent with hail - investigate other causes\"\n\n        severe_count = sum(1 for i in impacts if i.severity_score > 0.7)\n        if severe_count > 5:\n            return \"Significant hail damage - recommend full roof replacement claim\"\n        elif severe_count > 0:\n            return \"Moderate hail damage - recommend repair claim\"\n        else:\n            return \"Minor hail damage - monitor and document\"\n\n\nclass InsuranceClaimPackager:\n    \"\"\"\n    Package drone inspection data for insurance claims.\n    Generates documentation meeting industry standards.\n    \"\"\"\n    def __init__(self):\n        self.inspection_date = None\n        self.property_address = None\n        self.policy_number = None\n\n    def generate_claim_package(self, inspection_data: Dict,\n                               property_info: Dict,\n                               weather_data: Optional[Dict] = None) -> Dict:\n        \"\"\"\n        Generate comprehensive claim documentation.\n\n        Args:\n            inspection_data: Output from drone inspection\n            property_info: Property details (address, policy, etc.)\n            weather_data: Historical weather data for event correlation\n\n        Returns:\n            Structured claim package\n        \"\"\"\n        package = {\n            'metadata': {\n                'generated_date': datetime.datetime.now().isoformat(),\n                'inspection_date': inspection_data.get('date'),\n                'inspector': 'Autonomous Drone System',\n                'methodology': 'AI-assisted aerial imagery analysis'\n            },\n            'property': property_info,\n            'damage_assessment': {\n                'total_damage_areas': inspection_data.get('total_impacts', 0),\n                'damage_types': self._summarize_damage_types(inspection_data),\n                'affected_area_sqft': inspection_data.get('affected_area', 0),\n                'severity_rating': self._calculate_severity_rating(inspection_data)\n            },\n            'weather_correlation': None,\n            'cost_estimate': self._estimate_costs(inspection_data, property_info),\n            'supporting_evidence': {\n                'images': inspection_data.get('image_urls', []),\n                'thermal_analysis': inspection_data.get('thermal', {}),\n                'gps_coordinates': inspection_data.get('damage_locations', [])\n            },\n            'recommendations': inspection_data.get('recommendations', [])\n        }\n\n        if weather_data:\n            package['weather_correlation'] = self._correlate_weather(\n                weather_data, inspection_data\n            )\n\n        return package\n\n    def _summarize_damage_types(self, data: Dict) -> Dict:\n        \"\"\"Summarize damage by type\"\"\"\n        impacts = data.get('impacts', [])\n        summary = {}\n        for impact in impacts:\n            dtype = impact.damage_type.value if hasattr(impact, 'damage_type') else str(impact.get('type', 'unknown'))\n            summary[dtype] = summary.get(dtype, 0) + 1\n        return summary\n\n    def _calculate_severity_rating(self, data: Dict) -> str:\n        \"\"\"Calculate overall severity rating\"\"\"\n        impacts = data.get('impacts', [])\n        if not impacts:\n            return 'none'\n\n        avg_severity = np.mean([\n            i.severity_score if hasattr(i, 'severity_score') else 0.5\n            for i in impacts\n        ])\n\n        if avg_severity > 0.7:\n            return 'severe'\n        elif avg_severity > 0.5:\n            return 'moderate'\n        elif avg_severity > 0.3:\n            return 'minor'\n        return 'minimal'\n\n    def _estimate_costs(self, inspection_data: Dict, property_info: Dict) -> Dict:\n        \"\"\"Generate repair/replacement cost estimate\"\"\"\n        roof_area = property_info.get('roof_area_sqft', 2000)\n        material = property_info.get('roof_material', 'asphalt_shingle')\n\n        # Base costs per sq ft\n        costs = {\n            'asphalt_shingle': {'repair': 8, 'replace': 5},\n            'metal': {'repair': 12, 'replace': 10},\n            'tile': {'repair': 15, 'replace': 12},\n            'slate': {'repair': 25, 'replace': 20}\n        }\n\n        base_cost = costs.get(material, costs['asphalt_shingle'])\n        damage_ratio = min(inspection_data.get('damage_density', 0) / 100, 1.0)\n\n        if damage_ratio > 0.3:  # > 30% damage typically means replacement\n            estimated_cost = roof_area * base_cost['replace']\n            action = 'full_replacement'\n        else:\n            estimated_cost = roof_area * damage_ratio * base_cost['repair'] * 1.5\n            action = 'repair'\n\n        return {\n            'recommended_action': action,\n            'estimated_cost_low': estimated_cost * 0.8,\n            'estimated_cost_high': estimated_cost * 1.2,\n            'confidence': 'medium',\n            'note': 'Final costs subject to contractor assessment'\n        }\n\n    def _correlate_weather(self, weather_data: Dict, inspection_data: Dict) -> Dict:\n        \"\"\"Correlate damage with weather events\"\"\"\n        # Look for hail events in the area\n        hail_events = weather_data.get('hail_events', [])\n\n        if not hail_events:\n            return {\n                'correlated_event': None,\n                'correlation_confidence': 'low',\n                'note': 'No recorded hail events in area'\n            }\n\n        # Find most likely event based on timing and severity\n        best_match = None\n        for event in hail_events:\n            if event.get('hail_size_mm', 0) > 20:\n                best_match = event\n                break\n\n        if best_match:\n            return {\n                'correlated_event': best_match,\n                'correlation_confidence': 'high',\n                'event_date': best_match.get('date'),\n                'hail_size': best_match.get('hail_size_mm'),\n                'affected_area': best_match.get('affected_radius_km')\n            }\n\n        return {\n            'correlated_event': None,\n            'correlation_confidence': 'medium',\n            'note': 'Unable to correlate with specific event'\n        }\n```\n\n## Wildfire Risk Assessment\n\n```python\nimport numpy as np\nfrom typing import List, Dict, Tuple, Optional\nfrom dataclasses import dataclass\nfrom enum import Enum\nimport json\n\nclass VegetationType(Enum):\n    GRASS = 'grass'\n    BRUSH = 'brush'\n    TIMBER = 'timber'\n    SLASH = 'slash'          # Logging debris\n    CHAPARRAL = 'chaparral'\n\nclass DefensibleSpaceZone(Enum):\n    ZONE_0 = 0    # 0-5 ft: Ember-resistant zone\n    ZONE_1 = 1    # 5-30 ft: Lean, clean, green zone\n    ZONE_2 = 2    # 30-100 ft: Reduced fuel zone\n    ZONE_3 = 3    # 100+ ft: Extended buffer\n\n\n@dataclass\nclass FireRiskFactor:\n    factor_name: str\n    score: float          # 0-1 normalized\n    weight: float         # Importance weight\n    details: Dict\n\n\nclass WildfireRiskAssessor:\n    \"\"\"\n    Assess wildfire risk for properties using drone/satellite data.\n    Based on NFPA 1144 and CAL FIRE defensible space guidelines.\n    \"\"\"\n    def __init__(self):\n        # Risk factor weights (sum to 1)\n        self.weights = {\n            'vegetation_density': 0.20,\n            'vegetation_type': 0.15,\n            'slope': 0.15,\n            'defensible_space': 0.20,\n            'roof_material': 0.10,\n            'structure_spacing': 0.10,\n            'access_egress': 0.10\n        }\n\n    def assess_property_risk(self, property_data: Dict,\n                             drone_imagery: Optional[Dict] = None,\n                             satellite_data: Optional[Dict] = None) -> Dict:\n        \"\"\"\n        Comprehensive wildfire risk assessment.\n\n        Args:\n            property_data: Property characteristics\n            drone_imagery: Analyzed drone imagery data\n            satellite_data: NDVI, fuel load, etc. from satellite\n\n        Returns:\n            Risk assessment with mitigation recommendations\n        \"\"\"\n        risk_factors = []\n\n        # 1. Vegetation analysis\n        veg_risk = self._assess_vegetation(drone_imagery, satellite_data)\n        risk_factors.append(veg_risk)\n\n        # 2. Topography/slope\n        slope_risk = self._assess_slope(property_data)\n        risk_factors.append(slope_risk)\n\n        # 3. Defensible space compliance\n        space_risk = self._assess_defensible_space(drone_imagery, property_data)\n        risk_factors.append(space_risk)\n\n        # 4. Structure vulnerability\n        struct_risk = self._assess_structure(property_data, drone_imagery)\n        risk_factors.append(struct_risk)\n\n        # Calculate overall risk score\n        overall_score = sum(\n            f.score * f.weight for f in risk_factors\n        )\n\n        # Generate risk category\n        if overall_score > 0.7:\n            risk_category = 'EXTREME'\n        elif overall_score > 0.5:\n            risk_category = 'HIGH'\n        elif overall_score > 0.3:\n            risk_category = 'MODERATE'\n        else:\n            risk_category = 'LOW'\n\n        return {\n            'overall_risk_score': overall_score,\n            'risk_category': risk_category,\n            'risk_factors': [\n                {\n                    'name': f.factor_name,\n                    'score': f.score,\n                    'weight': f.weight,\n                    'contribution': f.score * f.weight,\n                    'details': f.details\n                }\n                for f in risk_factors\n            ],\n            'mitigation_recommendations': self._generate_mitigations(risk_factors),\n            'insurance_implications': self._insurance_implications(overall_score, risk_factors),\n            'estimated_mitigation_cost': self._estimate_mitigation_cost(risk_factors)\n        }\n\n    def _assess_vegetation(self, drone_data: Optional[Dict],\n                           satellite_data: Optional[Dict]) -> FireRiskFactor:\n        \"\"\"Assess vegetation-related fire risk\"\"\"\n        if satellite_data:\n            ndvi = satellite_data.get('ndvi', 0.5)\n            fuel_load = satellite_data.get('fuel_load_tons_acre', 10)\n            veg_type = satellite_data.get('dominant_vegetation', 'brush')\n        else:\n            ndvi = 0.5\n            fuel_load = 10\n            veg_type = 'brush'\n\n        # NDVI interpretation (0.2-0.8 typical range)\n        # Higher NDVI = more vegetation = more fuel\n        ndvi_score = min(max((ndvi - 0.2) / 0.6, 0), 1)\n\n        # Fuel load scoring\n        fuel_score = min(fuel_load / 30, 1)  # 30 tons/acre = max risk\n\n        # Vegetation type risk\n        type_scores = {\n            'grass': 0.4,      # Fast spread but low intensity\n            'brush': 0.7,      # High intensity\n            'chaparral': 0.9,  # Very high intensity\n            'timber': 0.6,     # Moderate, depends on undergrowth\n            'slash': 0.8       # Accumulated fuel\n        }\n        type_score = type_scores.get(veg_type, 0.5)\n\n        combined_score = (ndvi_score * 0.3 + fuel_score * 0.4 + type_score * 0.3)\n\n        return FireRiskFactor(\n            factor_name='vegetation',\n            score=combined_score,\n            weight=self.weights['vegetation_density'] + self.weights['vegetation_type'],\n            details={\n                'ndvi': ndvi,\n                'fuel_load_tons_acre': fuel_load,\n                'vegetation_type': veg_type,\n                'ndvi_score': ndvi_score,\n                'fuel_score': fuel_score,\n                'type_score': type_score\n            }\n        )\n\n    def _assess_slope(self, property_data: Dict) -> FireRiskFactor:\n        \"\"\"Assess slope-related risk (fire spreads faster uphill)\"\"\"\n        slope_percent = property_data.get('slope_percent', 0)\n\n        # Slope scoring: &gt;40% is extreme\n        if slope_percent < 10:\n            score = 0.2\n        elif slope_percent < 20:\n            score = 0.4\n        elif slope_percent < 30:\n            score = 0.6\n        elif slope_percent < 40:\n            score = 0.8\n        else:\n            score = 1.0\n\n        return FireRiskFactor(\n            factor_name='slope',\n            score=score,\n            weight=self.weights['slope'],\n            details={\n                'slope_percent': slope_percent,\n                'fire_behavior_note': 'Fire rate of spread doubles every 20% slope increase'\n            }\n        )\n\n    def _assess_defensible_space(self, drone_data: Optional[Dict],\n                                  property_data: Dict) -> FireRiskFactor:\n        \"\"\"Assess defensible space compliance by zone\"\"\"\n        zone_scores = []\n\n        # Zone 0: 0-5 ft (ember-resistant)\n        zone0_clear = property_data.get('zone0_cleared', False)\n        zone_scores.append(0.0 if zone0_clear else 1.0)\n\n        # Zone 1: 5-30 ft (lean, clean, green)\n        zone1_compliance = property_data.get('zone1_compliance', 0.5)\n        zone_scores.append(1.0 - zone1_compliance)\n\n        # Zone 2: 30-100 ft (reduced fuel)\n        zone2_compliance = property_data.get('zone2_compliance', 0.5)\n        zone_scores.append(1.0 - zone2_compliance)\n\n        # Weighted by proximity importance\n        weighted_score = zone_scores[0] * 0.5 + zone_scores[1] * 0.35 + zone_scores[2] * 0.15\n\n        return FireRiskFactor(\n            factor_name='defensible_space',\n            score=weighted_score,\n            weight=self.weights['defensible_space'],\n            details={\n                'zone_0_compliant': zone0_clear,\n                'zone_1_compliance': zone1_compliance,\n                'zone_2_compliance': zone2_compliance,\n                'zone_scores': zone_scores\n            }\n        )\n\n    def _assess_structure(self, property_data: Dict,\n                          drone_data: Optional[Dict]) -> FireRiskFactor:\n        \"\"\"Assess structure vulnerability\"\"\"\n        roof_material = property_data.get('roof_material', 'asphalt_shingle')\n        siding_material = property_data.get('siding_material', 'wood')\n        vents_screened = property_data.get('vents_screened', False)\n        deck_material = property_data.get('deck_material', 'wood')\n\n        # Roof fire rating\n        roof_scores = {\n            'metal': 0.1,\n            'tile': 0.2,\n            'asphalt_shingle_class_a': 0.3,\n            'asphalt_shingle': 0.4,\n            'wood_shake_treated': 0.7,\n            'wood_shake': 1.0\n        }\n        roof_score = roof_scores.get(roof_material, 0.5)\n\n        # Siding vulnerability\n        siding_scores = {\n            'stucco': 0.1,\n            'brick': 0.1,\n            'fiber_cement': 0.2,\n            'vinyl': 0.5,\n            'wood': 0.8\n        }\n        siding_score = siding_scores.get(siding_material, 0.5)\n\n        # Vent protection\n        vent_score = 0.0 if vents_screened else 0.8\n\n        combined = roof_score * 0.4 + siding_score * 0.3 + vent_score * 0.3\n\n        return FireRiskFactor(\n            factor_name='structure_vulnerability',\n            score=combined,\n            weight=self.weights['roof_material'],\n            details={\n                'roof_material': roof_material,\n                'roof_score': roof_score,\n                'siding_material': siding_material,\n                'siding_score': siding_score,\n                'vents_screened': vents_screened\n            }\n        )\n\n    def _generate_mitigations(self, risk_factors: List[FireRiskFactor]) -> List[Dict]:\n        \"\"\"Generate prioritized mitigation recommendations\"\"\"\n        mitigations = []\n\n        # Sort by contribution to risk\n        sorted_factors = sorted(\n            risk_factors,\n            key=lambda f: f.score * f.weight,\n            reverse=True\n        )\n\n        for factor in sorted_factors:\n            if factor.factor_name == 'vegetation' and factor.score > 0.5:\n                mitigations.append({\n                    'priority': 'high',\n                    'action': 'Reduce vegetation density within 100ft',\n                    'estimated_risk_reduction': 0.15,\n                    'cost_range': '$500-$3000'\n                })\n\n            if factor.factor_name == 'defensible_space' and factor.score > 0.5:\n                mitigations.append({\n                    'priority': 'critical',\n                    'action': 'Create compliant defensible space zones',\n                    'estimated_risk_reduction': 0.20,\n                    'cost_range': '$1000-$5000'\n                })\n\n            if factor.factor_name == 'structure_vulnerability' and factor.score > 0.5:\n                if factor.details.get('roof_score', 0) > 0.5:\n                    mitigations.append({\n                        'priority': 'medium',\n                        'action': 'Upgrade to Class A fire-rated roofing',\n                        'estimated_risk_reduction': 0.10,\n                        'cost_range': '$5000-$15000'\n                    })\n                if not factor.details.get('vents_screened', True):\n                    mitigations.append({\n                        'priority': 'high',\n                        'action': 'Install 1/8\" mesh screens on all vents',\n                        'estimated_risk_reduction': 0.08,\n                        'cost_range': '$200-$800'\n                    })\n\n        return mitigations\n\n    def _insurance_implications(self, overall_score: float,\n                                risk_factors: List[FireRiskFactor]) -> Dict:\n        \"\"\"Calculate insurance implications\"\"\"\n        # Premium adjustment factors\n        if overall_score > 0.7:\n            premium_factor = 2.0\n            coverage_note = 'May require high-risk carrier'\n            deductible_note = 'Expect higher deductibles (2-5% of dwelling)'\n        elif overall_score > 0.5:\n            premium_factor = 1.5\n            coverage_note = 'Standard carriers with surcharge'\n            deductible_note = 'Standard deductibles may apply'\n        elif overall_score > 0.3:\n            premium_factor = 1.2\n            coverage_note = 'Standard coverage available'\n            deductible_note = 'Standard deductibles'\n        else:\n            premium_factor = 1.0\n            coverage_note = 'Standard coverage, possible discount available'\n            deductible_note = 'Standard deductibles'\n\n        return {\n            'estimated_premium_factor': premium_factor,\n            'coverage_availability': coverage_note,\n            'deductible_expectations': deductible_note,\n            'mitigation_credit_available': overall_score > 0.3,\n            'note': 'Implementing mitigations may reduce premiums significantly'\n        }\n\n    def _estimate_mitigation_cost(self, risk_factors: List[FireRiskFactor]) -> Dict:\n        \"\"\"Estimate total mitigation costs\"\"\"\n        total_low = 0\n        total_high = 0\n\n        for factor in risk_factors:\n            if factor.score > 0.5:\n                if factor.factor_name == 'vegetation':\n                    total_low += 500\n                    total_high += 3000\n                elif factor.factor_name == 'defensible_space':\n                    total_low += 1000\n                    total_high += 5000\n                elif factor.factor_name == 'structure_vulnerability':\n                    total_low += 500\n                    total_high += 15000\n\n        return {\n            'estimated_low': total_low,\n            'estimated_high': total_high,\n            'roi_note': 'Mitigation costs typically offset by 10-30% premium reduction over 5 years'\n        }\n```\n\n## Satellite & Aerial Data Integration\n\n```python\nimport numpy as np\nfrom typing import Dict, List, Tuple, Optional\nfrom dataclasses import dataclass\nfrom datetime import datetime, timedelta\n\n@dataclass\nclass SatellitePass:\n    satellite: str        # 'sentinel-2', 'landsat-8', 'planet'\n    timestamp: datetime\n    resolution_m: float\n    bands: List[str]\n    cloud_cover_pct: float\n\n\nclass PreconditionDataCollector:\n    \"\"\"\n    Collect precondition data for insurance risk assessment.\n    Integrates drone, aircraft, and satellite data sources.\n    \"\"\"\n\n    # Data requirements by assessment type\n    DATA_REQUIREMENTS = {\n        'wildfire_risk': {\n            'satellite': ['ndvi', 'fuel_moisture', 'land_cover'],\n            'drone': ['vegetation_density', 'defensible_space', 'structure_materials'],\n            'ground': ['slope', 'aspect', 'soil_moisture']\n        },\n        'hail_damage': {\n            'satellite': ['historical_imagery'],\n            'drone': ['damage_detection', 'material_classification'],\n            'weather': ['hail_reports', 'storm_tracks']\n        },\n        'flood_risk': {\n            'satellite': ['dem', 'historical_flooding', 'land_use'],\n            'drone': ['drainage_patterns', 'elevation_mapping'],\n            'ground': ['soil_type', 'water_table']\n        }\n    }\n\n    def __init__(self):\n        self.satellite_sources = {\n            'sentinel-2': {'resolution': 10, 'revisit_days': 5},\n            'landsat-8': {'resolution': 30, 'revisit_days': 16},\n            'planet': {'resolution': 3, 'revisit_days': 1}\n        }\n\n    def plan_data_collection(self, property_locations: List[Tuple[float, float]],\n                             assessment_type: str,\n                             timeline_days: int = 30) -> Dict:\n        \"\"\"\n        Plan comprehensive data collection campaign.\n\n        Args:\n            property_locations: List of (lat, lon) coordinates\n            assessment_type: Type of assessment (e.g., 'wildfire_risk')\n            timeline_days: Days available for collection\n\n        Returns:\n            Collection plan with satellite passes, drone missions, ground tasks\n        \"\"\"\n        requirements = self.DATA_REQUIREMENTS.get(assessment_type, {})\n\n        plan = {\n            'assessment_type': assessment_type,\n            'properties': len(property_locations),\n            'timeline_days': timeline_days,\n            'satellite_plan': self._plan_satellite_collection(\n                property_locations, requirements.get('satellite', [])\n            ),\n            'drone_missions': self._plan_drone_missions(\n                property_locations, requirements.get('drone', [])\n            ),\n            'ground_verification': self._plan_ground_tasks(\n                property_locations, requirements.get('ground', [])\n            ),\n            'estimated_cost': None,\n            'data_fusion_strategy': self._fusion_strategy(assessment_type)\n        }\n\n        plan['estimated_cost'] = self._estimate_collection_cost(plan)\n\n        return plan\n\n    def _plan_satellite_collection(self, locations: List[Tuple],\n                                    data_needs: List[str]) -> Dict:\n        \"\"\"Plan satellite data acquisition\"\"\"\n        # Determine best satellite based on needs\n        if 'fuel_moisture' in data_needs:\n            best_satellite = 'sentinel-2'  # Has SWIR bands\n        elif any('high_res' in need for need in data_needs):\n            best_satellite = 'planet'\n        else:\n            best_satellite = 'landsat-8'\n\n        source = self.satellite_sources[best_satellite]\n\n        return {\n            'primary_source': best_satellite,\n            'resolution_m': source['resolution'],\n            'revisit_days': source['revisit_days'],\n            'required_bands': self._get_required_bands(data_needs),\n            'cloud_threshold_pct': 20,\n            'historical_baseline': True,\n            'years_of_baseline': 5,\n            'derived_products': data_needs\n        }\n\n    def _plan_drone_missions(self, locations: List[Tuple],\n                              data_needs: List[str]) -> List[Dict]:\n        \"\"\"Plan drone missions for each property\"\"\"\n        missions = []\n\n        for i, (lat, lon) in enumerate(locations):\n            mission = {\n                'property_id': i,\n                'location': (lat, lon),\n                'flight_plans': []\n            }\n\n            # RGB mapping flight\n            if any(need in ['vegetation_density', 'structure_materials']\n                   for need in data_needs):\n                mission['flight_plans'].append({\n                    'type': 'rgb_mapping',\n                    'altitude_m': 50,\n                    'overlap_pct': 80,\n                    'estimated_duration_min': 20,\n                    'outputs': ['orthomosaic', '3d_model']\n                })\n\n            # Thermal flight (if needed)\n            if 'defensible_space' in data_needs:\n                mission['flight_plans'].append({\n                    'type': 'thermal_survey',\n                    'altitude_m': 40,\n                    'overlap_pct': 70,\n                    'estimated_duration_min': 15,\n                    'outputs': ['thermal_mosaic', 'heat_signature_map']\n                })\n\n            # Detail inspection\n            if 'damage_detection' in data_needs:\n                mission['flight_plans'].append({\n                    'type': 'close_inspection',\n                    'altitude_m': 10,\n                    'pattern': 'orbit_structure',\n                    'estimated_duration_min': 10,\n                    'outputs': ['high_res_images', 'damage_annotations']\n                })\n\n            missions.append(mission)\n\n        return missions\n\n    def _plan_ground_tasks(self, locations: List[Tuple],\n                           data_needs: List[str]) -> List[Dict]:\n        \"\"\"Plan ground-based data collection\"\"\"\n        tasks = []\n\n        for i, (lat, lon) in enumerate(locations):\n            property_tasks = {\n                'property_id': i,\n                'location': (lat, lon),\n                'tasks': []\n            }\n\n            if 'slope' in data_needs:\n                property_tasks['tasks'].append({\n                    'type': 'topographic_survey',\n                    'method': 'gps_transect',\n                    'estimated_time_hours': 2\n                })\n\n            if 'soil_moisture' in data_needs:\n                property_tasks['tasks'].append({\n                    'type': 'soil_sampling',\n                    'method': 'tdr_probe',\n                    'sample_count': 5,\n                    'estimated_time_hours': 1\n                })\n\n            tasks.append(property_tasks)\n\n        return tasks\n\n    def _get_required_bands(self, data_needs: List[str]) -> List[str]:\n        \"\"\"Determine satellite bands needed\"\"\"\n        bands = ['red', 'green', 'blue', 'nir']  # Always need these\n\n        if 'fuel_moisture' in data_needs:\n            bands.extend(['swir1', 'swir2'])\n        if 'ndvi' in data_needs:\n            pass  # Already have red and nir\n\n        return list(set(bands))\n\n    def _fusion_strategy(self, assessment_type: str) -> Dict:\n        \"\"\"Define data fusion approach\"\"\"\n        strategies = {\n            'wildfire_risk': {\n                'primary_framework': 'weighted_overlay',\n                'temporal_fusion': 'multi_temporal_composite',\n                'spatial_resolution': 'upsample_to_drone',\n                'model_type': 'ensemble_ml',\n                'validation': 'ground_truth_sampling'\n            },\n            'hail_damage': {\n                'primary_framework': 'change_detection',\n                'temporal_fusion': 'before_after_comparison',\n                'spatial_resolution': 'native_drone',\n                'model_type': 'object_detection',\n                'validation': 'field_verification'\n            }\n        }\n        return strategies.get(assessment_type, strategies['wildfire_risk'])\n\n    def _estimate_collection_cost(self, plan: Dict) -> Dict:\n        \"\"\"Estimate data collection costs\"\"\"\n        satellite_cost = 500  # Per scene, roughly\n\n        drone_cost = sum(\n            sum(fp['estimated_duration_min'] * 5  # $5/minute flight time\n                for fp in mission['flight_plans'])\n            for mission in plan['drone_missions']\n        )\n\n        ground_cost = sum(\n            sum(task.get('estimated_time_hours', 0) * 75  # $75/hour field work\n                for task in prop['tasks'])\n            for prop in plan['ground_verification']\n        )\n\n        return {\n            'satellite_data': satellite_cost,\n            'drone_operations': drone_cost,\n            'ground_verification': ground_cost,\n            'total': satellite_cost + drone_cost + ground_cost,\n            'per_property': (satellite_cost + drone_cost + ground_cost) / max(plan['properties'], 1)\n        }\n```\n\n## Reinsurance Risk Modeling\n\n```python\nimport numpy as np\nfrom typing import Dict, List, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass PropertyRisk:\n    property_id: str\n    location: Tuple[float, float]\n    tiv: float                    # Total Insured Value\n    risk_score: float\n    peril_exposures: Dict[str, float]\n\n\nclass CatastropheRiskModel:\n    \"\"\"\n    Catastrophe risk modeling for reinsurance applications.\n    Integrates drone-collected data into probabilistic models.\n    \"\"\"\n\n    def __init__(self):\n        # Return period probabilities (annual exceedance probability)\n        self.return_periods = [10, 25, 50, 100, 250, 500]\n\n    def build_portfolio_model(self, properties: List[PropertyRisk],\n                              peril: str = 'wildfire') -> Dict:\n        \"\"\"\n        Build catastrophe model for property portfolio.\n\n        Args:\n            properties: List of properties with risk data\n            peril: Peril type (wildfire, hail, flood, etc.)\n\n        Returns:\n            Portfolio risk metrics and loss distribution\n        \"\"\"\n        # Aggregate TIV\n        total_tiv = sum(p.tiv for p in properties)\n\n        # Calculate loss distribution\n        losses_by_return_period = {}\n        for rp in self.return_periods:\n            loss = self._calculate_loss_at_return_period(properties, peril, rp)\n            losses_by_return_period[rp] = loss\n\n        # Calculate key metrics\n        aal = self._calculate_aal(losses_by_return_period)  # Average Annual Loss\n        pml_250 = losses_by_return_period.get(250, 0)        # Probable Maximum Loss\n        tce_250 = self._calculate_tce(losses_by_return_period, 250)  # Tail Conditional Expectation\n\n        return {\n            'portfolio_summary': {\n                'property_count': len(properties),\n                'total_tiv': total_tiv,\n                'peril': peril\n            },\n            'loss_metrics': {\n                'aal': aal,\n                'aal_rate': aal / total_tiv if total_tiv > 0 else 0,\n                'pml_250': pml_250,\n                'pml_250_rate': pml_250 / total_tiv if total_tiv > 0 else 0,\n                'tce_250': tce_250\n            },\n            'exceedance_curve': losses_by_return_period,\n            'concentration_risk': self._assess_concentration(properties),\n            'risk_drivers': self._identify_risk_drivers(properties, peril)\n        }\n\n    def _calculate_loss_at_return_period(self, properties: List[PropertyRisk],\n                                         peril: str, return_period: int) -> float:\n        \"\"\"Calculate aggregate loss at given return period\"\"\"\n        aep = 1 / return_period  # Annual Exceedance Probability\n\n        # Event intensity factor (increases with return period)\n        intensity_factor = np.log(return_period) / np.log(100)\n\n        total_loss = 0\n        for prop in properties:\n            exposure = prop.peril_exposures.get(peril, 0.5)\n            vulnerability = prop.risk_score * intensity_factor\n\n            # Loss = TIV * damage ratio\n            damage_ratio = min(exposure * vulnerability, 1.0)\n            loss = prop.tiv * damage_ratio\n\n            # Apply spatial correlation (nearby properties affected together)\n            # Simplified - real model would use event footprints\n            total_loss += loss\n\n        return total_loss\n\n    def _calculate_aal(self, loss_curve: Dict[int, float]) -> float:\n        \"\"\"Calculate Average Annual Loss from exceedance curve\"\"\"\n        sorted_rps = sorted(loss_curve.keys())\n\n        aal = 0\n        for i in range(len(sorted_rps) - 1):\n            rp1 = sorted_rps[i]\n            rp2 = sorted_rps[i + 1]\n\n            aep1 = 1 / rp1\n            aep2 = 1 / rp2\n\n            loss1 = loss_curve[rp1]\n            loss2 = loss_curve[rp2]\n\n            # Trapezoid rule integration\n            aal += (aep1 - aep2) * (loss1 + loss2) / 2\n\n        return aal\n\n    def _calculate_tce(self, loss_curve: Dict[int, float],\n                       threshold_rp: int) -> float:\n        \"\"\"Calculate Tail Conditional Expectation (expected loss given exceedance)\"\"\"\n        threshold_loss = loss_curve.get(threshold_rp, 0)\n        higher_losses = [loss for rp, loss in loss_curve.items()\n                        if rp >= threshold_rp]\n        return np.mean(higher_losses) if higher_losses else threshold_loss\n\n    def _assess_concentration(self, properties: List[PropertyRisk]) -> Dict:\n        \"\"\"Assess geographic concentration risk\"\"\"\n        locations = np.array([p.location for p in properties])\n\n        if len(locations) < 2:\n            return {'risk_level': 'low', 'note': 'Single property'}\n\n        # Calculate centroid\n        centroid = np.mean(locations, axis=0)\n\n        # Calculate distances from centroid (rough km)\n        distances = np.sqrt(\n            ((locations[:, 0] - centroid[0]) * 111) ** 2 +\n            ((locations[:, 1] - centroid[1]) * 111 * np.cos(np.radians(centroid[0]))) ** 2\n        )\n\n        avg_distance = np.mean(distances)\n        max_distance = np.max(distances)\n\n        if avg_distance < 10:  # Within 10km average\n            risk_level = 'high'\n        elif avg_distance < 50:\n            risk_level = 'medium'\n        else:\n            risk_level = 'low'\n\n        return {\n            'risk_level': risk_level,\n            'avg_distance_km': avg_distance,\n            'max_distance_km': max_distance,\n            'centroid': tuple(centroid)\n        }\n\n    def _identify_risk_drivers(self, properties: List[PropertyRisk],\n                               peril: str) -> List[Dict]:\n        \"\"\"Identify main risk drivers in portfolio\"\"\"\n        drivers = []\n\n        # Sort by contribution to risk\n        sorted_props = sorted(\n            properties,\n            key=lambda p: p.tiv * p.risk_score * p.peril_exposures.get(peril, 0.5),\n            reverse=True\n        )\n\n        # Top 10 risk contributors\n        for prop in sorted_props[:10]:\n            contribution = prop.tiv * prop.risk_score * prop.peril_exposures.get(peril, 0.5)\n            drivers.append({\n                'property_id': prop.property_id,\n                'tiv': prop.tiv,\n                'risk_score': prop.risk_score,\n                'peril_exposure': prop.peril_exposures.get(peril, 0.5),\n                'risk_contribution': contribution\n            })\n\n        return drivers\n\n    def generate_reinsurance_report(self, portfolio_model: Dict) -> Dict:\n        \"\"\"Generate report for reinsurance placement\"\"\"\n        metrics = portfolio_model['loss_metrics']\n\n        # Suggested reinsurance structure\n        suggested_retention = metrics['pml_250'] * 0.1  # 10% of PML as retention\n        suggested_limit = metrics['pml_250'] * 0.9      # Cover 90% of PML\n\n        return {\n            'summary': portfolio_model['portfolio_summary'],\n            'key_metrics': {\n                'aal': metrics['aal'],\n                'aal_rate_pct': metrics['aal_rate'] * 100,\n                'pml_250': metrics['pml_250'],\n                'pml_250_rate_pct': metrics['pml_250_rate'] * 100\n            },\n            'suggested_structure': {\n                'retention': suggested_retention,\n                'limit': suggested_limit,\n                'attachment_point': suggested_retention,\n                'exhaustion_point': suggested_retention + suggested_limit,\n                'structure_type': 'excess_of_loss'\n            },\n            'pricing_indication': {\n                'technical_rate': metrics['aal_rate'] * 1.25,  # Load factor\n                'risk_load': 0.15,  # 15% risk load\n                'cat_load': 0.10    # 10% cat load\n            },\n            'concentration_warning': portfolio_model['concentration_risk'],\n            'top_risk_drivers': portfolio_model['risk_drivers'][:5]\n        }\n```\n"
        },
        {
          "name": "roof-inspection.md",
          "type": "file",
          "path": "drone-inspection-specialist/references/roof-inspection.md",
          "size": 20652,
          "content": "# Roof Inspection Reference\n\n## Damage Detection Pipeline\n\n```python\nimport cv2\nimport numpy as np\nfrom ultralytics import YOLO\nfrom typing import List, Dict, Tuple, Optional\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass DamageType(Enum):\n    MISSING_SHINGLE = 'missing_shingle'\n    CRACK = 'crack'\n    WEAR = 'wear'\n    DEBRIS = 'debris'\n    MOSS = 'moss'\n    PONDING = 'ponding'\n    FLASHING_DAMAGE = 'flashing_damage'\n    GUTTER_DAMAGE = 'gutter_damage'\n\nclass SeverityLevel(Enum):\n    LOW = 'low'\n    MEDIUM = 'medium'\n    HIGH = 'high'\n    CRITICAL = 'critical'\n\n\n@dataclass\nclass RoofDamage:\n    damage_type: DamageType\n    severity: SeverityLevel\n    confidence: float\n    bbox: Tuple[int, int, int, int]\n    gps_coords: Optional[Tuple[float, float]] = None\n    image_id: int = 0\n    area_sqft: Optional[float] = None\n    repair_cost_estimate: Optional[Tuple[float, float]] = None\n\n\nclass RoofInspector:\n    \"\"\"\n    Comprehensive roof inspection using drone imagery.\n    Detects damage, estimates severity, generates repair estimates.\n    \"\"\"\n    def __init__(self, damage_model_path: str = 'roof_damage_yolov8.pt',\n                 segment_model_path: str = 'roof_segmentation.pt',\n                 device: str = 'cuda'):\n        self.damage_model = YOLO(damage_model_path)\n        self.damage_model.to(device)\n\n        self.segment_model = YOLO(segment_model_path)\n        self.segment_model.to(device)\n\n        # Damage class mapping\n        self.class_map = {\n            0: DamageType.MISSING_SHINGLE,\n            1: DamageType.CRACK,\n            2: DamageType.WEAR,\n            3: DamageType.DEBRIS,\n            4: DamageType.MOSS,\n            5: DamageType.PONDING,\n            6: DamageType.FLASHING_DAMAGE,\n            7: DamageType.GUTTER_DAMAGE\n        }\n\n        # Repair cost estimates (USD per sq ft)\n        self.repair_costs = {\n            DamageType.MISSING_SHINGLE: (5, 15),\n            DamageType.CRACK: (10, 25),\n            DamageType.WEAR: (3, 10),\n            DamageType.DEBRIS: (1, 3),\n            DamageType.MOSS: (2, 5),\n            DamageType.PONDING: (15, 40),\n            DamageType.FLASHING_DAMAGE: (20, 50),\n            DamageType.GUTTER_DAMAGE: (10, 30)\n        }\n\n    def inspect_roof(self, image_sequence: List[np.ndarray],\n                     gps_data: List[Tuple[float, float, float]],\n                     altitude: float = 30.0) -> Dict:\n        \"\"\"\n        Full roof inspection from drone image sequence.\n\n        Args:\n            image_sequence: List of BGR images\n            gps_data: List of (lat, lon, alt) for each image\n            altitude: Average flight altitude for scale calculation\n\n        Returns:\n            Inspection report with damages and recommendations\n        \"\"\"\n        all_damages = []\n\n        for idx, (img, gps) in enumerate(zip(image_sequence, gps_data)):\n            # Segment roof area\n            roof_mask = self._segment_roof(img)\n\n            # Detect damages\n            damages = self._detect_damages(img, roof_mask, idx)\n\n            # Add GPS coordinates\n            for damage in damages:\n                damage.gps_coords = self._pixel_to_gps(\n                    damage.bbox, img.shape, gps, altitude\n                )\n\n            all_damages.extend(damages)\n\n        # Deduplicate overlapping detections\n        all_damages = self._deduplicate_damages(all_damages)\n\n        # Generate report\n        report = self._generate_report(all_damages, image_sequence)\n\n        return report\n\n    def _segment_roof(self, image: np.ndarray) -> np.ndarray:\n        \"\"\"Segment roof area from image\"\"\"\n        results = self.segment_model(image, verbose=False)[0]\n\n        if results.masks is not None:\n            # Combine all roof segment masks\n            mask = np.zeros(image.shape[:2], dtype=np.uint8)\n            for m in results.masks.data:\n                mask |= m.cpu().numpy().astype(np.uint8)\n            return mask\n\n        # Fallback: assume entire image is roof\n        return np.ones(image.shape[:2], dtype=np.uint8)\n\n    def _detect_damages(self, image: np.ndarray,\n                        roof_mask: np.ndarray, image_id: int) -> List[RoofDamage]:\n        \"\"\"Detect damages within roof area\"\"\"\n        results = self.damage_model(image, conf=0.4, verbose=False)[0]\n\n        damages = []\n        for box in results.boxes:\n            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n            class_id = int(box.cls[0].item())\n            confidence = float(box.conf[0].item())\n\n            # Check if detection is within roof area\n            center_x = (x1 + x2) // 2\n            center_y = (y1 + y2) // 2\n            if roof_mask[center_y, center_x] == 0:\n                continue  # Skip detections outside roof\n\n            damage_type = self.class_map.get(class_id, DamageType.WEAR)\n            severity = self._assess_severity(damage_type, image[y1:y2, x1:x2])\n\n            damage = RoofDamage(\n                damage_type=damage_type,\n                severity=severity,\n                confidence=confidence,\n                bbox=(x1, y1, x2, y2),\n                image_id=image_id\n            )\n            damages.append(damage)\n\n        return damages\n\n    def _assess_severity(self, damage_type: DamageType,\n                         damage_region: np.ndarray) -> SeverityLevel:\n        \"\"\"Assess damage severity based on type and visual analysis\"\"\"\n        area = damage_region.shape[0] * damage_region.shape[1]\n\n        if damage_type == DamageType.MISSING_SHINGLE:\n            return SeverityLevel.HIGH  # Always high - water can enter\n\n        elif damage_type == DamageType.CRACK:\n            # Larger cracks are more severe\n            if area > 5000:\n                return SeverityLevel.CRITICAL\n            elif area > 2000:\n                return SeverityLevel.HIGH\n            else:\n                return SeverityLevel.MEDIUM\n\n        elif damage_type == DamageType.WEAR:\n            # Analyze darkness (more wear = darker)\n            gray = cv2.cvtColor(damage_region, cv2.COLOR_BGR2GRAY) if len(damage_region.shape) == 3 else damage_region\n            mean_brightness = np.mean(gray) / 255\n            if mean_brightness < 0.3:\n                return SeverityLevel.HIGH\n            elif mean_brightness < 0.5:\n                return SeverityLevel.MEDIUM\n            return SeverityLevel.LOW\n\n        elif damage_type == DamageType.PONDING:\n            return SeverityLevel.HIGH  # Standing water is always concerning\n\n        elif damage_type in [DamageType.DEBRIS, DamageType.MOSS]:\n            if area > 10000:\n                return SeverityLevel.MEDIUM\n            return SeverityLevel.LOW\n\n        return SeverityLevel.MEDIUM\n\n    def _pixel_to_gps(self, bbox: Tuple, img_shape: Tuple,\n                      drone_gps: Tuple[float, float, float],\n                      altitude: float) -> Tuple[float, float]:\n        \"\"\"Convert pixel coordinates to GPS (simplified)\"\"\"\n        img_h, img_w = img_shape[:2]\n        lat, lon, _ = drone_gps\n\n        # Approximate ground coverage (assuming nadir shot)\n        # Typical drone camera: 84° FOV diagonal\n        ground_width = 2 * altitude * np.tan(np.radians(42))  # meters\n        ground_height = ground_width * img_h / img_w\n\n        # Pixel center\n        cx = (bbox[0] + bbox[2]) / 2\n        cy = (bbox[1] + bbox[3]) / 2\n\n        # Offset from image center\n        dx = (cx - img_w/2) / img_w * ground_width\n        dy = (cy - img_h/2) / img_h * ground_height\n\n        # Convert to GPS offset (rough)\n        dlat = -dy / 111000  # North is up in image\n        dlon = dx / (111000 * np.cos(np.radians(lat)))\n\n        return (lat + dlat, lon + dlon)\n\n    def _deduplicate_damages(self, damages: List[RoofDamage]) -> List[RoofDamage]:\n        \"\"\"Remove duplicate detections of same damage from different images\"\"\"\n        if not damages:\n            return []\n\n        # Sort by confidence\n        damages = sorted(damages, key=lambda d: d.confidence, reverse=True)\n\n        unique = []\n        for damage in damages:\n            is_duplicate = False\n            for existing in unique:\n                if damage.gps_coords and existing.gps_coords:\n                    dist = self._gps_distance(damage.gps_coords, existing.gps_coords)\n                    if dist < 1.0 and damage.damage_type == existing.damage_type:\n                        is_duplicate = True\n                        break\n            if not is_duplicate:\n                unique.append(damage)\n\n        return unique\n\n    def _gps_distance(self, coord1: Tuple, coord2: Tuple) -> float:\n        \"\"\"Distance between GPS coordinates in meters\"\"\"\n        lat1, lon1 = coord1\n        lat2, lon2 = coord2\n        dlat = (lat2 - lat1) * 111000\n        dlon = (lon2 - lon1) * 111000 * np.cos(np.radians(lat1))\n        return np.sqrt(dlat**2 + dlon**2)\n\n    def _generate_report(self, damages: List[RoofDamage],\n                         images: List[np.ndarray]) -> Dict:\n        \"\"\"Generate comprehensive inspection report\"\"\"\n        # Count by type and severity\n        damage_summary = {}\n        for damage in damages:\n            key = (damage.damage_type.value, damage.severity.value)\n            damage_summary[key] = damage_summary.get(key, 0) + 1\n\n        # Calculate repair estimates\n        total_cost_low = 0\n        total_cost_high = 0\n        for damage in damages:\n            cost_range = self.repair_costs.get(damage.damage_type, (5, 15))\n            # Assume average damage is 2 sq ft\n            total_cost_low += cost_range[0] * 2\n            total_cost_high += cost_range[1] * 2\n\n        # Overall condition rating\n        critical_count = sum(1 for d in damages if d.severity == SeverityLevel.CRITICAL)\n        high_count = sum(1 for d in damages if d.severity == SeverityLevel.HIGH)\n\n        if critical_count > 0:\n            condition = 'POOR - Immediate attention required'\n        elif high_count > 2:\n            condition = 'FAIR - Repairs recommended within 3 months'\n        elif high_count > 0:\n            condition = 'GOOD - Minor repairs needed'\n        else:\n            condition = 'EXCELLENT - No significant issues'\n\n        return {\n            'total_damages': len(damages),\n            'damage_summary': damage_summary,\n            'damages': [\n                {\n                    'type': d.damage_type.value,\n                    'severity': d.severity.value,\n                    'confidence': d.confidence,\n                    'location': d.gps_coords\n                }\n                for d in damages\n            ],\n            'repair_cost_estimate': {\n                'low': total_cost_low,\n                'high': total_cost_high,\n                'currency': 'USD'\n            },\n            'overall_condition': condition,\n            'images_analyzed': len(images),\n            'recommendations': self._get_recommendations(damages)\n        }\n\n    def _get_recommendations(self, damages: List[RoofDamage]) -> List[str]:\n        \"\"\"Generate actionable recommendations\"\"\"\n        recs = []\n\n        damage_types = set(d.damage_type for d in damages)\n\n        if DamageType.MISSING_SHINGLE in damage_types:\n            recs.append(\"Replace missing shingles immediately to prevent water damage\")\n\n        if DamageType.CRACK in damage_types:\n            recs.append(\"Seal cracks with roofing cement or schedule professional repair\")\n\n        if DamageType.PONDING in damage_types:\n            recs.append(\"Address drainage issues causing water ponding\")\n\n        if DamageType.MOSS in damage_types:\n            recs.append(\"Apply moss killer and consider zinc strips for prevention\")\n\n        if DamageType.FLASHING_DAMAGE in damage_types:\n            recs.append(\"Reseal or replace damaged flashing around vents and chimneys\")\n\n        if not recs:\n            recs.append(\"Continue regular maintenance and annual inspections\")\n\n        return recs\n```\n\n## Thermal Roof Analysis\n\n```python\nimport cv2\nimport numpy as np\nfrom typing import List, Dict, Tuple\nfrom dataclasses import dataclass\n\n@dataclass\nclass ThermalAnomaly:\n    anomaly_type: str  # 'moisture', 'insulation_loss', 'hvac_leak', 'electrical'\n    severity: str\n    bbox: Tuple[int, int, int, int]\n    temp_delta: float  # Temperature difference from surrounding\n    avg_temp: float\n\n\nclass ThermalRoofAnalyzer:\n    \"\"\"\n    Thermal analysis for roof inspection.\n    Detects moisture, insulation issues, and HVAC problems.\n    \"\"\"\n    def __init__(self):\n        self.moisture_threshold = -5.0  # Degrees colder than average\n        self.insulation_threshold = 3.0  # Degrees warmer than average\n        self.hvac_threshold = 8.0  # Significant heat anomaly\n\n    def analyze(self, thermal_frame: np.ndarray,\n                rgb_frame: Optional[np.ndarray] = None) -> List[ThermalAnomaly]:\n        \"\"\"\n        Analyze thermal image for roof anomalies.\n\n        Args:\n            thermal_frame: Temperature array in Celsius\n            rgb_frame: Optional RGB image for context\n\n        Returns:\n            List of detected anomalies\n        \"\"\"\n        anomalies = []\n\n        # Calculate baseline statistics\n        mean_temp = np.mean(thermal_frame)\n        std_temp = np.std(thermal_frame)\n\n        # Detect cold spots (potential moisture)\n        cold_anomalies = self._detect_cold_spots(thermal_frame, mean_temp, std_temp)\n        anomalies.extend(cold_anomalies)\n\n        # Detect hot spots (insulation/HVAC issues)\n        hot_anomalies = self._detect_hot_spots(thermal_frame, mean_temp, std_temp)\n        anomalies.extend(hot_anomalies)\n\n        return anomalies\n\n    def _detect_cold_spots(self, thermal: np.ndarray,\n                           mean_temp: float, std_temp: float) -> List[ThermalAnomaly]:\n        \"\"\"Detect moisture or missing insulation (cold spots)\"\"\"\n        threshold = mean_temp + self.moisture_threshold\n\n        cold_mask = (thermal < threshold).astype(np.uint8)\n\n        # Morphological cleanup\n        kernel = np.ones((5, 5), np.uint8)\n        cold_mask = cv2.morphologyEx(cold_mask, cv2.MORPH_OPEN, kernel)\n        cold_mask = cv2.morphologyEx(cold_mask, cv2.MORPH_CLOSE, kernel)\n\n        contours, _ = cv2.findContours(cold_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        anomalies = []\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < 500:  # Min area threshold\n                continue\n\n            x, y, w, h = cv2.boundingRect(contour)\n            region_temp = thermal[y:y+h, x:x+w]\n            avg_temp = float(np.mean(region_temp))\n            temp_delta = avg_temp - mean_temp\n\n            severity = 'high' if temp_delta < -8 else 'medium' if temp_delta < -5 else 'low'\n\n            anomaly = ThermalAnomaly(\n                anomaly_type='moisture' if temp_delta < -6 else 'insulation_loss',\n                severity=severity,\n                bbox=(x, y, x+w, y+h),\n                temp_delta=temp_delta,\n                avg_temp=avg_temp\n            )\n            anomalies.append(anomaly)\n\n        return anomalies\n\n    def _detect_hot_spots(self, thermal: np.ndarray,\n                          mean_temp: float, std_temp: float) -> List[ThermalAnomaly]:\n        \"\"\"Detect heat buildup or HVAC leaks\"\"\"\n        threshold = mean_temp + self.insulation_threshold\n\n        hot_mask = (thermal > threshold).astype(np.uint8)\n\n        # Morphological cleanup\n        kernel = np.ones((5, 5), np.uint8)\n        hot_mask = cv2.morphologyEx(hot_mask, cv2.MORPH_OPEN, kernel)\n\n        contours, _ = cv2.findContours(hot_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        anomalies = []\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < 500:\n                continue\n\n            x, y, w, h = cv2.boundingRect(contour)\n            region_temp = thermal[y:y+h, x:x+w]\n            avg_temp = float(np.mean(region_temp))\n            max_temp = float(np.max(region_temp))\n            temp_delta = avg_temp - mean_temp\n\n            # Classify type based on characteristics\n            if temp_delta > self.hvac_threshold:\n                anomaly_type = 'hvac_leak'\n                severity = 'high'\n            elif max_temp > mean_temp + 15:\n                anomaly_type = 'electrical'  # Potential electrical issue\n                severity = 'critical'\n            else:\n                anomaly_type = 'insulation_loss'\n                severity = 'medium' if temp_delta > 5 else 'low'\n\n            anomaly = ThermalAnomaly(\n                anomaly_type=anomaly_type,\n                severity=severity,\n                bbox=(x, y, x+w, y+h),\n                temp_delta=temp_delta,\n                avg_temp=avg_temp\n            )\n            anomalies.append(anomaly)\n\n        return anomalies\n\n    def generate_thermal_report(self, anomalies: List[ThermalAnomaly]) -> Dict:\n        \"\"\"Generate thermal inspection report\"\"\"\n        if not anomalies:\n            return {\n                'status': 'pass',\n                'message': 'No significant thermal anomalies detected',\n                'anomalies': []\n            }\n\n        critical = [a for a in anomalies if a.severity == 'critical']\n        high = [a for a in anomalies if a.severity == 'high']\n\n        recommendations = []\n        if any(a.anomaly_type == 'moisture' for a in anomalies):\n            recommendations.append(\"Investigate potential moisture infiltration\")\n        if any(a.anomaly_type == 'hvac_leak' for a in anomalies):\n            recommendations.append(\"Check HVAC system for leaks\")\n        if any(a.anomaly_type == 'electrical' for a in anomalies):\n            recommendations.append(\"URGENT: Have electrician inspect hot spots\")\n\n        return {\n            'status': 'fail' if critical else 'warning' if high else 'minor_issues',\n            'total_anomalies': len(anomalies),\n            'critical_count': len(critical),\n            'high_count': len(high),\n            'anomalies': [\n                {\n                    'type': a.anomaly_type,\n                    'severity': a.severity,\n                    'temp_delta': a.temp_delta,\n                    'location': a.bbox\n                }\n                for a in anomalies\n            ],\n            'recommendations': recommendations\n        }\n```\n\n## Material Classification\n\n```python\nimport torch\nimport numpy as np\nfrom typing import List, Dict, Tuple\nfrom ultralytics import YOLO\n\nclass RoofMaterialClassifier:\n    \"\"\"\n    Classify roofing materials from aerial imagery.\n    Important for accurate repair cost estimation.\n    \"\"\"\n    MATERIALS = [\n        'asphalt_shingle',\n        'metal_standing_seam',\n        'metal_corrugated',\n        'clay_tile',\n        'concrete_tile',\n        'slate',\n        'wood_shake',\n        'flat_membrane',\n        'solar_panel'\n    ]\n\n    COST_PER_SQFT = {\n        'asphalt_shingle': (3, 7),\n        'metal_standing_seam': (8, 14),\n        'metal_corrugated': (5, 10),\n        'clay_tile': (10, 18),\n        'concrete_tile': (8, 12),\n        'slate': (15, 30),\n        'wood_shake': (6, 12),\n        'flat_membrane': (4, 8),\n        'solar_panel': (0, 0)  # Special handling\n    }\n\n    def __init__(self, model_path: str = 'roof_material_classifier.pt'):\n        self.model = YOLO(model_path)\n\n    def classify(self, image: np.ndarray) -> Dict:\n        \"\"\"\n        Classify roofing material from image.\n\n        Returns:\n            Material type and confidence\n        \"\"\"\n        results = self.model(image, verbose=False)[0]\n\n        if results.probs is not None:\n            probs = results.probs.data.cpu().numpy()\n            top_idx = np.argmax(probs)\n            return {\n                'material': self.MATERIALS[top_idx],\n                'confidence': float(probs[top_idx]),\n                'all_probabilities': {\n                    self.MATERIALS[i]: float(probs[i])\n                    for i in range(len(self.MATERIALS))\n                }\n            }\n\n        return {'material': 'unknown', 'confidence': 0.0}\n\n    def estimate_replacement_cost(self, material: str,\n                                   area_sqft: float) -> Dict:\n        \"\"\"Estimate full roof replacement cost\"\"\"\n        if material not in self.COST_PER_SQFT:\n            material = 'asphalt_shingle'  # Default\n\n        cost_low, cost_high = self.COST_PER_SQFT[material]\n\n        return {\n            'material': material,\n            'area_sqft': area_sqft,\n            'cost_per_sqft': {'low': cost_low, 'high': cost_high},\n            'total_cost': {\n                'low': cost_low * area_sqft,\n                'high': cost_high * area_sqft\n            },\n            'note': 'Estimate only. Get professional quotes for accurate pricing.'\n        }\n```\n"
        }
      ]
    },
    {
      "name": "CHANGELOG.md",
      "type": "file",
      "path": "drone-inspection-specialist/CHANGELOG.md",
      "size": 2572,
      "content": "# Changelog\n\n## [2.0.0] - 2024-12-XX\n\n### Changed\n- **BREAKING**: Rewrote SKILL.md from 444 → 205 lines using skill-coach methodology\n- Updated frontmatter from `tools:` to `allowed-tools:` format\n- Added comprehensive NOT clause differentiating from drone-cv-expert\n\n### Added\n- Decision tree for skill selection\n- 6 anti-patterns with corrections:\n  1. Single-Sensor Dependence (fire detection)\n  2. Ignoring Hail Pattern (damage validation)\n  3. Thermal Temperature Trust (calibration)\n  4. 3DGS Frame Overload (processing efficiency)\n  5. Insurance Claim Speculation (material-based costing)\n  6. Defensible Space Zone Confusion (CAL FIRE compliance)\n- Quick reference tables (fire confidence, damage severity, risk factors, 3DGS settings)\n- Data collection strategy (satellite, drone, ground integration)\n- Insurance workflow diagram (underwriting, claims, reinsurance)\n- Reference files with detailed implementations:\n  - `references/fire-detection.md` - Multi-modal fire detection, thermal cameras, progression tracking\n  - `references/roof-inspection.md` - Damage detection, thermal analysis, material classification, hail damage\n  - `references/insurance-risk-assessment.md` - Hail damage patterns, wildfire risk modeling, catastrophe models, reinsurance data pipelines, satellite/drone/ground data integration\n  - `references/gaussian-splatting-3d.md` - COLMAP SfM, 3DGS training, inspection measurements, change detection\n\n### Expanded Domain Coverage\n- **Wildfire Risk Assessment**: NDVI, fuel load, defensible space evaluation per CAL FIRE/NFPA 1144\n- **Hail Damage Analysis**: Impact pattern validation (random vs. linear), size estimation, insurance claim packaging\n- **Insurance Integration**: Claim documentation, cost estimation by material, weather correlation\n- **Reinsurance Modeling**: Catastrophe models, loss distributions (AAL, PML, TCE), portfolio concentration risk\n- **Multi-Source Data**: Satellite (Sentinel-2, Landsat-8, Planet) + drone + ground truth fusion\n\n### Removed\n- Inline code examples (moved to reference files)\n- Redundant frontmatter (triggers, outputs, python_dependencies)\n\n### Migration Guide\nCode examples previously inline are now in `references/`:\n- `ForestFireDetector`, `FireAlertSystem` → `references/fire-detection.md`\n- `RoofInspector`, `ThermalRoofAnalysis` → `references/roof-inspection.md`\n- `HailDamageDetector`, `WildfireRiskAssessor`, `CatastropheRiskModel` → `references/insurance-risk-assessment.md`\n- `GaussianSplattingReconstructor`, `InspectionMeasurement` → `references/gaussian-splatting-3d.md`\n"
    },
    {
      "name": "reference.md",
      "type": "file",
      "path": "drone-inspection-specialist/reference.md",
      "size": 8728,
      "content": "        saved_count = 0\n        \n        while cap.isOpened():\n            ret, frame = cap.read()\n            if not ret:\n                break\n            \n            if frame_count % frame_skip == 0:\n                # Save frame\n                cv2.imwrite(f\"{output_dir}/frame_{saved_count:06d}.jpg\", \n                           frame, [cv2.IMWRITE_JPEG_QUALITY, 95])\n                \n                # Extract GPS from video metadata (if available)\n                # Otherwise use separate SRT file\n                gps = self.get_frame_gps(video_path, frame_count)\n                \n                # Save metadata\n                metadata = {\n                    'frame_id': saved_count,\n                    'original_frame': frame_count,\n                    'timestamp': frame_count / fps,\n                    'gps': gps\n                }\n                with open(f\"{output_dir}/frame_{saved_count:06d}.json\", 'w') as f:\n                    json.dump(metadata, f)\n                \n                saved_count += 1\n            \n            frame_count += 1\n        \n        cap.release()\n        print(f\"Extracted {saved_count} frames from {frame_count} total\")\n    \n    def run_colmap_sfm(self, images_dir, output_dir):\n        \"\"\"Structure from Motion with COLMAP\"\"\"\n        \n        os.makedirs(output_dir, exist_ok=True)\n        database_path = f\"{output_dir}/database.db\"\n        \n        # Feature extraction\n        subprocess.run([\n            self.colmap_path, \"feature_extractor\",\n            \"--database_path\", database_path,\n            \"--image_path\", images_dir,\n            \"--ImageReader.single_camera\", \"1\",\n            \"--ImageReader.camera_model\", \"OPENCV\",\n            \"--SiftExtraction.use_gpu\", \"1\"\n        ])\n        \n        # Feature matching\n        subprocess.run([\n            self.colmap_path, \"exhaustive_matcher\",\n            \"--database_path\", database_path,\n            \"--SiftMatching.use_gpu\", \"1\"\n        ])\n        \n        # Sparse reconstruction\n        sparse_path = f\"{output_dir}/0\"\n        subprocess.run([\n            self.colmap_path, \"mapper\",\n            \"--database_path\", database_path,\n            \"--image_path\", images_dir,\n            \"--output_path\", output_dir\n        ])\n        \n        # Convert to Gaussian Splatting format\n        subprocess.run([\n            self.colmap_path, \"model_converter\",\n            \"--input_path\", sparse_path,\n            \"--output_path\", sparse_path,\n            \"--output_type\", \"TXT\"\n        ])\n        \n        return sparse_path\n    \n    def train_gaussian_splatting(self, images_dir, sparse_dir, output_dir):\n        \"\"\"Train 3D Gaussian Splatting model\"\"\"\n        \n        # Training command\n        cmd = [\n            \"python\", self.gs_train_path,\n            \"-s\", images_dir,\n            \"-m\", output_dir,\n            \"--iterations\", \"30000\",\n            \"--eval\"  # Hold out test set\n        ]\n        \n        subprocess.run(cmd)\n        \n        return output_dir\n    \n    def export_for_viewer(self, model_dir, viewer_dir):\n        \"\"\"Export model for web-based viewer\"\"\"\n        \n        os.makedirs(viewer_dir, exist_ok=True)\n        \n        # Convert to compressed format for web\n        # Use antimatter15's WebGL viewer format\n        subprocess.run([\n            \"python\", \"convert_to_web.py\",\n            \"--model\", model_dir,\n            \"--output\", viewer_dir,\n            \"--compress\"\n        ])\n```\n\n### Interactive Inspection in 3D\n\n```python\nclass GaussianSplatInspectionTool:\n    \"\"\"Interactive tool for inspecting 3D reconstructions\"\"\"\n    \n    def __init__(self, model_path):\n        self.model = self.load_model(model_path)\n        self.annotations = []\n        \n    def annotate_damage_in_3d(self, point_3d, damage_type):\n        \"\"\"Mark damage location in 3D space\"\"\"\n        \n        annotation = {\n            'position': point_3d,\n            'type': damage_type,\n            'timestamp': time.time(),\n            'nearby_views': self.find_nearby_views(point_3d)\n        }\n        \n        self.annotations.append(annotation)\n        return annotation\n    \n    def find_nearby_views(self, point_3d, radius=2.0):\n        \"\"\"Find all camera views near a point\"\"\"\n        \n        nearby = []\n        for cam_idx, camera in enumerate(self.model.cameras):\n            dist = np.linalg.norm(camera.position - point_3d)\n            if dist &lt; radius:\n                nearby.append({\n                    'camera_idx': cam_idx,\n                    'distance': dist,\n                    'viewing_angle': self.compute_viewing_angle(\n                        camera, point_3d\n                    )\n                })\n        \n        return nearby\n    \n    def generate_damage_report(self):\n        \"\"\"Generate report with 3D visualization\"\"\"\n        \n        report = {\n            'total_damages': len(self.annotations),\n            'damage_breakdown': self.count_by_type(),\n            'model_path': self.model.path,\n            'viewer_url': self.generate_viewer_url(),\n            'annotations': self.annotations\n        }\n        \n        return report\n```\n\n## Residential Property Assessment\n\n### Comprehensive Property Analysis\n\n```python\nclass PropertyAssessmentSystem:\n    def __init__(self):\n        self.roof_inspector = RoofInspector()\n        self.thermal_analyzer = ThermalRoofAnalysis()\n        self.object_detector = YOLO('property_objects.pt')\n        # Detects: gutters, chimneys, vents, solar panels, trees, etc.\n        \n    def full_property_assessment(self, drone_mission_data):\n        \"\"\"Complete property analysis\"\"\"\n        \n        assessment = {\n            'roof': self.assess_roof(drone_mission_data['roof_images']),\n            'exterior': self.assess_exterior(drone_mission_data['exterior_images']),\n            'landscaping': self.assess_landscaping(drone_mission_data['overhead_images']),\n            'thermal': self.assess_thermal(drone_mission_data['thermal_images']),\n            'measurements': self.take_measurements(drone_mission_data['3d_model']),\n            'recommendations': []\n        }\n        \n        # Generate recommendations\n        assessment['recommendations'] = self.generate_recommendations(assessment)\n        \n        return assessment\n    \n    def assess_landscaping(self, images):\n        \"\"\"Analyze trees and vegetation\"\"\"\n        \n        tree_detector = YOLO('tree_detection.pt')\n        issues = []\n        \n        for img in images:\n            detections = tree_detector(img)\n            \n            for tree in detections:\n                # Check proximity to structure\n                distance_to_building = self.calculate_distance(\n                    tree.bbox, \n                    self.find_building_in_image(img)\n                )\n                \n                # Trees within 20ft are risk\n                if distance_to_building &lt; 20:  # feet\n                    issues.append({\n                        'type': 'TREE_TOO_CLOSE',\n                        'severity': 'MEDIUM',\n                        'location': tree.bbox,\n                        'distance': distance_to_building,\n                        'recommendation': 'Trim or remove to prevent damage'\n                    })\n                \n                # Check for dead branches (brown in green season)\n                if self.detect_dead_branches(img, tree.bbox):\n                    issues.append({\n                        'type': 'DEAD_BRANCHES',\n                        'severity': 'HIGH',\n                        'location': tree.bbox,\n                        'recommendation': 'Remove dead branches immediately'\n                    })\n        \n        return issues\n```\n\n## Best Practices\n\n### Mission Planning\n- **Overlap**: 80% front, 60% side for 3D reconstruction\n- **Altitude**: 30-50m for roof inspection, 100m+ for fire monitoring\n- **Speed**: 3-5 m/s for sharp images\n- **Lighting**: Early morning or late afternoon for best shadows\n- **Weather**: Avoid wind &gt;15mph, no rain\n\n### Data Quality\n- **Resolution**: Minimum 2cm/pixel for damage detection\n- **Frame Rate**: 30fps for video, 2 images/sec for stills\n- **Gimbal**: -90° (nadir) for orthomosaic, -60° for oblique\n- **ISO**: Keep low (100-400) to minimize noise\n- **Shutter Speed**: 1/1000s minimum for sharp images\n\n### Safety & Regulations\n- **FAA Part 107**: Commercial drone license required (US)\n- **VLOS**: Maintain visual line of sight\n- **Altitude Limits**: 400ft AGL maximum\n- **No-Fly Zones**: Check airspace before missions\n- **Insurance**: Liability coverage for commercial work\n\n---\n\n**Remember**: The best inspection system combines multiple sensors (RGB, thermal, LiDAR) with smart AI and human expertise. Always validate AI detections before reporting critical findings.\n"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "drone-inspection-specialist/SKILL.md",
      "size": 8930,
      "content": "---\nname: drone-inspection-specialist\ndescription: Advanced CV for infrastructure inspection including forest fire detection, wildfire precondition assessment, roof inspection, hail damage analysis, thermal imaging, and 3D Gaussian Splatting reconstruction. Expert in multi-modal detection, insurance risk modeling, and reinsurance data pipelines. Activate on \"fire detection\", \"wildfire risk\", \"roof inspection\", \"hail damage\", \"thermal analysis\", \"Gaussian Splatting\", \"3DGS\", \"insurance inspection\", \"defensible space\", \"property assessment\", \"catastrophe modeling\", \"NDVI\", \"fuel load\". NOT for general drone flight control, SLAM, path planning, or sensor fusion (use drone-cv-expert), GPU shader development (use metal-shader-expert), or generic object detection without inspection context (use clip-aware-embeddings).\nallowed-tools: Read,Write,Edit,Bash(python:*,pip:*),Grep,Glob,mcp__firecrawl__firecrawl_search,WebFetch,mcp__stability-ai__stability-ai-generate-image\ncategory: AI & Machine Learning\ntags:\n  - inspection\n  - fire-detection\n  - thermal\n  - gaussian-splatting\n  - insurance\npairs-with:\n  - skill: drone-cv-expert\n    reason: Core drone navigation and CV\n  - skill: clip-aware-embeddings\n    reason: Semantic understanding of inspected areas\n---\n\n# Drone Inspection Specialist\n\nExpert in drone-based infrastructure inspection with computer vision, thermal analysis, and 3D reconstruction for insurance, property assessment, and environmental monitoring.\n\n## Decision Tree: When to Use This Skill\n\n```\nUser mentions drones/UAV?\n├─ YES → Is it about inspection or assessment of something?\n│        ├─ Fire detection, smoke, thermal hotspots → THIS SKILL\n│        ├─ Roof damage, hail, shingles → THIS SKILL\n│        ├─ Property/insurance assessment → THIS SKILL\n│        ├─ 3D reconstruction for measurement → THIS SKILL\n│        ├─ Wildfire risk, defensible space → THIS SKILL\n│        └─ NO (flight control, navigation, general CV) → drone-cv-expert\n└─ NO → Is it about fire/roof/property assessment without drones?\n        ├─ YES → Still use THIS SKILL (methods apply)\n        └─ NO → Different skill needed\n```\n\n## Core Competencies\n\n### Fire Detection & Wildfire Risk\n- **Multi-Modal Detection**: RGB smoke + thermal hotspot fusion\n- **Precondition Assessment**: NDVI, fuel load, vegetation density\n- **Defensible Space**: CAL FIRE/NFPA 1144 compliance evaluation\n- **Progression Tracking**: Spread rate, direction prediction\n\n### Roof & Structural Inspection\n- **Damage Detection**: Cracks, missing shingles, wear, ponding\n- **Hail Analysis**: Impact pattern recognition, size estimation\n- **Thermal Analysis**: Moisture detection, insulation gaps, HVAC leaks\n- **Material Classification**: Asphalt, metal, tile, slate identification\n\n### 3D Reconstruction (Gaussian Splatting)\n- **Pipeline**: Video → COLMAP SfM → 3DGS training → Web viewer\n- **Measurements**: Roof area, damage dimensions, property bounds\n- **Change Detection**: Before/after comparison for claims\n\n### Insurance & Reinsurance\n- **Claim Packaging**: Documentation meeting industry standards\n- **Risk Modeling**: Catastrophe models, loss distributions\n- **Precondition Data**: Satellite + drone + ground integration\n\n## Anti-Patterns to Avoid\n\n### 1. \"Single-Sensor Dependence\"\n**Wrong**: Using only RGB for fire detection.\n**Right**: Multi-modal fusion (RGB + thermal) for high-confidence alerts.\n| Detection Source | Confidence | Action |\n|------------------|------------|--------|\n| Thermal fire only | 70% | Alert + verify |\n| RGB smoke only | 60% | Alert + investigate |\n| Thermal + RGB | 95% | Confirmed fire |\n\n### 2. \"Ignoring Hail Pattern\"\n**Wrong**: Counting damage without analyzing spatial distribution.\n**Right**: True hail damage has RANDOM distribution. Linear or clustered patterns indicate other causes (foot traffic, age).\n\n### 3. \"Thermal Temperature Trust\"\n**Wrong**: Using raw thermal values without calibration.\n**Right**: Account for:\n- Emissivity of materials (roof = 0.9-0.95)\n- Atmospheric transmission (humidity, distance)\n- Reflected temperature from surroundings\n- Time of day (thermal lag)\n\n### 4. \"3DGS Frame Overload\"\n**Wrong**: Extracting every frame from drone video.\n**Right**: Extract 2-3 fps with 80% overlap. More frames ≠ better reconstruction.\n| Video FPS | Extract Rate | Result |\n|-----------|--------------|--------|\n| 30 | 30 (all) | Redundant, slow processing |\n| 30 | 2-3 | Optimal quality/speed |\n| 30 | 0.5 | Insufficient overlap |\n\n### 5. \"Insurance Claim Speculation\"\n**Wrong**: Estimating costs without material identification.\n**Right**: Identify material → Apply correct cost matrix.\n| Material | Repair $/sqft | Replace $/sqft |\n|----------|--------------|----------------|\n| Asphalt shingle | $5-10 | $3-7 |\n| Metal | $10-15 | $8-14 |\n| Tile | $12-20 | $10-18 |\n| Slate | $20-40 | $15-30 |\n\n### 6. \"Defensible Space Zone Confusion\"\n**Wrong**: Treating all vegetation equally regardless of distance.\n**Right**: CAL FIRE zones have different requirements:\n| Zone | Distance | Requirement |\n|------|----------|-------------|\n| 0 | 0-5 ft | Ember-resistant (no combustibles) |\n| 1 | 5-30 ft | Lean, clean, green (spaced trees) |\n| 2 | 30-100 ft | Reduced fuel (selective thinning) |\n\n## Data Collection Strategy\n\n### Satellite Data (Regional Context)\n- **Sentinel-2**: 10m resolution, NDVI, fuel moisture (SWIR bands)\n- **Landsat-8**: 30m resolution, historical baseline, thermal band\n- **Planet**: 3m resolution daily, change detection\n- **Application**: Regional risk mapping, before/after events\n\n### Drone Data (Property Detail)\n- **RGB Mapping**: 2-5cm GSD, orthomosaic, 3D model\n- **Thermal Survey**: Moisture detection, heat signatures\n- **Close Inspection**: Damage documentation, detail photos\n- **Application**: Individual property assessment\n\n### Ground Truth\n- **Slope Measurement**: GPS transects for topographic risk\n- **Soil Sampling**: Moisture content for fire risk\n- **Material Verification**: Confirm roof type\n- **Application**: Calibration and validation\n\n## Quick Reference Tables\n\n### Fire Detection Confidence Levels\n| Signal Combination | Confidence | Alert Priority |\n|-------------------|------------|----------------|\n| Thermal &gt;150°C + Smoke | 95% | CRITICAL |\n| Thermal fire model | 80% | HIGH |\n| Hotspot &gt;80°C | 70% | MEDIUM |\n| Smoke only | 60% | MEDIUM |\n| Hotspot 60-80°C | 50% | LOW |\n\n### Roof Damage Severity\n| Type | Low | Medium | High | Critical |\n|------|-----|--------|------|----------|\n| Missing shingle | - | - | Always | - |\n| Crack | &lt;1\" | 1-3\" | &gt;3\" | Multiple |\n| Granule loss | &lt;10% | 10-30% | &gt;30% | - |\n| Ponding | - | Small | Large | Active leak |\n\n### Wildfire Risk Factors (Weighted)\n| Factor | Weight | High Risk Indicators |\n|--------|--------|---------------------|\n| Defensible space | 20% | Non-compliant zones |\n| Vegetation density | 20% | NDVI &gt;0.6, high fuel load |\n| Slope | 15% | &gt;30% grade |\n| Roof material | 10% | Wood shake, Class C |\n| Structure spacing | 10% | &lt;30ft between buildings |\n| Access/egress | 10% | Single road, narrow |\n\n### 3DGS Quality Settings\n| Quality Level | Iterations | Time | Use Case |\n|---------------|------------|------|----------|\n| Preview | 7K | 5 min | Quick check |\n| Standard | 30K | 30 min | General use |\n| High | 50K | 60 min | Documentation |\n| Inspection | 100K | 3 hrs | Damage measurement |\n\n## Reference Files\n\nDetailed implementations in `references/`:\n- `fire-detection.md` - Multi-modal fire detection, thermal cameras, progression tracking\n- `roof-inspection.md` - Damage detection, thermal analysis, material classification\n- `insurance-risk-assessment.md` - Hail damage, wildfire risk, catastrophe modeling, reinsurance\n- `gaussian-splatting-3d.md` - COLMAP pipeline, 3DGS training, inspection measurements\n\n## Integration Points\n\n- **drone-cv-expert**: Flight control, navigation, general CV algorithms\n- **metal-shader-expert**: GPU-accelerated 3DGS rendering\n- **collage-layout-expert**: Visual report composition\n- **clip-aware-embeddings**: Material/damage classification assistance\n\n## Insurance Workflow\n\n```\n1. Pre-Event Assessment (Underwriting)\n   ├─ Satellite: Regional risk context\n   ├─ Drone: Property-level risk factors\n   └─ Output: Risk score, premium factors\n\n2. Post-Event Inspection (Claims)\n   ├─ Drone survey: Damage documentation\n   ├─ 3DGS: Measurements, change detection\n   └─ Output: Claim package, cost estimate\n\n3. Portfolio Risk (Reinsurance)\n   ├─ Aggregate: TIV, loss curves\n   ├─ Model: AAL, PML, concentration\n   └─ Output: Treaty pricing, structure\n```\n\n---\n\n**Key Principle**: Inspection accuracy depends on multi-source data fusion. Single-sensor assessments miss critical context. Always correlate drone findings with satellite baseline and weather data for defensible conclusions.\n"
    }
  ]
}