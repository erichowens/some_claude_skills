{
  "name": "2000s-visualization-expert",
  "type": "folder",
  "path": "2000s-visualization-expert",
  "children": [
    {
      "name": "references",
      "type": "folder",
      "path": "2000s-visualization-expert/references",
      "children": [
        {
          "name": "butterchurn-guide.md",
          "type": "file",
          "path": "2000s-visualization-expert/references/butterchurn-guide.md",
          "size": 6885,
          "content": "# Butterchurn Integration Guide\n\nComplete guide to implementing Milkdrop-style visualizations with Butterchurn.\n\n---\n\n## Basic Setup\n\n```typescript\nimport butterchurn from 'butterchurn';\nimport butterchurnPresets from 'butterchurn-presets';\n\n// Setup\nconst visualizer = butterchurn.createVisualizer(audioContext, canvas, {\n  width: window.innerWidth,\n  height: window.innerHeight,\n  pixelRatio: window.devicePixelRatio || 1,\n  textureRatio: 1,  // Lower for performance\n});\n\n// Connect audio source\nvisualizer.connectAudio(audioNode);  // Can be MediaElementSource, Oscillator, etc.\n\n// Load preset\nconst presets = butterchurnPresets.getPresets();\nconst presetKeys = Object.keys(presets);\nvisualizer.loadPreset(presets[presetKeys[0]], 2.0);  // 2 second blend\n\n// Render loop\nfunction render() {\n  visualizer.render();\n  requestAnimationFrame(render);\n}\nrender();\n```\n\n---\n\n## Preset Recommendations\n\n### Psychedelic/Trippy\n- `Flexi, martin + geiss - dedicated to the sherwin maxawow`\n- `Rovastar - Fractopia`\n- `Unchained - Unified Drag`\n- `Zylot - Psychedelic Flower`\n- `martin - acid warp`\n\n### Smooth/Chill\n- `Flexi - predator-prey-spirals`\n- `Geiss - Cosmic Strings 2`\n- `Martin - liquid science`\n- `Rovastar - Harlequin's Fruit Salad`\n- `shifter - liquid glass`\n\n### High Energy\n- `Flexi + Martin - disconnected`\n- `shifter - tumbling cubes`\n- `Zylot - Clouds (Tunnel Mix)`\n- `martin - fire storm`\n- `Unchained - Demon's Gate`\n\n### Minimal/Clean\n- `Geiss - Explosion 3`\n- `Martin - Acid Warp Simple`\n- `Rovastar - Twilight`\n\n---\n\n## Preset Blending\n\n```typescript\nclass PresetManager {\n  private visualizer: any;\n  private presets: Record<string, any>;\n  private presetKeys: string[];\n  private currentIndex: number = 0;\n  private blendTime: number = 2.0;\n\n  constructor(visualizer: any) {\n    this.visualizer = visualizer;\n    this.presets = butterchurnPresets.getPresets();\n    this.presetKeys = Object.keys(this.presets);\n  }\n\n  next() {\n    this.currentIndex = (this.currentIndex + 1) % this.presetKeys.length;\n    this.load(this.presetKeys[this.currentIndex]);\n  }\n\n  previous() {\n    this.currentIndex = (this.currentIndex - 1 + this.presetKeys.length) % this.presetKeys.length;\n    this.load(this.presetKeys[this.currentIndex]);\n  }\n\n  random() {\n    const randomIndex = Math.floor(Math.random() * this.presetKeys.length);\n    this.currentIndex = randomIndex;\n    this.load(this.presetKeys[randomIndex]);\n  }\n\n  load(presetName: string, blendTime?: number) {\n    const preset = this.presets[presetName];\n    if (preset) {\n      this.visualizer.loadPreset(preset, blendTime ?? this.blendTime);\n    }\n  }\n\n  // Auto-advance every N seconds\n  startAutoAdvance(intervalSeconds: number = 30) {\n    return setInterval(() => this.random(), intervalSeconds * 1000);\n  }\n}\n```\n\n---\n\n## Full-Screen Setup\n\n```typescript\nfunction setupFullscreen(canvas: HTMLCanvasElement, visualizer: any) {\n  // Handle resize\n  function handleResize() {\n    const width = window.innerWidth;\n    const height = window.innerHeight;\n\n    canvas.width = width * devicePixelRatio;\n    canvas.height = height * devicePixelRatio;\n    canvas.style.width = `${width}px`;\n    canvas.style.height = `${height}px`;\n\n    visualizer.setRendererSize(width, height);\n  }\n\n  window.addEventListener('resize', handleResize);\n  handleResize();\n\n  // Full-screen toggle\n  async function toggleFullscreen() {\n    if (!document.fullscreenElement) {\n      await canvas.requestFullscreen();\n    } else {\n      await document.exitFullscreen();\n    }\n  }\n\n  canvas.addEventListener('dblclick', toggleFullscreen);\n\n  // Hide cursor after inactivity\n  let cursorTimeout: number;\n  document.addEventListener('mousemove', () => {\n    document.body.style.cursor = 'default';\n    clearTimeout(cursorTimeout);\n    cursorTimeout = window.setTimeout(() => {\n      document.body.style.cursor = 'none';\n    }, 3000);\n  });\n\n  return { handleResize, toggleFullscreen };\n}\n```\n\n---\n\n## Performance Optimization\n\n### Lower texture ratio for older GPUs\n```typescript\nconst visualizer = butterchurn.createVisualizer(audioContext, canvas, {\n  width: window.innerWidth,\n  height: window.innerHeight,\n  textureRatio: 0.5,  // Half resolution for textures\n});\n```\n\n### Reduce fftSize if not needed\n```typescript\nanalyserNode.fftSize = 512;  // 256, 512, 1024, 2048 (default)\n```\n\n### CSS Performance Hints\n```css\ncanvas.visualizer {\n  will-change: transform;\n  contain: strict;\n}\n```\n\n### Profile with Chrome DevTools\n1. Open DevTools → Performance tab\n2. Enable GPU timeline\n3. Record during visualization\n4. Look for dropped frames, GPU memory spikes\n\n---\n\n## Cleanup Pattern\n\n```typescript\nclass VisualizerController {\n  private animationId: number | null = null;\n  private visualizer: any;\n  private autoAdvanceInterval: number | null = null;\n\n  start() {\n    const render = () => {\n      this.visualizer.render();\n      this.animationId = requestAnimationFrame(render);\n    };\n    render();\n  }\n\n  stop() {\n    if (this.animationId) {\n      cancelAnimationFrame(this.animationId);\n      this.animationId = null;\n    }\n    if (this.autoAdvanceInterval) {\n      clearInterval(this.autoAdvanceInterval);\n      this.autoAdvanceInterval = null;\n    }\n  }\n\n  destroy() {\n    this.stop();\n    // Additional cleanup if needed\n  }\n}\n```\n\n---\n\n## React Hook\n\n```typescript\nimport { useEffect, useRef, useCallback } from 'react';\nimport butterchurn from 'butterchurn';\nimport butterchurnPresets from 'butterchurn-presets';\n\nexport function useButterchurn(audioContext: AudioContext | null, audioNode: AudioNode | null) {\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const visualizerRef = useRef<any>(null);\n  const animationRef = useRef<number>();\n\n  useEffect(() => {\n    if (!canvasRef.current || !audioContext || !audioNode) return;\n\n    const canvas = canvasRef.current;\n    const visualizer = butterchurn.createVisualizer(audioContext, canvas, {\n      width: canvas.width,\n      height: canvas.height,\n      pixelRatio: window.devicePixelRatio || 1,\n    });\n\n    visualizer.connectAudio(audioNode);\n    visualizerRef.current = visualizer;\n\n    // Load initial preset\n    const presets = butterchurnPresets.getPresets();\n    const keys = Object.keys(presets);\n    visualizer.loadPreset(presets[keys[0]], 0);\n\n    // Render loop\n    const render = () => {\n      visualizer.render();\n      animationRef.current = requestAnimationFrame(render);\n    };\n    render();\n\n    return () => {\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current);\n      }\n    };\n  }, [audioContext, audioNode]);\n\n  const loadPreset = useCallback((presetName: string, blendTime = 2.0) => {\n    const presets = butterchurnPresets.getPresets();\n    if (visualizerRef.current && presets[presetName]) {\n      visualizerRef.current.loadPreset(presets[presetName], blendTime);\n    }\n  }, []);\n\n  return { canvasRef, loadPreset };\n}\n```\n"
        },
        {
          "name": "glsl-shaders.md",
          "type": "file",
          "path": "2000s-visualization-expert/references/glsl-shaders.md",
          "size": 6699,
          "content": "# GLSL Shaders for Audio Visualization\n\nCustom shader implementations for audio-reactive effects.\n\n---\n\n## Basic Audio-Reactive Fragment Shader\n\n```glsl\nprecision mediump float;\n\nuniform float u_time;\nuniform vec2 u_resolution;\nuniform sampler2D u_audioData;  // FFT as 1D texture\nuniform float u_bass;\nuniform float u_mid;\nuniform float u_treble;\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n  vec2 center = uv - 0.5;\n\n  // Audio-reactive radius\n  float dist = length(center);\n  float audioSample = texture2D(u_audioData, vec2(dist, 0.0)).r;\n\n  // Psychedelic color cycling\n  float hue = u_time * 0.1 + audioSample * 0.5;\n  vec3 color = 0.5 + 0.5 * cos(6.28 * (hue + vec3(0.0, 0.33, 0.67)));\n\n  // Pulsing glow based on bass\n  float glow = smoothstep(0.5 - u_bass * 0.3, 0.0, dist);\n\n  gl_FragColor = vec4(color * glow, 1.0);\n}\n```\n\n---\n\n## Tunnel Effect\n\n```glsl\nprecision mediump float;\n\nuniform float u_time;\nuniform vec2 u_resolution;\nuniform float u_bass;\nuniform float u_speed;\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n  vec2 center = uv - 0.5;\n\n  // Convert to polar coordinates\n  float angle = atan(center.y, center.x);\n  float radius = length(center);\n\n  // Tunnel distortion\n  float tunnel = 0.1 / radius;\n\n  // Scrolling texture coordinates\n  float u = angle / 3.14159;\n  float v = tunnel + u_time * u_speed + u_bass * 0.5;\n\n  // Create stripe pattern\n  float stripes = sin(u * 10.0) * sin(v * 20.0);\n  stripes = smoothstep(0.0, 0.1, stripes);\n\n  // Color based on depth\n  vec3 color = vec3(0.2, 0.5, 1.0) * stripes;\n  color *= 1.0 - radius * 1.5;  // Fade at edges\n\n  gl_FragColor = vec4(color, 1.0);\n}\n```\n\n---\n\n## Plasma Effect\n\n```glsl\nprecision mediump float;\n\nuniform float u_time;\nuniform vec2 u_resolution;\nuniform float u_bass;\nuniform float u_mid;\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n\n  // Multiple sine waves\n  float v1 = sin(uv.x * 10.0 + u_time);\n  float v2 = sin(10.0 * (uv.x * sin(u_time / 2.0) + uv.y * cos(u_time / 3.0)) + u_time);\n\n  float cx = uv.x + 0.5 * sin(u_time / 5.0);\n  float cy = uv.y + 0.5 * cos(u_time / 3.0);\n  float v3 = sin(sqrt(100.0 * (cx * cx + cy * cy) + 1.0) + u_time);\n\n  float v = v1 + v2 + v3;\n\n  // Audio modulation\n  v *= 1.0 + u_bass * 0.5;\n\n  // Color palette\n  vec3 color;\n  color.r = sin(v * 3.14159 + u_mid);\n  color.g = sin(v * 3.14159 + 2.094 + u_mid);\n  color.b = sin(v * 3.14159 + 4.188 + u_mid);\n  color = color * 0.5 + 0.5;\n\n  gl_FragColor = vec4(color, 1.0);\n}\n```\n\n---\n\n## Kaleidoscope Effect\n\n```glsl\nprecision mediump float;\n\nuniform float u_time;\nuniform vec2 u_resolution;\nuniform sampler2D u_audioData;\nuniform float u_bass;\n\n#define PI 3.14159265359\n#define SEGMENTS 8.0\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n  vec2 center = uv - 0.5;\n\n  // Convert to polar\n  float angle = atan(center.y, center.x);\n  float radius = length(center);\n\n  // Kaleidoscope fold\n  float segment = PI * 2.0 / SEGMENTS;\n  angle = mod(angle, segment);\n  if (mod(floor(atan(center.y, center.x) / segment), 2.0) == 1.0) {\n    angle = segment - angle;\n  }\n\n  // Convert back to cartesian\n  vec2 kaleido = vec2(cos(angle), sin(angle)) * radius;\n\n  // Sample audio at radius\n  float audio = texture2D(u_audioData, vec2(radius * 2.0, 0.0)).r;\n\n  // Create pattern\n  float pattern = sin(kaleido.x * 20.0 + u_time * 2.0);\n  pattern *= sin(kaleido.y * 20.0 + u_time);\n  pattern = pattern * 0.5 + 0.5;\n\n  // Color\n  vec3 color = vec3(pattern) * (audio + 0.2);\n  color *= 0.5 + 0.5 * cos(6.28 * (u_time * 0.1 + vec3(0.0, 0.33, 0.67)));\n\n  // Vignette\n  color *= 1.0 - radius;\n\n  gl_FragColor = vec4(color, 1.0);\n}\n```\n\n---\n\n## Spectrum Bars (Classic)\n\n```glsl\nprecision mediump float;\n\nuniform vec2 u_resolution;\nuniform sampler2D u_audioData;\nuniform float u_barCount;\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n\n  // Which bar are we in?\n  float barIndex = floor(uv.x * u_barCount);\n  float barCenter = (barIndex + 0.5) / u_barCount;\n\n  // Sample audio at bar position\n  float audio = texture2D(u_audioData, vec2(barCenter, 0.0)).r;\n\n  // Bar shape\n  float barWidth = 0.8 / u_barCount;\n  float inBar = step(abs(uv.x - barCenter), barWidth * 0.5);\n\n  // Height\n  float barHeight = audio;\n  float inHeight = step(uv.y, barHeight);\n\n  // Color gradient (blue to red based on height)\n  vec3 color = mix(vec3(0.2, 0.5, 1.0), vec3(1.0, 0.2, 0.5), uv.y);\n\n  // Combine\n  float alpha = inBar * inHeight;\n\n  gl_FragColor = vec4(color * alpha, alpha);\n}\n```\n\n---\n\n## Waveform Display\n\n```glsl\nprecision mediump float;\n\nuniform vec2 u_resolution;\nuniform sampler2D u_waveformData;\nuniform float u_lineWidth;\n\nvoid main() {\n  vec2 uv = gl_FragCoord.xy / u_resolution;\n\n  // Sample waveform\n  float waveform = texture2D(u_waveformData, vec2(uv.x, 0.0)).r;\n  waveform = waveform * 2.0 - 1.0;  // Convert from 0-1 to -1 to 1\n\n  // Center the waveform\n  float y = waveform * 0.4 + 0.5;\n\n  // Distance from waveform line\n  float dist = abs(uv.y - y);\n\n  // Line with glow\n  float line = smoothstep(u_lineWidth, 0.0, dist);\n  float glow = smoothstep(u_lineWidth * 10.0, 0.0, dist) * 0.5;\n\n  vec3 color = vec3(0.3, 1.0, 0.5) * (line + glow);\n\n  gl_FragColor = vec4(color, 1.0);\n}\n```\n\n---\n\n## WebGL Shader Setup (TypeScript)\n\n```typescript\nfunction createShaderProgram(\n  gl: WebGLRenderingContext,\n  vertexSource: string,\n  fragmentSource: string\n): WebGLProgram {\n  const vertexShader = compileShader(gl, gl.VERTEX_SHADER, vertexSource);\n  const fragmentShader = compileShader(gl, gl.FRAGMENT_SHADER, fragmentSource);\n\n  const program = gl.createProgram()!;\n  gl.attachShader(program, vertexShader);\n  gl.attachShader(program, fragmentShader);\n  gl.linkProgram(program);\n\n  if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {\n    throw new Error('Shader program failed to link');\n  }\n\n  return program;\n}\n\nfunction compileShader(\n  gl: WebGLRenderingContext,\n  type: number,\n  source: string\n): WebGLShader {\n  const shader = gl.createShader(type)!;\n  gl.shaderSource(shader, source);\n  gl.compileShader(shader);\n\n  if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {\n    const info = gl.getShaderInfoLog(shader);\n    throw new Error(`Shader compilation error: ${info}`);\n  }\n\n  return shader;\n}\n\n// Basic vertex shader (fullscreen quad)\nconst VERTEX_SHADER = `\n  attribute vec2 a_position;\n  void main() {\n    gl_Position = vec4(a_position, 0.0, 1.0);\n  }\n`;\n\n// Create fullscreen quad\nfunction createFullscreenQuad(gl: WebGLRenderingContext): WebGLBuffer {\n  const buffer = gl.createBuffer()!;\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n  gl.bufferData(\n    gl.ARRAY_BUFFER,\n    new Float32Array([-1, -1, 1, -1, -1, 1, 1, 1]),\n    gl.STATIC_DRAW\n  );\n  return buffer;\n}\n```\n"
        },
        {
          "name": "web-audio-fft.md",
          "type": "file",
          "path": "2000s-visualization-expert/references/web-audio-fft.md",
          "size": 6814,
          "content": "# Web Audio API FFT Reference\n\nComprehensive guide to extracting and using audio frequency data.\n\n---\n\n## Basic FFT Setup\n\n```typescript\n// Create analyser\nconst analyserNode = audioContext.createAnalyser();\nanalyserNode.fftSize = 2048;  // Power of 2, 32-32768\nanalyserNode.smoothingTimeConstant = 0.8;  // 0-1, higher = smoother\n\n// Connect to audio chain\nsource.connect(analyserNode);\nanalyserNode.connect(audioContext.destination);\n\n// Get frequency data (spectrum)\nconst frequencyData = new Uint8Array(analyserNode.frequencyBinCount);\nanalyserNode.getByteFrequencyData(frequencyData);  // 0-255 values\n\n// Get waveform data (time domain)\nconst waveformData = new Uint8Array(analyserNode.fftSize);\nanalyserNode.getByteTimeDomainData(waveformData);  // 128 = silence\n```\n\n---\n\n## FFT Size Tradeoffs\n\n| fftSize | Bins | Frequency Resolution | Time Resolution | Use Case |\n|---------|------|---------------------|-----------------|----------|\n| 256 | 128 | 172 Hz | 5.8 ms | Beat detection |\n| 512 | 256 | 86 Hz | 11.6 ms | Fast visuals |\n| 1024 | 512 | 43 Hz | 23.2 ms | Balanced |\n| 2048 | 1024 | 22 Hz | 46.4 ms | Detailed spectrum |\n| 4096 | 2048 | 11 Hz | 92.9 ms | High-res analysis |\n\n**Rule of thumb**: Higher fftSize = better frequency resolution but slower response.\n\n---\n\n## Logarithmic Frequency Bands\n\n**Critical knowledge**: FFT bins are linear in frequency, but human hearing is logarithmic!\n\n```typescript\nfunction getLogarithmicBands(\n  frequencyData: Uint8Array,\n  numBands: number,\n  sampleRate: number = 44100\n): number[] {\n  const bands = new Array(numBands).fill(0);\n  const nyquist = sampleRate / 2;\n\n  for (let i = 0; i < numBands; i++) {\n    // Logarithmic frequency mapping (20Hz - Nyquist)\n    const lowFreq = 20 * Math.pow(nyquist / 20, i / numBands);\n    const highFreq = 20 * Math.pow(nyquist / 20, (i + 1) / numBands);\n\n    const lowBin = Math.floor(lowFreq / nyquist * frequencyData.length);\n    const highBin = Math.floor(highFreq / nyquist * frequencyData.length);\n\n    let sum = 0;\n    let count = 0;\n    for (let j = lowBin; j < highBin && j < frequencyData.length; j++) {\n      sum += frequencyData[j];\n      count++;\n    }\n    bands[i] = count > 0 ? sum / count : 0;\n  }\n  return bands;\n}\n```\n\n---\n\n## Common Frequency Ranges\n\n```typescript\nfunction getFrequencyRanges(\n  frequencyData: Uint8Array,\n  sampleRate: number = 44100\n): { bass: number; mid: number; treble: number } {\n  const nyquist = sampleRate / 2;\n  const binWidth = nyquist / frequencyData.length;\n\n  function getRange(lowHz: number, highHz: number): number {\n    const lowBin = Math.floor(lowHz / binWidth);\n    const highBin = Math.min(\n      Math.floor(highHz / binWidth),\n      frequencyData.length - 1\n    );\n\n    let sum = 0;\n    for (let i = lowBin; i <= highBin; i++) {\n      sum += frequencyData[i];\n    }\n    return sum / (highBin - lowBin + 1);\n  }\n\n  return {\n    bass: getRange(20, 250),      // Sub-bass + bass\n    mid: getRange(250, 4000),     // Low-mid + mid + high-mid\n    treble: getRange(4000, 20000) // Presence + brilliance\n  };\n}\n```\n\n---\n\n## Beat Detection\n\n```typescript\nclass BeatDetector {\n  private history: number[] = [];\n  private historySize = 43;  // ~1 second at 60fps\n  private threshold = 1.3;\n\n  detect(frequencyData: Uint8Array): boolean {\n    // Focus on bass frequencies (first 1/8 of spectrum)\n    const bassEnd = Math.floor(frequencyData.length / 8);\n    let bassEnergy = 0;\n    for (let i = 0; i < bassEnd; i++) {\n      bassEnergy += frequencyData[i] * frequencyData[i];\n    }\n    bassEnergy = Math.sqrt(bassEnergy / bassEnd);\n\n    // Add to history\n    this.history.push(bassEnergy);\n    if (this.history.length > this.historySize) {\n      this.history.shift();\n    }\n\n    // Compare to average\n    const average = this.history.reduce((a, b) => a + b, 0) / this.history.length;\n\n    // Beat if current energy exceeds threshold * average\n    return bassEnergy > average * this.threshold;\n  }\n}\n```\n\n---\n\n## Smoothing Techniques\n\n### Built-in Smoothing\n```typescript\nanalyserNode.smoothingTimeConstant = 0.8;  // 0 = no smoothing, 1 = frozen\n```\n\n### Manual Exponential Smoothing\n```typescript\nclass SmoothingFilter {\n  private smoothed: Float32Array;\n  private alpha: number;\n\n  constructor(size: number, alpha: number = 0.3) {\n    this.smoothed = new Float32Array(size);\n    this.alpha = alpha;\n  }\n\n  apply(raw: Uint8Array): Float32Array {\n    for (let i = 0; i < raw.length; i++) {\n      this.smoothed[i] = this.smoothed[i] * (1 - this.alpha) + raw[i] * this.alpha;\n    }\n    return this.smoothed;\n  }\n}\n```\n\n### Attack/Release Smoothing\n```typescript\nclass AttackRelease {\n  private current: number = 0;\n  private attack: number;   // Fast rise\n  private release: number;  // Slow fall\n\n  constructor(attack: number = 0.9, release: number = 0.3) {\n    this.attack = attack;\n    this.release = release;\n  }\n\n  apply(target: number): number {\n    const alpha = target > this.current ? this.attack : this.release;\n    this.current = this.current * (1 - alpha) + target * alpha;\n    return this.current;\n  }\n}\n```\n\n---\n\n## Audio Texture for Shaders\n\n```typescript\nfunction createAudioTexture(\n  gl: WebGLRenderingContext,\n  frequencyData: Uint8Array\n): WebGLTexture {\n  const texture = gl.createTexture();\n  gl.bindTexture(gl.TEXTURE_2D, texture);\n\n  // Upload as 1D texture (width = data length, height = 1)\n  gl.texImage2D(\n    gl.TEXTURE_2D,\n    0,\n    gl.LUMINANCE,\n    frequencyData.length,\n    1,\n    0,\n    gl.LUMINANCE,\n    gl.UNSIGNED_BYTE,\n    frequencyData\n  );\n\n  // Filtering\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n\n  return texture!;\n}\n\n// Update each frame\nfunction updateAudioTexture(\n  gl: WebGLRenderingContext,\n  texture: WebGLTexture,\n  frequencyData: Uint8Array\n) {\n  gl.bindTexture(gl.TEXTURE_2D, texture);\n  gl.texSubImage2D(\n    gl.TEXTURE_2D,\n    0,\n    0, 0,\n    frequencyData.length, 1,\n    gl.LUMINANCE,\n    gl.UNSIGNED_BYTE,\n    frequencyData\n  );\n}\n```\n\n---\n\n## AudioContext State Handling\n\n```typescript\nasync function ensureAudioContext(\n  audioContext: AudioContext\n): Promise<void> {\n  if (audioContext.state === 'suspended') {\n    await audioContext.resume();\n  }\n}\n\n// Require user interaction to start\nfunction setupAudioActivation(\n  audioContext: AudioContext,\n  element: HTMLElement\n) {\n  const activate = async () => {\n    await ensureAudioContext(audioContext);\n    element.removeEventListener('click', activate);\n    element.removeEventListener('touchstart', activate);\n  };\n\n  element.addEventListener('click', activate);\n  element.addEventListener('touchstart', activate);\n}\n```\n"
        }
      ]
    },
    {
      "name": "CHANGELOG.md",
      "type": "file",
      "path": "2000s-visualization-expert/CHANGELOG.md",
      "size": 982,
      "content": "# Changelog\n\nAll notable changes to the 2000s-visualization-expert skill.\n\n## [2.0.0] - 2024-12-14\n\n### Changed\n- **BREAKING**: Restructured skill following progressive disclosure pattern\n- Reduced SKILL.md from 360 lines to ~165 lines for faster loading\n- Extracted detailed content to reference files\n\n### Added\n- `references/butterchurn-guide.md` - Complete Butterchurn integration guide\n- `references/web-audio-fft.md` - FFT extraction and frequency analysis\n- `references/glsl-shaders.md` - Audio-reactive shader patterns\n\n### Improved\n- Clearer activation triggers and boundary definitions\n- Expanded anti-patterns section (4 → 6 items)\n- Better historical context presentation\n- Streamlined integration checklist\n\n## [1.0.0] - 2024-11-26\n\n### Added\n- Initial skill creation\n- Milkdrop/AVS/Geiss historical context\n- Butterchurn integration examples\n- Web Audio API FFT documentation\n- GLSL shader examples for audio visualization\n- Full-screen visualization best practices\n"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "2000s-visualization-expert/SKILL.md",
      "size": 5651,
      "content": "---\nname: 2000s-visualization-expert\nversion: 2.0.0\ndescription: Expert in 2000s-era music visualization (Milkdrop, AVS, Geiss) and modern WebGL implementations. Specializes in Butterchurn integration, Web Audio API AnalyserNode FFT data, GLSL shaders for audio-reactive visuals, and psychedelic generative art. Activate on \"Milkdrop\", \"music visualization\", \"WebGL visualizer\", \"Butterchurn\", \"audio reactive\", \"FFT visualization\", \"spectrum analyzer\". NOT for simple bar charts/waveforms (use basic canvas), video editing, or non-audio visuals.\nallowed-tools: Read,Write,Edit,Bash,WebFetch\n---\n\n# 2000s Music Visualization Expert\n\nExpert in recreating the legendary 2000s music visualization era - Milkdrop, AVS, Geiss - using modern WebGL and Web Audio APIs.\n\n## When to Use\n\n✅ **Use for:**\n- Implementing Milkdrop-style psychedelic visualizations\n- Butterchurn library integration (WebGL Milkdrop)\n- Web Audio API AnalyserNode FFT/waveform extraction\n- GLSL fragment shaders for audio-reactive effects\n- Full-screen immersive music experiences\n- Real-time beat detection and audio analysis\n- Preset systems and visualization transitions\n\n❌ **NOT for:**\n- Simple spectrum bar charts (use Canvas 2D)\n- Static audio waveform displays\n- Video editing or processing\n- Non-audio generative art\n- Audio playback/streaming issues (use audio-engineer skills)\n\n## The Golden Era (Summary)\n\n| Era | Key Software | Innovation |\n|-----|--------------|------------|\n| **1998-2000** | Geiss | Simple plasma effects, DirectX |\n| **2001-2007** | Milkdrop 1 & 2 | Per-pixel equations, preset system |\n| **2007-2015** | Decline | Streaming services rise |\n| **2018-Present** | Butterchurn | WebGL renaissance |\n\n**Milkdrop's magic**: Layering simple effects - blur, zoom, rotation, color shift - with audio-reactive parameters.\n\n→ See `references/butterchurn-guide.md` for full history and integration.\n\n## Core Technologies\n\n### Butterchurn (WebGL Milkdrop)\n- 1.7k GitHub stars, MIT licensed\n- Full preset compatibility with original Milkdrop\n- npm: `butterchurn`, `butterchurn-presets`\n\n```typescript\nimport butterchurn from 'butterchurn';\nconst visualizer = butterchurn.createVisualizer(audioContext, canvas, {\n  width: window.innerWidth,\n  height: window.innerHeight,\n  pixelRatio: window.devicePixelRatio || 1,\n});\nvisualizer.connectAudio(audioNode);\nvisualizer.loadPreset(preset, 2.0);  // 2s blend\n```\n\n### Web Audio API FFT\n```typescript\nconst analyser = audioContext.createAnalyser();\nanalyser.fftSize = 2048;\nanalyser.smoothingTimeConstant = 0.8;\nconst frequencyData = new Uint8Array(analyser.frequencyBinCount);\nanalyser.getByteFrequencyData(frequencyData);\n```\n\n**Critical**: FFT bins are linear but hearing is logarithmic! Use logarithmic mapping.\n\n→ See `references/web-audio-fft.md` for frequency band extraction.\n\n### GLSL Shaders\nPass audio data as 1D texture, use uniforms for bass/mid/treble:\n\n```glsl\nuniform float u_bass;\nfloat glow = smoothstep(0.5 - u_bass * 0.3, 0.0, dist);\n```\n\n→ See `references/glsl-shaders.md` for complete patterns.\n\n## Anti-Patterns to Avoid\n\n### 1. Ignoring AudioContext State\n**What it looks like**: Visualization silently fails\n**Why it's wrong**: AudioContext starts suspended, needs user interaction\n**Fix**: Resume on click: `await audioContext.resume()`\n\n### 2. Linear Frequency Display\n**What it looks like**: Bass dominates, treble invisible\n**Why it's wrong**: FFT bins are linear; first 100 bins might be 0-2kHz\n**Fix**: Use logarithmic bin mapping (code in references)\n\n### 3. No Smoothing\n**What it looks like**: Jittery, seizure-inducing visuals\n**Why it's wrong**: Raw FFT data is noisy frame-to-frame\n**Fix**: `analyserNode.smoothingTimeConstant = 0.7`\n\n### 4. requestAnimationFrame Without Cleanup\n**What it looks like**: Memory leaks, multiple render loops\n**Fix**: Store animation ID, call `cancelAnimationFrame` on unmount\n\n### 5. Hardcoded Canvas Size\n**What it looks like**: Blurry on retina, wrong aspect ratio\n**Fix**: Multiply by `devicePixelRatio`, handle resize events\n\n### 6. Blocking Main Thread\n**What it looks like**: Choppy audio, dropped frames\n**Why it's wrong**: Heavy shader compilation on UI thread\n**Fix**: Compile shaders during loading, not during playback\n\n## Preset Recommendations\n\n**Psychedelic/Trippy:**\n- `Flexi, martin + geiss - dedicated to the sherwin maxawow`\n- `Rovastar - Fractopia`\n\n**Smooth/Chill:**\n- `Flexi - predator-prey-spirals`\n- `Geiss - Cosmic Strings 2`\n\n**High Energy:**\n- `Flexi + Martin - disconnected`\n- `shifter - tumbling cubes`\n\n## Integration Checklist\n\n- [ ] AudioContext created and resumed on user interaction\n- [ ] AnalyserNode connected to audio source\n- [ ] Canvas sized correctly (account for devicePixelRatio)\n- [ ] Render loop with requestAnimationFrame\n- [ ] Cleanup on unmount (cancelAnimationFrame)\n- [ ] Preset loading with blend time\n- [ ] Resize handling\n- [ ] Full-screen support with ESC to exit\n- [ ] Track info overlay (z-index above canvas)\n- [ ] Cursor hiding after inactivity\n\n## Performance Tips\n\n1. **Lower texture ratio** for older GPUs: `textureRatio: 0.5`\n2. **Reduce fftSize** if not needed: 512 or 1024 vs 2048\n3. **Use `will-change: transform`** on canvas\n4. **Avoid DOM updates** during render loop\n5. **Profile with Chrome DevTools** GPU timeline\n\n## References\n\n→ `references/butterchurn-guide.md` - Complete Butterchurn integration\n→ `references/web-audio-fft.md` - FFT extraction and frequency analysis\n→ `references/glsl-shaders.md` - Audio-reactive shader patterns\n\n---\n\n**This skill covers**: Butterchurn/Milkdrop | Web Audio FFT | GLSL shaders | Full-screen visualization | Audio-reactive art\n"
    }
  ]
}