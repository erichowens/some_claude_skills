{
  "name": "skill-coach",
  "type": "folder",
  "path": "skill-coach",
  "children": [
    {
      "name": "examples",
      "type": "folder",
      "path": "skill-coach/examples",
      "children": [
        {
          "name": "good",
          "type": "folder",
          "path": "skill-coach/examples/good",
          "children": [
            {
              "name": "clip-aware-embeddings",
              "type": "folder",
              "path": "skill-coach/examples/good/clip-aware-embeddings",
              "children": [
                {
                  "name": "scripts",
                  "type": "folder",
                  "path": "skill-coach/examples/good/clip-aware-embeddings/scripts",
                  "children": [
                    {
                      "name": "validate_clip_usage.py",
                      "type": "file",
                      "path": "skill-coach/examples/good/clip-aware-embeddings/scripts/validate_clip_usage.py",
                      "size": 7094,
                      "content": "#!/usr/bin/env python3\n\"\"\"\nCLIP Usage Validator - Checks if CLIP is appropriate for a given query\n\nThis demonstrates domain-specific validation that encodes expert knowledge.\n\"\"\"\n\nimport sys\nimport re\nfrom enum import Enum\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n\nclass TaskType(Enum):\n    SEMANTIC_SEARCH = \"semantic_search\"\n    COUNTING = \"counting\"\n    FINE_GRAINED = \"fine_grained\"\n    SPATIAL = \"spatial\"\n    COMPOSITIONAL = \"compositional\"\n    ZERO_SHOT = \"zero_shot\"\n\n\n@dataclass\nclass ValidationResult:\n    is_appropriate: bool\n    task_type: TaskType\n    confidence: float\n    reason: str\n    alternative: Optional[str] = None\n\n\nclass CLIPValidator:\n    \"\"\"Validates whether CLIP is appropriate for a given task.\"\"\"\n    \n    # Keywords that indicate specific task types\n    COUNTING_KEYWORDS = [\n        'how many', 'count', 'number of', 'total', 'quantity',\n        'several', 'few', 'multiple'\n    ]\n    \n    SPATIAL_KEYWORDS = [\n        'left', 'right', 'above', 'below', 'next to', 'beside',\n        'between', 'in front', 'behind', 'under', 'over', 'near'\n    ]\n    \n    FINE_GRAINED_DOMAINS = [\n        'celebrity', 'celebrities', 'actor', 'actress',\n        'car model', 'vehicle model', 'car make',\n        'flower species', 'bird species', 'dog breed',\n        'person', 'face', 'people'\n    ]\n    \n    COMPOSITIONAL_PATTERNS = [\n        r'(\\w+)\\s+(\\w+)\\s+and\\s+(\\w+)\\s+(\\w+)',  # \"red car and blue truck\"\n        r'both\\s+',\n        r'neither\\s+',\n        r'either\\s+',\n    ]\n    \n    GOOD_USE_CASES = [\n        'find images', 'search for', 'similar to', 'looks like',\n        'classify', 'categorize', 'what is this', 'identify',\n        'semantic', 'concept', 'theme'\n    ]\n    \n    def validate(self, query: str) -> ValidationResult:\n        \"\"\"\n        Validate if CLIP is appropriate for the query.\n        \n        Args:\n            query: Natural language query\n            \n        Returns:\n            ValidationResult with recommendation\n        \"\"\"\n        query_lower = query.lower()\n        \n        # Check for counting tasks\n        if any(kw in query_lower for kw in self.COUNTING_KEYWORDS):\n            return ValidationResult(\n                is_appropriate=False,\n                task_type=TaskType.COUNTING,\n                confidence=0.95,\n                reason=\"Query requires counting objects. CLIP cannot preserve spatial information needed for counting.\",\n                alternative=\"Use object detection models: DETR, Faster R-CNN, YOLO\"\n            )\n        \n        # Check for spatial reasoning\n        if any(kw in query_lower for kw in self.SPATIAL_KEYWORDS):\n            return ValidationResult(\n                is_appropriate=False,\n                task_type=TaskType.SPATIAL,\n                confidence=0.90,\n                reason=\"Query requires spatial understanding. CLIP's embeddings lose spatial topology.\",\n                alternative=\"Use spatial reasoning models: GQA, SWIG, Visual Genome models\"\n            )\n        \n        # Check for fine-grained classification\n        if any(domain in query_lower for domain in self.FINE_GRAINED_DOMAINS):\n            return ValidationResult(\n                is_appropriate=False,\n                task_type=TaskType.FINE_GRAINED,\n                confidence=0.85,\n                reason=\"Query requires fine-grained classification. CLIP trained on coarse categories.\",\n                alternative=\"Use specialized models: Fine-tuned ResNet/EfficientNet for the specific domain\"\n            )\n        \n        # Check for compositional reasoning\n        if any(re.search(pattern, query_lower) for pattern in self.COMPOSITIONAL_PATTERNS):\n            return ValidationResult(\n                is_appropriate=False,\n                task_type=TaskType.COMPOSITIONAL,\n                confidence=0.80,\n                reason=\"Query requires attribute binding. CLIP cannot bind attributes to specific objects.\",\n                alternative=\"Use compositional models: DCSMs (Dense Cosine Similarity Maps), PC-CLIP\"\n            )\n        \n        # Check if it's a good CLIP use case\n        if any(use_case in query_lower for use_case in self.GOOD_USE_CASES):\n            return ValidationResult(\n                is_appropriate=True,\n                task_type=TaskType.SEMANTIC_SEARCH,\n                confidence=0.90,\n                reason=\"Query is appropriate for CLIP: semantic search or broad categorization.\",\n                alternative=None\n            )\n        \n        # Default: probably okay but lower confidence\n        return ValidationResult(\n            is_appropriate=True,\n            task_type=TaskType.ZERO_SHOT,\n            confidence=0.60,\n            reason=\"Query appears suitable for CLIP, but verify results carefully.\",\n            alternative=\"If results are poor, consider task-specific models\"\n        )\n\n\ndef print_result(query: str, result: ValidationResult):\n    \"\"\"Pretty-print validation results.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(f\"CLIP USAGE VALIDATION\")\n    print(\"=\"*70)\n    print(f\"\\nQuery: {query}\")\n    print(f\"Task Type: {result.task_type.value}\")\n    print(f\"Confidence: {result.confidence:.0%}\")\n    print()\n    \n    if result.is_appropriate:\n        print(\"‚úÖ CLIP IS APPROPRIATE\")\n        print(f\"\\nReason: {result.reason}\")\n        if result.alternative:\n            print(f\"\\nüí° Note: {result.alternative}\")\n    else:\n        print(\"‚ùå CLIP IS NOT APPROPRIATE\")\n        print(f\"\\nReason: {result.reason}\")\n        print(f\"\\nüí° Use Instead: {result.alternative}\")\n    \n    print(\"\\n\" + \"=\"*70 + \"\\n\")\n\n\ndef run_examples():\n    \"\"\"Run validation on example queries.\"\"\"\n    examples = [\n        \"Find images of beaches at sunset\",\n        \"How many cars are in this image?\",\n        \"Identify which celebrity this is\",\n        \"Is the cat to the left or right of the dog?\",\n        \"Find images with a red car and a blue truck\",\n        \"Classify this image as indoor or outdoor\",\n    ]\n    \n    validator = CLIPValidator()\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"EXAMPLE VALIDATIONS\")\n    print(\"=\"*70)\n    \n    for query in examples:\n        result = validator.validate(query)\n        print(f\"\\n{query}\")\n        print(f\"  ‚Üí {'‚úÖ CLIP' if result.is_appropriate else '‚ùå Alternative'}: {result.task_type.value}\")\n        if not result.is_appropriate:\n            print(f\"  ‚Üí {result.alternative}\")\n    \n    print(\"\\n\" + \"=\"*70 + \"\\n\")\n\n\ndef main():\n    if len(sys.argv) < 2:\n        print(\"Usage:\")\n        print(\"  python validate_clip_usage.py 'your query here'\")\n        print(\"  python validate_clip_usage.py --examples\")\n        print(\"\\nExample:\")\n        print(\"  python validate_clip_usage.py 'Find images of mountains'\")\n        sys.exit(1)\n    \n    if sys.argv[1] == '--examples':\n        run_examples()\n        return\n    \n    query = ' '.join(sys.argv[1:])\n    validator = CLIPValidator()\n    result = validator.validate(query)\n    print_result(query, result)\n    \n    # Exit code: 0 if appropriate, 1 if not\n    sys.exit(0 if result.is_appropriate else 1)\n\n\nif __name__ == '__main__':\n    main()\n"
                    }
                  ]
                },
                {
                  "name": "SKILL_.md",
                  "type": "file",
                  "path": "skill-coach/examples/good/clip-aware-embeddings/SKILL_.md",
                  "size": 8947,
                  "content": "---\nname: clip-aware-embeddings\ndescription: Semantic image-text matching with CLIP and alternatives. Use for image search, zero-shot classification, similarity matching. NOT for counting objects, fine-grained classification (celebrities, car models), spatial reasoning, or compositional queries. Mention CLIP, embeddings, image similarity, or semantic search.\nallowed-tools: Read,Write,Bash(pip:install)\n---\n\n# CLIP-Aware Image Embeddings\n\nSmart image-text matching that knows when CLIP works and when to use alternatives.\n\n## Quick Decision Tree\n\n```\nYour task:\n‚îú‚îÄ Semantic search (\"find beach images\") ‚Üí CLIP ‚úì\n‚îú‚îÄ Zero-shot classification (broad categories) ‚Üí CLIP ‚úì\n‚îú‚îÄ Counting objects ‚Üí DETR, Faster R-CNN ‚úó\n‚îú‚îÄ Fine-grained ID (celebrities, car models) ‚Üí Specialized model ‚úó\n‚îú‚îÄ Spatial relations (\"cat left of dog\") ‚Üí GQA, SWIG ‚úó\n‚îî‚îÄ Compositional (\"red car AND blue truck\") ‚Üí DCSMs, PC-CLIP ‚úó\n```\n\n## When to Use This Skill\n\n‚úÖ **Use for**:\n- Semantic image search\n- Broad category classification\n- Image similarity matching\n- Zero-shot tasks on new categories\n\n‚ùå **Do NOT use for**:\n- Counting objects in images\n- Fine-grained classification\n- Spatial understanding\n- Attribute binding\n- Negation handling\n\n## Installation\n\n```bash\npip install transformers pillow torch sentence-transformers --break-system-packages\n```\n\n**Validation**: Run `python scripts/validate_setup.py`\n\n## Basic Usage\n\n### Image Search\n\n```python\nfrom transformers import CLIPProcessor, CLIPModel\nfrom PIL import Image\n\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n\n# Embed images\nimages = [Image.open(f\"img{i}.jpg\") for i in range(10)]\ninputs = processor(images=images, return_tensors=\"pt\")\nimage_features = model.get_image_features(**inputs)\n\n# Search with text\ntext_inputs = processor(text=[\"a beach at sunset\"], return_tensors=\"pt\")\ntext_features = model.get_text_features(**text_inputs)\n\n# Compute similarity\nsimilarity = (image_features @ text_features.T).softmax(dim=0)\n```\n\n## Common Anti-Patterns\n\n### Anti-Pattern 1: \"CLIP for Everything\"\n\n**‚ùå Wrong**:\n```python\n# Using CLIP to count cars in an image\nprompt = \"How many cars are in this image?\"\n# CLIP cannot count - it will give nonsense results\n```\n\n**Why wrong**: CLIP's architecture collapses spatial information into a single vector. It literally cannot count.\n\n**‚úì Right**:\n```python\nfrom transformers import DetrImageProcessor, DetrForObjectDetection\n\nprocessor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\nmodel = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n\n# Detect objects\nresults = model(**processor(images=image, return_tensors=\"pt\"))\n# Filter for cars and count\ncar_detections = [d for d in results if d['label'] == 'car']\ncount = len(car_detections)\n```\n\n**How to detect**: If query contains \"how many\", \"count\", or numeric questions ‚Üí Use object detection\n\n---\n\n### Anti-Pattern 2: Fine-Grained Classification\n\n**‚ùå Wrong**:\n```python\n# Trying to identify specific celebrities with CLIP\nprompts = [\"Tom Hanks\", \"Brad Pitt\", \"Morgan Freeman\"]\n# CLIP will perform poorly - not trained for fine-grained face ID\n```\n\n**Why wrong**: CLIP trained on coarse categories. Fine-grained faces, car models, flower species require specialized models.\n\n**‚úì Right**:\n```python\n# Use a fine-tuned face recognition model\nfrom transformers import AutoFeatureExtractor, AutoModelForImageClassification\n\nmodel = AutoModelForImageClassification.from_pretrained(\n    \"microsoft/resnet-50\"  # Then fine-tune on celebrity dataset\n)\n# Or use dedicated face recognition: ArcFace, CosFace\n```\n\n**How to detect**: If query asks to distinguish between similar items in same category ‚Üí Use specialized model\n\n---\n\n### Anti-Pattern 3: Spatial Understanding\n\n**‚ùå Wrong**:\n```python\n# CLIP cannot understand spatial relationships\nprompts = [\n    \"cat to the left of dog\",\n    \"cat to the right of dog\"\n]\n# Will give nearly identical scores\n```\n\n**Why wrong**: CLIP embeddings lose spatial topology. \"Left\" and \"right\" are treated as bag-of-words.\n\n**‚úì Right**:\n```python\n# Use a spatial reasoning model\n# Examples: GQA models, Visual Genome models, SWIG\nfrom swig_model import SpatialRelationModel\n\nmodel = SpatialRelationModel()\nresult = model.predict_relation(image, \"cat\", \"dog\")\n# Returns: \"left\", \"right\", \"above\", \"below\", etc.\n```\n\n**How to detect**: If query contains directional words (left, right, above, under, next to) ‚Üí Use spatial model\n\n---\n\n### Anti-Pattern 4: Attribute Binding\n\n**‚ùå Wrong**:\n```python\nprompts = [\n    \"red car and blue truck\",\n    \"blue car and red truck\"\n]\n# CLIP often gives similar scores for both\n```\n\n**Why wrong**: CLIP cannot bind attributes to objects. It sees \"red, blue, car, truck\" as a bag of concepts.\n\n**‚úì Right - Use PC-CLIP or DCSMs**:\n```python\n# PC-CLIP: Fine-tuned for pairwise comparisons\nfrom pc_clip import PCCLIPModel\n\nmodel = PCCLIPModel.from_pretrained(\"pc-clip-vit-l\")\n# Or use DCSMs (Dense Cosine Similarity Maps)\n```\n\n**How to detect**: If query has multiple objects with different attributes ‚Üí Use compositional model\n\n---\n\n## Evolution Timeline\n\n### 2021: CLIP Released\n- Revolutionary: zero-shot, 400M image-text pairs\n- Widely adopted for everything\n- Limitations not yet understood\n\n### 2022-2023: Limitations Discovered\n- Cannot count objects\n- Poor at fine-grained classification\n- Fails spatial reasoning\n- Can't bind attributes\n\n### 2024: Alternatives Emerge\n- **DCSMs**: Preserve patch/token topology\n- **PC-CLIP**: Trained on pairwise comparisons\n- **SpLiCE**: Sparse interpretable embeddings\n\n### 2025: Current Best Practices\n- Use CLIP for what it's good at\n- Task-specific models for limitations\n- Compositional models for complex queries\n\n**LLM Mistake**: LLMs trained on 2021-2023 data will suggest CLIP for everything because limitations weren't widely known. This skill corrects that.\n\n---\n\n## Validation Script\n\nBefore using CLIP, check if it's appropriate:\n\n```bash\npython scripts/validate_clip_usage.py \\\n    --query \"your query here\" \\\n    --check-all\n```\n\nReturns:\n- ‚úÖ CLIP is appropriate\n- ‚ùå Use alternative (with suggestion)\n\n## Task-Specific Guidance\n\n### Image Search (CLIP ‚úì)\n```python\n# Good use of CLIP\nqueries = [\"beach\", \"mountain\", \"city skyline\"]\n# Works well for broad semantic concepts\n```\n\n### Zero-Shot Classification (CLIP ‚úì)\n```python\n# Good: Broad categories\ncategories = [\"indoor\", \"outdoor\", \"nature\", \"urban\"]\n# CLIP excels at this\n```\n\n### Object Counting (CLIP ‚úó)\n```python\n# Use object detection instead\nfrom transformers import DetrImageProcessor, DetrForObjectDetection\n# See /references/object_detection.md\n```\n\n### Fine-Grained Classification (CLIP ‚úó)\n```python\n# Use specialized models\n# See /references/fine_grained_models.md\n```\n\n### Spatial Reasoning (CLIP ‚úó)\n```python\n# Use spatial relation models\n# See /references/spatial_models.md\n```\n\n---\n\n## Troubleshooting\n\n### Issue: CLIP gives unexpected results\n\n**Check**:\n1. Is this a counting task? ‚Üí Use object detection\n2. Fine-grained classification? ‚Üí Use specialized model\n3. Spatial query? ‚Üí Use spatial model\n4. Multiple objects with attributes? ‚Üí Use compositional model\n\n**Validation**:\n```bash\npython scripts/diagnose_clip_issue.py --image path/to/image --query \"your query\"\n```\n\n### Issue: Low similarity scores\n\n**Possible causes**:\n1. Query too specific (CLIP works better with broad concepts)\n2. Fine-grained task (not CLIP's strength)\n3. Need to adjust threshold\n\n**Solution**: Try broader query or use alternative model\n\n---\n\n## Model Selection Guide\n\n| Model | Best For | Avoid For |\n|-------|----------|-----------|\n| CLIP ViT-L/14 | Semantic search, broad categories | Counting, fine-grained, spatial |\n| DETR | Object detection, counting | Semantic similarity |\n| DINOv2 | Fine-grained features | Text-image matching |\n| PC-CLIP | Attribute binding, comparisons | General embedding |\n| DCSMs | Compositional reasoning | Simple similarity |\n\n## Performance Notes\n\n**CLIP models**:\n- ViT-B/32: Fast, lower quality\n- ViT-L/14: Balanced (recommended)\n- ViT-g-14: Highest quality, slower\n\n**Inference time** (single image, CPU):\n- ViT-B/32: ~100ms\n- ViT-L/14: ~300ms\n- ViT-g-14: ~1000ms\n\n## Further Reading\n\n- `/references/clip_limitations.md` - Detailed analysis of CLIP's failures\n- `/references/alternatives.md` - When to use what model\n- `/references/compositional_reasoning.md` - DCSMs and PC-CLIP deep dive\n- `/scripts/validate_clip_usage.py` - Pre-flight validation tool\n- `/scripts/diagnose_clip_issue.py` - Debug unexpected results\n\n## Changelog\n\n### v1.2.0 (2025-03-15)\n- Added DCSMs and PC-CLIP alternatives\n- Updated for 2025 best practices\n- Improved validation scripts\n\n### v1.1.0 (2024-06-10)\n- Added anti-pattern detection\n- Expanded troubleshooting\n\n### v1.0.0 (2024-01-15)\n- Initial release\n"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "name": "references",
      "type": "folder",
      "path": "skill-coach/references",
      "children": [
        {
          "name": "antipatterns.md",
          "type": "file",
          "path": "skill-coach/references/antipatterns.md",
          "size": 14614,
          "content": "# Skill Anti-Patterns: The Shibboleths\n\nThis document catalogs **domain-specific knowledge that separates novices from experts** - the things LLMs get wrong because their training data includes outdated patterns, oversimplified tutorials, or cargo-culted code.\n\n## Table of Contents\n\n1. [ML/AI Model Selection](#mlai-model-selection)\n2. [Framework Evolution](#framework-evolution)\n3. [Tool Architecture](#tool-architecture)\n4. [Skill Design](#skill-design)\n\n---\n\n## ML/AI Model Selection\n\n### Anti-Pattern: CLIP for Everything\n\n**Novice thinking**: \"CLIP is pre-trained on 400M image-text pairs and does zero-shot classification. Use it for all image-text tasks!\"\n\n**Reality**: CLIP has **fundamental geometric limitations**. Research from 2023-2025 proves it cannot simultaneously handle:\n\n1. Basic descriptions\n2. Attribute binding (\"red car AND blue truck\" vs \"blue car AND red truck\")\n3. Spatial relationships (\"cat left of dog\" vs \"dog left of cat\")\n4. Negation (\"not a cat\")\n\n**What CLIP fails at**:\n- ‚ùå Counting objects in images\n- ‚ùå Fine-grained classification (celebrity ID, car models, flower species)\n- ‚ùå Compositional reasoning\n- ‚ùå Spatial understanding\n- ‚ùå Handwritten text (MNIST-style)\n\n**When to use alternatives**:\n\n| Task | Use Instead | Why |\n|------|-------------|-----|\n| Counting objects | DETR, Faster R-CNN | Object detection models built for counting |\n| Fine-grained classification | EfficientNet + task head | Transfer learning on specific domain |\n| Compositional reasoning | DCSMs, PC-CLIP | Preserve patch/token topology |\n| Spatial relationships | GQA models, SWIG | Built for spatial understanding |\n| Attribute binding | PC-CLIP (pairwise) | Trained on comparative data |\n\n**Timeline**:\n- 2021: Original CLIP released\n- 2022-2023: Limitations discovered in research\n- 2024: DCSMs (Dense Cosine Similarity Maps) paper\n- 2024: PC-CLIP (Pairwise Comparison CLIP)\n- 2025: SpLiCE (Sparse Linear Concept Embeddings)\n\n**LLM mistake**: LLMs trained on 2021-2023 data will suggest CLIP for everything because limitations weren't widely known yet.\n\n---\n\n### Anti-Pattern: Single Embedding Model\n\n**Novice thinking**: \"Pick one embedding model and use it everywhere\"\n\n**Expert knowledge**: Different tasks need different models:\n\n**Text embeddings**:\n- Semantic search: `text-embedding-3-large`, `voyage-2`\n- Code search: `voyage-code-2`, `text-embedding-ada-002`\n- Multi-lingual: `multilingual-e5-large`\n- Long documents: `jina-embeddings-v2` (8k tokens)\n\n**Image embeddings**:\n- General: CLIP ViT-L/14\n- Fine-grained: DINOv2\n- Medical: BiomedCLIP\n- Faces: ArcFace, CosFace\n\n**Multi-modal**:\n- Image-text: CLIP, BLIP-2\n- Video: X-CLIP, VideoCLIP\n- 3D: ULIP, PointCLIP\n\n**Why this matters**: Embedding quality directly impacts retrieval accuracy. Using the wrong model can drop accuracy by 20-40%.\n\n---\n\n### Anti-Pattern: Ignoring Model Versioning\n\n**Problem**: \"We're using `text-embedding-ada-002`\" (doesn't specify when)\n\n**Why wrong**: Models evolve:\n- `text-embedding-ada-002` (Dec 2022) vs `text-embedding-3-small` (Jan 2024)\n- CLIP ViT-B/32 vs ViT-L/14 vs ViT-g-14\n- Different training data, different capabilities\n\n**Best practice**: Pin versions, document when you adopted them:\n```python\n# embeddings.py\nMODEL = \"text-embedding-3-large\"  # Adopted: 2024-03-15\nMODEL_DIMENSIONS = 3072\nTRAINING_CUTOFF = \"2023-09\"  # Approximate\n```\n\n---\n\n## Framework Evolution\n\n### Anti-Pattern: Pages Router in App Router Projects\n\n**Context**: Next.js 13 (Oct 2022) introduced App Router, fundamentally changing architecture.\n\n**Outdated pattern** (Pages Router):\n```javascript\n// pages/api/users.js\nexport default function handler(req, res) {\n  res.json({ users: [] })\n}\n\n// pages/users.js\nexport async function getServerSideProps() {\n  return { props: { users: [] } }\n}\n```\n\n**Current pattern** (App Router):\n```javascript\n// app/api/users/route.js\nexport async function GET() {\n  return Response.json({ users: [] })\n}\n\n// app/users/page.js\nasync function UsersPage() {\n  const users = await fetchUsers()  // Server Component\n  return <UserList users={users} />\n}\n```\n\n**Why it matters**: Pages Router patterns don't work in App Router and vice versa.\n\n**LLM mistake**: Training data from 2020-2023 overwhelmingly shows Pages Router. LLMs will default to old patterns unless specifically prompted.\n\n**Timeline**:\n- 2016-2022: Pages Router only\n- Oct 2022: App Router introduced (beta)\n- May 2023: App Router stable\n- 2024+: App Router is default\n\n---\n\n### Anti-Pattern: Redux for Everything\n\n**Novice thinking**: \"Global state needs Redux\"\n\n**Timeline**:\n- 2015-2020: Redux dominated\n- 2019: Context API improved in React 16.3\n- 2020: Zustand, Jotai emerged\n- 2023: React Server Components changed the game\n\n**Current wisdom**:\n- **Local UI state**: `useState`, `useReducer`\n- **Derived state**: `useMemo`, selectors\n- **Global state (simple)**: Context API\n- **Global state (complex)**: Zustand, Jotai\n- **Server state**: React Query, SWR\n- **URL state**: Next.js searchParams\n- **Redux**: Only if you need time-travel debugging or complex middleware\n\n**Why Redux fell out of favor**:\n- Boilerplate heavy\n- Server Components make much state \"server-native\"\n- Simpler alternatives emerged\n\n**LLM mistake**: LLMs will suggest Redux by default because 80% of training data predates alternatives.\n\n---\n\n### Anti-Pattern: Class Components\n\n**Timeline**:\n- 2013-2018: Class components only\n- Feb 2019: Hooks introduced (React 16.8)\n- 2020+: Functional components are standard\n\n**Outdated**:\n```javascript\nclass UserProfile extends React.Component {\n  state = { user: null }\n  \n  componentDidMount() {\n    fetchUser().then(user => this.setState({ user }))\n  }\n  \n  render() {\n    return <div>{this.state.user?.name}</div>\n  }\n}\n```\n\n**Current**:\n```javascript\nfunction UserProfile() {\n  const [user, setUser] = useState(null)\n  \n  useEffect(() => {\n    fetchUser().then(setUser)\n  }, [])\n  \n  return <div>{user?.name}</div>\n}\n```\n\n**When class components are still valid**:\n- Error boundaries (no hook equivalent yet)\n- Legacy codebases\n\n**LLM mistake**: Will generate class components for complex state management\n\n---\n\n## Tool Architecture\n\n### Anti-Pattern: MCP for Everything\n\n**Novice thinking**: \"MCP is the new standard, make everything an MCP!\"\n\n**Expert reality**: MCPs have overhead. Use them strategically.\n\n**Use MCP when**:\n- ‚úÖ External API with authentication\n- ‚úÖ Stateful connections (WebSocket, database)\n- ‚úÖ Real-time data streams\n- ‚úÖ Security boundaries (credentials, OAuth)\n\n**Use Scripts when**:\n- ‚úÖ Local file operations\n- ‚úÖ Batch transformations\n- ‚úÖ Stateless computations\n- ‚úÖ CLI wrappers\n\n**Example - Wrong**:\n```python\n# mcp_server_for_json_parsing.py - OVERKILL!\n@mcp.tool()\ndef parse_json(file_path: str):\n    with open(file_path) as f:\n        return json.load(f)\n```\n\n**Example - Right**:\n```python\n# scripts/parse_json.py - Simple script!\nimport json\nimport sys\n\nwith open(sys.argv[1]) as f:\n    data = json.load(f)\n    print(json.dumps(data, indent=2))\n```\n\n**Philosophy**: \"MCP's job isn't to abstract reality for the agent; its job is to manage the auth, networking, and security boundaries and then get out of the way.\"\n\n---\n\n### Anti-Pattern: Premature Abstraction\n\n**Problem**: Building a complex MCP before understanding the use case\n\n**Better approach**: Start with scripts, graduate to MCP when you need:\n1. Auth/security boundaries\n2. Multiple tools in same domain\n3. State management\n4. Error handling standardization\n\n**Evolution path**:\n```\nScript ‚Üí Multiple Scripts ‚Üí Helper Library ‚Üí MCP Server\n```\n\nOnly promote to MCP when complexity justifies it.\n\n---\n\n## Skill Design\n\n### Anti-Pattern: Skill as Documentation Dump\n\n**Bad**:\n```markdown\n---\nname: react-guide\ndescription: Everything about React\n---\n\n# React Guide\n\nReact is a JavaScript library for building user interfaces...\n[50 pages of tutorial content]\n```\n\n**Why wrong**: Not progressive disclosure, not actionable, not targeted.\n\n**Good**:\n```markdown\n---\nname: react-server-components\ndescription: Use React Server Components correctly. Use when working with Next.js App Router, async components, or server-side data fetching.\n---\n\n# React Server Components\n\n## Quick Decision Tree\n\nIs your component:\n- Fetching data? ‚Üí Server Component\n- Using hooks/events? ‚Üí Client Component\n- Both? ‚Üí Server Component wrapper + Client Component child\n\n## Common Anti-Pattern: Everything is 'use client'\n\n‚ùå **Wrong**:\n```jsx\n'use client'\nasync function Page() {  // This doesn't work!\n  const data = await fetch(...)\n  return <div>{data}</div>\n}\n```\n\n‚úÖ **Right**:\n```jsx\n// Server Component (default)\nasync function Page() {\n  const data = await fetchData()\n  return <ClientComponent data={data} />\n}\n\n// client-component.jsx\n'use client'\nfunction ClientComponent({ data }) {\n  const [count, setCount] = useState(0)\n  return <div onClick={() => setCount(count + 1)}>{data}</div>\n}\n```\n\n## When This Pattern Changed\n\n- Pre-Next.js 13: All components are client-side\n- Next.js 13+: Server Components by default\n- LLM confusion: Will add 'use client' everywhere because older patterns\n\nSee /references/server-components-deep-dive.md for more.\n```\n\n---\n\n### Anti-Pattern: Missing \"When NOT to Use\"\n\n**Problem**: Skills activate on false positives\n\n**Example - Without negatives**:\n```yaml\ndescription: Processes images using computer vision techniques\n```\nActivates for: image resizing, image generation, image editing, OCR, face detection, etc.\n\n**Example - With negatives**:\n```yaml\ndescription: Semantic image search using CLIP embeddings. Use for finding similar images, zero-shot classification. NOT for image generation, editing, or OCR. NOT for counting objects or fine-grained classification.\n```\n\n**Pattern**: Always include \"NOT for X, Y, Z\" to prevent false activation.\n\n---\n\n### Anti-Pattern: No Validation Script\n\n**Problem**: Skill gives instructions but no way to check correctness\n\n**Better**: Include validation\n\n```python\n# scripts/validate.py\ndef validate_setup():\n    \"\"\"Check if environment is configured correctly.\"\"\"\n    checks = {\n        \"Node version\": check_node_version(),\n        \"Dependencies\": check_dependencies(),\n        \"API keys\": check_api_keys(),\n    }\n    \n    for name, passed in checks.items():\n        print(f\"{'‚úÖ' if passed else '‚ùå'} {name}\")\n    \n    return all(checks.values())\n```\n\n---\n\n### Anti-Pattern: Overly Permissive Tools\n\n**Bad**:\n```yaml\nallowed-tools: Bash\n```\n\n**Why**: Can execute ANY bash command\n\n**Better**:\n```yaml\nallowed-tools: Bash(git:*,npm:run,npm:install),Read,Write\n```\n\n**Principle**: Least privilege - only grant what's needed\n\n---\n\n## Temporal Knowledge Patterns\n\nWhen documenting anti-patterns, always include:\n\n1. **Timeline**: When was this practice common?\n2. **Why deprecated**: What replaced it and why?\n3. **LLM confusion**: Why will LLMs suggest the old pattern?\n4. **Migration path**: How to update from old to new?\n\n**Template**:\n```markdown\n### Anti-Pattern: [Pattern Name]\n\n**Used**: [Date range]\n**Replaced by**: [New approach]\n**Why deprecated**: [Reason]\n\n**Old way**:\n[code example]\n\n**New way**:\n[code example]\n\n**LLM mistake**: [Why LLM suggests old pattern]\n**How to detect**: [Validation rule]\n```\n\n---\n\n---\n\n## Real-World Failure Case Studies\n\n### Case Study 1: The Photo Expert Explosion\n\n**Skill**: `photo-expert` (v1.0)\n**Problem**: Single skill for ALL photo operations\n\n**Symptoms**:\n- Activated on \"photo\" anywhere in query\n- 800+ lines of instructions\n- Slow loading, high token usage\n- Wrong advice given (composition advice when user wanted color theory)\n\n**Root Cause**: Everything Skill anti-pattern\n\n**Resolution**: Split into 5 focused skills:\n- `clip-aware-embeddings` - semantic search\n- `photo-composition-critic` - aesthetic analysis\n- `color-theory-palette-harmony-expert` - color science\n- `collage-layout-expert` - arrangement algorithms\n- `event-detection-temporal-intelligence-expert` - clustering\n\n**Lesson**: One domain ‚â† one skill. Split by expertise type.\n\n---\n\n### Case Study 2: The Phantom MCP\n\n**Skill**: `github-workflow-helper` (v1.1)\n**Problem**: Referenced MCP server that didn't exist\n\n**SKILL.md said**:\n```markdown\nUse the included MCP server for GitHub API access.\nRun: `npx github-helper-mcp`\n```\n\n**Reality**: No `mcp-server/` directory existed\n\n**Symptoms**:\n- Claude confidently told users to run non-existent commands\n- Users filed bug reports\n- Trust in skill ecosystem damaged\n\n**Root Cause**: Reference Illusion anti-pattern\n\n**Resolution**:\n1. Added `check_self_contained.py` to detect phantom tools\n2. Either create the MCP or remove the reference\n3. Added validation to CI\n\n**Lesson**: Don't promise tools you don't deliver.\n\n---\n\n### Case Study 3: The Time Bomb\n\n**Skill**: `react-hooks-expert` (v2.0)\n**Problem**: Temporal knowledge became stale\n\n**Original content (2023)**:\n```markdown\nUse useEffect with empty deps for componentDidMount behavior\n```\n\n**By 2024**: This caused issues with React 18 Strict Mode double-mounting\n\n**Symptoms**:\n- Users followed advice ‚Üí got bugs\n- Skill became actively harmful\n- No CHANGELOG to track when content was written\n\n**Root Cause**: Missing temporal knowledge markers\n\n**Resolution**:\n```markdown\n## Temporal Context\n- **Pre-React 18**: useEffect with [] = componentDidMount\n- **React 18+**: useEffect with [] runs TWICE in dev (Strict Mode)\n- **Current best practice**: Use refs for \"run once\" patterns\n```\n\n**Lesson**: Date your knowledge. Update quarterly.\n\n---\n\n### Case Study 4: The Activation Black Hole\n\n**Skill**: `api-design-expert` (v1.0)\n**Problem**: Never activated when needed\n\n**Description**:\n```yaml\ndescription: Expert guidance for API design\n```\n\n**Symptoms**:\n- User: \"How should I structure my REST endpoints?\"\n- Skill: *silence*\n- User confused why skill existed but never helped\n\n**Root Cause**: Missing Exclusions + no keywords\n\n**Resolution**:\n```yaml\ndescription: REST/GraphQL API design patterns. Activate on \"API design\",\n\"endpoint structure\", \"REST architecture\", \"GraphQL schema\".\nNOT for API implementation, SDK generation, or documentation.\n```\n\n**Lesson**: Generic descriptions = zero activations\n\n---\n\n## Contributing\n\nWhen you discover a new anti-pattern:\n\n1. Document what looks right but is wrong\n2. Explain the fundamental reason it's wrong\n3. Show the correct approach\n4. Include temporal context (when did this change?)\n5. Note why LLMs make this mistake\n6. Add detection/validation if possible\n\n**Remember**: The goal is to encode the knowledge that separates \"it compiles\" from \"it's correct\" - the shibboleths that reveal expertise.\n"
        },
        {
          "name": "mcp_vs_scripts.md",
          "type": "file",
          "path": "skill-coach/references/mcp_vs_scripts.md",
          "size": 22397,
          "content": "# Skills vs Agents vs MCPs vs Scripts: An Architectural Decision Guide\n\n## TL;DR\n\n**Use Skills** for: Domain expertise, anti-patterns, decision trees (no runtime state)\n**Use Agents** for: Multi-step workflows needing tool orchestration and autonomy\n**Use MCPs** for: External APIs, auth boundaries, stateful connections\n**Use Scripts** for: Local, stateless operations with no auth\n\n## The Philosophy\n\n> \"MCP's job isn't to abstract reality for the agent; it's to manage the auth, networking, and security boundaries and then get out of the way.\"\n>\n> ‚Äî Shrivu Shankar, \"How I Use Every Claude Code Feature\"\n\nEach tool serves a distinct purpose:\n\n- **Skills** encode domain expertise and decision trees without runtime state\n- **Agents** orchestrate multi-step workflows with tool autonomy\n- **MCPs** manage auth boundaries and external service connections\n- **Scripts** handle local, stateless operations\n\nNone is inherently \"better\" - they solve different problems at different layers.\n\n## Decision Matrix\n\n```\n                           ‚îÇ Expertise ‚îÇ Multi-step ‚îÇ Runtime ‚îÇ Local ‚îÇ Remote ‚îÇ Auth ‚îÇ Decision\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nCLIP anti-patterns         ‚îÇ ‚úì         ‚îÇ            ‚îÇ         ‚îÇ       ‚îÇ        ‚îÇ      ‚îÇ Skill\nCode review workflow       ‚îÇ           ‚îÇ ‚úì          ‚îÇ ‚úì       ‚îÇ       ‚îÇ        ‚îÇ      ‚îÇ Agent\nJSON parsing               ‚îÇ           ‚îÇ            ‚îÇ         ‚îÇ ‚úì     ‚îÇ        ‚îÇ      ‚îÇ Script\nAWS S3 operations          ‚îÇ           ‚îÇ            ‚îÇ         ‚îÇ       ‚îÇ ‚úì      ‚îÇ ‚úì    ‚îÇ MCP\nDatabase queries           ‚îÇ           ‚îÇ            ‚îÇ ‚úì       ‚îÇ       ‚îÇ ‚úì      ‚îÇ ‚úì    ‚îÇ MCP\nPR creation workflow       ‚îÇ           ‚îÇ ‚úì          ‚îÇ ‚úì       ‚îÇ       ‚îÇ        ‚îÇ      ‚îÇ Agent\nGit operations             ‚îÇ           ‚îÇ            ‚îÇ         ‚îÇ ‚úì     ‚îÇ        ‚îÇ      ‚îÇ Script\nJira API                   ‚îÇ           ‚îÇ            ‚îÇ         ‚îÇ       ‚îÇ ‚úì      ‚îÇ ‚úì    ‚îÇ MCP\nFramework evolution guide  ‚îÇ ‚úì         ‚îÇ            ‚îÇ         ‚îÇ       ‚îÇ        ‚îÇ      ‚îÇ Skill\nImage resizing             ‚îÇ           ‚îÇ            ‚îÇ         ‚îÇ ‚úì     ‚îÇ        ‚îÇ      ‚îÇ Script\nTesting pipeline           ‚îÇ           ‚îÇ ‚úì          ‚îÇ ‚úì       ‚îÇ       ‚îÇ        ‚îÇ      ‚îÇ Agent\nWebSocket client           ‚îÇ           ‚îÇ            ‚îÇ ‚úì       ‚îÇ       ‚îÇ ‚úì      ‚îÇ ‚úì    ‚îÇ MCP\nPDF generation             ‚îÇ           ‚îÇ            ‚îÇ         ‚îÇ ‚úì     ‚îÇ        ‚îÇ      ‚îÇ Script\nGitHub API                 ‚îÇ           ‚îÇ            ‚îÇ         ‚îÇ       ‚îÇ ‚úì      ‚îÇ ‚úì    ‚îÇ MCP\nFile organization          ‚îÇ           ‚îÇ            ‚îÇ         ‚îÇ ‚úì     ‚îÇ        ‚îÇ      ‚îÇ Script\n```\n\n**Legend:**\n- **Expertise**: Domain knowledge, anti-patterns, decision trees\n- **Multi-step**: Orchestrates multiple operations autonomously\n- **Runtime**: Maintains state across operations\n- **Local**: File system operations\n- **Remote**: External service calls\n- **Auth**: Requires authentication/authorization\n\n## Use Skills When...\n\n### ‚úÖ Domain Expertise Needed\n\n```yaml\n# .claude/skills/clip-aware-embeddings/SKILL.md\n---\nname: clip-aware-embeddings\ndescription: CLIP semantic search expertise. Use for image-text matching, zero-shot classification. NOT for counting, fine-grained classification, spatial reasoning.\n---\n\n## When NOT to Use CLIP\n\n### Anti-Pattern: Using CLIP to Count Objects\n**Why wrong**: CLIP's architecture cannot preserve spatial information\n**What to do**: Use DETR or Faster R-CNN for object detection\n**How to detect**: If query contains \"how many\" or \"count\"\n```\n\n**Why Skill**:\n- No runtime state needed\n- Encodes expert knowledge (shibboleths)\n- Prevents common mistakes via anti-patterns\n- Available across all conversations\n\n### ‚úÖ Framework Evolution Knowledge\n\n```yaml\n# .claude/skills/react-performance-expert/SKILL.md\n---\nname: react-performance-expert\ndescription: React performance optimization expertise. Pre-2024 patterns vs modern best practices. NOT for Vue/Angular.\n---\n\n## Evolution Timeline\n- Pre-2019: Class components + shouldComponentUpdate\n- 2019-2023: Hooks + React.memo\n- 2024+: React Compiler (automatic memoization)\n\n## Watch For\nLLMs may suggest manual useMemo/useCallback when React Compiler handles it automatically.\n```\n\n**Why Skill**:\n- Captures temporal knowledge\n- Warns about deprecated patterns\n- No execution needed, just guidance\n\n### ‚úÖ Architectural Decision Trees\n\n```yaml\n# .claude/skills/state-management-advisor/SKILL.md\n---\nname: state-management-advisor\ndescription: State management decision guidance. Use when choosing Redux vs Zustand vs Context. NOT for implementation.\n---\n\n## Decision Tree\n- Simple boolean/string state shared by 2-3 components ‚Üí Context\n- Complex state with actions (todo list, shopping cart) ‚Üí Zustand\n- Time-travel debugging required ‚Üí Redux Toolkit\n- NEVER: Redux for simple state\n```\n\n**Why Skill**:\n- Decision logic, not code templates\n- Prevents overengineering\n- No tools needed, just expertise\n\n## Use Agents When...\n\n### ‚úÖ Multi-Step Workflows with Tool Orchestration\n\n```python\n# Agents orchestrate multiple tools autonomously\n# Example: Code Review Agent\n\nfrom anthropic import Agent\n\nreview_agent = Agent(\n    name=\"code-reviewer\",\n    instructions=\"\"\"\n    1. Read modified files\n    2. Run linter and tests\n    3. Check for security issues\n    4. Generate review comments\n    5. Create summary report\n    \"\"\",\n    tools=[\"Read\", \"Bash\", \"Grep\", \"Write\"]\n)\n\n# Agent autonomously:\n# - Decides which files to read\n# - Runs appropriate tests\n# - Generates contextual feedback\n```\n\n**Why Agent**:\n- Multiple steps requiring decisions\n- Needs tool access (Read, Bash, etc.)\n- Maintains context across operations\n- Autonomy in execution order\n\n### ‚úÖ Task Decomposition and Parallel Execution\n\n```python\n# Example: Testing Pipeline Agent\n\ntesting_agent = Agent(\n    name=\"test-runner\",\n    instructions=\"\"\"\n    1. Identify all test files\n    2. Run unit tests in parallel\n    3. Run integration tests\n    4. Generate coverage report\n    5. Fail fast on critical errors\n    \"\"\",\n    tools=[\"Bash\", \"Read\", \"Write\"]\n)\n\n# Agent manages:\n# - Parallel test execution\n# - State aggregation (pass/fail counts)\n# - Conditional logic (fail fast)\n```\n\n**Why Agent**:\n- Orchestrates multiple bash commands\n- Maintains state (test results)\n- Makes runtime decisions (fail fast)\n\n### ‚úÖ Complex Debugging Workflows\n\n```python\n# Example: Bug Investigation Agent\n\ndebug_agent = Agent(\n    name=\"debugger\",\n    instructions=\"\"\"\n    1. Search codebase for error patterns\n    2. Read relevant files\n    3. Identify root cause\n    4. Propose fixes\n    5. Test proposed solutions\n    \"\"\",\n    tools=[\"Grep\", \"Read\", \"Edit\", \"Bash\"]\n)\n\n# Agent autonomously:\n# - Searches strategically\n# - Follows leads based on findings\n# - Iterates on hypotheses\n```\n\n**Why Agent**:\n- Non-linear investigation path\n- Requires multiple tool types\n- Runtime decision-making\n- Iterative refinement\n\n### ‚ùå When NOT to Use Agents\n\n**Don't use Agent for**:\n- Single operations (just use tool directly)\n- Pure expertise (use Skill instead)\n- External API calls (use MCP)\n- Simple scripts (use Script)\n\n**Anti-Pattern: Agent for Static Knowledge**\n```python\n# BAD: Agent that just returns information\nAgent(\n    name=\"python-docs\",\n    instructions=\"Answer Python questions\",\n    tools=[]\n)\n# BETTER: Use a Skill with /references/ to documentation\n```\n\n## Use Scripts When...\n\n### ‚úÖ Local File Operations\n\n```python\n# scripts/organize_photos.py\nimport os\nimport shutil\nfrom datetime import datetime\n\ndef organize_by_date(source_dir):\n    for file in os.listdir(source_dir):\n        if file.lower().endswith(('.jpg', '.png')):\n            creation_time = os.path.getctime(os.path.join(source_dir, file))\n            date = datetime.fromtimestamp(creation_time).strftime('%Y-%m')\n            os.makedirs(f\"{source_dir}/{date}\", exist_ok=True)\n            shutil.move(f\"{source_dir}/{file}\", f\"{source_dir}/{date}/{file}\")\n```\n\n**Why script**: No auth, no external APIs, pure file operations.\n\n### ‚úÖ Stateless Transformations\n\n```python\n# scripts/convert_markdown.py\nimport markdown\nimport sys\n\nwith open(sys.argv[1]) as f:\n    html = markdown.markdown(f.read())\n    print(html)\n```\n\n**Why script**: Input ‚Üí Output, no state, no network.\n\n### ‚úÖ CLI Wrappers\n\n```python\n# scripts/git_summary.py\nimport subprocess\nimport json\n\ndef get_commit_summary(since=\"1 week ago\"):\n    result = subprocess.run(\n        ['git', 'log', f'--since={since}', '--oneline'],\n        capture_output=True,\n        text=True\n    )\n    return result.stdout.split('\\n')\n\nprint(json.dumps(get_commit_summary()))\n```\n\n**Why script**: Wrapping existing CLI tools, no auth needed.\n\n### ‚úÖ Batch Processing\n\n```bash\n# scripts/batch_resize.sh\n#!/bin/bash\nfor img in *.jpg; do\n    convert \"$img\" -resize 800x600 \"resized_$img\"\ndone\n```\n\n**Why script**: Simple, local, no coordination needed.\n\n## Use MCPs When...\n\n### ‚úÖ External APIs with Auth\n\n```python\n# Good MCP example\nfrom mcp.server import Server\nfrom anthropic import Anthropic\n\napp = Server(\"claude-api\")\nclient = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n\n@app.tool()\nasync def ask_claude(prompt: str) -> str:\n    \"\"\"Query Claude API with authentication.\"\"\"\n    message = client.messages.create(\n        model=\"claude-sonnet-4-20250514\",\n        max_tokens=1024,\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return message.content[0].text\n```\n\n**Why MCP**: \n- Authentication (API key)\n- External service\n- Standardized error handling\n- Rate limiting concerns\n\n### ‚úÖ Stateful Connections\n\n```python\n# Database MCP\nfrom mcp.server import Server\nimport psycopg2\n\napp = Server(\"postgres-mcp\")\nconn = None  # Persistent connection\n\n@app.tool()\nasync def connect_db(connection_string: str):\n    \"\"\"Establish database connection.\"\"\"\n    global conn\n    conn = psycopg2.connect(connection_string)\n    return \"Connected\"\n\n@app.tool()\nasync def query_db(sql: str):\n    \"\"\"Execute query on open connection.\"\"\"\n    if not conn:\n        raise Exception(\"Not connected\")\n    cursor = conn.cursor()\n    cursor.execute(sql)\n    return cursor.fetchall()\n```\n\n**Why MCP**: \n- Maintains state (connection)\n- Multiple related operations\n- Connection pooling\n- Transaction management\n\n### ‚úÖ Real-Time Data\n\n```python\n# Stock price MCP\nfrom mcp.server import Server\nimport websocket\nimport json\n\napp = Server(\"stock-prices\")\nws = None\n\n@app.tool()\nasync def subscribe_stock(ticker: str):\n    \"\"\"Subscribe to real-time stock updates.\"\"\"\n    global ws\n    ws = websocket.WebSocketApp(\n        f\"wss://api.example.com/stocks/{ticker}\",\n        on_message=handle_message\n    )\n    ws.run_forever()\n```\n\n**Why MCP**: WebSocket connection, real-time updates, persistent connection.\n\n### ‚úÖ Multiple Related Tools\n\n```python\n# GitHub MCP\nfrom mcp.server import Server\nimport requests\n\napp = Server(\"github-api\")\nBASE = \"https://api.github.com\"\nTOKEN = os.getenv(\"GITHUB_TOKEN\")\nHEADERS = {\"Authorization\": f\"token {TOKEN}\"}\n\n@app.tool()\nasync def list_repos(org: str):\n    \"\"\"List organization repositories.\"\"\"\n    r = requests.get(f\"{BASE}/orgs/{org}/repos\", headers=HEADERS)\n    return r.json()\n\n@app.tool()\nasync def create_issue(repo: str, title: str, body: str):\n    \"\"\"Create GitHub issue.\"\"\"\n    r = requests.post(\n        f\"{BASE}/repos/{repo}/issues\",\n        headers=HEADERS,\n        json={\"title\": title, \"body\": body}\n    )\n    return r.json()\n\n@app.tool()\nasync def get_pr(repo: str, pr_number: int):\n    \"\"\"Get pull request details.\"\"\"\n    r = requests.get(f\"{BASE}/repos/{repo}/pulls/{pr_number}\", headers=HEADERS)\n    return r.json()\n```\n\n**Why MCP**: \n- All tools share auth\n- Related domain (GitHub)\n- Standardized error handling\n- Single configuration\n\n## Anti-Patterns\n\n### ‚ùå Skill for Runtime Execution\n\n**Bad**:\n```yaml\n# .claude/skills/file-organizer/SKILL.md\n---\nname: file-organizer\ndescription: Organizes files by date\nallowed-tools: Bash,Read,Write\n---\n\nRun this script to organize files:\npython scripts/organize.py /path/to/files\n```\n\n**Why it's wrong**: Skills provide expertise, not execution. Use Script or Agent for actual work.\n\n**What to do instead**:\n- **Skill**: Provide decision tree (\"When to organize by date vs by type\")\n- **Script**: Do the actual organizing\n- **Agent**: Orchestrate multiple organization strategies\n\n### ‚ùå Agent for Static Knowledge\n\n**Bad**:\n```python\n# Agent that just returns information\nAgent(\n    name=\"python-syntax-helper\",\n    instructions=\"Answer Python syntax questions\",\n    tools=[]\n)\n```\n\n**Why it's wrong**: No tools needed, no multi-step workflow, just knowledge lookup.\n\n**What to do instead**: Use a Skill with /references/ to documentation.\n\n### ‚ùå Agent for Single Operations\n\n**Bad**:\n```python\n# Agent that just runs one command\nAgent(\n    name=\"test-runner\",\n    instructions=\"Run pytest on the codebase\",\n    tools=[\"Bash\"]\n)\n```\n\n**Why it's wrong**: Single bash command doesn't justify agent overhead.\n\n**What to do instead**: Just run `pytest` directly via Bash tool.\n\n### ‚ùå MCP for Local Operations\n\n**Bad**:\n```python\n# mcp_server_json.py - OVERKILL\nfrom mcp.server import Server\nimport json\n\napp = Server(\"json-parser\")\n\n@app.tool()\nasync def parse_json(file_path: str):\n    with open(file_path) as f:\n        return json.load(f)\n\n@app.tool()\nasync def write_json(file_path: str, data: dict):\n    with open(file_path, 'w') as f:\n        json.dump(data, f, indent=2)\n```\n\n**Better**:\n```python\n# scripts/json_utils.py\nimport json\nimport sys\n\n# Parse\nwith open(sys.argv[1]) as f:\n    print(json.dumps(json.load(f), indent=2))\n```\n\n**Why**: No auth, no network, no state. Script is simpler.\n\n### ‚ùå Script for Authenticated APIs\n\n**Bad**:\n```python\n# scripts/query_jira.py\nimport requests\n\n# API key hardcoded or in environment - not great!\nresponse = requests.get(\n    \"https://company.atlassian.net/rest/api/3/issue/PROJ-123\",\n    auth=(\"user@example.com\", os.getenv(\"JIRA_TOKEN\"))\n)\nprint(response.json())\n```\n\n**Why problematic**:\n- Credentials in script or environment\n- No error handling\n- No rate limiting\n- Can't compose with other Jira operations\n- Each agent invocation re-authenticates\n\n**Better**: MCP with proper auth flow, connection reuse, error handling.\n\n### ‚ùå Overengineered MCP\n\n**Bad**:\n```python\n# mcp_server_calculator.py - TOO SIMPLE FOR MCP\nfrom mcp.server import Server\n\napp = Server(\"calculator\")\n\n@app.tool()\nasync def add(a: float, b: float) -> float:\n    return a + b\n\n@app.tool()\nasync def subtract(a: float, b: float) -> float:\n    return a - b\n```\n\n**Better**: Claude can do this natively. No tool needed.\n\n## Evolution Path\n\nGood architecture evolves through layers of abstraction:\n\n### Stage 0: Direct Tool Use\n```bash\n# Just use Claude's tools directly\nRead file ‚Üí Edit file ‚Üí Bash command\n```\n\n### Stage 1: Single Script\n```bash\n# fetch_data.py\nimport requests\ndata = requests.get(\"https://api.example.com/data\").json()\nprint(data)\n```\n\n**Use when**: One-off operation, local, no auth\n\n### Stage 2: Multiple Scripts\n```bash\nscripts/\n‚îú‚îÄ‚îÄ fetch_data.py\n‚îú‚îÄ‚îÄ process_data.py\n‚îî‚îÄ‚îÄ upload_results.py\n```\n\n**Use when**: Related operations, still local, no orchestration needed\n\n### Stage 3: Skill for Expertise\n```yaml\n# .claude/skills/data-pipeline-expert/SKILL.md\n---\nname: data-pipeline-expert\ndescription: Data pipeline anti-patterns and decision trees\n---\n\n## When to Batch Process\n- Data size > 100MB ‚Üí Batch with pagination\n- Real-time updates needed ‚Üí Use streaming instead\n\n## Anti-Patterns\n- Processing entire dataset in memory ‚Üí OOM errors\n```\n\n**Use when**: You have domain expertise to encode, prevent common mistakes\n\n### Stage 4: Agent for Orchestration\n```python\n# When scripts need coordination\nAgent(\n    name=\"pipeline-runner\",\n    instructions=\"\"\"\n    1. Validate data format\n    2. Run fetch_data.py\n    3. If fetch succeeds, run process_data.py\n    4. If validation passes, run upload_results.py\n    5. Generate summary report\n    \"\"\",\n    tools=[\"Bash\", \"Read\", \"Write\"]\n)\n```\n\n**Use when**: Multi-step workflow with runtime decisions, state management\n\n### Stage 5: Helper Library\n```python\n# lib/data_client.py\nclass DataClient:\n    def fetch(self): ...\n    def process(self): ...\n    def upload(self): ...\n\n# scripts/run_pipeline.py\nfrom lib.data_client import DataClient\nclient = DataClient()\nclient.fetch()\nclient.process()\nclient.upload()\n```\n\n**Use when**: Shared logic across multiple scripts, testability needed\n\n### Stage 6: MCP Server\n```python\n# Only when you need:\n# - Auth management\n# - Multiple agents using it\n# - External API access\n# - Connection pooling\n\nfrom mcp.server import Server\nfrom lib.data_client import DataClient\n\napp = Server(\"data-pipeline\")\nclient = DataClient()\n\n@app.tool()\nasync def fetch_data():\n    return client.fetch()\n# ... etc\n```\n\n**Use when**: External APIs, auth boundaries, stateful connections\n\n**The Rule**: Start simple. Each stage adds complexity - only evolve when the complexity pays for itself.\n\n## Performance Considerations\n\n### Skills\n- ‚úÖ Zero runtime overhead (loaded as context)\n- ‚úÖ Prevents mistakes before execution\n- ‚úÖ Cached across conversations\n- ‚ùå Takes up context window\n- ‚ùå No execution capability\n\n### Agents\n- ‚úÖ Autonomy reduces back-and-forth\n- ‚úÖ Parallel tool execution\n- ‚úÖ Context maintained across steps\n- ‚ùå Higher token usage\n- ‚ùå More complex debugging\n\n### Scripts\n- ‚úÖ Zero latency overhead\n- ‚úÖ Simple debugging\n- ‚úÖ No network calls for local ops\n- ‚ùå No connection reuse\n- ‚ùå No shared state across calls\n\n### MCPs\n- ‚úÖ Connection pooling\n- ‚úÖ Shared state\n- ‚úÖ Standardized errors\n- ‚ùå Network overhead\n- ‚ùå More complex debugging\n\n## Security Considerations\n\n### Scripts\n- ‚úÖ No credential management complexity\n- ‚úÖ Run in user context\n- ‚ùå Credentials in environment or hardcoded\n- ‚ùå Each invocation re-authenticates\n\n### MCPs\n- ‚úÖ Centralized credential management\n- ‚úÖ OAuth flows\n- ‚úÖ Connection reuse (fewer auth requests)\n- ‚ùå More attack surface\n- ‚ùå Requires secure credential storage\n\n## Testing\n\n### Scripts\n```bash\n# Easy to test\npython scripts/process_data.py test_input.json\n```\n\n### MCPs\n```python\n# MCP Inspector or custom client needed\nfrom mcp.client import Client\n\nasync def test():\n    async with Client(\"http://localhost:8000\") as client:\n        result = await client.call_tool(\"process_data\", {\"input\": \"test\"})\n        assert result == expected\n```\n\n## Documentation Recommendations\n\nIn your skill's SKILL.md:\n\n```markdown\n## Tools Required\n\nThis skill uses:\n- **Scripts** for local processing: `/scripts/validate.py`\n- **MCP** for GitHub API access: Requires `github-mcp` installed\n\n### Setup MCP\n\n```bash\n/plugin marketplace add github-mcp\n```\n\nOr use CLI directly if GitHub MCP unavailable:\n```bash\ngh issue list\n```\n```\n\n## Decision Flowchart\n\n```\nDo you need to encode expertise/anti-patterns?\n‚îú‚îÄ Yes ‚Üí Skill (with decision trees, no execution)\n‚îî‚îÄ No ‚Üí Is it multi-step with runtime decisions?\n    ‚îú‚îÄ Yes ‚Üí Agent (orchestrates tools autonomously)\n    ‚îî‚îÄ No ‚Üí Is it a local operation?\n        ‚îú‚îÄ Yes ‚Üí Script (stateless, no auth)\n        ‚îî‚îÄ No ‚Üí Does it require auth/external API?\n            ‚îú‚îÄ Yes ‚Üí MCP Server (manages auth boundaries)\n            ‚îî‚îÄ No ‚Üí Script (with curl/CLI)\n```\n\n**Key Questions:**\n1. **Expertise?** ‚Üí Skill (anti-patterns, decision trees)\n2. **Multi-step + decisions?** ‚Üí Agent (tool orchestration)\n3. **External API + auth?** ‚Üí MCP (connection management)\n4. **Everything else?** ‚Üí Script (simple execution)\n\n## Real-World Examples\n\n### Good: CLIP Limitations as Skill\n- Domain expertise (what NOT to use CLIP for)\n- Anti-patterns with alternatives\n- No runtime execution needed\n- Prevents common mistakes before coding\n\n### Good: Code Review as Agent\n- Multi-step workflow (read ‚Üí lint ‚Üí test ‚Üí summarize)\n- Runtime decisions (which files to read)\n- Tool orchestration (Read, Bash, Grep, Write)\n- Autonomous execution\n\n### Good: Git as Script\n- CLI wrapper\n- Local operations\n- No auth needed\n- Simple subprocess calls\n\n### Good: Playwright as MCP\n- Complex browser automation\n- Stateful (browser context)\n- Multiple related operations\n- Security boundaries (sandbox)\n\n### Good: Framework Evolution as Skill\n- Temporal knowledge (pre-2024 vs 2024+)\n- Warns about deprecated patterns\n- Decision trees for migration\n- No execution needed\n\n### Good: Testing Pipeline as Agent\n- Orchestrates test suite\n- Parallel execution management\n- State aggregation (pass/fail counts)\n- Fail-fast logic\n\n### Good: Image Processing as Script\n- Local file operations\n- Stateless transformations\n- No network needed\n- Simple input/output\n\n### Good: AWS SDK as MCP\n- Many related services\n- Auth required\n- Connection pooling\n- Error handling standardization\n\n## Summary\n\n**Skills win on**:\n- Domain expertise encoding\n- Anti-pattern prevention\n- Zero runtime overhead\n- Context persistence\n- Decision tree guidance\n\n**Agents win on**:\n- Multi-step orchestration\n- Tool autonomy\n- Runtime decision-making\n- Workflow automation\n- Parallel execution\n\n**Scripts win on**:\n- Simplicity\n- Local operations\n- No dependencies\n- Easy testing\n- Zero overhead\n\n**MCPs win on**:\n- Auth management\n- Connection reuse\n- Multiple related operations\n- Stateful interactions\n- Standardization\n\n**The Hierarchy**:\n1. **Start with**: Direct tool use (Read, Edit, Bash)\n2. **Extract to**: Script (when operation repeats)\n3. **Add**: Skill (when expertise/anti-patterns emerge)\n4. **Coordinate with**: Agent (when multi-step workflows appear)\n5. **Promote to**: MCP (when auth/external APIs needed)\n\n**The Rule**: Each layer adds complexity. Only add layers when the value justifies the cost.\n\n---\n\n## Further Reading\n\n- `/references/antipatterns.md` - \"MCP for Everything\" anti-pattern\n- `/examples/good/mcp-vs-script-comparison/` - Side-by-side examples\n- Model Context Protocol docs: https://modelcontextprotocol.io/\n"
        },
        {
          "name": "scoring-rubric.md",
          "type": "file",
          "path": "skill-coach/references/scoring-rubric.md",
          "size": 3488,
          "content": "# Skill Scoring Rubric\n\nQuantitative metrics for evaluating skill quality. Score each category 0-10.\n\n## Scoring Categories\n\n### 1. Activation Precision (0-10)\nHow accurately does the skill activate?\n\n| Score | Criteria |\n|-------|----------|\n| 0-2 | No keywords, vague description, activates randomly |\n| 3-4 | Some keywords, missing NOT clause, many false positives |\n| 5-6 | Good keywords + NOT clause, occasional misfires |\n| 7-8 | Precise activation, clear boundaries, &lt;10% false positives |\n| 9-10 | Perfect activation, comprehensive exclusions, &lt;2% false positives |\n\n**Quick check**: Count (correct activations) / (total queries) for 10 test queries\n\n### 2. Domain Expertise Depth (0-10)\nHow much expert knowledge is encoded?\n\n| Score | Criteria |\n|-------|----------|\n| 0-2 | Generic advice, could be Googled easily |\n| 3-4 | Some domain knowledge, no anti-patterns |\n| 5-6 | Good expertise, 1-2 anti-patterns, some shibboleths |\n| 7-8 | Deep expertise, 3+ anti-patterns, decision trees |\n| 9-10 | Expert-level with temporal knowledge, edge cases, and shibboleths |\n\n**Quick check**: Count shibboleths + anti-patterns + decision trees\n\n### 3. Progressive Disclosure (0-10)\nHow well is information layered?\n\n| Score | Criteria |\n|-------|----------|\n| 0-2 | Everything in one file, &gt;500 lines, no structure |\n| 3-4 | Some structure, still too dense |\n| 5-6 | Core in SKILL.md, some refs, ~300-500 lines |\n| 7-8 | Clean SKILL.md &lt;300 lines, refs for deep dives |\n| 9-10 | Optimal: &lt;200 line core, refs load on-demand |\n\n**Quick check**: `wc -l SKILL.md` ‚Üí Target &lt;300\n\n### 4. Self-Containment (0-10)\nDoes the skill ship working tools?\n\n| Score | Criteria |\n|-------|----------|\n| 0-2 | Instructions only, user must implement everything |\n| 3-4 | Mentions tools but doesn't include them |\n| 5-6 | Has scripts but they're templates |\n| 7-8 | Working scripts, no phantom tools |\n| 9-10 | Complete tooling: scripts, validation, maybe MCP |\n\n**Quick check**: Run `check_self_contained.py`\n\n### 5. Maintainability (0-10)\nHow easy is the skill to update?\n\n| Score | Criteria |\n|-------|----------|\n| 0-2 | No CHANGELOG, no versioning, no structure |\n| 3-4 | Basic structure, no versioning |\n| 5-6 | Has CHANGELOG, some documentation |\n| 7-8 | Versioned, documented, modular references |\n| 9-10 | SemVer, complete changelog, validation scripts |\n\n**Quick check**: Has CHANGELOG.md? Uses semantic versioning?\n\n---\n\n## Composite Score\n\n**Formula**: (Œ£ category scores) / 5\n\n| Total | Grade | Meaning |\n|-------|-------|---------|\n| 9-10 | A | Production-ready, exemplary |\n| 7-8.9 | B | Good quality, minor improvements possible |\n| 5-6.9 | C | Functional but needs work |\n| 3-4.9 | D | Significant issues, needs revision |\n| 0-2.9 | F | Not ready for use |\n\n## Example Evaluation\n\n```\nSkill: clip-aware-embeddings\n------------------------------\nActivation Precision:    9/10 (clear NOT clause, specific triggers)\nDomain Expertise Depth:  8/10 (shibboleths, anti-patterns, temporal)\nProgressive Disclosure:  8/10 (~150 line core, refs for details)\nSelf-Containment:        7/10 (working scripts, no MCP)\nMaintainability:         7/10 (versioned, has CHANGELOG)\n------------------------------\nComposite Score:         7.8/10 (Grade: B)\n```\n\n## Automation\n\nRun validation scripts for automated scoring:\n```bash\n# Structure + content checks\npython scripts/validate_skill.py /path/to/skill\n\n# Self-containment check\npython scripts/check_self_contained.py /path/to/skill\n```\n"
        },
        {
          "name": "self-contained-tools.md",
          "type": "file",
          "path": "skill-coach/references/self-contained-tools.md",
          "size": 8974,
          "content": "# Self-Contained Tools\n\nImplementation patterns for scripts, MCP servers, and subagents that make skills immediately useful.\n\n## Philosophy\n\n**The best skill is one where the user can start working immediately.**\n\n| Approach | Result |\n|----------|--------|\n| \"Here's how to build a CLIP embedder\" | User spends 2 hours implementing |\n| \"Here's a working CLIP embedder, run it\" | User is productive in 2 minutes |\n\nSkills should encode expertise AND provide working tools to apply that expertise.\n\n---\n\n## Scripts\n\n### When to Include Scripts\n\n- Skill describes repeatable operations (analysis, validation, transformation)\n- Domain has specific algorithms that should be implemented correctly\n- Pre-flight checks would prevent common errors\n\n### Script Requirements\n\n1. **Actually work** - Not templates, not pseudocode\n2. **Minimal dependencies** - Prefer stdlib, document any pip/npm installs\n3. **Clear interface** - CLI args or stdin/stdout\n4. **Error handling** - Graceful failures with helpful messages\n5. **README** - How to install and run\n\n### Example: Domain Analysis Script\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nPhoto Composition Analyzer\nAnalyzes images for composition quality using rule of thirds,\nvisual weight distribution, and color harmony.\n\nUsage: python analyze_composition.py <image_path>\nDependencies: pip install pillow numpy\n\"\"\"\n\nimport sys\nfrom pathlib import Path\n\ndef analyze_composition(image_path: str) -> dict:\n    \"\"\"Analyze composition and return scores.\"\"\"\n    # Import here to give helpful error if missing\n    try:\n        from PIL import Image\n        import numpy as np\n    except ImportError:\n        print(\"Install dependencies: pip install pillow numpy\")\n        sys.exit(1)\n\n    img = Image.open(image_path)\n    # ... actual implementation ...\n\n    return {\n        \"rule_of_thirds\": 0.85,\n        \"visual_balance\": 0.72,\n        \"color_harmony\": 0.91,\n        \"overall\": 0.83\n    }\n\nif __name__ == \"__main__\":\n    if len(sys.argv) != 2:\n        print(f\"Usage: {sys.argv[0]} <image_path>\")\n        sys.exit(1)\n\n    result = analyze_composition(sys.argv[1])\n    for metric, score in result.items():\n        print(f\"{metric}: {score:.2f}\")\n```\n\n### Example: Validation Script\n\n```bash\n#!/bin/bash\n# validate_skill.sh - Pre-flight checks for skill quality\n# Usage: ./validate_skill.sh /path/to/skill\n\nSKILL_DIR=\"$1\"\n\nif [ -z \"$SKILL_DIR\" ]; then\n    echo \"Usage: $0 <skill_directory>\"\n    exit 1\nfi\n\nerrors=0\n\n# Check SKILL.md exists\nif [ ! -f \"$SKILL_DIR/SKILL.md\" ]; then\n    echo \"‚ùå Missing SKILL.md\"\n    ((errors++))\nelse\n    echo \"‚úÖ SKILL.md exists\"\nfi\n\n# Check line count\nlines=$(wc -l < \"$SKILL_DIR/SKILL.md\")\nif [ \"$lines\" -gt 500 ]; then\n    echo \"‚ö†Ô∏è  SKILL.md is $lines lines (target: &lt;500)\"\nelse\n    echo \"‚úÖ SKILL.md is $lines lines\"\nfi\n\n# Check for NOT clause in description\nif grep -q \"NOT for\" \"$SKILL_DIR/SKILL.md\"; then\n    echo \"‚úÖ Description has NOT clause\"\nelse\n    echo \"‚ùå Missing NOT clause in description\"\n    ((errors++))\nfi\n\nexit $errors\n```\n\n---\n\n## MCP Servers\n\n### When to Build an MCP\n\n- Skill needs external API access (GitHub, Figma, databases, etc.)\n- OAuth or API key authentication required\n- Stateful connections (websockets, streaming)\n- Rate limiting or caching needed\n\n### MCP Server Structure\n\n```\nmcp-server/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îî‚îÄ‚îÄ index.ts       # Server implementation\n‚îú‚îÄ‚îÄ package.json       # Dependencies and scripts\n‚îú‚îÄ‚îÄ tsconfig.json      # TypeScript config\n‚îî‚îÄ‚îÄ README.md          # Installation instructions\n```\n\n### Example: Minimal MCP Server\n\n```typescript\n// src/index.ts\nimport { Server } from \"@modelcontextprotocol/sdk/server/index.js\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\n\nconst server = new Server(\n  { name: \"my-skill-mcp\", version: \"1.0.0\" },\n  { capabilities: { tools: {} } }\n);\n\n// Define tools\nserver.setRequestHandler(\"tools/list\", async () => ({\n  tools: [\n    {\n      name: \"analyze_repo\",\n      description: \"Analyze a GitHub repository structure\",\n      inputSchema: {\n        type: \"object\",\n        properties: {\n          repo: { type: \"string\", description: \"owner/repo format\" }\n        },\n        required: [\"repo\"]\n      }\n    }\n  ]\n}));\n\nserver.setRequestHandler(\"tools/call\", async (request) => {\n  const { name, arguments: args } = request.params;\n\n  if (name === \"analyze_repo\") {\n    // Actual implementation\n    const result = await analyzeRepo(args.repo);\n    return { content: [{ type: \"text\", text: JSON.stringify(result) }] };\n  }\n\n  throw new Error(`Unknown tool: ${name}`);\n});\n\n// Start server\nconst transport = new StdioServerTransport();\nawait server.connect(transport);\n```\n\n### package.json\n\n```json\n{\n  \"name\": \"my-skill-mcp\",\n  \"version\": \"1.0.0\",\n  \"type\": \"module\",\n  \"bin\": { \"my-skill-mcp\": \"dist/index.js\" },\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"start\": \"node dist/index.js\"\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"^1.0.0\"\n  },\n  \"devDependencies\": {\n    \"typescript\": \"^5.0.0\"\n  }\n}\n```\n\n### README Template\n\n```markdown\n# My Skill MCP Server\n\nMCP server for [domain] operations.\n\n## Installation\n\n\\`\\`\\`bash\ncd mcp-server\nnpm install\nnpm run build\n\\`\\`\\`\n\n## Configuration\n\nAdd to your Claude Code MCP settings:\n\n\\`\\`\\`json\n{\n  \"mcpServers\": {\n    \"my-skill\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-server/dist/index.js\"],\n      \"env\": {\n        \"API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n\\`\\`\\`\n\n## Tools\n\n- `analyze_repo` - Analyze a GitHub repository structure\n- `fetch_issues` - Get open issues with labels\n```\n\n---\n\n## Subagents\n\n### When to Define Subagents\n\n- Skill involves multi-step workflows\n- Different phases need different tool access\n- Orchestration logic is complex enough to warrant isolation\n\n### Subagent Definition Format\n\n```markdown\n# agents/research-workflow.md\n\n## Agent: Research Coordinator\n\n### Purpose\nOrchestrate multi-source research with synthesis.\n\n### System Prompt\nYou are a research coordinator. Your job is to:\n1. Break down research questions into searchable queries\n2. Dispatch searches to appropriate sources\n3. Synthesize findings into coherent answers\n\n### Tools Required\n- WebSearch\n- WebFetch\n- Read\n- Write\n\n### Workflow\n1. Receive research question\n2. Generate 3-5 search queries\n3. Execute searches in parallel\n4. Read and extract relevant content\n5. Synthesize into final answer\n\n### Success Criteria\n- All claims have citations\n- Multiple sources corroborate findings\n- Contradictions are explicitly noted\n```\n\n### Multi-Agent Orchestration Pattern\n\n```markdown\n# agents/orchestrator.md\n\n## Pipeline: Code Review\n\n### Agents\n1. **security-scanner** - Check for vulnerabilities\n2. **style-checker** - Verify code style\n3. **architecture-reviewer** - Assess design patterns\n\n### Orchestration\n\\`\\`\\`\nparallel:\n  - security-scanner ‚Üí security_report\n  - style-checker ‚Üí style_report\nthen:\n  - architecture-reviewer(security_report, style_report) ‚Üí final_review\n\\`\\`\\`\n\n### Handoff Protocol\nEach agent produces structured output:\n- `status`: pass | warn | fail\n- `findings`: list of issues\n- `recommendations`: suggested fixes\n```\n\n---\n\n## Anti-Patterns\n\n### Phantom Tools\n**What it looks like**: SKILL.md references `scripts/analyze.py` but file doesn't exist\n\n**Why it's wrong**: Users try to run non-existent code, lose trust in skill\n\n**Fix**: Only reference tools that actually exist and work\n\n### Template Soup\n**What it looks like**: Scripts are templates with `# TODO: implement` comments\n\n**Why it's wrong**: User still has to do the implementation work\n\n**Fix**: Ship working code or don't ship at all\n\n### Dependency Hell\n**What it looks like**: Script requires 15 pip packages, specific Python version, system libraries\n\n**Why it's wrong**: Most users won't complete setup\n\n**Fix**: Minimize dependencies, prefer stdlib, document clearly\n\n### MCP Without Purpose\n**What it looks like**: MCP server for operations that could be a simple script\n\n**Why it's wrong**: Over-engineering; MCP has setup overhead\n\n**Fix**: Use MCP only when you need: auth, state, external APIs, or caching\n\n---\n\n## Checklist: Is My Skill Self-Contained?\n\n```\n‚ñ° Can a user start using this skill immediately?\n‚ñ° Are all referenced scripts/tools actually present and working?\n‚ñ° Do scripts have clear installation instructions?\n‚ñ° Do scripts handle errors gracefully?\n‚ñ° If MCP needed, is server implementation complete?\n‚ñ° If subagents needed, are prompts and workflows defined?\n‚ñ° Is there a validation script to check environment?\n‚ñ° Does README explain how to set everything up?\n```\n\n---\n\n## Examples of Self-Contained Skills\n\n| Skill | Tools Included |\n|-------|----------------|\n| clip-aware-embeddings | `scripts/validate_clip_usage.py` |\n| site-reliability-engineer | `scripts/validate-brackets.js`, `scripts/validate-liquid.js` |\n| skill-coach | `scripts/validate_skill.py` |\n\n**Goal**: Every skill with repeatable operations should have working tools.\n"
        },
        {
          "name": "shibboleths.md",
          "type": "file",
          "path": "skill-coach/references/shibboleths.md",
          "size": 3076,
          "content": "# Domain Shibboleths\n\nExpert knowledge that separates novices from experts.\n\n## What Are Shibboleths?\n\nDeep knowledge markers that reveal true expertise. Great skills encode these to prevent Claude from giving novice-level advice.\n\n## Skill Creation Shibboleths\n\n**Novice skill creator**:\n- \"I'll make a comprehensive skill that handles everything related to X\"\n- Focuses on templates and examples\n- Description: \"Helps with many things\"\n- Thinks more tools = better\n\n**Expert skill creator**:\n- \"I'll create a focused skill that encodes THIS specific expertise about X\"\n- Focuses on decision trees and anti-patterns\n- Description: \"Does A, B, C. Activate on keywords X, Y. NOT for D, E, F.\"\n- Minimal tools, knows when NOT to use the skill\n- Encodes temporal knowledge: \"Pre-2024 pattern X was common, now use Y\"\n\n## Domain Example Shibboleths\n\n### CLIP Embeddings\n\n**Novice**: \"CLIP is great for image-text matching\"\n\n**Expert**: \"CLIP fails at:\n- Counting objects\n- Fine-grained classification (specific dog breeds, car models)\n- Attribute binding ('red cube' vs 'blue sphere')\n- Spatial relationships ('left of', 'above')\n- Negation ('no dogs in image')\n\nUse instead:\n- DCSMs for compositional queries\n- PC-CLIP for geometric reasoning\n- Specialized counting models\n- Task-specific fine-tuned models\"\n\n### MCPs vs Scripts\n\n**Novice**: \"MCPs are better because they're more powerful\"\n\n**Expert**: \"MCP for auth/external APIs. Script for local/stateless.\n- MCP: OAuth tokens, rate-limited APIs, persistent connections\n- Script: File processing, transformations, local tools\n- Building an MCP when a script would suffice = over-engineering\"\n\n### React Performance\n\n**Novice**: \"Use useMemo and useCallback everywhere\"\n\n**Expert**: \"Profile first. Premature optimization causes:\n- Complexity without benefit\n- Memory overhead from closures\n- Harder debugging\n\nOnly memoize when:\n- Measured re-render cost &gt; 16ms\n- Referential equality matters (deps of other hooks)\n- Expensive computations\"\n\n### API Design\n\n**Novice**: \"Use REST for everything\"\n\n**Expert**: \"Match API style to use case:\n- REST: CRUD resources, cacheable, simple clients\n- GraphQL: Complex queries, mobile/low-bandwidth, rapidly evolving\n- gRPC: Internal services, high throughput, typed contracts\n- WebSocket: Real-time bidirectional\n\nAnti-pattern: GraphQL for simple CRUD = overengineering\"\n\n## Encoding Shibboleths in Skills\n\n### Structure\n\n```markdown\n## Expert Knowledge: [Domain]\n\n### Novice Approach\n[What beginners do/think]\n\n### Expert Insight\n[What experienced practitioners know]\n\n### Implications for This Skill\n[How this affects the skill's guidance]\n```\n\n### Example Encoding\n\n```markdown\n## Expert Knowledge: Caching\n\n### Novice Approach\n\"Cache everything for performance\"\n\n### Expert Insight\nCache invalidation is the hard problem:\n- Stale data causes user confusion\n- Thundering herd on expiry\n- Memory pressure under load\n\n### Implications\nThis skill recommends cache-aside pattern with:\n- Short TTLs (5min default)\n- Explicit invalidation hooks\n- Graceful degradation on cache miss\n```\n"
        },
        {
          "name": "skill-composition.md",
          "type": "file",
          "path": "skill-coach/references/skill-composition.md",
          "size": 3840,
          "content": "# Skill Composition Patterns\n\nHow skills work together, depend on each other, and compose into workflows.\n\n## Dependency Types\n\n### 1. Sequential Dependency\nOne skill's output feeds another's input.\n\n```\nclip-aware-embeddings ‚Üí collage-layout-expert\n   [generates embeddings]     [uses embeddings for layout]\n```\n\n**Implementation**: Reference the upstream skill in your description:\n```yaml\ndescription: \"...Requires embeddings from clip-aware-embeddings skill...\"\n```\n\n### 2. Parallel Composition\nMultiple skills apply simultaneously to different aspects.\n\n```\n         ‚îå‚îÄ‚îÄ color-theory-expert ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n         ‚îÇ                              ‚îÇ\nPhoto ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ photo-composition-critic ‚îÄ‚îº‚îÄ‚îÄ Combined Analysis\n         ‚îÇ                              ‚îÇ\n         ‚îî‚îÄ‚îÄ event-detection-expert ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**Implementation**: Each skill operates independently; user/orchestrator combines results.\n\n### 3. Hierarchical (Meta-Skills)\nA skill that orchestrates other skills.\n\n```\ndesign-archivist (meta)\n    ‚îú‚îÄ‚îÄ vibe-matcher\n    ‚îú‚îÄ‚îÄ color-theory-expert\n    ‚îî‚îÄ‚îÄ competitive-cartographer\n```\n\n**Implementation**: Define subagent that invokes other skills.\n\n---\n\n## Composition Anti-Patterns\n\n### Circular Dependency\n**Wrong**: Skill A depends on B, B depends on A\n```\nskill-coach ‚Üí skill-documentarian ‚Üí skill-coach (cycle!)\n```\n**Fix**: Make dependencies unidirectional or extract shared functionality.\n\n### Implicit Dependency\n**Wrong**: Skill assumes another is present but doesn't document it\n```yaml\ndescription: \"Uses CLIP embeddings for search\"\n# But doesn't mention clip-aware-embeddings skill\n```\n**Fix**: Explicit dependencies in description or README.\n\n### Monolithic Anti-Composition\n**Wrong**: One skill tries to do everything\n```yaml\nname: photo-everything-expert\ndescription: \"Handles composition, color, events, layout, embeddings...\"\n```\n**Fix**: Split into focused, composable skills.\n\n---\n\n## Best Practices\n\n### 1. Document Dependencies\nIn your SKILL.md or README:\n```markdown\n## Dependencies\n- **Required**: `clip-aware-embeddings` for vector search\n- **Optional**: `color-theory-expert` for palette analysis\n```\n\n### 2. Use Consistent Data Formats\nWhen skills pass data:\n- Embeddings: Float arrays or paths to .npy files\n- Color palettes: Hex arrays or LAB tuples\n- Scores: 0.0-1.0 normalized floats\n\n### 3. Fail Gracefully Without Dependencies\n```python\ndef analyze_with_optional_color():\n    try:\n        # Try using color-theory skill output\n        palette = load_palette()\n    except FileNotFoundError:\n        # Degrade gracefully\n        palette = extract_basic_colors(image)\n```\n\n### 4. Composition Keywords\nAdd to description for discovery:\n- \"Composes with X, Y, Z\"\n- \"Extends X with Y capabilities\"\n- \"Downstream of X\"\n- \"Input for Y workflows\"\n\n---\n\n## Example: Photo Analysis Pipeline\n\n```\nInput Photo\n    ‚îÇ\n    ‚îú‚îÄ[1]‚îÄ‚îÄ clip-aware-embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ         ‚Üí semantic embedding                 ‚îÇ\n    ‚îÇ                                              ‚îÇ\n    ‚îú‚îÄ[2]‚îÄ‚îÄ photo-composition-critic ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n    ‚îÇ         ‚Üí aesthetic scores                   ‚îÇ\n    ‚îÇ                                              ‚îú‚îÄ‚îÄ‚Üí collage-layout-expert\n    ‚îú‚îÄ[3]‚îÄ‚îÄ color-theory-palette-harmony ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§      ‚Üí optimal grid\n    ‚îÇ         ‚Üí palette + harmony score            ‚îÇ\n    ‚îÇ                                              ‚îÇ\n    ‚îî‚îÄ[4]‚îÄ‚îÄ event-detection-temporal ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚Üí event clusters\n```\n\nEach skill:\n- Works independently\n- Has clear input/output contract\n- Can be used standalone or composed\n- Documents what it depends on\n"
        },
        {
          "name": "skill-lifecycle.md",
          "type": "file",
          "path": "skill-coach/references/skill-lifecycle.md",
          "size": 3754,
          "content": "# Skill Lifecycle Management\n\nFrom creation to deprecation - how to maintain skills over time.\n\n## Lifecycle Stages\n\n```\nDRAFT ‚Üí ACTIVE ‚Üí MATURE ‚Üí DEPRECATED ‚Üí ARCHIVED\n  ‚îÇ        ‚îÇ        ‚îÇ          ‚îÇ           ‚îÇ\n  v        v        v          v           v\nTesting  In use   Stable    Phasing out  Read-only\n```\n\n---\n\n## Stage 1: DRAFT\n\n**Characteristics**:\n- New skill under development\n- May have incomplete features\n- Not yet validated\n\n**Tasks**:\n- [ ] Write initial SKILL.md\n- [ ] Add description with keywords + NOT clause\n- [ ] Create at least 1 anti-pattern\n- [ ] Run validation scripts\n- [ ] Test activation with 10+ queries\n\n**Version**: 0.x.x (pre-release)\n\n---\n\n## Stage 2: ACTIVE\n\n**Characteristics**:\n- Validated and working\n- Being actively used and refined\n- Accepting feedback\n\n**Tasks**:\n- [ ] Monitor activation precision\n- [ ] Add anti-patterns as discovered\n- [ ] Update temporal knowledge\n- [ ] Respond to user feedback\n- [ ] Keep CHANGELOG updated\n\n**Version**: 1.0.0+\n\n---\n\n## Stage 3: MATURE\n\n**Characteristics**:\n- Stable, well-documented\n- Comprehensive anti-patterns\n- Working tools included\n- Rarely needs changes\n\n**Tasks**:\n- [ ] Periodic review (quarterly)\n- [ ] Check temporal knowledge freshness\n- [ ] Validate against latest Claude behavior\n- [ ] Consider extracting sub-skills if grown too large\n\n**Version**: 2.0.0+ (stable API)\n\n---\n\n## Stage 4: DEPRECATED\n\n**Characteristics**:\n- Being phased out\n- Better alternative exists\n- Still functional but not recommended\n\n**Tasks**:\n- [ ] Add deprecation notice to SKILL.md header\n- [ ] Document migration path\n- [ ] Point to replacement skill\n- [ ] Set end-of-support date\n\n**Example deprecation notice**:\n```markdown\n> ‚ö†Ô∏è **DEPRECATED**: This skill is deprecated as of v2.3.0.\n> Use `new-skill-name` instead. Migration guide: `references/migration.md`\n> End of support: 2025-06-01\n```\n\n---\n\n## Stage 5: ARCHIVED\n\n**Characteristics**:\n- No longer maintained\n- Kept for historical reference\n- May still work but unsupported\n\n**Tasks**:\n- [ ] Move to `/archived/` directory\n- [ ] Update any references\n- [ ] Document why archived\n\n---\n\n## Maintenance Checklist\n\n### Monthly\n- [ ] Check activation logs for issues\n- [ ] Review user feedback\n- [ ] Update any broken links\n\n### Quarterly\n- [ ] Validate temporal knowledge\n- [ ] Run full test suite\n- [ ] Check for new anti-patterns\n- [ ] Update dependencies (if MCP/scripts)\n\n### Annually\n- [ ] Full skill audit\n- [ ] Consider restructuring\n- [ ] Evaluate if still needed\n\n---\n\n## Versioning\n\nFollow Semantic Versioning (SemVer):\n\n| Change Type | Version Bump | Example |\n|-------------|--------------|---------|\n| Bug fix, typo | PATCH (0.0.X) | 1.0.0 ‚Üí 1.0.1 |\n| New feature, anti-pattern | MINOR (0.X.0) | 1.0.1 ‚Üí 1.1.0 |\n| Breaking change, restructure | MAJOR (X.0.0) | 1.1.0 ‚Üí 2.0.0 |\n\n**CHANGELOG format**:\n```markdown\n## [1.2.0] - 2025-01-15\n\n### Added\n- New anti-pattern: Template Theater\n- Script for activation testing\n\n### Changed\n- Updated NOT clause for better precision\n\n### Fixed\n- Typo in example code\n```\n\n---\n\n## When to Create vs Extend\n\n| Scenario | Action |\n|----------|--------|\n| New domain expertise | Create new skill |\n| Extension of existing | Extend that skill |\n| Skill > 500 lines | Split into focused skills |\n| Cross-domain | Create composition pattern |\n| Experiment | Create in DRAFT, delete if fails |\n\n---\n\n## Skill Health Indicators\n\n| Indicator | Healthy | Warning | Critical |\n|-----------|---------|---------|----------|\n| Activation precision | &gt;90% | 70-90% | &lt;70% |\n| SKILL.md lines | &lt;300 | 300-500 | &gt;500 |\n| Anti-patterns | 3+ | 1-2 | 0 |\n| Last update | &lt;3 months | 3-6 months | &gt;6 months |\n| Validation errors | 0 | 1-2 | &gt;2 |\n"
        },
        {
          "name": "validation-checklist.md",
          "type": "file",
          "path": "skill-coach/references/validation-checklist.md",
          "size": 3284,
          "content": "# Skill Validation Checklist\n\nComplete guide to reviewing and testing skills.\n\n## Review Checklist\n\n### CRITICAL (must-have)\n\n- [ ] Description has keywords AND NOT clause\n- [ ] SKILL.md under 500 lines (`wc -l SKILL.md`)\n- [ ] All referenced files exist (`find skill-dir/ -type f`)\n- [ ] Test activation: Does it activate when it should?\n- [ ] Test non-activation: Does it NOT activate when it shouldn't?\n\n### HIGH PRIORITY (should-have)\n\n- [ ] Has \"When to Use\" and \"When NOT to Use\" sections\n- [ ] Includes 1-3 anti-patterns with \"Why it's wrong\"\n- [ ] Encodes domain shibboleths (expert vs novice knowledge)\n- [ ] `allowed-tools` is minimal\n\n### NICE TO HAVE (polish)\n\n- [ ] Temporal knowledge (what changed when)\n- [ ] Working code examples (not just templates)\n- [ ] References for deep dives\n- [ ] Bash restrictions if applicable\n\n## Activation Testing\n\n### Positive Tests (SHOULD activate)\n\nAsk Claude questions that should trigger the skill:\n```\n# Example for a React skill:\n\"Help me optimize this React component's re-renders\"\n\"Why is my useEffect running twice?\"\n\"How do I prevent unnecessary renders?\"\n\n# Check: Did the skill activate?\n```\n\n### Negative Tests (SHOULD NOT activate)\n\nAsk questions that should NOT trigger the skill:\n```\n# Example for a React skill:\n\"Help me write a Python script\"\n\"What's the best database for my project?\"\n\"How do I set up nginx?\"\n\n# Check: Did it correctly NOT activate?\n```\n\n### Edge Cases\n\nTest ambiguous queries at the boundary:\n```\n# For a React skill - might or might not be React-specific:\n\"How do I handle forms?\"\n\"What's the best state management?\"\n```\n\n## Integration Testing\n\n- [ ] Test with related skills (do they conflict or complement?)\n- [ ] Test with MCPs (does skill guide MCP usage?)\n- [ ] Test in different project contexts\n\n## Security Audit\n\n- [ ] Read all scripts before enabling skill\n- [ ] Check for network calls / data exfiltration\n- [ ] Verify allowed-tools are minimal\n- [ ] Test in isolated project first\n\n## File Structure Validation\n\n```bash\n# Check for orphaned references\ngrep -r \"references/\" skill-dir/SKILL.md | \\\n  sed 's/.*references\\//references\\//' | \\\n  while read ref; do\n    [ -f \"skill-dir/$ref\" ] || echo \"Missing: $ref\"\n  done\n\n# Check line count\nwc -l skill-dir/SKILL.md\n# Should be &lt; 500\n\n# List all files\nfind skill-dir/ -type f -name \"*.md\" -o -name \"*.py\" -o -name \"*.sh\"\n```\n\n## Description Quality Check\n\nGood description formula:\n```\n[What it does]. [Use cases]. Activate on [keywords]. NOT for [exclusions].\n```\n\n**Red flags**:\n- No keywords ‚Üí Won't activate correctly\n- No NOT clause ‚Üí False positives\n- \"Helps with many things\" ‚Üí Too vague\n- Over 200 chars ‚Üí Consider splitting\n\n## Success Metrics\n\n| Metric | Target |\n|--------|--------|\n| Correct activation | &gt;90% |\n| False positive rate | &lt;5% |\n| Token usage | &lt;5k typical |\n| Error prevention | Measurable reduction |\n\n## Common Issues\n\n| Issue | Symptom | Fix |\n|-------|---------|-----|\n| Won't activate | Missing keywords | Add specific trigger words |\n| Activates too much | No exclusions | Add NOT clause |\n| Claude ignores sections | Buried too deep | Move to main SKILL.md |\n| Missing files | Reference errors | Remove refs or create files |\n| Token bloat | Slow loading | Extract to /references |\n"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "folder",
      "path": "skill-coach/scripts",
      "children": [
        {
          "name": "check_self_contained.py",
          "type": "file",
          "path": "skill-coach/scripts/check_self_contained.py",
          "size": 16398,
          "content": "#!/usr/bin/env python3\n\"\"\"\nSelf-Contained Skill Checker\n\nVerifies that a skill ships working tools, not just instructions.\nDetects: Phantom Tools, Template Soup, Incomplete MCPs, Missing Agents.\n\nUsage: python check_self_contained.py <skill_path>\n\"\"\"\n\nimport os\nimport sys\nimport re\nimport json\nfrom pathlib import Path\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import List, Optional, Set\n\n\nclass Status(Enum):\n    PASS = \"PASS\"\n    WARN = \"WARN\"\n    FAIL = \"FAIL\"\n    SKIP = \"SKIP\"\n\n\n@dataclass\nclass Check:\n    name: str\n    status: Status\n    message: str\n    details: List[str] = field(default_factory=list)\n\n\nclass SelfContainedChecker:\n    \"\"\"Check if a skill ships working tools.\"\"\"\n\n    # Markers that indicate template/placeholder code\n    # Must be actual placeholders, not descriptions of anti-patterns\n    TEMPLATE_MARKERS = [\n        r'#\\s*TODO:',                     # TODO: with colon (action item)\n        r'//\\s*TODO:',                    # JS TODO:\n        r'#\\s*FIXME:',                    # FIXME: with colon\n        r'//\\s*FIXME:',                   # JS FIXME:\n        r'raise\\s+NotImplementedError\\(\\)',  # Unimplemented function\n        r'throw\\s+new\\s+Error\\([\"\\']Not implemented',\n        r'^\\s*pass\\s*$',                  # bare pass (placeholder)\n        r'YOUR_[A-Z_]+_HERE',             # YOUR_API_KEY_HERE\n        r'REPLACE_THIS',\n        r'^\\s*\\.\\.\\.\\s*$',                # bare ... placeholder\n    ]\n\n    def __init__(self, skill_path: str):\n        self.skill_path = Path(skill_path)\n        self.skill_md = self.skill_path / \"SKILL.md\"\n        self.checks: List[Check] = []\n        self.skill_content = \"\"\n\n    def run(self) -> List[Check]:\n        \"\"\"Run all self-contained checks.\"\"\"\n        if not self.skill_path.exists():\n            self.checks.append(Check(\n                \"Skill exists\",\n                Status.FAIL,\n                f\"Skill directory not found: {self.skill_path}\"\n            ))\n            return self.checks\n\n        if self.skill_md.exists():\n            self.skill_content = self.skill_md.read_text()\n\n        self.check_scripts()\n        self.check_mcp_server()\n        self.check_agents()\n        self.check_referenced_files()\n        self.summarize()\n\n        return self.checks\n\n    def check_scripts(self):\n        \"\"\"Check scripts/ directory for working code.\"\"\"\n        scripts_dir = self.skill_path / \"scripts\"\n\n        if not scripts_dir.exists():\n            # Check if skill mentions scripts but doesn't have them\n            if re.search(r'scripts/', self.skill_content):\n                self.checks.append(Check(\n                    \"Scripts directory\",\n                    Status.FAIL,\n                    \"SKILL.md references scripts/ but directory doesn't exist\",\n                    [\"This is a Phantom Tools anti-pattern\"]\n                ))\n            else:\n                self.checks.append(Check(\n                    \"Scripts directory\",\n                    Status.SKIP,\n                    \"No scripts/ directory (not required)\"\n                ))\n            return\n\n        # Find all script files\n        scripts = list(scripts_dir.glob(\"*.py\")) + \\\n                  list(scripts_dir.glob(\"*.sh\")) + \\\n                  list(scripts_dir.glob(\"*.js\")) + \\\n                  list(scripts_dir.glob(\"*.ts\"))\n\n        if not scripts:\n            self.checks.append(Check(\n                \"Scripts directory\",\n                Status.WARN,\n                \"scripts/ exists but contains no script files\"\n            ))\n            return\n\n        # Check each script for template markers\n        template_scripts = []\n        working_scripts = []\n\n        for script in scripts:\n            content = script.read_text()\n            lines = content.split('\\n')\n            is_template = False\n            markers_found = []\n\n            for pattern in self.TEMPLATE_MARKERS:\n                # Check each line for patterns with ^ anchors\n                for line in lines:\n                    # Skip lines that are defining string patterns (like in this checker)\n                    stripped = line.strip()\n                    if stripped.startswith((\"r'\", 'r\"', \"'\", '\"')):\n                        continue\n                    if re.search(pattern, line, re.IGNORECASE | re.MULTILINE):\n                        is_template = True\n                        if pattern not in markers_found:\n                            markers_found.append(pattern)\n                        break\n\n            if is_template:\n                template_scripts.append((script.name, markers_found))\n            else:\n                working_scripts.append(script.name)\n\n        if template_scripts and not working_scripts:\n            self.checks.append(Check(\n                \"Scripts quality\",\n                Status.FAIL,\n                f\"All {len(template_scripts)} scripts are templates, not working code\",\n                [f\"  {name}: contains {markers}\" for name, markers in template_scripts]\n            ))\n        elif template_scripts:\n            self.checks.append(Check(\n                \"Scripts quality\",\n                Status.WARN,\n                f\"{len(template_scripts)} of {len(scripts)} scripts are templates\",\n                [f\"  Template: {name}\" for name, _ in template_scripts] +\n                [f\"  Working: {name}\" for name in working_scripts]\n            ))\n        else:\n            self.checks.append(Check(\n                \"Scripts quality\",\n                Status.PASS,\n                f\"All {len(working_scripts)} scripts appear to be working code\",\n                [f\"  {name}\" for name in working_scripts]\n            ))\n\n    def check_mcp_server(self):\n        \"\"\"Check mcp-server/ directory for complete implementation.\"\"\"\n        mcp_dir = self.skill_path / \"mcp-server\"\n\n        if not mcp_dir.exists():\n            # Only flag if skill claims to SHIP an MCP (path reference), not just discusses them\n            # Look for: `mcp-server/`, \"See mcp-server/\", \"Run mcp-server/\"\n            ships_mcp = re.search(r'`mcp-server/', self.skill_content) or \\\n                        re.search(r'[Ss]ee\\s+mcp-server/', self.skill_content) or \\\n                        re.search(r'[Rr]un\\s+.*mcp-server/', self.skill_content)\n            if ships_mcp:\n                self.checks.append(Check(\n                    \"MCP Server\",\n                    Status.FAIL,\n                    \"SKILL.md references mcp-server/ path but directory doesn't exist\",\n                    [\"This is a Phantom Tools anti-pattern\"]\n                ))\n            else:\n                self.checks.append(Check(\n                    \"MCP Server\",\n                    Status.SKIP,\n                    \"No mcp-server/ directory (not required)\"\n                ))\n            return\n\n        issues = []\n        passes = []\n\n        # Check for package.json\n        package_json = mcp_dir / \"package.json\"\n        if not package_json.exists():\n            issues.append(\"Missing package.json\")\n        else:\n            passes.append(\"Has package.json\")\n            try:\n                pkg = json.loads(package_json.read_text())\n                if \"dependencies\" not in pkg and \"devDependencies\" not in pkg:\n                    issues.append(\"package.json has no dependencies\")\n                if \"@modelcontextprotocol/sdk\" not in str(pkg):\n                    issues.append(\"Missing @modelcontextprotocol/sdk dependency\")\n                else:\n                    passes.append(\"Has MCP SDK dependency\")\n            except json.JSONDecodeError:\n                issues.append(\"package.json is invalid JSON\")\n\n        # Check for source files\n        src_files = list(mcp_dir.glob(\"src/*.ts\")) + \\\n                    list(mcp_dir.glob(\"src/*.js\")) + \\\n                    list(mcp_dir.glob(\"*.ts\")) + \\\n                    list(mcp_dir.glob(\"*.js\"))\n\n        if not src_files:\n            issues.append(\"No source files found\")\n        else:\n            passes.append(f\"Has {len(src_files)} source file(s)\")\n\n            # Check for template markers in source\n            for src in src_files:\n                content = src.read_text()\n                for pattern in self.TEMPLATE_MARKERS:\n                    if re.search(pattern, content, re.IGNORECASE):\n                        issues.append(f\"{src.name} contains template markers\")\n                        break\n\n        # Check for README\n        readme = mcp_dir / \"README.md\"\n        if not readme.exists():\n            issues.append(\"Missing README.md with installation instructions\")\n        else:\n            passes.append(\"Has README.md\")\n\n        # Determine status\n        if len(issues) >= 3:\n            status = Status.FAIL\n            msg = \"MCP server is incomplete\"\n        elif issues:\n            status = Status.WARN\n            msg = \"MCP server has issues\"\n        else:\n            status = Status.PASS\n            msg = \"MCP server appears complete\"\n\n        self.checks.append(Check(\n            \"MCP Server\",\n            status,\n            msg,\n            [f\"  ‚úì {p}\" for p in passes] + [f\"  ‚úó {i}\" for i in issues]\n        ))\n\n    def check_agents(self):\n        \"\"\"Check agents/ directory for complete definitions.\"\"\"\n        agents_dir = self.skill_path / \"agents\"\n\n        if not agents_dir.exists():\n            # Only flag if skill claims to SHIP agents (path reference), not just discusses them\n            ships_agents = re.search(r'`agents/', self.skill_content) or \\\n                           re.search(r'[Ss]ee\\s+agents/', self.skill_content) or \\\n                           re.search(r'[Rr]un\\s+.*agents/', self.skill_content)\n            if ships_agents:\n                self.checks.append(Check(\n                    \"Agents\",\n                    Status.FAIL,\n                    \"SKILL.md references agents/ path but directory doesn't exist\",\n                    [\"This is a Phantom Tools anti-pattern\"]\n                ))\n            else:\n                self.checks.append(Check(\n                    \"Agents\",\n                    Status.SKIP,\n                    \"No agents/ directory (not required)\"\n                ))\n            return\n\n        # Find agent definitions\n        agent_files = list(agents_dir.glob(\"*.md\")) + \\\n                      list(agents_dir.glob(\"*.yaml\")) + \\\n                      list(agents_dir.glob(\"*.yml\"))\n\n        if not agent_files:\n            self.checks.append(Check(\n                \"Agents\",\n                Status.WARN,\n                \"agents/ exists but contains no definition files\"\n            ))\n            return\n\n        # Check each agent definition\n        complete = []\n        incomplete = []\n\n        required_sections = ['purpose', 'prompt', 'tools', 'workflow']\n\n        for agent_file in agent_files:\n            content = agent_file.read_text().lower()\n            missing = []\n\n            for section in required_sections:\n                if section not in content:\n                    missing.append(section)\n\n            if missing:\n                incomplete.append((agent_file.name, missing))\n            else:\n                complete.append(agent_file.name)\n\n        if incomplete and not complete:\n            self.checks.append(Check(\n                \"Agents\",\n                Status.FAIL,\n                f\"All {len(incomplete)} agent definitions are incomplete\",\n                [f\"  {name}: missing {missing}\" for name, missing in incomplete]\n            ))\n        elif incomplete:\n            self.checks.append(Check(\n                \"Agents\",\n                Status.WARN,\n                f\"{len(incomplete)} of {len(agent_files)} agent definitions incomplete\",\n                [f\"  Incomplete: {name}\" for name, _ in incomplete] +\n                [f\"  Complete: {name}\" for name in complete]\n            ))\n        else:\n            self.checks.append(Check(\n                \"Agents\",\n                Status.PASS,\n                f\"All {len(complete)} agent definitions appear complete\",\n                [f\"  {name}\" for name in complete]\n            ))\n\n    def check_referenced_files(self):\n        \"\"\"Check that files referenced in SKILL.md actually exist.\"\"\"\n        if not self.skill_content:\n            return\n\n        # Find file references like `scripts/foo.py` or `/references/bar.md`\n        patterns = [\n            r'`(scripts/[^`]+)`',\n            r'`(references/[^`]+)`',\n            r'`(agents/[^`]+)`',\n            r'`(mcp-server/[^`]+)`',\n        ]\n\n        referenced = set()\n        for pattern in patterns:\n            matches = re.findall(pattern, self.skill_content)\n            referenced.update(matches)\n\n        if not referenced:\n            self.checks.append(Check(\n                \"Referenced files\",\n                Status.SKIP,\n                \"No specific file paths referenced in SKILL.md\"\n            ))\n            return\n\n        missing = []\n        found = []\n\n        for ref in referenced:\n            full_path = self.skill_path / ref\n            if full_path.exists():\n                found.append(ref)\n            else:\n                missing.append(ref)\n\n        if missing:\n            self.checks.append(Check(\n                \"Referenced files\",\n                Status.FAIL,\n                f\"{len(missing)} referenced files don't exist (Phantom Tools)\",\n                [f\"  Missing: {f}\" for f in missing] +\n                [f\"  Found: {f}\" for f in found]\n            ))\n        else:\n            self.checks.append(Check(\n                \"Referenced files\",\n                Status.PASS,\n                f\"All {len(found)} referenced files exist\",\n                [f\"  {f}\" for f in found]\n            ))\n\n    def summarize(self):\n        \"\"\"Add summary check.\"\"\"\n        fails = sum(1 for c in self.checks if c.status == Status.FAIL)\n        warns = sum(1 for c in self.checks if c.status == Status.WARN)\n        passes = sum(1 for c in self.checks if c.status == Status.PASS)\n        skips = sum(1 for c in self.checks if c.status == Status.SKIP)\n\n        # Determine if skill is self-contained\n        has_tools = any(\n            c.status in (Status.PASS, Status.WARN)\n            for c in self.checks\n            if c.name in (\"Scripts quality\", \"MCP Server\", \"Agents\")\n        )\n\n        if fails > 0:\n            status = Status.FAIL\n            msg = f\"Skill has {fails} critical issues\"\n        elif warns > 0:\n            status = Status.WARN\n            msg = f\"Skill has {warns} warnings to address\"\n        elif has_tools:\n            status = Status.PASS\n            msg = \"Skill is self-contained with working tools\"\n        else:\n            status = Status.WARN\n            msg = \"Skill has no tools (instructions only)\"\n\n        self.checks.append(Check(\n            \"SUMMARY\",\n            status,\n            msg,\n            [f\"  {passes} passed, {warns} warnings, {fails} failed, {skips} skipped\"]\n        ))\n\n\ndef print_report(checks: List[Check]):\n    \"\"\"Print formatted report.\"\"\"\n    status_icons = {\n        Status.PASS: \"‚úÖ\",\n        Status.WARN: \"‚ö†Ô∏è \",\n        Status.FAIL: \"‚ùå\",\n        Status.SKIP: \"‚è≠Ô∏è \",\n    }\n\n    print(f\"\\n{'='*60}\")\n    print(\"SELF-CONTAINED SKILL CHECK\")\n    print(f\"{'='*60}\\n\")\n\n    for check in checks:\n        icon = status_icons[check.status]\n        print(f\"{icon} {check.name}: {check.message}\")\n        for detail in check.details:\n            print(f\"   {detail}\")\n        print()\n\n    print(f\"{'='*60}\\n\")\n\n\ndef main():\n    if len(sys.argv) < 2:\n        print(\"Usage: python check_self_contained.py <skill_path>\")\n        print(\"\\nChecks if a skill ships working tools or just instructions.\")\n        print(\"\\nDetects:\")\n        print(\"  - Phantom Tools: Referenced files that don't exist\")\n        print(\"  - Template Soup: Scripts with TODO/FIXME markers\")\n        print(\"  - Incomplete MCPs: Missing package.json, dependencies, etc.\")\n        print(\"  - Missing Agents: Referenced but undefined subagents\")\n        print(\"\\nExample:\")\n        print(\"  python check_self_contained.py ~/.claude/skills/my-skill/\")\n        sys.exit(1)\n\n    skill_path = sys.argv[1]\n\n    print(f\"Checking self-contained status: {skill_path}\")\n\n    checker = SelfContainedChecker(skill_path)\n    checks = checker.run()\n\n    print_report(checks)\n\n    # Exit code based on failures\n    fails = sum(1 for c in checks if c.status == Status.FAIL)\n    sys.exit(1 if fails else 0)\n\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "test_activation.py",
          "type": "file",
          "path": "skill-coach/scripts/test_activation.py",
          "size": 6146,
          "content": "#!/usr/bin/env python3\n\"\"\"\nSkill Activation Tester\n\nTests whether a skill's description correctly identifies queries that\nshould/should not activate it. Uses keyword matching as a proxy for\nClaude's activation logic.\n\nUsage: python test_activation.py <skill_path> [--verbose]\n\"\"\"\n\nimport sys\nimport re\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import List, Tuple, Optional\n\n\n@dataclass\nclass ActivationTest:\n    query: str\n    should_activate: bool\n    reason: str\n\n\ndef extract_keywords(description: str) -> Tuple[List[str], List[str]]:\n    \"\"\"Extract positive and negative keywords from description.\"\"\"\n    positive = []\n    negative = []\n\n    # Find \"Activate on\" keywords\n    activate_match = re.search(\n        r'[Aa]ctivate\\s+on\\s+(?:keywords?:?)?\\s*[\"\\']?([^.\"\\']+)[\"\\']?',\n        description\n    )\n    if activate_match:\n        keywords_str = activate_match.group(1)\n        # Split by comma or 'and' or quotes\n        positive = [k.strip().strip('\"\\'') for k in re.split(r',|\\sand\\s', keywords_str)]\n        positive = [k for k in positive if k and len(k) > 1]\n\n    # Find \"NOT for\" exclusions\n    not_match = re.search(r'NOT\\s+for\\s+([^.]+)', description, re.IGNORECASE)\n    if not_match:\n        exclusions_str = not_match.group(1)\n        negative = [k.strip().strip('\"\\'') for k in re.split(r',|\\sor\\s', exclusions_str)]\n        negative = [k for k in negative if k and len(k) > 1]\n\n    return positive, negative\n\n\ndef generate_test_queries(positive_kw: List[str], negative_kw: List[str]) -> List[ActivationTest]:\n    \"\"\"Generate test queries from keywords.\"\"\"\n    tests = []\n\n    # Positive tests (should activate)\n    for kw in positive_kw[:5]:  # Limit to first 5\n        tests.append(ActivationTest(\n            query=f\"Help me with {kw}\",\n            should_activate=True,\n            reason=f\"Contains keyword '{kw}'\"\n        ))\n\n    # Negative tests (should NOT activate)\n    for kw in negative_kw[:5]:  # Limit to first 5\n        tests.append(ActivationTest(\n            query=f\"I need help with {kw}\",\n            should_activate=False,\n            reason=f\"Contains exclusion '{kw}'\"\n        ))\n\n    # Generic negative tests\n    generic_negative = [\n        \"What's the weather today?\",\n        \"Write a haiku about cats\",\n        \"Explain quantum physics\",\n    ]\n    for q in generic_negative:\n        tests.append(ActivationTest(\n            query=q,\n            should_activate=False,\n            reason=\"Generic query unrelated to skill\"\n        ))\n\n    return tests\n\n\ndef check_activation(query: str, description: str,\n                     positive_kw: List[str], negative_kw: List[str]) -> Tuple[bool, str]:\n    \"\"\"\n    Simulate activation check.\n    Returns (would_activate, explanation)\n    \"\"\"\n    query_lower = query.lower()\n\n    # Check for negative keywords first (exclusions take priority)\n    for neg in negative_kw:\n        if neg.lower() in query_lower:\n            return False, f\"Blocked by exclusion: '{neg}'\"\n\n    # Check for positive keywords\n    for pos in positive_kw:\n        if pos.lower() in query_lower:\n            return True, f\"Matched keyword: '{pos}'\"\n\n    # Check description terms\n    desc_terms = set(description.lower().split())\n    query_terms = set(query_lower.split())\n    overlap = desc_terms & query_terms\n\n    if len(overlap) >= 2:\n        return True, f\"Matched description terms: {overlap}\"\n\n    return False, \"No keyword match\"\n\n\ndef run_tests(skill_path: str, verbose: bool = False) -> int:\n    \"\"\"Run activation tests on a skill.\"\"\"\n    skill_dir = Path(skill_path).resolve()\n    skill_md = skill_dir / \"SKILL.md\"\n\n    if not skill_md.exists():\n        print(f\"Error: {skill_md} not found\")\n        return 1\n\n    content = skill_md.read_text()\n\n    # Extract description from frontmatter\n    desc_match = re.search(r'description:\\s*[\"\\']([^\"\\']+)[\"\\']', content)\n    if not desc_match:\n        print(\"Error: Could not find description in frontmatter\")\n        return 1\n\n    description = desc_match.group(1)\n    positive_kw, negative_kw = extract_keywords(description)\n\n    print(f\"\\n{'='*60}\")\n    print(f\"ACTIVATION TEST: {skill_dir.name}\")\n    print(f\"{'='*60}\\n\")\n\n    print(f\"Positive keywords: {positive_kw}\")\n    print(f\"Negative keywords: {negative_kw}\\n\")\n\n    # Generate and run tests\n    tests = generate_test_queries(positive_kw, negative_kw)\n\n    passed = 0\n    failed = 0\n\n    for test in tests:\n        activated, explanation = check_activation(\n            test.query, description, positive_kw, negative_kw\n        )\n\n        if activated == test.should_activate:\n            passed += 1\n            status = \"‚úÖ PASS\"\n        else:\n            failed += 1\n            status = \"‚ùå FAIL\"\n\n        if verbose or activated != test.should_activate:\n            expected = \"ACTIVATE\" if test.should_activate else \"NO ACTIVATE\"\n            actual = \"activated\" if activated else \"did not activate\"\n            print(f\"{status}: \\\"{test.query}\\\"\")\n            print(f\"         Expected: {expected}, Actually: {actual}\")\n            print(f\"         {explanation}\")\n            print()\n\n    # Summary\n    total = passed + failed\n    rate = (passed / total * 100) if total > 0 else 0\n\n    print(f\"\\n{'='*60}\")\n    print(f\"RESULTS: {passed}/{total} passed ({rate:.1f}%)\")\n    print(f\"{'='*60}\")\n\n    if rate >= 90:\n        print(\"‚úÖ Activation precision meets target (>90%)\")\n    elif rate >= 70:\n        print(\"‚ö†Ô∏è  Activation precision below target (70-90%)\")\n    else:\n        print(\"‚ùå Activation precision needs work (<70%)\")\n\n    return 0 if failed == 0 else 1\n\n\ndef main():\n    if len(sys.argv) < 2:\n        print(\"Usage: python test_activation.py <skill_path> [--verbose]\")\n        print(\"\\nTests skill activation based on description keywords.\")\n        print(\"\\nExample:\")\n        print(\"  python test_activation.py ~/.claude/skills/my-skill/\")\n        print(\"  python test_activation.py ~/.claude/skills/my-skill/ --verbose\")\n        sys.exit(1)\n\n    skill_path = sys.argv[1]\n    verbose = \"--verbose\" in sys.argv or \"-v\" in sys.argv\n\n    sys.exit(run_tests(skill_path, verbose))\n\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "validate_skill.py",
          "type": "file",
          "path": "skill-coach/scripts/validate_skill.py",
          "size": 13121,
          "content": "#!/usr/bin/env python3\n\"\"\"\nSkill Validator - Pre-flight checks for Agent Skills\n\nValidates skill structure, content quality, and best practices.\n\"\"\"\n\nimport os\nimport sys\nimport re\nimport yaml\nfrom pathlib import Path\nfrom typing import List, Dict, Tuple\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n\nclass Severity(Enum):\n    ERROR = \"ERROR\"\n    WARNING = \"WARNING\"\n    INFO = \"INFO\"\n\n\n@dataclass\nclass ValidationIssue:\n    severity: Severity\n    message: str\n    line: int = None\n    suggestion: str = None\n\n\nclass SkillValidator:\n    def __init__(self, skill_path: str):\n        self.skill_path = Path(skill_path)\n        self.issues: List[ValidationIssue] = []\n        self.skill_md = self.skill_path / \"SKILL.md\"\n        \n    def validate(self) -> List[ValidationIssue]:\n        \"\"\"Run all validation checks.\"\"\"\n        self.check_structure()\n        self.check_skill_md()\n        self.check_description_quality()\n        self.check_progressive_disclosure()\n        self.check_antipatterns_section()\n        self.check_usage_sections()\n        self.check_allowed_tools()\n        return self.issues\n    \n    def check_structure(self):\n        \"\"\"Verify required files and folders exist.\"\"\"\n        if not self.skill_path.exists():\n            self.issues.append(ValidationIssue(\n                Severity.ERROR,\n                f\"Skill directory not found: {self.skill_path}\"\n            ))\n            return\n        \n        if not self.skill_md.exists():\n            self.issues.append(ValidationIssue(\n                Severity.ERROR,\n                \"SKILL.md file missing\"\n            ))\n            return\n        \n        # Check for recommended structure\n        scripts_dir = self.skill_path / \"scripts\"\n        if not scripts_dir.exists():\n            self.issues.append(ValidationIssue(\n                Severity.INFO,\n                \"No /scripts directory found. Consider adding validation or example scripts.\"\n            ))\n        \n        references_dir = self.skill_path / \"references\"\n        if not references_dir.exists():\n            self.issues.append(ValidationIssue(\n                Severity.INFO,\n                \"No /references directory. Consider splitting detailed docs into references.\"\n            ))\n    \n    def check_skill_md(self):\n        \"\"\"Validate SKILL.md content and structure.\"\"\"\n        with open(self.skill_md, 'r', encoding='utf-8') as f:\n            content = f.read()\n        \n        # Check for YAML frontmatter\n        if not content.startswith('---'):\n            self.issues.append(ValidationIssue(\n                Severity.ERROR,\n                \"Missing YAML frontmatter. Must start with '---'\"\n            ))\n            return\n        \n        # Extract frontmatter\n        try:\n            parts = content.split('---', 2)\n            frontmatter = yaml.safe_load(parts[1])\n        except Exception as e:\n            self.issues.append(ValidationIssue(\n                Severity.ERROR,\n                f\"Invalid YAML frontmatter: {e}\"\n            ))\n            return\n        \n        # Check required fields\n        if 'name' not in frontmatter:\n            self.issues.append(ValidationIssue(\n                Severity.ERROR,\n                \"Missing required field: name\"\n            ))\n        else:\n            # Validate name format\n            name = frontmatter['name']\n            if not re.match(r'^[a-z0-9-]+$', name):\n                self.issues.append(ValidationIssue(\n                    Severity.ERROR,\n                    f\"Invalid name format: '{name}'. Must use lowercase letters, numbers, and hyphens only.\"\n                ))\n            if len(name) > 64:\n                self.issues.append(ValidationIssue(\n                    Severity.ERROR,\n                    f\"Name too long: {len(name)} chars (max 64)\"\n                ))\n        \n        if 'description' not in frontmatter:\n            self.issues.append(ValidationIssue(\n                Severity.ERROR,\n                \"Missing required field: description\"\n            ))\n        \n        # Check line count\n        lines = content.split('\\n')\n        if len(lines) > 500:\n            self.issues.append(ValidationIssue(\n                Severity.WARNING,\n                f\"SKILL.md is {len(lines)} lines (recommended: <500). Consider splitting into /references.\"\n            ))\n    \n    def check_description_quality(self):\n        \"\"\"Analyze description field quality.\"\"\"\n        with open(self.skill_md, 'r') as f:\n            content = f.read()\n        \n        try:\n            parts = content.split('---', 2)\n            frontmatter = yaml.safe_load(parts[1])\n            description = frontmatter.get('description', '')\n        except:\n            return  # Already reported in check_skill_md\n        \n        if not description:\n            return\n        \n        # Check length\n        if len(description) > 1024:\n            self.issues.append(ValidationIssue(\n                Severity.ERROR,\n                f\"Description too long: {len(description)} chars (max 1024)\"\n            ))\n        \n        if len(description) < 20:\n            self.issues.append(ValidationIssue(\n                Severity.WARNING,\n                \"Description too short. Should explain what, when, and triggers.\"\n            ))\n        \n        # Check for key components\n        has_what = any(word in description.lower() for word in ['create', 'analyze', 'generate', 'process', 'handle', 'manage'])\n        has_when = any(word in description.lower() for word in ['when', 'use for', 'use when', 'for'])\n        \n        if not has_what:\n            self.issues.append(ValidationIssue(\n                Severity.WARNING,\n                \"Description should explain WHAT the skill does\"\n            ))\n        \n        if not has_when:\n            self.issues.append(ValidationIssue(\n                Severity.WARNING,\n                \"Description should explain WHEN to use it\",\n                suggestion=\"Add: 'Use when...' or 'Use for...'\"\n            ))\n        \n        # Check for negative triggers (what NOT to use it for)\n        has_not = 'not' in description.lower() or \"don't\" in description.lower()\n        if not has_not:\n            self.issues.append(ValidationIssue(\n                Severity.INFO,\n                \"Consider adding what NOT to use this skill for to prevent false activation\"\n            ))\n        \n        # Check point of view (use word boundaries to avoid false positives like \"skill\" matching \"i \")\n        import re\n        first_second_person = re.compile(r'\\b(i|you|your|my|we|our)\\b', re.IGNORECASE)\n        if first_second_person.search(description):\n            self.issues.append(ValidationIssue(\n                Severity.WARNING,\n                \"Description should use third person, not first/second person\",\n                suggestion=\"Change 'you can use this to...' to 'Use for...'\"\n            ))\n    \n    def check_progressive_disclosure(self):\n        \"\"\"Check for proper progressive disclosure structure.\"\"\"\n        with open(self.skill_md, 'r') as f:\n            content = f.read()\n        \n        # Check for references to external files\n        has_references = bool(re.search(r'/references/', content) or \n                             re.search(r'/scripts/', content))\n        \n        lines = content.split('\\n')\n        if len(lines) > 300 and not has_references:\n            self.issues.append(ValidationIssue(\n                Severity.WARNING,\n                \"Long SKILL.md without references. Consider splitting detailed content.\",\n                suggestion=\"Move deep dives to /references/ and link from main file\"\n            ))\n        \n        # Check for \"See X for details\" patterns\n        if len(lines) > 200:\n            has_see_references = bool(re.search(r'See .* for', content))\n            if not has_see_references:\n                self.issues.append(ValidationIssue(\n                    Severity.INFO,\n                    \"Consider adding 'See /references/X for...' to defer detailed content\"\n                ))\n    \n    def check_antipatterns_section(self):\n        \"\"\"Check if skill includes anti-pattern guidance.\"\"\"\n        with open(self.skill_md, 'r') as f:\n            content = f.read().lower()\n        \n        has_antipatterns = any(term in content for term in [\n            'anti-pattern', 'antipattern', 'common mistake', \n            'avoid', 'don\\'t', 'deprecated', 'wrong'\n        ])\n        \n        if not has_antipatterns:\n            self.issues.append(ValidationIssue(\n                Severity.INFO,\n                \"No anti-pattern guidance found. Consider adding common mistakes section.\",\n                suggestion=\"Add '## Common Anti-Patterns' section\"\n            ))\n\n    def check_usage_sections(self):\n        \"\"\"Check for When to Use / NOT to Use sections.\"\"\"\n        with open(self.skill_md, 'r') as f:\n            content = f.read().lower()\n\n        has_when_to_use = any(pattern in content for pattern in [\n            'when to use', 'use for:', '‚úÖ use for'\n        ])\n        has_when_not = any(pattern in content for pattern in [\n            'not for:', 'when not to', '‚ùå not for'\n        ])\n\n        if not has_when_to_use:\n            self.issues.append(ValidationIssue(\n                Severity.WARNING,\n                \"Missing 'When to Use' section. Helps activation clarity.\",\n                suggestion=\"Add section listing what the skill is for\"\n            ))\n\n        if not has_when_not:\n            self.issues.append(ValidationIssue(\n                Severity.WARNING,\n                \"Missing 'When NOT to Use' section. Prevents false activation.\",\n                suggestion=\"Add section listing what the skill should NOT handle\"\n            ))\n\n    def check_allowed_tools(self):\n        \"\"\"Validate allowed-tools field.\"\"\"\n        with open(self.skill_md, 'r') as f:\n            content = f.read()\n        \n        try:\n            parts = content.split('---', 2)\n            frontmatter = yaml.safe_load(parts[1])\n            allowed_tools = frontmatter.get('allowed-tools', '')\n        except:\n            return\n        \n        if not allowed_tools:\n            self.issues.append(ValidationIssue(\n                Severity.INFO,\n                \"No allowed-tools specified. Claude will ask for permission.\"\n            ))\n            return\n        \n        # Check for overly permissive tools\n        tools = [t.strip() for t in str(allowed_tools).split(',')]\n        \n        if 'Bash' in tools and not any('Bash(' in t for t in tools):\n            self.issues.append(ValidationIssue(\n                Severity.WARNING,\n                \"Unrestricted Bash access. Consider scoping: Bash(git:*,npm:*)\",\n                suggestion=\"Restrict bash to specific commands\"\n            ))\n        \n        # Check for unnecessary tools\n        body_content = content.split('---', 2)[2].lower()\n        for tool in tools:\n            tool_lower = tool.split('(')[0].lower()\n            if tool_lower not in body_content:\n                self.issues.append(ValidationIssue(\n                    Severity.INFO,\n                    f\"Tool '{tool}' in allowed-tools but not mentioned in content\"\n                ))\n\n\ndef print_report(issues: List[ValidationIssue]):\n    \"\"\"Print validation report.\"\"\"\n    if not issues:\n        print(\"‚úÖ Validation passed! No issues found.\")\n        return\n    \n    errors = [i for i in issues if i.severity == Severity.ERROR]\n    warnings = [i for i in issues if i.severity == Severity.WARNING]\n    info = [i for i in issues if i.severity == Severity.INFO]\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"VALIDATION REPORT\")\n    print(f\"{'='*60}\\n\")\n    \n    if errors:\n        print(f\"‚ùå ERRORS ({len(errors)}):\")\n        for issue in errors:\n            print(f\"  ‚Ä¢ {issue.message}\")\n            if issue.suggestion:\n                print(f\"    üí° {issue.suggestion}\")\n        print()\n    \n    if warnings:\n        print(f\"‚ö†Ô∏è  WARNINGS ({len(warnings)}):\")\n        for issue in warnings:\n            print(f\"  ‚Ä¢ {issue.message}\")\n            if issue.suggestion:\n                print(f\"    üí° {issue.suggestion}\")\n        print()\n    \n    if info:\n        print(f\"‚ÑπÔ∏è  SUGGESTIONS ({len(info)}):\")\n        for issue in info:\n            print(f\"  ‚Ä¢ {issue.message}\")\n            if issue.suggestion:\n                print(f\"    üí° {issue.suggestion}\")\n        print()\n    \n    print(f\"{'='*60}\")\n    print(f\"Summary: {len(errors)} errors, {len(warnings)} warnings, {len(info)} suggestions\")\n    print(f\"{'='*60}\\n\")\n\n\ndef main():\n    if len(sys.argv) < 2:\n        print(\"Usage: python validate_skill.py <skill_path>\")\n        print(\"\\nExample:\")\n        print(\"  python validate_skill.py ~/my-skill/\")\n        sys.exit(1)\n    \n    skill_path = sys.argv[1]\n    \n    print(f\"Validating skill at: {skill_path}\")\n    print()\n    \n    validator = SkillValidator(skill_path)\n    issues = validator.validate()\n    \n    print_report(issues)\n    \n    # Exit code based on errors\n    errors = [i for i in issues if i.severity == Severity.ERROR]\n    sys.exit(1 if errors else 0)\n\n\nif __name__ == '__main__':\n    main()\n"
        }
      ]
    },
    {
      "name": "CHANGELOG.md",
      "type": "file",
      "path": "skill-coach/CHANGELOG.md",
      "size": 5424,
      "content": "# Changelog\n\nAll notable changes to the skill-coach skill will be documented in this file.\n\n## [2.2.0] - 2025-12-04\n\n### Added\n- `scripts/test_activation.py` - Automated activation testing with keyword extraction\n  - Extracts positive/negative keywords from description\n  - Generates test queries automatically\n  - Reports pass/fail rate against 90% target\n- `references/scoring-rubric.md` - Quantitative skill evaluation (0-10 scoring)\n  - 5 scoring categories: Activation Precision, Domain Expertise, Progressive Disclosure, Self-Containment, Maintainability\n  - Composite score formula with grade mapping (A-F)\n- `references/skill-composition.md` - Cross-skill dependency patterns\n  - Sequential, Parallel, Hierarchical dependency types\n  - Composition anti-patterns with fixes\n  - Example photo analysis pipeline\n- `references/skill-lifecycle.md` - Maintenance and versioning guidance\n  - 5 lifecycle stages: DRAFT ‚Üí ACTIVE ‚Üí MATURE ‚Üí DEPRECATED ‚Üí ARCHIVED\n  - Maintenance checklists (monthly, quarterly, annually)\n  - Health indicators table\n- 4 real-world failure case studies added to `references/antipatterns.md`:\n  - Photo Expert Explosion (Everything Skill anti-pattern)\n  - Phantom MCP (Reference Illusion anti-pattern)\n  - Time Bomb (stale temporal knowledge)\n  - Activation Black Hole (generic description)\n- Activation debugging flowchart in SKILL.md (ASCII decision tree)\n- Recursive self-improvement workflow in SKILL.md\n\n### Changed\n- Description now uses third person (\"Activates for...\" not \"when users mention...\")\n- Bash permissions scoped from `Bash` to `Bash(python:*,wc:*,find:*,grep:*)`\n- Added \"improve skill\" to activation keywords\n- Consolidated duplicate antipatterns files (merged `anti-patterns.md` into `antipatterns.md`)\n- Updated reference table with 4 new files\n\n### Fixed\n- Validation warning: Description no longer uses first/second person\n- Validation warning: Bash tool is now scoped (was unrestricted)\n\n### Metrics\n- Activation precision: 100% (12/12 tests passed)\n- SKILL.md: 240 lines (within 500 line limit)\n- New reference files: 4 (scoring-rubric, skill-composition, skill-lifecycle, test_activation.py)\n\n## [2.1.1] - 2025-12-01\n\n### Added\n- `scripts/check_self_contained.py` - Validates skills ship working tools, not just instructions\n  - Detects Phantom Tools (referenced files that don't exist)\n  - Detects Template Soup (scripts with TODO/FIXME markers)\n  - Validates MCP server completeness (package.json, dependencies, source)\n  - Checks agent definition completeness\n  - Reports \"instructions only\" vs \"self-contained with tools\"\n\n### Changed\n- skill-coach now practices what it preaches (eats its own dogfood)\n\n## [2.1.0] - 2025-12-01\n\n### Added\n- **Self-Contained Skills** section (RECOMMENDED) - strongly advocates shipping working tools\n- `references/self-contained-tools.md` - Complete implementation patterns for:\n  - Working scripts (not templates)\n  - MCP server implementations\n  - Subagent definitions and orchestration\n- Decision tree: \"What tools does my skill need?\"\n- Anti-patterns: Phantom Tools, Template Soup, Dependency Hell, MCP Without Purpose\n- Self-contained checklist for skill authors\n\n### Changed\n- Skill structure now shows scripts/mcp-server/agents as **Strongly Recommended**\n- Philosophy shift: \"Skills with working tools are immediately useful\"\n\n### Why This Matters\nSkills that only provide instructions require users to implement everything themselves.\nSkills that ship working tools let users be productive immediately.\n\n## [2.0.0] - 2025-11-29\n\n### Changed\n- **SKILL.md restructured** for progressive disclosure (471 ‚Üí ~161 lines)\n- Content organized into quick reference format\n\n### Added\n- `references/anti-patterns.md` - 12 documented anti-patterns with fixes\n- `references/shibboleths.md` - 9 expert vs novice indicators\n- `references/validation-checklist.md` - 30+ validation criteria organized by category\n- Decision tree format for common scenarios\n- Integration guide with other skills\n\n### Migration\n- No changes to frontmatter or activation triggers\n- Validation checklist now available for systematic review\n- Anti-patterns guide helps avoid common mistakes\n\n## [1.2.0] - 2025-11-26\n\n### Added\n- **MCP & Tool Research (MANDATORY)** section - comprehensive guide for researching MCPs\n- Research process with 4 steps: Web Search, Check Registries, Evaluate Quality, Add to Skill\n- Domain-Specific MCP Examples table\n- Anti-pattern: Assuming No MCPs Exist\n- Anti-pattern: Adding MCPs Without Testing\n- MCP research added to Quick Start workflow (step 2)\n- MCP research added to Review Checklist (CRITICAL section)\n\n### Changed\n- Updated Review Checklist: `allowed-tools` guidance now emphasizes including relevant MCPs\n- Quick Start now has 6 steps instead of 5 (added MCP research step)\n\n## [1.1.0] - 2025-11-26\n\n### Added\n- Versioning Skills section with complete guidance\n- CHANGELOG.md format template\n- Version numbering explanation (MAJOR/MINOR/PATCH)\n- \"Why version skills?\" rationale\n- Recommended structure now includes CHANGELOG.md\n- CHANGELOG.md tracking added to Review Checklist (HIGH PRIORITY)\n\n## [1.0.0] - 2025-01-01\n\n### Added\n- Initial skill creation\n- Progressive disclosure architecture\n- Description field design patterns\n- Anti-pattern detection framework\n- Temporal knowledge capture\n- Domain-specific shibboleths\n- Skill review checklist\n- Testing guidelines\n- Decision trees for skill creation\n"
    },
    {
      "name": "DEPRECATED.md",
      "type": "file",
      "path": "skill-coach/DEPRECATED.md",
      "size": 520,
      "content": "# DEPRECATED\n\nThis skill has been superseded by **skill-architect** as of 2026-01-14.\n\n## Why Deprecated\n\nskill-coach and skill-creator have been unified into a single authoritative meta-skill that combines:\n- Systematic workflow from skill-creator\n- Domain expertise encoding from skill-coach\n\n## Migration\n\nUse `/skill-architect` instead of this skill.\n\nAll functionality from skill-coach has been preserved and enhanced in skill-architect.\n\n## Location\n\nNew skill: `/Users/erichowens/.claude/skills/skill-architect/`\n"
    },
    {
      "name": "OVERVIEW.md",
      "type": "file",
      "path": "skill-coach/OVERVIEW.md",
      "size": 7450,
      "content": "# Skill-Coach: Overview\n\n## What This Is\n\nA **meta-skill** that guides creation of expert-level Agent Skills - the kind that encode real domain knowledge and shibboleths, not just surface-level instructions.\n\n**Status**: Iteratively self-improved 5 times using its own guidance (Nov 2025), demonstrating the improvement loop it teaches.\n\n## Key Innovation: Encoding the Shibboleths\n\nMost skills say: \"Here's how to use X\"\n\nThis teaches: \"Here's how to use X, and here's where everyone gets it wrong, and why, and what to use instead\"\n\n## Structure\n\n```\nskill-coach/\n‚îú‚îÄ‚îÄ README.md                           # Start here\n‚îú‚îÄ‚îÄ SKILL.md                            # The coach skill itself\n‚îú‚îÄ‚îÄ scripts/\n‚îÇ   ‚îî‚îÄ‚îÄ validate_skill.py              # ‚úÖ Validates skill structure & quality\n‚îú‚îÄ‚îÄ references/\n‚îÇ   ‚îú‚îÄ‚îÄ antipatterns.md                # üéØ Domain-specific shibboleths\n‚îÇ   ‚îî‚îÄ‚îÄ mcp_vs_scripts.md              # When to use MCP vs Scripts\n‚îî‚îÄ‚îÄ examples/\n    ‚îî‚îÄ‚îÄ good/\n        ‚îî‚îÄ‚îÄ clip-aware-embeddings/     # üåü Exemplary skill\n            ‚îú‚îÄ‚îÄ SKILL.md\n            ‚îî‚îÄ‚îÄ scripts/\n                ‚îî‚îÄ‚îÄ validate_clip_usage.py  # Domain-specific validator\n```\n\n## The CLIP Example: Why This Matters\n\nLook at `examples/good/clip-aware-embeddings/SKILL.md` - it doesn't just say \"use CLIP for image-text matching.\"\n\nIt says:\n\n**Novice knowledge** (what LLMs trained on 2021-2023 data know):\n> \"CLIP is pre-trained on 400M image-text pairs! Use it for all image tasks!\"\n\n**Expert knowledge** (the shibboleth):\n> \"CLIP has fundamental geometric limitations. It CANNOT:\n> - Count objects (use DETR instead)\n> - Do fine-grained classification (use specialized models)\n> - Understand spatial relationships (use GQA models)\n> - Bind attributes ('red car AND blue truck' ‚Üí use DCSMs)\"\n\nThis is the knowledge gap that separates \"it compiles\" from \"it's correct.\"\n\n## What Makes This Different\n\n### 1. Anti-Patterns Catalog\n\n`references/antipatterns.md` documents:\n- CLIP's actual limitations (with research citations)\n- Framework evolution (Next.js Pages ‚Üí App Router)\n- Architecture decisions (MCP vs Scripts philosophy)\n- Temporal context (when things changed and why)\n\n### 2. Validation Tooling\n\n**General validation** (`scripts/validate_skill.py`):\n- Checks structure (YAML, required fields)\n- Validates description quality\n- Ensures progressive disclosure\n- Checks line count (&lt;500)\n- Verifies allowed-tools scope\n\n**Domain-specific validation** (`examples/.../validate_clip_usage.py`):\n- Detects counting queries ‚Üí suggests object detection\n- Identifies spatial queries ‚Üí suggests spatial models\n- Catches fine-grained tasks ‚Üí suggests specialized models\n\nThis is **executable domain knowledge**.\n\n### 3. Progressive Disclosure Done Right\n\nThe CLIP skill is 380 lines but FEELS concise because:\n- Quick decision tree upfront\n- Anti-patterns clearly marked\n- References to deep dives (not inline)\n- Validation scripts (run, don't read)\n\n### 4. Temporal Knowledge\n\nEvery anti-pattern includes:\n- **Timeline**: \"2021: CLIP released, 2023: limitations discovered\"\n- **Why LLMs get it wrong**: \"Training data predates the research\"\n- **Migration path**: \"If you're doing X, use Y instead\"\n\n## Test It Out\n\n### Validate Your Skills\n\n```bash\ncd skill-coach\npython scripts/validate_skill.py /path/to/your-skill/\n```\n\n### See Domain Validation\n\n```bash\ncd examples/good/clip-aware-embeddings\npython scripts/validate_clip_usage.py \"How many cars are in this image?\"\n# ‚Üí ‚ùå Use object detection: DETR, Faster R-CNN, YOLO\n\npython scripts/validate_clip_usage.py \"Find images of beaches\"\n# ‚Üí ‚úÖ CLIP is appropriate\n```\n\n## The MCP vs Scripts Philosophy\n\nFrom `references/mcp_vs_scripts.md`:\n\n> \"MCP's job isn't to abstract reality for the agent; it's to manage the auth, networking, and security boundaries and then get out of the way.\"\n\n**Use Scripts for**:\n- Local file operations\n- Stateless transformations\n- CLI wrappers\n- Batch processing\n\n**Use MCPs for**:\n- External APIs with auth\n- Stateful connections\n- Real-time data\n- Multiple related operations\n\nThe guide includes decision matrix, evolution path, and anti-examples.\n\n## Key Shibboleths Encoded\n\n### ML/AI\n- CLIP's geometric impossibilities\n- Embedding model selection by task\n- Model versioning and temporal changes\n\n### Frameworks\n- Next.js: Pages Router ‚Üí App Router (Oct 2022)\n- React: Class Components ‚Üí Hooks (Feb 2019)\n- State: Redux ‚Üí Zustand/Context (2020+)\n\n### Architecture\n- When complexity justifies MCP over scripts\n- Security via least-privilege tool access\n- Performance vs simplicity tradeoffs\n\n## What You Can Do With This\n\n1. **Use it as-is**: Ask Claude to apply skill-coach when creating skills\n2. **Study the example**: See all principles in action\n3. **Add your shibboleths**: Contribute domain knowledge you've learned\n4. **Validate existing skills**: Run the validator on skills you have\n\n## Recent Improvements (5 Iterations)\n\nThe skill-coach has been iteratively improved using its own guidance:\n\n**Iteration 1**: Foundation\n- Added 5 skill-specific anti-patterns (Reference Illusion, Description Soup, Template Theater, Everything Skill, Orphaned Sections)\n- Added Evolution Timeline (2024-2025 skill framework best practices)\n- Created comprehensive Skill Review Checklist\n- Removed all references to non-existent files\n\n**Iteration 2**: Actionability\n- Added 3 Common Workflows (create, debug activation, reduce false positives)\n- Made iteration strategy actionable with specific prompts\n- Explained why THIS skill uses each tool\n- Condensed validation patterns to concepts\n\n**Iteration 3**: Expert Knowledge\n- Added Skill Creation Shibboleths (novice vs expert skill creator)\n- Enhanced \"What Makes a Great Skill\" (5‚Üí7 items)\n- Condensed domain examples\n- Added meta-note about self-improvement\n\n**Iteration 4**: Usability\n- Added \"Quick Wins\" - 5 immediate improvements\n- Simplified skill structure (honest about what's needed)\n- Description progression (Bad‚ÜíBetter‚ÜíGood)\n- Realistic file structure (SKILL.md only is mandatory)\n\n**Iteration 5**: Decision Support\n- Added Decision Trees (when to create new skill, Skill vs Subagent vs MCP)\n- Prioritized checklist (CRITICAL/HIGH PRIORITY/NICE TO HAVE)\n- Final polish and consistency\n\n**Result**: 482 ‚Üí 470 lines, more concise yet more comprehensive.\n\n## The Meta Point\n\nThis skill **practices what it preaches**:\n\n- ‚úÖ Progressive disclosure (SKILL.md ‚Üí references/)\n- ‚úÖ Anti-patterns specific to skill creation\n- ‚úÖ Validation tooling (validate_skill.py)\n- ‚úÖ Working examples (CLIP skill)\n- ‚úÖ Temporal knowledge (2024-2025 evolution)\n- ‚úÖ Clear decision trees (when to create, Skill vs MCP)\n- ‚úÖ Iteratively improved using its own guidance\n\nIt's not just teaching - it's demonstrating.\n\n## Start Here\n\n1. Read `README.md` for getting started\n2. Check `SKILL.md` for Quick Wins (immediate improvements)\n3. Study `examples/good/clip-aware-embeddings/SKILL.md`\n4. Review `references/antipatterns.md` for domain shibboleths\n5. Use skill-coach when creating/improving your own skills\n\n## The Philosophy\n\n> \"Great skills don't just say 'here's how' - they say 'here's how, and here's where everyone gets it wrong, and why, and what to use instead.'\"\n\nThis is about encoding expertise and shibboleths, not just instructions.\n\n---\n\nCreated: 2025-11-23\nLast Improved: 2025-11-24 (5 iterations)\nVersion: 2.0.0\n"
    },
    {
      "name": "README.md",
      "type": "file",
      "path": "skill-coach/README.md",
      "size": 10579,
      "content": "# Skill Coach: Master Agent Skills Development\n\nA comprehensive guide and toolkit for creating expert-level Agent Skills that encode real domain knowledge, not just surface-level instructions.\n\n**Latest**: Iteratively self-improved 5 times (Nov 2024), demonstrating the improvement loop it teaches.\n\n## What This Skill Does\n\nSkill Coach helps you build skills that:\n- **Activate precisely** - Specific keywords + NOT clause prevents false activation\n- **Encode shibboleths** - Domain knowledge separating experts from novices\n- **Surface anti-patterns** - \"If you see X, that's wrong because Y, use Z\"\n- **Capture temporal knowledge** - \"Pre-2024: X. 2024+: Y. Watch for LLMs suggesting X\"\n- **Know their limits** - \"Use this for A, B, C. NOT for D, E, F\"\n- **Provide decision trees** - Not templates, but \"If X then A, if Y then B, never C\"\n- **Include validation** - Pre-flight checks catching errors early\n\n## Quick Start\n\n### 1. Install and Use\n\nCopy this folder to your skills directory:\n\n```bash\n# For Claude Code\ncp -r skill-coach ~/.claude/skills/\n\n# For Claude.ai\n# Upload via the Skills interface\n```\n\n### 2. Validate Your Skills\n\n```bash\ncd skill-coach\npython scripts/validate_skill.py /path/to/your-skill/\n```\n\n### 3. Study Examples\n\nLook at `/examples/good/clip-aware-embeddings/` to see all principles in action.\n\n## What's Inside\n\n```\nskill-coach/\n‚îú‚îÄ‚îÄ SKILL.md                    # Main skill instructions\n‚îú‚îÄ‚îÄ scripts/\n‚îÇ   ‚îî‚îÄ‚îÄ validate_skill.py       # Skill validation tool\n‚îú‚îÄ‚îÄ references/\n‚îÇ   ‚îú‚îÄ‚îÄ antipatterns.md         # Domain shibboleths catalog\n‚îÇ   ‚îî‚îÄ‚îÄ mcp_vs_scripts.md       # Architecture decisions\n‚îî‚îÄ‚îÄ examples/\n    ‚îú‚îÄ‚îÄ good/\n    ‚îÇ   ‚îî‚îÄ‚îÄ clip-aware-embeddings/  # Exemplary skill\n    ‚îî‚îÄ‚îÄ bad/\n        ‚îî‚îÄ‚îÄ (anti-examples)\n```\n\n## Key Concepts\n\n### 1. Progressive Disclosure\n\nSkills load in three phases:\n- **Phase 1 (~100 tokens)**: Metadata - \"Should I activate?\"\n- **Phase 2 (&lt;5k tokens)**: Instructions - \"How do I do this?\"\n- **Phase 3 (as needed)**: Details - \"Show me more\"\n\n### 2. The Shibboleths\n\nDeep knowledge that reveals expertise:\n\n**Example - CLIP Embeddings**:\n- **Novice**: \"CLIP is great for image-text tasks!\"\n- **Expert**: \"CLIP fails at counting, fine-grained classification, spatial reasoning, and attribute binding. Use DETR for counting, specialized models for fine-grained, DCSMs for compositional.\"\n\n### 3. Anti-Pattern Detection\n\nGreat skills actively warn about mistakes:\n\n```markdown\n### Anti-Pattern: Using CLIP to Count Objects\n\n**Why wrong**: CLIP's architecture cannot preserve spatial information\n**What to do**: Use DETR or Faster R-CNN\n**How to detect**: If query contains \"how many\" or \"count\"\n```\n\n### 4. Temporal Knowledge\n\nCapture what changed and when:\n\n```markdown\n## Evolution Timeline\n- Pre-2024: Redux for all state management\n- 2024+: Zustand/Jotai for global state, Context for simple cases\n- Watch for: LLMs suggesting Redux by default\n```\n\n## Creating Your First Skill\n\n### Step 1: Define Scope\n\n```markdown\n---\nname: your-skill-name\ndescription: [What it does] [When to use] [Specific triggers]. NOT for [What it's NOT for].\n---\n```\n\n### Step 2: Add Instructions\n\n```markdown\n# Your Skill\n\n## When to Use\n‚úÖ Use for: ...\n‚ùå Do NOT use for: ...\n\n## Quick Start\n[Minimal working example]\n\n## Common Anti-Patterns\n[What looks right but is wrong]\n```\n\n### Step 3: Include Validation\n\n```python\n# scripts/validate.py\ndef validate_setup():\n    # Check environment, dependencies, config\n    pass\n```\n\n### Step 4: Test\n\n```bash\npython scripts/validate_skill.py your-skill/\n```\n\n## Quick Wins (Improve Existing Skills Fast)\n\nApply these immediately to existing skills:\n\n1. **Add NOT clause** to description ‚Üí Prevents false activation\n2. **Add 1-2 anti-patterns** ‚Üí Prevents common mistakes\n3. **Check line count** (`wc -l`) ‚Üí Should be &lt;500\n4. **Remove dead files** ‚Üí Delete unreferenced scripts/references\n5. **Test activation** ‚Üí Ask questions that should/shouldn't trigger it\n\n## Validation Checklist (Prioritized)\n\n**CRITICAL** (must-have):\n- [ ] Description has keywords AND NOT clause\n- [ ] SKILL.md under 500 lines\n- [ ] All referenced files exist\n- [ ] Test activation: Does it activate when it should?\n- [ ] Test non-activation: Doesn't activate when it shouldn't?\n\n**HIGH PRIORITY** (should-have):\n- [ ] Has \"When to Use\" and \"When NOT to Use\" sections\n- [ ] Includes 1-3 anti-patterns with \"Why it's wrong\"\n- [ ] Encodes domain shibboleths (expert vs novice knowledge)\n- [ ] `allowed-tools` is minimal\n\n**NICE TO HAVE** (polish):\n- [ ] Temporal knowledge (what changed when)\n- [ ] Working code examples (not just templates)\n- [ ] References for deep dives\n- [ ] Bash restrictions if applicable\n\n## Real Examples\n\n### Good: CLIP-Aware Embeddings\n\nSee `/examples/good/clip-aware-embeddings/` for a skill that:\n- Knows when CLIP works and when it doesn't\n- Provides alternatives for each limitation\n- Includes validation scripts\n- Documents evolution (2021 ‚Üí 2025)\n- Has clear anti-patterns\n\n### Study This Example\n\nIt demonstrates:\n1. ‚úÖ Progressive disclosure\n2. ‚úÖ Anti-pattern detection\n3. ‚úÖ Temporal knowledge\n4. ‚úÖ Task-specific guidance\n5. ‚úÖ Validation tooling\n6. ‚úÖ Clear alternatives\n\n## Domain-Specific Shibboleths\n\nThese are the knowledge gaps where skills add most value:\n\n### ML/AI Models\n- CLIP limitations (counting, fine-grained, spatial)\n- When to use specialized models\n- Embedding model selection by task\n\n### Framework Evolution\n- Next.js: Pages Router ‚Üí App Router (2022)\n- React: Class Components ‚Üí Hooks (2019)\n- State Management: Redux ‚Üí Zustand (2020+)\n\n### Architecture\n- When to use MCP vs Scripts\n- Evolution from scripts ‚Üí library ‚Üí MCP\n- Security and performance tradeoffs\n\n**See `/references/antipatterns.md` for comprehensive catalog**\n\n## Best Practices\n\n### Description Field\n\n**Good**:\n```yaml\ndescription: Semantic image search with CLIP. Use for finding similar images, zero-shot classification. NOT for counting objects, fine-grained classification, or spatial reasoning. Mention CLIP, embeddings, image similarity.\n```\n\n**Bad**:\n```yaml\ndescription: Helps with images\n```\n\n### Progressive Structure\n\n**Good**:\n```markdown\n# Skill Name\n\n## Quick Decision Tree\n[Fast decision making]\n\n## Common Anti-Patterns\n[What to avoid]\n\n## Validation\n[How to check]\n\nSee /references/deep_dive.md for detailed theory\n```\n\n**Bad**:\n```markdown\n# Skill Name\n\n[50 pages of comprehensive tutorial]\n```\n\n### Validation\n\n**Good**:\n```python\n# scripts/validate.py\ndef check_environment():\n    \"\"\"Specific, actionable errors\"\"\"\n    if not has_model():\n        raise Error(\"Model X not found. Install: pip install x\")\n\ndef check_task_appropriate(query):\n    \"\"\"Task-specific validation\"\"\"\n    if \"count\" in query.lower():\n        raise Error(\"Use object detection for counting, not CLIP\")\n```\n\n**Bad**:\n```python\n# No validation script\n# Or generic \"check passed/failed\" with no guidance\n```\n\n## Tools & Scripts\n\n### Validate Skill Structure\n\n```bash\npython scripts/validate_skill.py your-skill/\n```\n\nChecks:\n- Required files and structure\n- Description quality\n- Line count (&lt;500)\n- Progressive disclosure\n- Anti-patterns section\n- allowed-tools scope\n\n### Create New Skill\n\nAsk Claude:\n```\nUsing the skill-coach skill, help me create a new skill for [your domain].\nFocus on anti-patterns where novices get it wrong.\n```\n\n## Common Mistakes\n\n### ‚ùå Skill as Documentation Dump\n\nDon't create a 500-line tutorial. Create actionable instructions with references.\n\n### ‚ùå Missing \"NOT for\"\n\nWithout negative triggers, skills activate on false positives.\n\n### ‚ùå No Temporal Context\n\nLLMs suggest outdated patterns. Document what changed and when.\n\n### ‚ùå Overly Permissive Tools\n\n```yaml\nallowed-tools: Bash  # Can execute ANYTHING\n```\n\nBetter:\n```yaml\nallowed-tools: Bash(git:*,npm:run),Read,Write\n```\n\n### ‚ùå No Validation\n\nSkills should include scripts to check if environment is correct.\n\n## Integration with Other Tools\n\n### Works with MCP\n\nSkills can reference MCPs:\n```markdown\n## Requirements\n- GitHub MCP (for API access)\n- Scripts for local validation\n\nInstall: `/plugin marketplace add github-mcp`\n```\n\n### Works with Subagents\n\nSubagents can use skills for domain expertise:\n```\nSkill provides knowledge ‚Üí Subagent executes with tools\n```\n\n### Works with Projects\n\nSkills available across all conversations in a project.\n\n## Contributing Patterns\n\nWhen you discover a new anti-pattern:\n\n1. **Document what looks right but is wrong**\n2. **Explain WHY it's wrong** (fundamental reason)\n3. **Show the correct approach**\n4. **Add temporal context** (when did this change?)\n5. **Note why LLMs make this mistake**\n6. **Include detection/validation if possible**\n\n## Resources\n\n### In This Skill\n\n- `/references/antipatterns.md` - Comprehensive anti-pattern catalog\n- `/references/mcp_vs_scripts.md` - When to use what\n- `/examples/good/` - Exemplary skills to study\n- `/scripts/validate_skill.py` - Validation tool\n\n### External\n\n- [Anthropic Skills Docs](https://docs.claude.com/en/docs/agents-and-tools/agent-skills)\n- [Skills Explained](https://claude.com/blog/skills-explained)\n- [Equipping Agents](https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills)\n- [MCP Documentation](https://modelcontextprotocol.io/)\n\n## Version History\n\n### v2.0.0 (2025-11-24)\n**5 Iterations of Self-Improvement:**\n- Iteration 1: Added 5 skill-specific anti-patterns, Evolution Timeline, removed non-existent file references\n- Iteration 2: Added Common Workflows, Tool Permissions explanation, actionable iteration strategy\n- Iteration 3: Added Skill Creation Shibboleths, enhanced \"What Makes a Great Skill\" (5‚Üí7 items)\n- Iteration 4: Added Quick Wins, simplified structure, Description progression (Bad‚ÜíBetter‚ÜíGood)\n- Iteration 5: Added Decision Trees (when to create, Skill vs MCP), prioritized checklist\n- Result: 482 ‚Üí 470 lines, more concise yet comprehensive\n\n### v1.0.0 (2025-11-23)\n- Initial release\n- Comprehensive anti-patterns catalog\n- CLIP-aware embeddings example\n- Validation tooling\n- MCP vs Scripts guide\n\n---\n\n## Get Started\n\n1. Read SKILL.md **Quick Wins** for immediate improvements\n2. Study `/examples/good/clip-aware-embeddings/`\n3. Run validation on your existing skills\n4. Use this skill when creating new skills\n5. Share your domain-specific shibboleths\n\n**Remember**: Great skills don't just say \"here's how\" - they say \"here's how, and here's where everyone gets it wrong, and why, and what to use instead.\"\n"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "skill-coach/SKILL.md",
      "size": 10345,
      "content": "---\nname: skill-coach\ndescription: \"Guides creation of high-quality Agent Skills with domain expertise, anti-pattern detection, and progressive disclosure best practices. Activate on keywords: create skill, review skill, skill quality, skill best practices, skill anti-patterns, improve skill, skill audit. NOT for general coding advice, slash commands, MCP development, or non-skill Claude Code features.\"\nallowed-tools: Read,Write,Edit,Glob,Grep,Bash(python:*)\ncategory: Productivity & Meta\ntags:\n  - skills\n  - quality\n  - anti-patterns\n  - best-practices\n  - review\npairs-with:\n  - skill: agent-creator\n    reason: Quality review for new skills\n  - skill: automatic-stateful-prompt-improver\n    reason: Optimize skill prompts\n---\n\n# Skill Coach: Creating Expert-Level Agent Skills\n\nEncode real domain expertise, not just surface-level instructions. Focus on **shibboleths** - the deep knowledge that separates novices from experts.\n\n## When to Use This Skill\n\n**Use for:**\n- Creating new Agent Skills from scratch\n- Reviewing/auditing existing skills\n- Improving skill activation rates\n- Adding domain expertise to skills\n- Debugging why skills don't activate\n\n**NOT for:**\n- General Claude Code features (slash commands, MCPs)\n- Non-skill coding advice\n- Debugging runtime errors (use domain skills)\n\n## Quick Wins\n\n**Immediate improvements for existing skills**:\n1. **Add NOT clause** to description ‚Üí Prevents false activation\n2. **Add 1-2 anti-patterns** ‚Üí Prevents common mistakes\n3. **Check line count** (run validator) ‚Üí Should be fewer than 500 lines\n4. **Remove dead files** ‚Üí Delete unreferenced scripts/references\n5. **Test activation** ‚Üí Questions that should/shouldn't trigger it\n\n## What Makes a Great Skill\n\nGreat skills are **progressive disclosure machines** that:\n1. **Activate precisely** - Specific keywords + NOT clause\n2. **Encode shibboleths** - Expert knowledge that separates novice from expert\n3. **Surface anti-patterns** - \"If you see X, that's wrong because Y, use Z\"\n4. **Capture temporal knowledge** - \"Pre-2024: X. 2024+: Y\"\n5. **Know their limits** - \"Use for A, B, C. NOT for D, E, F\"\n6. **Provide decision trees** - Not templates, but \"If X then A, if Y then B\"\n7. **Stay under 500 lines** - Core in SKILL.md, deep dives in /references\n\n## Core Principles\n\n### Progressive Disclosure\n\n- **Phase 1 (~100 tokens)**: Metadata - \"Should I activate?\"\n- **Phase 2 (&lt;5k tokens)**: SKILL.md - \"How do I do this?\"\n- **Phase 3 (as needed)**: References - \"Show me the details\"\n\n**Critical**: Keep SKILL.md under 500 lines. Split details into `/references`.\n\n### Description Formula\n\n**[What] [Use for] [Keywords] NOT for [Exclusions]**\n\n```\n‚ùå Bad: \"Helps with images\"\n‚ö†Ô∏è Better: \"Image processing with CLIP\"\n‚úÖ Good: \"CLIP semantic search. Use for image-text matching.\n   Activate on 'CLIP', 'embeddings'. NOT for counting, spatial reasoning.\"\n```\n\n## SKILL.md Template\n\n```markdown\n---\nname: your-skill-name\ndescription: [What] [When] [Triggers]. NOT for [Exclusions].\nallowed-tools: Read,Write  # Minimal only\n---\n\n# Skill Name\n[One sentence purpose]\n\n## When to Use\n‚úÖ Use for: [A, B, C]\n‚ùå NOT for: [D, E, F]\n\n## Core Instructions\n[Step-by-step, decision trees, not templates]\n\n## Common Anti-Patterns\n### [Pattern]\n**Symptom**: [Recognition]\n**Problem**: [Why wrong]\n**Solution**: [Better approach]\n```\n\n## Frontmatter Rules (CRITICAL)\n\n**Only these frontmatter keys are allowed by Claude's skill marketplace:**\n\n| Key | Required | Purpose |\n|-----|----------|---------|\n| `name` | ‚úÖ | Lowercase-hyphenated identifier |\n| `description` | ‚úÖ | Activation keywords + NOT clause |\n| `allowed-tools` | ‚ö†Ô∏è | Comma-separated tool names |\n| `license` | ‚ùå | e.g., \"MIT\" |\n| `metadata` | ‚ùå | Custom key-value pairs |\n\n**Invalid keys that will FAIL upload:**\n```yaml\n# ‚ùå WRONG - These will break skill upload\nintegrates_with:\n  - orchestrator\ntriggers:\n  - \"activate on this\"\ntools: Read,Write\noutputs: formatted text\ncoordinates_with: other-skill\npython_dependencies:\n  - numpy\n```\n\n**Move custom info to the body:**\n```markdown\n## Integrations\nWorks with: orchestrator, team-builder\n\n## Activation Triggers\nResponds to: \"create skill\", \"review skill\", \"skill quality\"\n```\n\n**Validation command:**\n```bash\n# Find invalid frontmatter keys\nfor skill in .claude/skills/*/SKILL.md; do\n  sed -n '/^---$/,/^---$/p' \"$skill\" | grep -E \"^[a-zA-Z_-]+:\" | cut -d: -f1 | \\\n    grep -vE \"^(name|description|license|allowed-tools|metadata)$\" && \\\n    echo \"  ^ in $(basename $(dirname $skill))\"\ndone\n```\n\n## Skill Structure\n\n**Mandatory**:\n```\nyour-skill/\n‚îî‚îÄ‚îÄ SKILL.md           # Core instructions (max 500 lines)\n```\n\n**Strongly Recommended** (self-contained skills):\n```\n‚îú‚îÄ‚îÄ scripts/           # Working code - NOT templates\n‚îú‚îÄ‚îÄ mcp-server/        # Custom MCP if external APIs needed\n‚îú‚îÄ‚îÄ agents/            # Subagent definitions if orchestration needed\n‚îú‚îÄ‚îÄ references/        # Deep dives on domain knowledge\n‚îî‚îÄ‚îÄ CHANGELOG.md       # Version history\n```\n\n## Self-Contained Skills (RECOMMENDED)\n\n**Skills with working tools are immediately useful.** See `references/self-contained-tools.md` for full patterns.\n\n**Quick decision**: External APIs? ‚Üí MCP. Multi-step workflow? ‚Üí Subagents. Repeatable operations? ‚Üí Scripts.\n\n## Decision Trees\n\n**When to create a NEW skill?**\n- ‚úÖ Domain expertise not in existing skills\n- ‚úÖ Pattern repeats across 3+ projects\n- ‚úÖ Anti-patterns you want to prevent\n- ‚ùå One-time task ‚Üí Just do it directly\n- ‚ùå Existing skill could be extended ‚Üí Improve that one\n\n**Skill vs Subagent vs MCP?**\n- **Skill**: Domain expertise, decision trees (no runtime state)\n- **Subagent**: Multi-step workflows needing tool orchestration\n- **MCP**: External APIs, auth, stateful connections\n\n## Skill Creation Process (6 Steps)\n\nFollow these steps in order when creating a new skill:\n\n### Step 1: Understand with Concrete Examples\nSkip only if usage patterns are already clear. Ask:\n- \"What functionality should this skill support?\"\n- \"Can you give examples of how it would be used?\"\n- \"What would a user say that should trigger this skill?\"\n\n### Step 2: Plan Reusable Contents\nFor each example, analyze:\n1. How to execute from scratch\n2. What scripts, references, assets would help with repeated execution\n\n**Example analyses**:\n- `pdf-editor` for \"rotate this PDF\" ‚Üí Needs `scripts/rotate_pdf.py`\n- `frontend-webapp-builder` ‚Üí Needs `assets/hello-world/` template\n- `big-query` skill ‚Üí Needs `references/schema.md` for table schemas\n\n### Step 3: Initialize the Skill\nCreate the skill directory structure:\n```\nyour-skill/\n‚îú‚îÄ‚îÄ SKILL.md           # Core instructions (max 500 lines)\n‚îú‚îÄ‚îÄ scripts/           # Working code - NOT templates\n‚îú‚îÄ‚îÄ references/        # Deep dives on domain knowledge\n‚îî‚îÄ‚îÄ assets/            # Files used in output (templates, icons)\n```\n\n### Step 4: Write SKILL.md\n- Write in **imperative/infinitive form** (\"To accomplish X, do Y\")\n- Answer: Purpose? When to use? How to use bundled resources?\n- Reference all scripts/references so Claude knows they exist\n\n### Step 5: Validate and Package\n```bash\n# Validate skill structure and content\npython scripts/validate_skill.py <path>\n\n# Check for self-contained tool completeness\npython scripts/check_self_contained.py <path>\n```\n\n### Step 6: Iterate\nAfter real-world use:\n1. Notice struggles or inefficiencies\n2. Identify how SKILL.md or bundled resources should be updated\n3. Implement changes and test again\n\n---\n\n## Common Workflows\n\n**Create Skill from Expertise**:\n1. Define scope: What expertise? What keywords? What NOT to handle?\n2. Write description with keywords and NOT clause\n3. Add anti-patterns you've observed\n4. Test activation thoroughly\n\n**Debug Activation Issues** (flowchart):\n```\nSkill not activating when expected?\n‚îú‚îÄ‚îÄ Check description has specific keywords\n‚îÇ   ‚îú‚îÄ‚îÄ NO ‚Üí Add \"Activate on: keyword1, keyword2\"\n‚îÇ   ‚îî‚îÄ‚îÄ YES ‚Üí Check if query contains those keywords\n‚îÇ       ‚îú‚îÄ‚îÄ NO ‚Üí Add missing keyword variations\n‚îÇ       ‚îî‚îÄ‚îÄ YES ‚Üí Check for conflicting NOT clause\n‚îÇ           ‚îú‚îÄ‚îÄ YES ‚Üí Narrow exclusion scope\n‚îÇ           ‚îî‚îÄ‚îÄ NO ‚Üí Check file structure\n‚îÇ               ‚îú‚îÄ‚îÄ SKILL.md missing ‚Üí Create it\n‚îÇ               ‚îî‚îÄ‚îÄ Wrong location ‚Üí Move to .claude/skills/\n\nSkill activating when it shouldn't?\n‚îú‚îÄ‚îÄ Missing NOT clause?\n‚îÇ   ‚îú‚îÄ‚îÄ YES ‚Üí Add \"NOT for: exclusion1, exclusion2\"\n‚îÇ   ‚îî‚îÄ‚îÄ NO ‚Üí NOT clause too narrow\n‚îÇ       ‚îî‚îÄ‚îÄ Expand exclusions based on false positive queries\n```\nRun `python scripts/test_activation.py <path>` to validate\n\n**Recursive Self-Improvement** (use this skill to improve skills):\n1. Run `python scripts/validate_skill.py <path>` ‚Üí Get validation report\n2. Run `python scripts/check_self_contained.py <path>` ‚Üí Check tool completeness\n3. Address ERRORS first, then WARNINGS, then SUGGESTIONS\n4. Re-run validation until clean\n5. Update CHANGELOG.md with improvements made\n\n## Tool Permissions\n\n**Guidelines**:\n- Read-only skill: `Read,Grep,Glob`\n- File modifier: `Read,Write,Edit`\n- Build integration: `Read,Write,Bash(npm:*,git:*)`\n- ‚ö†Ô∏è **Never**: Unrestricted `Bash` for untrusted skills\n\n## Success Metrics\n\n| Metric | Target |\n|--------|--------|\n| Correct activation | &gt;90% |\n| False positive rate | &lt;5% |\n| Token usage | &lt;5k typical |\n\n## Reference Files\n\n| File | Contents |\n|------|----------|\n| `references/antipatterns.md` | Domain shibboleths and anti-pattern catalog with case studies |\n| `references/shibboleths.md` | Expert vs novice knowledge patterns |\n| `references/validation-checklist.md` | Complete review and testing guide |\n| `references/self-contained-tools.md` | Scripts, MCP servers, and subagent implementation patterns |\n| `references/scoring-rubric.md` | Quantitative skill evaluation (0-10 scoring) |\n| `references/skill-composition.md` | Cross-skill dependencies and composition patterns |\n| `references/skill-lifecycle.md` | Maintenance, versioning, and deprecation guidance |\n| `references/mcp_vs_scripts.md` | Architectural decision guide: Skills vs Agents vs MCPs vs Scripts |\n\n---\n\n**This skill guides**: Skill creation | Skill auditing | Anti-pattern detection | Progressive disclosure | Domain expertise encoding\n"
    }
  ]
}