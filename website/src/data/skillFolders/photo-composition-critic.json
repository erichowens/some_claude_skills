{
  "name": "photo-composition-critic",
  "type": "folder",
  "path": "photo-composition-critic",
  "children": [
    {
      "name": "references",
      "type": "folder",
      "path": "photo-composition-critic/references",
      "children": [
        {
          "name": "analysis-scripts.md",
          "type": "file",
          "path": "photo-composition-critic/references/analysis-scripts.md",
          "size": 6419,
          "content": "# Analysis Scripts\n\nPython implementations for photo critique.\n\n## Multi-Model Ensemble Scorer\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nphoto_critic.py - Multi-model image aesthetic analysis\nRequires: torch, transformers, clip, pillow\n\"\"\"\n\nimport torch\nimport clip\nfrom PIL import Image\nfrom pathlib import Path\n\nclass PhotoCritic:\n    def __init__(self):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self._load_models()\n\n    def _load_models(self):\n        # CLIP for embeddings\n        self.clip_model, self.clip_preprocess = clip.load(\"ViT-L/14\", self.device)\n        # LAION aesthetic predictor (simple MLP)\n        self.aesthetic_model = self._load_aesthetic_mlp()\n        # NIMA model\n        self.nima_model = self._load_nima()\n\n    def analyze(self, image_path: str) -> dict:\n        \"\"\"Full aesthetic analysis of an image.\"\"\"\n        img = Image.open(image_path).convert(\"RGB\")\n\n        results = {\n            \"laion_aesthetic\": self._laion_score(img),\n            \"nima_technical\": self._nima_score(img, \"technical\"),\n            \"nima_aesthetic\": self._nima_score(img, \"aesthetic\"),\n            \"composition\": self._analyze_composition(img),\n            \"color_harmony\": self._analyze_color(img),\n            \"technical_quality\": self._analyze_technical(img),\n        }\n\n        results[\"overall\"] = self._compute_overall(results)\n        results[\"critique\"] = self._generate_critique(results)\n\n        return results\n\n    def _analyze_composition(self, img) -> dict:\n        \"\"\"Rule of thirds, golden ratio, visual weight analysis.\"\"\"\n        import numpy as np\n\n        arr = np.array(img.convert(\"L\"))\n\n        # Find visual weight center (centroid of intensity)\n        y_coords, x_coords = np.mgrid[0:arr.shape[0], 0:arr.shape[1]]\n        total = arr.sum()\n        center_y = (y_coords * arr).sum() / total\n        center_x = (x_coords * arr).sum() / total\n\n        # Normalize to 0-1\n        norm_y = center_y / arr.shape[0]\n        norm_x = center_x / arr.shape[1]\n\n        # Distance from rule of thirds intersections\n        thirds_points = [(1/3, 1/3), (2/3, 1/3), (1/3, 2/3), (2/3, 2/3)]\n        min_thirds_dist = min(\n            ((norm_x - px)**2 + (norm_y - py)**2)**0.5\n            for px, py in thirds_points\n        )\n\n        # Golden ratio analysis\n        phi = 0.618\n        golden_points = [(phi, phi), (1-phi, phi), (phi, 1-phi), (1-phi, 1-phi)]\n        min_golden_dist = min(\n            ((norm_x - px)**2 + (norm_y - py)**2)**0.5\n            for px, py in golden_points\n        )\n\n        return {\n            \"visual_center\": (norm_x, norm_y),\n            \"thirds_alignment\": max(0, 1 - min_thirds_dist * 3),\n            \"golden_alignment\": max(0, 1 - min_golden_dist * 3),\n            \"balance\": 1 - abs(norm_x - 0.5) - abs(norm_y - 0.5)\n        }\n\n    def _generate_critique(self, results: dict) -> str:\n        \"\"\"Generate human-readable critique from analysis.\"\"\"\n        critique_parts = []\n\n        # Overall impression\n        overall = results[\"overall\"]\n        if overall >= 8:\n            critique_parts.append(\"Exceptional image with professional-level execution.\")\n        elif overall >= 6.5:\n            critique_parts.append(\"Strong image with good technical and aesthetic qualities.\")\n        elif overall >= 5:\n            critique_parts.append(\"Competent image with room for improvement.\")\n        else:\n            critique_parts.append(\"Image needs significant work on fundamentals.\")\n\n        # Composition feedback\n        comp = results[\"composition\"]\n        if comp[\"thirds_alignment\"] > 0.7:\n            critique_parts.append(\"Strong rule-of-thirds placement.\")\n        elif comp[\"golden_alignment\"] > 0.7:\n            critique_parts.append(\"Nice golden ratio composition.\")\n        elif comp[\"balance\"] < 0.3:\n            critique_parts.append(\"Consider rebalancing - visual weight is off-center.\")\n\n        # Color feedback\n        color = results[\"color_harmony\"]\n        critique_parts.append(f\"Color scheme: {color['harmony_type']} \"\n                            f\"(harmony score: {color['score']:.2f})\")\n\n        return \" \".join(critique_parts)\n```\n\n## MCP Server for Photo Critique\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nphoto_critic_mcp.py - MCP server for photo composition analysis\n\"\"\"\n\nfrom mcp.server import Server\nfrom mcp.types import Tool, TextContent\nimport asyncio\n\napp = Server(\"photo-critic\")\n\n@app.tool()\nasync def analyze_composition(image_path: str) -> str:\n    \"\"\"Analyze image composition using ML models and classical theory.\"\"\"\n    from photo_critic import PhotoCritic\n\n    critic = PhotoCritic()\n    results = critic.analyze(image_path)\n\n    return f\"\"\"\n## Aesthetic Analysis Results\n\n**Overall Score: {results['overall']:.1f}/10**\n\n### Model Scores\n- LAION Aesthetic: {results['laion_aesthetic']:.2f}\n- NIMA Technical: {results['nima_technical']:.2f}\n- NIMA Aesthetic: {results['nima_aesthetic']:.2f}\n\n### Composition Analysis\n- Rule of Thirds Alignment: {results['composition']['thirds_alignment']:.0%}\n- Golden Ratio Alignment: {results['composition']['golden_alignment']:.0%}\n- Visual Balance: {results['composition']['balance']:.0%}\n\n### Color Analysis\n- Harmony Type: {results['color_harmony']['harmony_type']}\n- Harmony Score: {results['color_harmony']['score']:.2f}\n\n### Critique\n{results['critique']}\n\"\"\"\n\n@app.tool()\nasync def compare_crops(image_path: str, crops: list[dict]) -> str:\n    \"\"\"Compare multiple crop options for an image.\n\n    crops: List of {x, y, width, height} dicts defining crop regions\n    \"\"\"\n    from photo_critic import PhotoCritic\n    from PIL import Image\n\n    critic = PhotoCritic()\n    img = Image.open(image_path)\n\n    results = []\n    for i, crop in enumerate(crops):\n        cropped = img.crop((\n            crop['x'], crop['y'],\n            crop['x'] + crop['width'],\n            crop['y'] + crop['height']\n        ))\n        temp_path = f\"/tmp/crop_{i}.jpg\"\n        cropped.save(temp_path)\n        score = critic.analyze(temp_path)['overall']\n        results.append((i, score, crop))\n\n    results.sort(key=lambda x: x[1], reverse=True)\n\n    output = \"## Crop Comparison\\n\\n\"\n    for rank, (idx, score, crop) in enumerate(results, 1):\n        output += f\"{rank}. Crop {idx}: **{score:.1f}/10** \"\n        output += f\"({crop['width']}x{crop['height']} at {crop['x']},{crop['y']})\\n\"\n\n    return output\n\nif __name__ == \"__main__\":\n    asyncio.run(app.run())\n```\n"
        },
        {
          "name": "color-theory.md",
          "type": "file",
          "path": "photo-composition-critic/references/color-theory.md",
          "size": 2145,
          "content": "# Color Theory\n\nAdvanced color perception and harmony systems.\n\n## Josef Albers - Interaction of Color\n\n```\nKEY PRINCIPLES\n├── Colors change based on neighbors\n├── One color can appear as two different colors\n├── Two colors can appear identical\n└── Quantity affects perception (small vs large areas)\n```\n\n**Critical for photo critique**: The Bezold Effect - a color appears different depending on surrounding colors. Essential when evaluating edits.\n\n## Johannes Itten - 7 Color Contrasts\n\n| Contrast | Description |\n|----------|-------------|\n| Hue | Different colors |\n| Value | Light vs dark |\n| Saturation | Pure vs muted |\n| Temperature | Warm vs cool |\n| Complementary | Opposites |\n| Simultaneous | Induced complementary |\n| Extension | Ratio of color areas |\n\n## Color Harmony Detection\n\n```python\ndef analyze_color_harmony(img):\n    \"\"\"Analyze hue distribution for harmony type.\"\"\"\n    hsv_pixels = [rgb_to_hsv(p) for p in img.getdata()]\n    hues = [p[0] for p in hsv_pixels if p[1] > 0.2]  # Ignore desaturated\n\n    if not hues:\n        return {\"harmony_type\": \"achromatic\", \"score\": 0.7}\n\n    hue_hist = np.histogram(hues, bins=12, range=(0, 360))[0]\n    active_bins = np.sum(hue_hist > len(hues) * 0.05)\n\n    if active_bins == 1:\n        return {\"harmony_type\": \"monochromatic\", \"score\": 0.85}\n    elif active_bins == 2:\n        is_comp = are_complementary(hue_hist)\n        return {\"harmony_type\": \"complementary\" if is_comp else \"analogous\",\n                \"score\": 0.9 if is_comp else 0.8}\n    elif active_bins == 3:\n        return {\"harmony_type\": \"triadic\", \"score\": 0.85}\n    else:\n        return {\"harmony_type\": \"complex\", \"score\": 0.6}\n```\n\n## Harmony Score Guide\n\n| Harmony Type | Score | Notes |\n|--------------|-------|-------|\n| Complementary | 0.9 | High visual interest |\n| Monochromatic | 0.85 | Safe, cohesive |\n| Triadic | 0.85 | Balanced, vibrant |\n| Analogous | 0.8 | Natural, harmonious |\n| Achromatic | 0.7 | B&W or desaturated |\n| Complex | 0.6 | May be chaotic or intentional |\n\n## Essential Reading\n\n- Albers, J. (1963). *Interaction of Color*\n- Itten, J. (1961). *The Art of Color*\n"
        },
        {
          "name": "composition-theory.md",
          "type": "file",
          "path": "photo-composition-critic/references/composition-theory.md",
          "size": 2231,
          "content": "# Composition Theory\n\nGraduate-level visual aesthetics foundations.\n\n## Visual Weight & Balance (Arnheim, 1974)\n\n```\nVISUAL WEIGHT FACTORS\n├── Size: Larger = heavier\n├── Color: Warm/saturated = heavier than cool/desaturated\n├── Isolation: Isolated elements carry more weight\n├── Intrinsic Interest: Faces, text, unusual shapes\n├── Position: Upper-right carries more weight (Western reading)\n└── Depth: Objects appearing closer = heavier\n\nBALANCE TYPES\n├── Symmetrical: Formal, stable, static\n├── Asymmetrical: Dynamic, interesting, requires skill\n├── Radial: Energy emanating from center\n└── Crystallographic: All-over pattern (Pollock)\n```\n\n## Gestalt Principles in Photography\n\n```\nPROXIMITY: Elements near each other = grouped\nSIMILARITY: Similar elements = related\nCONTINUITY: Eye follows lines/curves\nCLOSURE: Brain completes incomplete shapes\nFIGURE-GROUND: Subject/background separation\nPRÄGNANZ: Simplest interpretation preferred\n```\n\n## Dynamic Symmetry (Hambidge)\n\nBeyond golden ratio - the full system:\n\n```\nROOT RECTANGLES\n├── √2 (1:1.414) - A-series paper, dynamic diagonal\n├── √3 (1:1.732) - Hexagonal harmony\n├── √4 (1:2) - Double square, panoramic\n├── √5 (1:2.236) - Contains golden ratio\n└── φ (1:1.618) - Golden rectangle\n\nCONSTRUCTION\n├── Diagonal from corner to corner\n├── Reciprocal from corner to opposite diagonal\n├── Intersection points = \"eyes\" of the rectangle\n└── Baroque/Sinister diagonals (left-rising vs right-rising)\n```\n\n## The Arabesque (Harold Speed)\n\nThe continuous line that leads the eye through the composition.\n\n```\nTYPES\n├── S-curve (Hogarth's \"Line of Beauty\")\n├── Spiral (nautilus, cochlea)\n├── Diagonal thrust\n├── Circular containment\n└── Zigzag energy\n\nQUALITY METRICS\n├── Does it enter the frame naturally?\n├── Does it touch key subjects?\n├── Does it avoid exits (corners, edges)?\n└── Does it create rhythm through variation?\n```\n\n## Essential Reading\n\n- Arnheim, R. (1974). *Art and Visual Perception*\n- Hambidge, J. (1926). *The Elements of Dynamic Symmetry*\n- Freeman, M. (2007). *The Photographer's Eye*\n"
        },
        {
          "name": "ml-models.md",
          "type": "file",
          "path": "photo-composition-critic/references/ml-models.md",
          "size": 2683,
          "content": "# Computational Aesthetics Models\n\nML models and datasets for image quality assessment.\n\n## AVA Dataset (Aesthetic Visual Analysis)\n\n```\n250,000+ images from dpchallenge.com\n├── Mean scores from 78-549 votes each\n├── Semantic tags (landscape, portrait, etc.)\n├── Style tags (HDR, vintage, etc.)\n└── Ground truth for training aesthetics models\n\nSCORE DISTRIBUTION INSIGHT\n├── Most images: 5.0-5.5 (mediocre)\n├── Great images: 6.5+ (top ~5%)\n├── Exceptional: 7.0+ (top ~1%)\n└── Bimodal: Some images polarize voters\n```\n\n## NIMA (Neural Image Assessment)\n\nGoogle's 2017 model predicting AVA scores. Key innovation: predicts **distribution**, not just mean score.\n\n```python\n# Architecture: MobileNet/VGG16/Inception + custom head\n# Output: 10-class probability distribution (scores 1-10)\n# Loss: Earth Mover's Distance (EMD)\n\ndef get_nima_score(image_path):\n    img = preprocess(load_image(image_path))\n    distribution = model.predict(img)\n    mean_score = sum(i * distribution[i] for i in range(10))\n    return mean_score, distribution\n\n# INTERPRETATION\n# Mean: Overall quality prediction\n# Std Dev: How polarizing/consistent\n# Distribution shape: Technical vs aesthetic issues\n```\n\n## LAION-Aesthetics\n\nLAION-5B filtered by aesthetic predictor. **Used to train Stable Diffusion.**\n\n```\nSUBSETS\n├── aesthetics_6plus: ~600M images, score ≥6\n├── aesthetics_5plus: ~1.2B images, score ≥5\n\nTHE AESTHETIC PREDICTOR\n├── CLIP ViT-L/14 embeddings\n├── Simple MLP regression head\n├── Trained on SAC (Simulacra Aesthetic Captions)\n└── Fast inference, reasonable accuracy\n```\n\n```python\ndef laion_aesthetic_score(image):\n    clip_embedding = clip_model.encode_image(image)\n    score = aesthetic_mlp(clip_embedding)\n    return score  # 1-10 scale\n```\n\n## VisualQuality-R1 (2024)\n\nRecent reasoning-augmented quality assessment.\n\n```\nKEY INNOVATION\n├── Chain-of-thought reasoning about quality\n├── Explains WHY an image scores high/low\n├── Trained on quality rationales, not just scores\n└── Better generalization than pure regression\n\nEVALUATION DIMENSIONS\n├── Technical: Sharpness, noise, exposure, color\n├── Aesthetic: Composition, lighting, subject\n├── Semantic: Meaning, story, emotional impact\n└── Contextual: Genre-appropriate quality\n```\n\n## Key Papers\n\n- Murray, N. et al. (2012). \"AVA: A Large-Scale Database for Aesthetic Visual Analysis\"\n- Talebi, H. & Milanfar, P. (2018). \"NIMA: Neural Image Assessment\"\n- Schuhmann, C. et al. (2022). \"LAION-5B: An open large-scale dataset\"\n- Wu, Q. et al. (2024). \"Q-Instruct: Improving Low-level Visual Abilities\"\n"
        }
      ]
    },
    {
      "name": "CHANGELOG.md",
      "type": "file",
      "path": "photo-composition-critic/CHANGELOG.md",
      "size": 2131,
      "content": "# Changelog\n\nAll notable changes to the photo-composition-critic skill will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [2.0.0] - 2025-11-29\n\n### Changed\n- **SKILL.md restructured** for progressive disclosure (499 → ~132 lines)\n- Detailed content moved to reference files\n\n### Added\n- `references/composition-theory.md` - Rule of Thirds, Dynamic Symmetry, Arnheim, Gestalt\n- `references/color-theory.md` - LAB/CIECAM02, harmony, psychological effects\n- `references/ml-models.md` - AVA, NIMA, LAION-Aesthetics, VisualQuality-R1\n- `references/analysis-scripts.md` - Python implementations for edge detection, color extraction\n- Shibboleths table for expert vs novice detection\n- Anti-patterns section with visual diagnosis\n\n### Migration\n- No changes to frontmatter or activation triggers\n- Reference files provide deeper context when needed\n- Main SKILL.md now serves as index with quick reference\n\n## [1.1.0] - 2025-11-26\n\n### Changed\n- Updated frontmatter to standard `allowed-tools` format\n- Added activation keywords to description\n- Removed custom YAML fields (version, category, tags, author)\n\n### Added\n- **When to Use This Skill** section with clear scope boundaries\n- **Do NOT use for** section with skill alternatives\n- **MCP Integrations** section (Firecrawl, Hugging Face)\n\n## [1.0.0] - 2024-XX-XX\n\n### Added\n- Initial photo-composition-critic skill\n- Graduate-level composition theory:\n  - Visual weight & balance (Arnheim)\n  - Gestalt principles in photography\n  - Dynamic symmetry (Hambidge)\n  - The arabesque (Harold Speed)\n- Color theory foundations:\n  - Josef Albers - Interaction of Color\n  - Johannes Itten - 7 Color Contrasts\n  - Bezold Effect\n- Computational aesthetics models:\n  - AVA Dataset analysis\n  - NIMA (Neural Image Assessment)\n  - LAION-Aesthetics\n  - VisualQuality-R1\n- Custom analysis scripts:\n  - Multi-model ensemble scorer (PhotoCritic class)\n  - MCP server for photo critique\n- Full critique framework protocol\n- Academic references\n"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "photo-composition-critic/SKILL.md",
      "size": 5070,
      "content": "---\nname: photo-composition-critic\ndescription: Expert photography composition critic grounded in graduate-level visual aesthetics education, computational aesthetics research (AVA, NIMA, LAION-Aesthetics, VisualQuality-R1), and professional image analysis with custom tooling. Use for image quality assessment, composition analysis, aesthetic scoring, photo critique. Activate on \"photo critique\", \"composition analysis\", \"image aesthetics\", \"NIMA\", \"AVA dataset\", \"visual quality\". NOT for photo editing/retouching (use native-app-designer), generating images (use Stability AI directly), or basic image processing (use clip-aware-embeddings).\nallowed-tools: Read,Write,Edit,Bash,mcp__firecrawl__firecrawl_search\n---\n\n# Photo Composition Critic\n\nExpert photography critic with deep grounding in graduate-level visual aesthetics, computational aesthetics research, and professional image analysis.\n\n## When to Use This Skill\n\n**Use for:**\n- Evaluating image composition quality\n- Aesthetic scoring with ML models (NIMA, LAION)\n- Photo critique with actionable feedback\n- Analyzing color harmony and visual balance\n- Comparing multiple crop options\n- Understanding photography theory\n\n**Do NOT use for:**\n- Generating images → use **Stability AI** directly\n- Photo editing/retouching → use **native-app-designer**\n- Simple image similarity → use **clip-aware-embeddings**\n- Collage creation → use **collage-layout-expert**\n\n## MCP Integrations\n\n| MCP | Purpose |\n|-----|---------|\n| **Firecrawl** | Research latest computational aesthetics papers |\n| **Hugging Face** (if configured) | Access NIMA, LAION aesthetic models |\n\n## Quick Reference\n\n### Compositional Frameworks\n\n| Framework | Key Points |\n|-----------|------------|\n| **Visual Weight** | Size, color warmth, isolation, intrinsic interest, position |\n| **Gestalt** | Proximity, similarity, continuity, closure, figure-ground |\n| **Dynamic Symmetry** | Root rectangles (√2, √3, φ), baroque/sinister diagonals |\n| **Arabesque** | S-curve, spiral, diagonal thrust - eye flow through frame |\n\n### Color Harmony Types\n\n| Type | Score | Notes |\n|------|-------|-------|\n| Complementary | 0.9 | High visual interest |\n| Monochromatic | 0.85 | Safe, cohesive |\n| Triadic | 0.85 | Balanced, vibrant |\n| Analogous | 0.8 | Natural, harmonious |\n| Achromatic | 0.7 | B&W or desaturated |\n| Complex | 0.6 | May be chaotic or intentional |\n\n### ML Model Score Interpretation\n\n| Score Range | Meaning |\n|-------------|---------|\n| 7.0+ | Exceptional (top ~1%) |\n| 6.5+ | Great (top ~5%) |\n| 5.0-5.5 | Mediocre (most images) |\n| &lt;5.0 | Below average |\n\n## Analysis Protocol\n\n```\n1. FIRST IMPRESSION (2 seconds)\n   └── Where does the eye go? Emotional hit? Anything \"off\"?\n\n2. TECHNICAL SCAN\n   └── Exposure, focus, noise, color, artifacts\n\n3. COMPOSITIONAL ANALYSIS\n   └── Subject clarity, structure, balance, flow, depth, edges\n\n4. AESTHETIC EVALUATION\n   └── Light quality, color harmony, decisive moment, story\n\n5. CONTEXTUAL ASSESSMENT\n   └── Genre success, photographer intent, audience fit\n\n6. ACTIONABLE RECOMMENDATIONS\n   └── Specific improvements, post-processing, alt crops\n```\n\n## Anti-Patterns\n\n### \"Just use rule of thirds\"\n\n| What it looks like | Why it's wrong |\n|--------------------|----------------|\n| Blindly placing subjects on thirds intersections | Oversimplification ignores visual weight, gestalt, dynamic symmetry |\n| **Instead**: Analyze visual weight center, consider multiple frameworks |\n\n### \"Higher NIMA score = better photo\"\n\n| What it looks like | Why it's wrong |\n|--------------------|----------------|\n| Using ML score as sole quality metric | Models trained on averages, miss artistic intent, polarizing works |\n| **Instead**: Use ML as one input alongside theoretical analysis |\n\n### \"Color harmony means matching colors\"\n\n| What it looks like | Why it's wrong |\n|--------------------|----------------|\n| Recommending monochromatic or matchy palettes | Ignores Itten's contrasts, Albers' interaction effects |\n| **Instead**: Evaluate harmony type AND contextual appropriateness |\n\n### Ignoring genre context\n\n| What it looks like | Why it's wrong |\n|--------------------|----------------|\n| Applying portrait criteria to documentary | Different genres have different quality signals |\n| **Instead**: Assess against genre-appropriate standards |\n\n## Reference Files\n\nLoad these for detailed implementations:\n\n| File | Contents |\n|------|----------|\n| `references/composition-theory.md` | Arnheim visual weight, Gestalt, Dynamic Symmetry, Arabesque |\n| `references/color-theory.md` | Albers interaction, Itten's 7 contrasts, harmony detection algo |\n| `references/ml-models.md` | AVA dataset, NIMA, LAION-Aesthetics, VisualQuality-R1 |\n| `references/analysis-scripts.md` | PhotoCritic class, MCP server implementation |\n\n## Key Sources\n\n**Theory**: Arnheim (1974), Hambidge (1926), Itten (1961), Albers (1963), Freeman (2007)\n\n**Research**: AVA dataset (Murray 2012), NIMA (Talebi 2018), LAION-5B (Schuhmann 2022), Q-Instruct (Wu 2024)\n"
    }
  ]
}