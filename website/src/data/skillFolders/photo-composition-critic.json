{
  "name": "photo-composition-critic",
  "type": "folder",
  "path": "photo-composition-critic",
  "children": [
    {
      "name": "CHANGELOG.md",
      "type": "file",
      "path": "photo-composition-critic/CHANGELOG.md",
      "size": 1348,
      "content": "# Changelog\n\nAll notable changes to the photo-composition-critic skill will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [1.1.0] - 2025-11-26\n\n### Changed\n- Updated frontmatter to standard `allowed-tools` format\n- Added activation keywords to description\n- Removed custom YAML fields (version, category, tags, author)\n\n### Added\n- **When to Use This Skill** section with clear scope boundaries\n- **Do NOT use for** section with skill alternatives\n- **MCP Integrations** section (Firecrawl, Hugging Face)\n\n## [1.0.0] - 2024-XX-XX\n\n### Added\n- Initial photo-composition-critic skill\n- Graduate-level composition theory:\n  - Visual weight & balance (Arnheim)\n  - Gestalt principles in photography\n  - Dynamic symmetry (Hambidge)\n  - The arabesque (Harold Speed)\n- Color theory foundations:\n  - Josef Albers - Interaction of Color\n  - Johannes Itten - 7 Color Contrasts\n  - Bezold Effect\n- Computational aesthetics models:\n  - AVA Dataset analysis\n  - NIMA (Neural Image Assessment)\n  - LAION-Aesthetics\n  - VisualQuality-R1\n- Custom analysis scripts:\n  - Multi-model ensemble scorer (PhotoCritic class)\n  - MCP server for photo critique\n- Full critique framework protocol\n- Academic references\n"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "photo-composition-critic/SKILL.md",
      "size": 16764,
      "content": "---\nname: photo-composition-critic\ndescription: Expert photography composition critic grounded in graduate-level visual aesthetics education, computational aesthetics research (AVA, NIMA, LAION-Aesthetics, VisualQuality-R1), and professional image analysis with custom tooling. Use for image quality assessment, composition analysis, aesthetic scoring, photo critique. Activate on \"photo critique\", \"composition analysis\", \"image aesthetics\", \"NIMA\", \"AVA dataset\", \"visual quality\". NOT for photo editing/retouching (use native-app-designer), generating images (use Stability AI directly), or basic image processing (use clip-aware-embeddings).\nallowed-tools: Read,Write,Edit,Bash,mcp__firecrawl__firecrawl_search\n---\n\n# Photo Composition Critic\n\nExpert photography critic with deep grounding in graduate-level visual aesthetics, computational aesthetics research, and professional image analysis.\n\n## When to Use This Skill\n\n✅ **Use for:**\n- Evaluating image composition quality\n- Aesthetic scoring with ML models (NIMA, LAION)\n- Photo critique with actionable feedback\n- Analyzing color harmony and visual balance\n- Comparing multiple crop options\n- Understanding photography theory\n\n❌ **Do NOT use for:**\n- Generating images → use **Stability AI** directly\n- Photo editing/retouching → use **native-app-designer**\n- Simple image similarity → use **clip-aware-embeddings**\n- Collage creation → use **collage-layout-expert**\n\n## MCP Integrations\n\n| MCP | Purpose |\n|-----|---------|\n| **Firecrawl** | Research latest computational aesthetics papers |\n| **Hugging Face** (if configured) | Access NIMA, LAION aesthetic models |\n\n## Theoretical Foundations\n\n### Graduate-Level Composition Theory\n\nBeyond \"rule of thirds\" - the actual principles:\n\n#### Visual Weight & Balance\n```\nVISUAL WEIGHT FACTORS (Arnheim, 1974)\n├── Size: Larger = heavier\n├── Color: Warm/saturated = heavier than cool/desaturated\n├── Isolation: Isolated elements carry more weight\n├── Intrinsic Interest: Faces, text, unusual shapes\n├── Position: Upper-right carries more weight (Western reading)\n└── Depth: Objects appearing closer = heavier\n\nBALANCE TYPES\n├── Symmetrical: Formal, stable, static\n├── Asymmetrical: Dynamic, interesting, requires skill\n├── Radial: Energy emanating from center\n└── Crystallographic: All-over pattern (Pollock)\n```\n\n#### Gestalt Principles in Photography\n```\nPROXIMITY: Elements near each other = grouped\nSIMILARITY: Similar elements = related\nCONTINUITY: Eye follows lines/curves\nCLOSURE: Brain completes incomplete shapes\nFIGURE-GROUND: Subject/background separation\nPRÄGNANZ: Simplest interpretation preferred\n```\n\n#### Dynamic Symmetry (Hambidge)\n```\nNot just golden ratio - the full system:\n\nROOT RECTANGLES\n├── √2 (1:1.414) - A-series paper, dynamic diagonal\n├── √3 (1:1.732) - Hexagonal harmony\n├── √4 (1:2) - Double square, panoramic\n├── √5 (1:2.236) - Contains golden ratio\n└── φ (1:1.618) - Golden rectangle\n\nCONSTRUCTION\n├── Diagonal from corner to corner\n├── Reciprocal from corner to opposite diagonal\n├── Intersection points = \"eyes\" of the rectangle\n└── Baroque/Sinister diagonals (left-rising vs right-rising)\n```\n\n#### The Arabesque (Harold Speed)\n```\nThe continuous line that leads the eye through the composition.\nNOT just leading lines - the entire visual flow:\n\nTYPES\n├── S-curve (Hogarth's \"Line of Beauty\")\n├── Spiral (nautilus, cochlea)\n├── Diagonal thrust\n├── Circular containment\n└── Zigzag energy\n\nQUALITY METRICS\n├── Does it enter the frame naturally?\n├── Does it touch key subjects?\n├── Does it avoid exits (corners, edges)?\n└── Does it create rhythm through variation?\n```\n\n### Color Theory Beyond Basics\n\n```\nJOSEF ALBERS - INTERACTION OF COLOR\n├── Colors change based on neighbors\n├── One color can appear as two different colors\n├── Two colors can appear identical\n└── Quantity affects perception (small vs large areas)\n\nJOHANNES ITTEN - 7 COLOR CONTRASTS\n├── Hue: Different colors\n├── Value: Light vs dark\n├── Saturation: Pure vs muted\n├── Temperature: Warm vs cool\n├── Complementary: Opposites\n├── Simultaneous: Induced complementary\n└── Extension: Ratio of color areas\n\nBEZOLD EFFECT\n└── A color appears different depending on surrounding colors\n    (Critical for evaluating edits)\n```\n\n## Computational Aesthetics\n\n### Key Models & Datasets\n\n#### AVA Dataset (Aesthetic Visual Analysis)\n```\n250,000+ images from dpchallenge.com\n├── Mean scores from 78-549 votes each\n├── Semantic tags (landscape, portrait, etc.)\n├── Style tags (HDR, vintage, etc.)\n└── Ground truth for training aesthetics models\n\nSCORE DISTRIBUTION INSIGHT\n├── Most images: 5.0-5.5 (mediocre)\n├── Great images: 6.5+ (top ~5%)\n├── Exceptional: 7.0+ (top ~1%)\n└── Bimodal: Some images polarize voters\n```\n\n#### NIMA (Neural Image Assessment)\n```python\n# Google's 2017 model predicting AVA scores\n# Predicts DISTRIBUTION not just mean score\n\nArchitecture: MobileNet/VGG16/Inception + custom head\nOutput: 10-class probability distribution (scores 1-10)\nLoss: Earth Mover's Distance (EMD)\n\nINTERPRETATION\n├── Mean: Overall quality prediction\n├── Std Dev: How polarizing/consistent\n└── Distribution shape: Technical vs aesthetic issues\n\n# Example inference\ndef get_nima_score(image_path):\n    img = preprocess(load_image(image_path))\n    distribution = model.predict(img)\n    mean_score = sum(i * distribution[i] for i in range(10))\n    return mean_score, distribution\n```\n\n#### LAION-Aesthetics\n```\nLAION-5B filtered by aesthetic predictor\n\nSUBSETS\n├── aesthetics_6plus: ~600M images, score ≥6\n├── aesthetics_5plus: ~1.2B images, score ≥5\n└── Used to train Stable Diffusion!\n\nTHE AESTHETIC PREDICTOR\n├── CLIP ViT-L/14 embeddings\n├── Simple MLP regression head\n├── Trained on SAC (Simulacra Aesthetic Captions)\n└── Fast inference, reasonable accuracy\n\n# Get LAION aesthetic score\ndef laion_aesthetic_score(image):\n    clip_embedding = clip_model.encode_image(image)\n    score = aesthetic_mlp(clip_embedding)\n    return score  # 1-10 scale\n```\n\n#### VisualQuality-R1\n```\nRecent (2024) reasoning-augmented quality assessment\n\nKEY INNOVATION\n├── Chain-of-thought reasoning about quality\n├── Explains WHY an image scores high/low\n├── Trained on quality rationales, not just scores\n└── Better generalization than pure regression\n\nEVALUATION DIMENSIONS\n├── Technical: Sharpness, noise, exposure, color\n├── Aesthetic: Composition, lighting, subject\n├── Semantic: Meaning, story, emotional impact\n└── Contextual: Genre-appropriate quality\n```\n\n### Custom Analysis Scripts\n\n#### Multi-Model Ensemble Scorer\n```python\n#!/usr/bin/env python3\n\"\"\"\nphoto_critic.py - Multi-model image aesthetic analysis\nRequires: torch, transformers, clip, pillow\n\"\"\"\n\nimport torch\nimport clip\nfrom PIL import Image\nfrom pathlib import Path\n\nclass PhotoCritic:\n    def __init__(self):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self._load_models()\n\n    def _load_models(self):\n        # CLIP for embeddings\n        self.clip_model, self.clip_preprocess = clip.load(\"ViT-L/14\", self.device)\n\n        # LAION aesthetic predictor (simple MLP)\n        self.aesthetic_model = self._load_aesthetic_mlp()\n\n        # NIMA model\n        self.nima_model = self._load_nima()\n\n    def analyze(self, image_path: str) -> dict:\n        \"\"\"Full aesthetic analysis of an image.\"\"\"\n        img = Image.open(image_path).convert(\"RGB\")\n\n        results = {\n            \"laion_aesthetic\": self._laion_score(img),\n            \"nima_technical\": self._nima_score(img, \"technical\"),\n            \"nima_aesthetic\": self._nima_score(img, \"aesthetic\"),\n            \"composition\": self._analyze_composition(img),\n            \"color_harmony\": self._analyze_color(img),\n            \"technical_quality\": self._analyze_technical(img),\n        }\n\n        results[\"overall\"] = self._compute_overall(results)\n        results[\"critique\"] = self._generate_critique(results)\n\n        return results\n\n    def _analyze_composition(self, img) -> dict:\n        \"\"\"Rule of thirds, golden ratio, visual weight analysis.\"\"\"\n        import numpy as np\n        from scipy import ndimage\n\n        arr = np.array(img.convert(\"L\"))\n\n        # Find visual weight center (centroid of intensity)\n        y_coords, x_coords = np.mgrid[0:arr.shape[0], 0:arr.shape[1]]\n        total = arr.sum()\n        center_y = (y_coords * arr).sum() / total\n        center_x = (x_coords * arr).sum() / total\n\n        # Normalize to 0-1\n        norm_y = center_y / arr.shape[0]\n        norm_x = center_x / arr.shape[1]\n\n        # Distance from rule of thirds intersections\n        thirds_points = [(1/3, 1/3), (2/3, 1/3), (1/3, 2/3), (2/3, 2/3)]\n        min_thirds_dist = min(\n            ((norm_x - px)**2 + (norm_y - py)**2)**0.5\n            for px, py in thirds_points\n        )\n\n        # Golden ratio analysis\n        phi = 0.618\n        golden_points = [(phi, phi), (1-phi, phi), (phi, 1-phi), (1-phi, 1-phi)]\n        min_golden_dist = min(\n            ((norm_x - px)**2 + (norm_y - py)**2)**0.5\n            for px, py in golden_points\n        )\n\n        return {\n            \"visual_center\": (norm_x, norm_y),\n            \"thirds_alignment\": max(0, 1 - min_thirds_dist * 3),\n            \"golden_alignment\": max(0, 1 - min_golden_dist * 3),\n            \"balance\": 1 - abs(norm_x - 0.5) - abs(norm_y - 0.5)\n        }\n\n    def _analyze_color(self, img) -> dict:\n        \"\"\"Color harmony and palette analysis.\"\"\"\n        import numpy as np\n        from collections import Counter\n\n        # Quantize to find dominant colors\n        small = img.resize((100, 100))\n        pixels = list(small.getdata())\n\n        # Convert to HSV for harmony analysis\n        hsv_pixels = [self._rgb_to_hsv(p) for p in pixels]\n        hues = [p[0] for p in hsv_pixels if p[1] > 0.2]  # Ignore desaturated\n\n        if not hues:\n            return {\"harmony_type\": \"achromatic\", \"score\": 0.7}\n\n        # Analyze hue distribution\n        hue_hist = np.histogram(hues, bins=12, range=(0, 360))[0]\n        active_bins = np.sum(hue_hist > len(hues) * 0.05)\n\n        if active_bins == 1:\n            harmony = \"monochromatic\"\n            score = 0.85\n        elif active_bins == 2:\n            harmony = \"complementary\" if self._are_complementary(hue_hist) else \"analogous\"\n            score = 0.9 if harmony == \"complementary\" else 0.8\n        elif active_bins == 3:\n            harmony = \"triadic\"\n            score = 0.85\n        else:\n            harmony = \"complex\"\n            score = 0.6\n\n        return {\"harmony_type\": harmony, \"score\": score, \"active_hues\": active_bins}\n\n    def _generate_critique(self, results: dict) -> str:\n        \"\"\"Generate human-readable critique from analysis.\"\"\"\n        critique_parts = []\n\n        # Overall impression\n        overall = results[\"overall\"]\n        if overall >= 8:\n            critique_parts.append(\"Exceptional image with professional-level execution.\")\n        elif overall >= 6.5:\n            critique_parts.append(\"Strong image with good technical and aesthetic qualities.\")\n        elif overall >= 5:\n            critique_parts.append(\"Competent image with room for improvement.\")\n        else:\n            critique_parts.append(\"Image needs significant work on fundamentals.\")\n\n        # Composition feedback\n        comp = results[\"composition\"]\n        if comp[\"thirds_alignment\"] > 0.7:\n            critique_parts.append(\"Strong rule-of-thirds placement.\")\n        elif comp[\"golden_alignment\"] > 0.7:\n            critique_parts.append(\"Nice golden ratio composition.\")\n        elif comp[\"balance\"] < 0.3:\n            critique_parts.append(\"Consider rebalancing - visual weight is off-center.\")\n\n        # Color feedback\n        color = results[\"color_harmony\"]\n        critique_parts.append(f\"Color scheme: {color['harmony_type']} \"\n                            f\"(harmony score: {color['score']:.2f})\")\n\n        return \" \".join(critique_parts)\n```\n\n#### MCP Server for Photo Critique\n```python\n#!/usr/bin/env python3\n\"\"\"\nphoto_critic_mcp.py - MCP server for photo composition analysis\n\"\"\"\n\nfrom mcp.server import Server\nfrom mcp.types import Tool, TextContent\nimport asyncio\n\napp = Server(\"photo-critic\")\n\n@app.tool()\nasync def analyze_composition(image_path: str) -> str:\n    \"\"\"Analyze image composition using ML models and classical theory.\"\"\"\n    from photo_critic import PhotoCritic\n\n    critic = PhotoCritic()\n    results = critic.analyze(image_path)\n\n    return f\"\"\"\n## Aesthetic Analysis Results\n\n**Overall Score: {results['overall']:.1f}/10**\n\n### Model Scores\n- LAION Aesthetic: {results['laion_aesthetic']:.2f}\n- NIMA Technical: {results['nima_technical']:.2f}\n- NIMA Aesthetic: {results['nima_aesthetic']:.2f}\n\n### Composition Analysis\n- Rule of Thirds Alignment: {results['composition']['thirds_alignment']:.0%}\n- Golden Ratio Alignment: {results['composition']['golden_alignment']:.0%}\n- Visual Balance: {results['composition']['balance']:.0%}\n\n### Color Analysis\n- Harmony Type: {results['color_harmony']['harmony_type']}\n- Harmony Score: {results['color_harmony']['score']:.2f}\n\n### Critique\n{results['critique']}\n\"\"\"\n\n@app.tool()\nasync def compare_crops(image_path: str, crops: list[dict]) -> str:\n    \"\"\"Compare multiple crop options for an image.\n\n    crops: List of {x, y, width, height} dicts defining crop regions\n    \"\"\"\n    from photo_critic import PhotoCritic\n    from PIL import Image\n\n    critic = PhotoCritic()\n    img = Image.open(image_path)\n\n    results = []\n    for i, crop in enumerate(crops):\n        cropped = img.crop((\n            crop['x'], crop['y'],\n            crop['x'] + crop['width'],\n            crop['y'] + crop['height']\n        ))\n        # Save temp and analyze\n        temp_path = f\"/tmp/crop_{i}.jpg\"\n        cropped.save(temp_path)\n        score = critic.analyze(temp_path)['overall']\n        results.append((i, score, crop))\n\n    results.sort(key=lambda x: x[1], reverse=True)\n\n    output = \"## Crop Comparison\\n\\n\"\n    for rank, (idx, score, crop) in enumerate(results, 1):\n        output += f\"{rank}. Crop {idx}: **{score:.1f}/10** \"\n        output += f\"({crop['width']}x{crop['height']} at {crop['x']},{crop['y']})\\n\"\n\n    return output\n\nif __name__ == \"__main__\":\n    asyncio.run(app.run())\n```\n\n## Critique Framework\n\n### The Full Analysis Protocol\n\n```\n1. FIRST IMPRESSION (2 seconds)\n   └── What does your eye do? Where does it go first, second, third?\n   └── What's the emotional hit?\n   └── Does anything feel \"off\"?\n\n2. TECHNICAL SCAN\n   ├── Exposure: Histogram, highlight/shadow clipping\n   ├── Focus: Sharpness at intended focal point\n   ├── Noise: ISO artifacts, luminance vs chroma noise\n   ├── Color: White balance, color cast, saturation\n   └── Artifacts: Chromatic aberration, distortion, banding\n\n3. COMPOSITIONAL ANALYSIS\n   ├── Subject: Clear? Dominant? Well-placed?\n   ├── Structure: What geometric framework is used?\n   ├── Balance: Visual weight distribution\n   ├── Flow: How does the eye move through the frame?\n   ├── Depth: Foreground/middle/background relationships\n   └── Edges: What's happening at frame boundaries?\n\n4. AESTHETIC EVALUATION\n   ├── Light: Quality, direction, contrast, mood\n   ├── Color: Harmony, emotion, intention\n   ├── Moment: Decisive? Peak action? Emotional truth?\n   └── Story: What narrative is being told?\n\n5. CONTEXTUAL ASSESSMENT\n   ├── Genre: Does it succeed at what it's trying to be?\n   ├── Intent: What was the photographer's goal?\n   └── Audience: Who is this for? Does it work for them?\n\n6. ACTIONABLE RECOMMENDATIONS\n   ├── What specifically would improve this image?\n   ├── Post-processing suggestions with parameters\n   ├── Alternative crop/composition ideas\n   └── What to do differently next time\n```\n\n## References\n\n### Essential Reading\n- Arnheim, R. (1974). *Art and Visual Perception*\n- Hambidge, J. (1926). *The Elements of Dynamic Symmetry*\n- Itten, J. (1961). *The Art of Color*\n- Albers, J. (1963). *Interaction of Color*\n- Freeman, M. (2007). *The Photographer's Eye*\n\n### Key Papers\n- Murray, N. et al. (2012). \"AVA: A Large-Scale Database for Aesthetic Visual Analysis\"\n- Talebi, H. & Milanfar, P. (2018). \"NIMA: Neural Image Assessment\"\n- Schuhmann, C. et al. (2022). \"LAION-5B: An open large-scale dataset\"\n- Wu, Q. et al. (2024). \"Q-Instruct: Improving Low-level Visual Abilities\"\n"
    }
  ]
}